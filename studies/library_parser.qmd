---
title: "Library Parser"
---

**Status:** in progress.

**TODO**: - Separate scripts and functions into separate .qmd files/directories. - Update `model_rate_emotion_values` nomenclature process for classification papers.

# Pre-processing

## Preparing data

The follow code extracts information from the .bib library to format it as a `data.frame` for further processing. The code makes use of the stringr package and uses regular expressions to extract relevant parameters. First we read in the .bib file and use some string manipulations to retrieve the citation keys.

```{r results = 'hide'}
require(stringr)
```

```{r}
bib_file <- read.delim('bib/extractions.bib',
           sep = '@', header = F)

# get citekeys from bibtex file:
citekeys <- unique(bib_file$V2)
# improve formatting
citekeys <- str_remove(citekeys, '\\{')
citekeys <- str_remove(citekeys, ',')
citekeys <- str_remove(citekeys, '%%.*$')
citekeys <- str_remove(citekeys, 'Article')
citekeys[citekeys ==''] <- NA
citekeys <- na.omit(citekeys)

```

*R* reads the .bib file as a two column data.frame, with the citation key appearing in the second column and the remaining metadata appearing in the first column. When the citation key appears in the second column, the corresponding row in the first column is blank. Because of this quirk, we can index metadata matching each citation key by keeping track of blank rows in the first column. We'll append each to a new entry of a list. The name of each list entry is the citation key; the corresponding value is the remaining unprocessed metadata.

```{r}
# find where new entries begin:
new_entries = which(bib_file$V2 != '')

# loop across unique indices for each entry
meta_list = list()
# loop across unique indices for each entry
meta_list = list()
for(this_entry in 1:(length(new_entries)-1))
{
  # get unique citekey
  this_cite_key <- citekeys[this_entry]
  # capture lines following citekey
  corresponding_lines <- bib_file[new_entries[this_entry]:new_entries[this_entry+1]-1,]$V1
  # store matching lines as data frame
  corresponding_lines <- data.frame(corresponding_lines)
  # assign lines distinct name
  names(corresponding_lines) <- this_cite_key
  # add to a list for further processing
  meta_list <- append(meta_list, corresponding_lines)
}


```

## Extracting Relevant .bib Fields

Not every bibtex field is equally useful for analysis. To facilitate data manipulation, we can save the names of the target fields separately in a .txt file, and use a regular expression to create a new column each time *R* finds one of the target fields in a string containing the bibtex metadata.

```{r}
# read in target bibtex fields
search_fields <- field_names <- readLines('bibtex_fields.txt')

# match casing in bibtex file
field_names <- toupper(field_names)
# add a pattern allowing us to find text between two adjacent bibtex fields
rep_pattern <- paste0(field_names[1:length(field_names)-1], '\\s*(.*?)\\s')
# apply this same pattern to all but the last of the field names                  
field_names[1:length(field_names)-1] <- rep_pattern
# collapse all the new field names into a single string for string manipulation with stringr
field_names[length(field_names)] <- paste0(field_names[length(field_names)], '.*')
field_names <- paste0(field_names, collapse = '')
```

## Prepare dataframe

Now we can convert our list into a data frame with the target bibtex fields. For the last field `MODEL_VALIDATION`, we will apply a different regex pattern which matches all characters following the field name `(?<=MODEL_VALIDATION).*` .

```{r}
# create new column containing information between two adjacent target fields for all entries in list
meta_df <- lapply(meta_list, function(x) str_match(paste0(x, collapse = ' '), field_names))
meta_df <- lapply(meta_list, function(x) str_match(paste0(x, collapse = ' '), field_names))

# collapse list entries into rows
meta_df <- do.call('rbind', meta_df)
# format as a data.frame
meta_df <- data.frame(meta_df)
# match text after final column name
meta_df[,ncol(meta_df)+1] <- sapply(meta_df[,1], function(x) str_match(paste0(x, collapse = ' '), '(?<=MODEL_VALIDATION).*'))
# replace first column with citationkeys
meta_df[,1] <- names(meta_list)
names(meta_df) <- c('citekey', search_fields)
```

## Formatting

Finally, we'll perform some formatting to remove unwanted characters left over following the conversion (in progress)

```{r}
## remove bibtext field formatting
# remove curly braces
meta_df <- apply(meta_df, 2, function(x) str_remove_all(x, '\\{')) 
meta_df <- apply(meta_df, 2, function(x) str_remove_all(x, '\\},'))
# remove first '=' (from bibtex field )
meta_df <- apply(meta_df, 2, function(x) str_remove(x, '='))
# remove double-commas
#meta_df <- apply(meta_df, 2, function(x) str_remove_all(x, ',,'))
# remove comments
meta_df <- apply(meta_df, 2, function(x) str_remove_all(x, '%%.*'))
#meta_df <- apply(meta_df, 2, function(x) str_remove_all(x, ' , '))
# remove extra characters in final column
meta_df[, ncol(meta_df)] = str_remove_all(meta_df[, ncol(meta_df)], '\\}')
meta_df <- as.data.frame(meta_df)

```

```{r}
knitr::kable(meta_df)
```

Evaluate cell as r code example

```{r}
eval(parse(text = meta_df$model_rate_emotion_values[22]))
```

# Dealing with nested bibtex fields.

Some studies include multiple bibtex fields for substudies/evaluations of different feature sets. E.g., `MODEL_RATE_EMOTION_VALUES_A` and `MODEL_RATE_EMOTION_VALUES_B`. We need to apply special operations to separate these values for further analysis.

```{r}
## function to parse output of multiple models nested within a single cell
parse_model_output = function(df)
{ # loop across rows
  # apply function to replace NAs with empty string
  sapply(1:nrow(df), function(x) {
    df$model_rate_emotion_values <- tidyr::replace_na(df$model_rate_emotion_values, '') # detect cells with rbind in them
    if(str_count(df$model_rate_emotion_values[x], "rbind") > 1) {
      # match first model (name between first underscore and rbind)
      model_1_name <- str_match(df$model_rate_emotion_values[x], 
                                "(?<=_).*?(?=rbind)")
      # match subsequent models (name between MODEL_RATE_EMOTION_VALUES_ and rbind)
      model_names <- str_extract_all(df$model_rate_emotion_values[x], 
                                     "(?<=MODEL_RATE_EMOTION_VALUES_).*?(?=rbind)")
      # combine names
      model_names <- unlist(c(model_1_name, model_names))
      # remove special characters
      model_names <- gsub("[^[:alnum:]]", "", model_names)
      # get corresponding values for each model
      model_results <- str_split(df$model_rate_emotion_values[x], 
                "MODEL_RATE_EMOTION_VALUES")
      # get rid of everything up to "rbind"
      model_results <- lapply(model_results, function(x) str_remove(x, 
                                                          '.+?(?=rbind)'))
      # now unlist the models and give them names to add later
      model_results <- unlist(model_results)
       model_results <- paste(model_names, '=', model_results)
      names(model_results) <- model_names
     # return(model_results)
    }
    else { # otherwise, if dealing with non-listed, just return the existing value
      model_results <- df$model_rate_emotion_values[x]
    }
    return(model_results)
  }
    )
  # see whether rbind appears multiple times
  
}

# get results from nested models:
model_outputs <- parse_model_output(meta_df)
# assign unique names
model_names <- lapply(model_outputs, names)

```

## Data Frame Expansion

Next we want to copy the number of rows for each of the bibtex cells requiring special nesting

```{r}
# count the numbers 
n_entries <- unlist(lapply(model_outputs, function(x) length(x)))
# for those returning 0, change value to 1
n_entries[n_entries == 0]<- 1
# replicate rows based on number of models reported
meta_df_unpacked <- meta_df[rep(seq_len(nrow(meta_df)), n_entries), ]
# now overwrite model_rate_emotion_values with the output of parse_model_output
meta_df_unpacked$model_rate_emotion_values <- unlist(model_outputs)

```

## Sanity check

```{r}
ex_substudy_1 <- eval(parse(text = meta_df_unpacked[7, 'model_rate_emotion_values']))
ex_substudy_2 <- eval(parse(text = meta_df_unpacked[8, 'model_rate_emotion_values']))


knitr::kable(rbind(ex_substudy_1, ex_substudy_2),
             caption = sum(ex_substudy_1))
```

## Print output of all studies:

```{r}
sapply(1:nrow(meta_df_unpacked), function(i) {
  print(i) 
  print(eval(parse(text = meta_df_unpacked$model_rate_emotion_values[i])))
}
)
```

```{r}
classification_studies = subset(meta_df_unpacked, paradigm == " classification  ")

sapply(1:nrow(classification_studies), function(i) {
  print(i) 
  print(eval(parse(text = classification_studies$model_rate_emotion_values[i])))
}
)
```

```{r eval = F}
regression_studies = subset(meta_df_unpacked, paradigm == " regression  ")

sapply(1:nrow(regression_studies), function(i) {
  print(i) 
  print(eval(parse(text = regression_studies$model_rate_emotion_values[i])))
}
)
```

```{r}
# low-level function to extract relevant values from named array
model_result_2_df <- function(x) {
  # get algorithm name from variable at beginning of string (before parsing)
  toolbox <- trimws(stringr::str_extract(x, pattern = "[^\\=]+"))
  print(toolbox)
  # now evaluate the expression
  x <- rlang::eval_tidy(rlang::parse_expr(x))
  # get name of fitted models from column names
  model_names <- colnames(x)
  # print(model_names)
  # split across model name for summary statistic (e.g., mean, sd, etc.)
  model_statistic <- str_split(model_names, '\\.')
  model_statistic <- unlist(lapply(model_statistic, function(x) x[2]))
  # get values
  model_values <- as.numeric(x)
  # names(model_values) <- 'score'
  print(model_values)
  # get additional attributes (feature.data.exp)
  model_attributes <- rownames(x)
  data.frame(model_attributes)
  # get additional model details
  model_attributes <- data.frame(do.call('rbind', str_split(model_attributes, '\\.')))
  names(model_attributes) <- c('model_id', 'feature_id', 'data_id', 'experiment_id')
  print(names(model_attributes))
  # split across '_' to 
  model_measures <- data.frame(do.call('rbind', stringr::str_split(colnames(x), '_')))
  print(model_measures)
  names(model_measures) <- c('dimension', 'measure')
  model_measures_split <- stringr::str_split(model_measures[,'measure'], '\\.')
  model_measures[,'measure'] <- unlist(lapply(model_measures_split, 
                                              function(x) x[1]))
  return(data.frame(toolbox, 
             model_attributes, 
             model_measures, 
             values = model_values,
             statistic = model_statistic))
}

# high level function to apply model_result_2_df to multiple studies
get_study_summaries <- function(df) {
  do.call(rbind,
          lapply(df$model_rate_emotion_values, 
                 FUN = function(x) {
                   study_id <- unique(df$citekey[which(df$model_rate_emotion_values == x)])
                   model_results <- model_result_2_df(x)
                   return(cbind(study_id, model_results))
                   }
                 )
          )
}

```

# Parsing Regression Studies

The following functions provide a working example for converting the r code contained in `model_rate_emotion_values` to a data frame for further analysis (currently working for regression studies).

### Template

Encoded values should use the following nomenclature:

```         
library = rbind(model.features.data.exp = c(dim_measure.summary = 0.5, dim_measure.summary = 0.1), model.features.data.exp = c(dim_measure.summary = 0.2, dim_measure.summary = 0.5))

# e.g.

librosa = rbind(randomforest.mfcc.msd.1 = c(valence_r2.mean = 0.5, arousal_r2.mean = 0.1), 
temporal.msd.1 = c(valence_r2.mean = 0.2, arousal_r2.mean = 0.5,
valence_r2.sd = 0.1, arousal_r2.sd = 0.1))
```

### Working example

```{r}
this_study <- data.frame(citekey = c('testStudy2023ab','testStudy2023ab', 'testStudy2020of'),
  model_rate_emotion_values = c("marsyas = rbind('random forest.mfcc.msd.1' = c(valence_r2.mean = 0.9, arousal_r2.mean = 0.5,
                                  valence_r2.sd = 0.4, arousal_r2.sd = 0.3,
  valence_mse.mean = 0.3, arousal_mse.mean = 9.1),
  'random forest.mfcc.deam.1' = c(valence_r2.mean = 0.9, arousal_r2.mean = 0.5))",
  "librosa = rbind('linear regression.mfcc.ismir.1' = c(valence_r2.mean = 0.1, arousal_r2.mean = 0.3,
                                  valence_r2.sd = 0.2, arousal_r2.sd = 0.4,
  euclid_euclid.mean = 0.32, euclid_euclid.sd = 0.1))",
  "mirtoolbox = rbind('neural net.pitch.filmMusic.2' = c(valence_r2.mean = 0.1, arousal_r2.mean = 0.3))")
)
```

### Summary data frame

```{r}
knitr::kable(get_study_summaries(this_study))
```
