# Preprocessing

This assumes that the data has been parsed from the BibTeX files into table and exported as CSV file.

## Read annotated data

```{r}
#| warning: false
require(here)
source(here::here('R/build-df.R'))
source(here::here('R/format-study-results.R'))
source(here::here('R/parse-model-output.R'))
```

```{r}
#| warning: false
# get metaMER df:
meta_df <- get_metaMER_df(path_2_studies = here::here('studies'))

# get included studies
included_studies <- meta_df[which(
  !stringr::str_detect(meta_df$final_notes, '!EXCL!')),] |> 
  dplyr::tibble()

```

### Recoded

```{r}
#| warning: false
# get studies re-coded (currently identifiable by presence of bind_field.)
recoded_studies <- included_studies[which(stringr::str_detect(
  included_studies$model_rate_emotion_values,
                                     'bind_field')),] 

```

### Add unique identifiers

```{r}
#| warning: false

metaMER_results <-
do.call(
  rbind,
    lapply(1:nrow(recoded_studies),
       function(x) get_study_results(recoded_studies[x,])
       )
) 

# add unique identifiers

unique_id <- apply(metaMER_results[,c('citekey',
                        'library_id',
                         'model_id',
                         'feature_id',
                         'data_id',
                         'experiment_id')],
                      1, 
                      paste0, 
                      collapse = '-'
) 
metaMER_results$unique_id <- stringr::str_remove_all(unique_id, 
                                                     ' ')

metaMER_results <- metaMER_results |> dplyr::select(unique_id, 
                                 dplyr::everything()) 

metaMER_results |> dplyr::tibble()

```


### Summarise annotated data (optional)

```{r}
#| eval: false
#| output: asis

print(knitr::kable(table(metaMER_results$citekey,metaMER_results$dimension)))
print(knitr::kable(table(metaMER_results$citekey,metaMER_results$model_id)))
print(knitr::kable(table(metaMER_results$citekey,metaMER_results$feature_id)))
print(knitr::kable(table(metaMER_results$citekey,metaMER_results$data_id)))

```


### Add human readable author+date field

```{r}
#| echo: false
#| eval: true
library(stringr)
metaMER_results$studyREF <- substr(metaMER_results$citekey,1,nchar(metaMER_results$citekey)-2)
metaMER_results$studyREF <- str_replace_all(metaMER_results$studyREF,'([0-9]+)',' et al \\1')
metaMER_results$studyREF <- str_to_sentence(metaMER_results$studyREF)
```

### Classify modelling techniques used

```{r}
#| eval: true
# Classify techniques according Hastie, Tibshirani, Friedman (2008)
# https://www.sas.upenn.edu/~fdiebold/NoHesitations/BookAdvanced.pdf
#
library(stringr)
metaMER_results$model_id <- tolower(metaMER_results$model_id)
metaMER_results$model_class_id <- 'Unclassified'
metaMER_results$model_class_id[str_detect(metaMER_results$model_id,'lr|lm|pls|mlr|pcr|logistic regression|2d model full|pentagon|gaussian process regression|sparse bayesian regression|variational bayesian regression|logistic regression|lda|rda|regularized discriminant analysis|reguliarized discriminant analysis')] <- 'Linear Methods' # Class name from Elements of Stat.."
#metaMER_results$model_class_id[str_detect(metaMER_results$model_id,'logistic regression|lda|rda|regularized discriminant analysis|reguliarized discriminant analysis')] <- 'Linear Classification'
#metaMER_results$model_class_id[str_detect(metaMER_results$model_id,'mars|gam')]<-'Additive Trees and Related Methods' #
metaMER_results$model_class_id[str_detect(metaMER_results$model_id,'rbf|gmm|local|polynomial|polygonal|knn|mars|gam')]<-'Kernel Smoothing, Additive and KNN'
#metaMER_results$model_class_id[str_detect(metaMER_results$model_id,'adaboost|gradient')]<-'Boosting'
metaMER_results$model_class_id[str_detect(metaMER_results$model_id,'nn|gru|lstm|ltsm|long short term memory|rprop|mcan')]<-'Neural Nets'
metaMER_results$model_class_id[str_detect(metaMER_results$model_id,'svm|svr|support vector regression|smoreg|smo ')]<-'Flexible Discriminants'
#metaMER_results$model_class_id[str_detect(metaMER_results$model_id,'knn')]<-'Prototype methods'
metaMER_results$model_class_id[str_detect(metaMER_results$model_id,'rf|extremely randomized tree regression|random forest|adaboost|gradient')]<-'Random Forests'
#metaMER_results$model_class_id[str_detect(metaMER_results$model_id,'rf')]<-'Ensemble Learning'

```

## Summarise

```{r}
#| eval: true
#| output: asis
print(knitr::kable(table(metaMER_results$model_class_id)))
print(knitr::kable(table(metaMER_results$model_class_id,metaMER_results$model_category)))

print(paste("We have", nrow(metaMER_results), "observations"))

print(paste("We have", length(unique(metaMER_results$citekey)), "studies"))

print(paste("Where", length(unique(metaMER_results$citekey[metaMER_results$model_category=='regression'])), "are regression studies"))

print(paste("Where", length(unique(metaMER_results$citekey[metaMER_results$model_category=='classification'])), "are classification studies"))
# note that we have some classification studies that also do regression and vice versa?

```

### Pull data to analyse regression studies

```{r}
R_studies <- dplyr::filter(metaMER_results,model_category=='regression' & str_detect(measure,'r|cc|r2|R2')) #  
dim(R_studies)

# eliminate measures that we don't need now
R_studies <- dplyr::filter(R_studies,!str_detect(statistic,'r2-95l|r2-95u|pvalue|upper|lower|sd|null|rmse'))
R_studies <- dplyr::filter(R_studies,!str_detect(measure,'nFeatures|rmse|jensen shannon divergence|accuracy|ccc|vector distance'))

table(R_studies$measure)


table(R_studies$measure, R_studies$statistic)

dim(R_studies)
R_studies$values[R_studies$measure=='R2']<-sqrt(R_studies$values[R_studies$measure=='R2']) # recode R2 into r
R_studies$values[R_studies$measure=='r2']<-sqrt(R_studies$values[R_studies$measure=='r2']) # recode R2 into r


```
### Homogenise the outcome variable names to valence and arousal

```{r}
R_studies$dimension[str_detect(R_studies$dimension,'activation|energy arousal|tension arousal')]<-'arousal'
R_studies$dimension[str_detect(R_studies$dimension,'pleasantness')]<-'valence'
R_studies <- dplyr::filter(R_studies,!str_detect(dimension,'av')) # relates to distances, can be omitted

table(R_studies$dimension)  

table(R_studies$stimulus_n)  

# Deal with four studies involving multiple datasets: 
R_studies$stimulus_n[R_studies$stimulus_n==" emoMusic: 1000, soundtracks: 360, chinese: 500 "] <- 938 #resolved from the paper
R_studies$stimulus_n[R_studies$stimulus_n==" 2372 (subset of PSIC3839, total n: 3839)    "] <- 2372 # resolved
R_studies$stimulus_n[R_studies$stimulus_n==" study 1: 20; study 2: 40) % three outliers  "] <- 40 # decided to take this from validation
# REDO with a clearer function
eliminate <- str_detect(R_studies$unique_id,"hu2017cr") & !str_detect(R_studies$unique_id,"all")
R_studies <- R_studies[!eliminate,]
R_studies$stimulus_n[R_studies$stimulus_n==" MER60: 60, CH818: 818, AMG1608: 1608  "] <- 60+818+1608 #
R_studies$stimulus_n <- as.numeric(R_studies$stimulus_n)
  
```

### Diagnostics

```{r}
library(ggplot2)

g1<-ggplot(R_studies,aes(x=values,fill=citekey,color=dimension))+
  geom_histogram()+
  facet_wrap(.~model_class_id)+
  scale_color_manual(values = c('black','white'))+
  theme_dark()+
  scale_x_continuous(breaks = seq(0,1,by=.1))

g1
```

### Select a summary measure for valence and arousal separately

```{r}
library(tidyverse)
R_studies$citekey <- factor(R_studies$citekey)
R_studies$dimension <- factor(R_studies$dimension)

R_summary <- summarise(group_by(R_studies,dimension,citekey),valuesMean=mean(values,na.rm=T),valuesMedian=median(values,na.rm=T),valuesMax=max(values,na.rm=T),stimulus_n=first(stimulus_n),studyREF=first(studyREF),model_class_id=first(model_class_id))

```

### Visualise Summary on two dimensions

Add variation from within the studies (alternative models)

```{r}
R_summary_split <- pivot_wider(R_summary,id_cols = citekey, names_from = c(dimension), values_from = valuesMax)

g2 <- ggplot(R_summary_split,aes(x=valence,y=arousal,label=citekey))+
  geom_label()+
  theme_bw()+
  scale_x_continuous(breaks = seq(0,1,by=.1))+
  scale_y_continuous(breaks = seq(0,1,by=.1))

g2

## could be more informative when done with the full data
R_studies$citekey<-factor(R_studies$citekey)
R_studies$dimension<-factor(R_studies$dimension)

R_studies_split <- pivot_wider(R_studies,id_cols = c(unique_id,citekey,model_class_id), names_from = c(dimension), values_from = c(values),values_fn = mean)
R_studies_split<-drop_na(R_studies_split)

library(ggrepel)

g3 <- ggplot(R_studies_split,aes(x=valence,y=arousal,label=citekey,color=model_class_id,fill=model_class_id))+
  geom_point(size=4)+
  geom_label_repel(size=3, max.overlaps=50,show.legend = T,color='white')+
  scale_x_continuous(breaks = seq(0,1,by=.25),limits = c(0,1))+
  scale_y_continuous(breaks = seq(0,1,by=.25),limits = c(0,1))+
  theme_bw()
g3

```

### Plot success across the years

```{r}
#| eval: true
# Add year!
R_studies$year <- as.numeric(str_match(R_studies$citekey,'[0-9]+'))

g3 <- ggplot(R_studies,aes(x=year,y=values,colour=model_class_id))+
  geom_point(show.legend = T)+
  facet_wrap(.~dimension)+
  theme_bw()
g3
```
### Simple model complexity metric

Ratio of obs./features or just a classification based on feature n (quintiles).

```{r}
R_studies$feature_n==" 15; 23 in table, but 15 reported "

R_studies$feature_n[R_studies$feature_n==" 15; 23 in table, but 15 reported  "] <- 15 #resolved from the paper

R_studies$feature_n[R_studies$feature_n==" 15; 23 in table, but 15 reported  "] <- 15 #resolved
R_studies$feature_n[R_studies$feature_n==" before_selection = 45, after_selection = 6  "] <- 45 #resolved
R_studies$feature_n[R_studies$feature_n==" model 1: 52, model 2 = 68, model 3 = 260, model 4 = 388 "] <- 388 #resolved
R_studies$feature_n[R_studies$feature_n==" variable, 557 before feature selection "] <- 557 #resolved

R_studies$feature_n[R_studies$feature_n==" 50 PCA features "] <- 50 #resolved
#R_studies$feature_n[R_studies$feature_n==""] <- 0 #resolved
#R_studies$feature_n[R_studies$feature_n==""] <- 0 #resolved

R_studies$feature_n<-as.numeric(R_studies$feature_n)

print(quantile(R_studies$feature_n,c(0.333,0.666),na.rm = T))
#quantile(R_studies$feature_n,c(0.25,0.50,0.75),na.rm = T)

# Assign
R_studies$feature_n_complexity <- cut(R_studies$feature_n,
                                      breaks = c(0,
                                                 as.numeric(quantile(R_studies$feature_n,c(0.333),na.rm = T)),
                                                 as.numeric(quantile(R_studies$feature_n,c(0.666),na.rm = T)),
                                                 1000),
                                      labels = c("Feature n < 18","Feature n > 18 & < 260","Feature n > 260"))
table(R_studies$feature_n_complexity)
```

### Explore feature_n_complexity and model success

Needs to be done from the unsummarised data (`R_studies`).

```{r}
tmp <- drop_na(R_studies)
library(ggdist)

tmp$dimension<-str_to_title(tmp$dimension)
tmp$model_class_id<-factor(tmp$model_class_id,
                           levels = c("Neural Nets","Flexible Discriminants", "Kernel Smoothing, Additive and KNN", "Random Forests","Linear Methods"),
                           labels = c("Neural\nNets","Flexible\nDiscriminants", "KS\n & KNN", "Random\nForests", "Linear\nMethods"))

g <- ggplot(tmp,aes(x=model_class_id,y=values,color=citekey,label=citekey))+
  stat_halfeye(aes(fill=citekey),point_interval="mean_qi", trim=FALSE, expand=FALSE, show.legend = FALSE,adjust = 1.25, density="bounded", point_size=3,scale = 1,alpha=0.5) + 
  geom_point(alpha=0.5,show.legend = F,position = position_jitter(width = .3))+
  #geom_label_repel(size=2,max.overlaps = 50)+
  facet_wrap(dimension~feature_n_complexity)+
  ylab("Correlation Coefficient")+
  xlab("Model Technique")+
#  scale_y_continuous(limits = c(0,1),expand = c(0.01,0.01))+
  geom_text_repel(aes(x = model_class_id, y = values, label = studyREF),
             stat = "summary", fun = mean,show.legend = F)+
  theme_bw()
g
#ggsave(filename = 'FeatureN_regression.pdf',g,height = 7,width = 11)
```

## Export as csv 

```{r}
write.csv(x = R_studies,file = 'R_studies.csv')
write.csv(x = R_summary,file = 'R_summary.csv')
```