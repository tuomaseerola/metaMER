[
  {
    "objectID": "manuscript/manuscript.html",
    "href": "manuscript/manuscript.html",
    "title": "A Meta-Analysis of Music Emotion Recognition Studies",
    "section": "",
    "text": "Emotional engagement is a key reason why people engage with music in their every day activities, and it is also why music is increasingly being used in various health applications (Agres et al., 2021; Juslin et al., 2022). In recent years, significant advances have been made in music information retrieval, particularly in music emotion recognition (MER) tasks (Gómez-Cañón et al., 2021; Panda et al., 2023). Improvements in available features, modeling techniques, and datasets have provided the field with opportunities to enhance the accuracy and reliability of predicting annotated emotions from audio. Over the past 25 years, numerous studies have established the types of emotions that listeners perceive and recognize in music. In the last 15 years, research has increasingly focused on tracing these recognized emotions back to specific musical components, such as expressive features (Lindström et al., 2003), structural aspects of music (Anderson & Schutz, 2022; Eerola et al., 2013; Grimaud & Eerola, 2022), acoustic features (Eerola, 2011; Panda et al., 2023, 2013; Saari et al., 2015; Y. H. Yang et al., 2008), or emergent properties revealed through deep learning techniques (Er & Aydilek, 2019; Sarkar et al., 2020).\nHowever, there is no consensus on the extent to which emotions can be accurately recognized by computational models. The current literature presents a diverse and mixed picture regarding the success of models in predicting emotions within the affective circumplex – valence and arousal– (Russell, 1980) and in classifying distinct emotion categories (Fu et al., 2010)."
  },
  {
    "objectID": "manuscript/manuscript.html#aims",
    "href": "manuscript/manuscript.html#aims",
    "title": "A Meta-Analysis of Music Emotion Recognition Studies",
    "section": "Aims",
    "text": "Aims\nOur aim is to evaluate the predictive accuracy of two models of emotional expression in music: (a) models that predict track-specific coordinates in affective circumplex space (valence and arousal), and (b) models that classify discrete emotion categories. We focus on recent to identify key factors such as modeling techniques and features that significantly affect prediction accuracy. To achieve this, we conduct a meta-analysis of journal articles published in the past 10 years. Based on existing literature, we hypothesize that arousal will be predicted with higher accuracy than valence, as valence tends to be more context-dependent and challenging to model. For emotion classification, we expect simple utilitarian emotions (e.g., fear, anger) will be easier to predict than more complex social emotions (e.g., sadness, nostalgia)."
  },
  {
    "objectID": "manuscript/manuscript.html#quality-control",
    "href": "manuscript/manuscript.html#quality-control",
    "title": "A Meta-Analysis of Music Emotion Recognition Studies",
    "section": "Quality Control",
    "text": "Quality Control\nThe search yielded studies of variable (and occasionally questionable) quality. To mitigate potentially spurious effects resulting from the inclusion of low-quality studies, we excluded studies lacking sufficient details about stimuli, analyzed features, or model architecture. Finally, we excluded studies published in journals of questionable relevance/quality, (e.g., Mathematical Problems in Engineering ceased publication following 17 retractions published between July and September 2024). Overall this step eliminated 12 studies, leaving us with 34 studies in total."
  },
  {
    "objectID": "manuscript/manuscript.html#study-encoding",
    "href": "manuscript/manuscript.html#study-encoding",
    "title": "A Meta-Analysis of Music Emotion Recognition Studies",
    "section": "Study Encoding",
    "text": "Study Encoding\nTo capture key details of each study, we added additional fields to BibTeX entries for each study. Fields included information about the genre/type of stimuli employed, along with their duration and number; the number of analyzed features; and the model type – Neural Nets (NN), Support Vector Machines (SVM), Linear Methods (LM), Tree-based Methods (TM), KS, Add. and KNN Methods (KM) – validation procedure and output measures. Additionally, we included study results using executable R code containing custom functions for meta-analysis. For complete details about our encoding procedure, see studies/extraction_details.qmd ."
  },
  {
    "objectID": "manuscript/manuscript.html#prediction-success-for-valence-and-arousal-or-affect-dimensions",
    "href": "manuscript/manuscript.html#prediction-success-for-valence-and-arousal-or-affect-dimensions",
    "title": "Meta-analysis of regression and classification success of emotion ratings from audio",
    "section": "Prediction success for valence and arousal (or affect dimensions)",
    "text": "Prediction success for valence and arousal (or affect dimensions)\nSee analysis/analysis.qmd\nSince there are many models contained within each of the studies, we will report the results in two parts; We first give an overview of the results for all models, and then we focus on the best performing models of each study. The best performing model is the model within each study with the highest correlation coefficient. This reduction is done to avoid the issue of multiple models from the same study deflating the results as majority of the models included are relative modest baseline or alternative models that do not represent the novelty or content of the article. Table 2 summarises the results for all models (All) as well as best performing models (Max) for each study. The summary includes the number of models and observations, the correlation coefficient and its 95% confidence interval, the t-value and p-value for the correlation, the heterogeneity statistics \\(\\tau^2\\) and \\(I^2\\), calculated through appropriate transformations (Fisher’s Z) for the correlation coefficient as part of a random-effects model using meta library (Balduzzi et al., 2019).\nTable 2. Meta-analytic diagnostic for all regression studies predicting valence from audio.\n\n\n\n\n\n\n\n\n\n\n\n\nConcept\nModels, obs\n\\(r\\) [95%-CI]\n\\(t\\)\n\\(p\\)\n\\(\\tau^2\\)\n\\(I^2\\)\n\n\n\n\nValence All\n120,73685\n0.567 [0.530; 0.603]\n23.7\n.0001\n0.083\n97.5%\n\n\nValence Max\n24,15660\n0.659 [0.557; 0.740]\n10.14\n.0001\n0.138\n98.2%\n\n\nN Features\n\n\n\n\n\n\n\n\n&lt;18 F\n5,3036\n0.811 [0.566; 0.775]\n-\n-\n0.182\n98.9%\n\n\n18-260 F\n11,7318\n0.548 [0.343; 0.703]\n-\n-\n0.133\n97.6%\n\n\n260+ F\n7,4562\n0.685 [0.566; 0.775]\n-\n-\n0.044\n97.2%\n\n\nTechniques\n\n\n\n\n\n\n\n\nKS\n2,2582\n0.466 [-0.634; 0.942]\n-\n-\n0.0185\n95.1%\n\n\nLM\n8,1762\n0.784 [0.625; 0.881]\n-\n-\n0.1370\n96.4%\n\n\nFD\n6,4993\n0.656 [0.484; 0.779]\n-\n-\n0.0574\n96.9%\n\n\nNN\n4,2249\n0.340 [-0.097; 0.668]\n-\n-\n0.0761\n97.1%\n\n\nRF\n4,4074\n0.702 [0.391; 0.869]\n-\n-\n0.057\n98.5%\n\n\n\n\n\n\n\n\nOTHER GROUPINGS? STIMULUS MIXED/SINGLE GENRE, PREDICTION/EXPLANATION\n\n\n\n\n\n\n\nForest plot of valence predictions from the MER models.\n\n\n\n\nSummarise the results here briefly\nMoving on the arousal, …\nTable 3. Meta-analytic diagnostic for all regression studies predicting arousal from audio.\n\n\n\n\n\n\n\n\n\n\n\n\nConcept\nModels, obs\n\\(r\\) [95%-CI]\n\\(t\\)\n\\(p\\)\n\\(\\tau^2\\)\n\\(I^2\\)\n\n\n\n\nArousal\n\n0.7959 [0.7666; 0.8218]\n29.0\n0.0001\n0.0676\n95.6%\n\n\nArousal Max\n24,15660\n0.8070 [0.7453; 0.8550]\n10.3\n0.0001\n0.155\n96.8%\n\n\nN Features\n\n\n\n\n\n\n\n\n&lt;18 F\n\n\n\n\n\n\n\n\n18-260 F\n\n\n\n\n\n\n\n\n260+ F\n\n\n\n\n\n\n\n\nTechniques\n\n\n\n\n\n\n\n\nKS\n\n\n\n\n\n\n\n\nLM\n\n\n\n\n\n\n\n\nFD\n\n\n\n\n\n\n\n\nNN\n\n\n\n\n\n\n\n\nRF\n\n\n\n\n\n\n\n\n\nFigure 2. Forest plot of arousal prediction (using Max?)\n\n\n\n\nSummarise here the pattern of results"
  },
  {
    "objectID": "manuscript/manuscript.html#classification-studies",
    "href": "manuscript/manuscript.html#classification-studies",
    "title": "A Meta-Analysis of Music Emotion Recognition Studies",
    "section": "Classification studies",
    "text": "Classification studies\nSummary of details contained in Table 1, but summarise at least the categories predicted before moving onto the main findings.\nTable 4. Meta-analytic diagnostic for all classification studies predicting emotion categories from audio.\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nModels, obs\n\\(r\\) [95%-CI]\n\\(t\\)\n\\(p\\)\n\\(\\tau^2\\)\n\\(I^2\\)\n\n\n\n\nAll\n89,87347\n0.8074 [0.7681; 0.8407]\n21.4\n0.0001\n0.2415\n99.7%\n\n\nMax\n14,17184\n0.8564 [0.7386; 0.9234]\n8.32\n0.0001\n0.329\n99.8%\n\n\n\n\n\nHeterogeneity issues\nFigure 3. Forest plot of arousal prediction (Max?) (Unless we do some custom plotting)\n\nFigure Optional: Funnel plot (I haven’t seen this yet)\n\n\nNotes to results: In the pre-registration, we promised the following:\n\ngroupings based on genre, model complexity (high, medium, low), model validation (exists or not)\nwe promised to carry out sensitivity analyses based on type of journal the studies were published in."
  },
  {
    "objectID": "manuscript/manuscript.html#concise-summary-of-what-we-did-and-found",
    "href": "manuscript/manuscript.html#concise-summary-of-what-we-did-and-found",
    "title": "A Meta-Analysis of Music Emotion Recognition Studies",
    "section": "Concise summary of what we did and found",
    "text": "Concise summary of what we did and found"
  },
  {
    "objectID": "manuscript/manuscript.html#main-outcomes",
    "href": "manuscript/manuscript.html#main-outcomes",
    "title": "A Meta-Analysis of Music Emotion Recognition Studies",
    "section": "Main outcomes",
    "text": "Main outcomes\n\nArousal is easier to predict (r = 0.7627) than valence (r = 0.6236), as we predicted. The glass ceiling seems to be at …\nClassification …\nModel accuracy is surprisingly little affected by the number of features (?) or modelling technique (?).\nSome of the complex state-of-the-art techniques (e.g., NNs) do not deliver impressive improvements over older techniques (e.g., SVR, RF)\nVariation in study/model/data quality is large and can be seen in heterogenuity and the amount of studies eliminated\n\n[this is the discussion section]"
  },
  {
    "objectID": "manuscript/manuscript.html#calls-for-actionpoints-to-improve-in-such-studies",
    "href": "manuscript/manuscript.html#calls-for-actionpoints-to-improve-in-such-studies",
    "title": "A Meta-Analysis of Music Emotion Recognition Studies",
    "section": "Calls for action/points to improve in such studies",
    "text": "Calls for action/points to improve in such studies\n\nDocumentation the details in full (features, stimuli, model details, cross-validation)\nQuality of the underlying data (emotion ratings, classes, or even stimulus properties?\nGeneralisibility of the models (some studies such as X and Y address this by applying the models across several datasets)\nDiversity in the evaluative aspects of studies: overfitting, numerous ways of cross-validating, not sharing data or analysis scripts, not reporting in the same way\nWhat proportion of stimuli are Western music, and what genres tend to dominate?\n\n\nFunding statement\nCA was funded by Mitacs Globalink Research Award (Mitacs & British High Commission - Ottawa, Canada).\n\n\nCompeting interests statement\nThere were no competing interests.\n\n\nOpen practices statement\nStudy preregistration, data, analysis scripts and supporting information is available at Github, https://tuomaseerola.github.io/metaMER.\n\n\nAcknowledgements\nWe thank Greggs food-on-the-go retailer for sustaining the work with affordable sandwiches and coffee."
  },
  {
    "objectID": "manuscript/manuscript.html#footnotes",
    "href": "manuscript/manuscript.html#footnotes",
    "title": "A Meta-Analysis of Music Emotion Recognition Studies",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe best-performing model to date reached 69.83 % in the 2017 competition (Park et al., 2017).↩︎"
  },
  {
    "objectID": "analysis/preprocessing.html",
    "href": "analysis/preprocessing.html",
    "title": "Preprocessing",
    "section": "",
    "text": "This assumes that the data has been parsed from the BibTeX files into table and exported as CSV file.\n\n\n\nsource(here::here('R/build-df.R'))\nsource(here::here('R/format-study-results.R'))\nsource(here::here('R/parse-model-output.R'))\n\n\n# get metaMER df:\nmeta_df &lt;- get_metaMER_df(path_2_studies = here::here('studies'))\n\n# get included studies\nincluded_studies &lt;- meta_df[which(\n  !stringr::str_detect(meta_df$final_notes, '!EXCL!')),] |&gt; \n  dplyr::tibble()\n\n\n\n\n# get studies re-coded (currently identifiable by presence of bind_field.)\nrecoded_studies &lt;- included_studies[which(stringr::str_detect(\n  included_studies$model_rate_emotion_values,\n                                     'bind_field')),] \n\n\n\n\n\nmetaMER_results &lt;-\ndo.call(\n  rbind,\n    lapply(1:nrow(recoded_studies),\n       function(x) get_study_results(recoded_studies[x,])\n       )\n) \n\n# add unique identifiers\nunique_id &lt;- apply(metaMER_results[,c('citekey',\n                        'library_id',\n                         'model_id',\n                         'feature_id',\n                         'data_id',\n                         'experiment_id')],\n                      1, \n                      paste0, \n                      collapse = '-'\n) \nmetaMER_results$unique_id &lt;- stringr::str_remove_all(unique_id, \n                                                     ' ')\n\nmetaMER_results &lt;- metaMER_results |&gt; dplyr::select(unique_id, \n                                 dplyr::everything()) \n\nmetaMER_results |&gt; dplyr::tibble()\n\n# A tibble: 1,114 × 19\n   unique_id  citekey journal stimulus_genre model_category stimulus_n feature_n\n   &lt;chr&gt;      &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;          &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt;    \n 1 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 2 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 3 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 4 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 5 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 6 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 7 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 8 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 9 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n10 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n# ℹ 1,104 more rows\n# ℹ 12 more variables: participant_n &lt;chr&gt;, feature_source &lt;chr&gt;,\n#   feature_reduction_method &lt;chr&gt;, library_id &lt;chr&gt;, model_id &lt;chr&gt;,\n#   feature_id &lt;chr&gt;, data_id &lt;chr&gt;, experiment_id &lt;chr&gt;, dimension &lt;chr&gt;,\n#   measure &lt;chr&gt;, statistic &lt;chr&gt;, values &lt;dbl&gt;\n\n\n\n\n\nprint(knitr::kable(table(metaMER_results$citekey,metaMER_results$dimension)))\nprint(knitr::kable(table(metaMER_results$citekey,metaMER_results$model_id)))\nprint(knitr::kable(table(metaMER_results$citekey,metaMER_results$feature_id)))\nprint(knitr::kable(table(metaMER_results$citekey,metaMER_results$data_id)))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprint(knitr::kable(table(metaMER_results$model_class_id)))\n\n\n\nVar1\nFreq\n\n\n\n\nFlexible Discriminants\n339\n\n\nKernel Smoothing, Additive and KNN\n54\n\n\nLinear Methods\n257\n\n\nNeural Nets\n354\n\n\nRandom Forests\n85\n\n\nUnclassified\n25\n\n\n\nprint(knitr::kable(table(metaMER_results$model_class_id,metaMER_results$model_category)))\n\n\n\n\nclassification\nregression\n\n\n\n\nFlexible Discriminants\n155\n184\n\n\nKernel Smoothing, Additive and KNN\n18\n36\n\n\nLinear Methods\n59\n198\n\n\nNeural Nets\n190\n164\n\n\nRandom Forests\n69\n16\n\n\nUnclassified\n25\n0\n\n\n\ncat(paste(\"We have\", nrow(metaMER_results), \"observations\"))\nWe have 1114 observations\ncat(paste(\"\\nWe have\", length(unique(metaMER_results$citekey)), \"studies\"))\nWe have 34 studies\ncat(paste(\"\\nWhere\", length(unique(metaMER_results$citekey[metaMER_results$model_category=='regression'])), \"are regression studies\"))\nWhere 22 are regression studies\ncat(paste(\"\\nWhere\", length(unique(metaMER_results$citekey[metaMER_results$model_category=='classification'])), \"are classification studies\"))\nWhere 12 are classification studies\n# note that we have some classification studies that also do regression and vice versa?\n# THIS IS CORRECT (updated 24 October 2024):\n# [1] \"We have 1284 observations\"\n# [1] \"We have 36 studies\"\n# [1] \"Where 22 are regression studies\"\n# [1] \"Where 14 are classification studies\"\n\n# Add a check for these properties ToDo\n2024-10-21: Update studies with multiple unique_ids due to multiple stats reported\n\nmetaMER_results &lt;- metaMER_results |&gt; \n  dplyr::filter(!(citekey == \"zhang2017fe\" & statistic == \"mean\"),\n         !(citekey == \"zhang2016br\" & statistic == \"mean\"),\n         !(citekey == \"zhang2016br\" & is.na(values)),\n         !(citekey == \"coutinho2017sh\" & measure == \"ccc\"),\n         # Include only results for energy arousal\n         !(citekey == \"wang2022cr\" & dimension == \"tension arousal\"),\n         !(citekey == \"wang2021ac\" & dimension == \"tension arousal\"),\n         !(citekey == \"deng2015em\" & dimension == \"resonance\"))\n\nDeal with repeated experiment IDs in hu2017cr\n\n# get citation keys (all currently say experiment 1)\nhu2017models &lt;- metaMER_results[str_detect(metaMER_results$citekey, \n                                           \"hu2017cr\"),]$unique_id\n\n# replace the last digit with 1:4 (representing each experiment)\nhu2017models_replacement &lt;- paste0(\nsubstr(hu2017models, \n       1, \n       nchar(hu2017models) - 1),\n1:4\n)\n\n\n# overwrite original values\nmetaMER_results[metaMER_results$unique_id %in% \n                  hu2017models,]$unique_id &lt;- hu2017models_replacement"
  },
  {
    "objectID": "analysis/preprocessing.html#read-annotated-data",
    "href": "analysis/preprocessing.html#read-annotated-data",
    "title": "Preprocessing",
    "section": "",
    "text": "source(here::here('R/build-df.R'))\nsource(here::here('R/format-study-results.R'))\nsource(here::here('R/parse-model-output.R'))\n\n\n# get metaMER df:\nmeta_df &lt;- get_metaMER_df(path_2_studies = here::here('studies'))\n\n# get included studies\nincluded_studies &lt;- meta_df[which(\n  !stringr::str_detect(meta_df$final_notes, '!EXCL!')),] |&gt; \n  dplyr::tibble()\n\n\n\n\n# get studies re-coded (currently identifiable by presence of bind_field.)\nrecoded_studies &lt;- included_studies[which(stringr::str_detect(\n  included_studies$model_rate_emotion_values,\n                                     'bind_field')),] \n\n\n\n\n\nmetaMER_results &lt;-\ndo.call(\n  rbind,\n    lapply(1:nrow(recoded_studies),\n       function(x) get_study_results(recoded_studies[x,])\n       )\n) \n\n# add unique identifiers\nunique_id &lt;- apply(metaMER_results[,c('citekey',\n                        'library_id',\n                         'model_id',\n                         'feature_id',\n                         'data_id',\n                         'experiment_id')],\n                      1, \n                      paste0, \n                      collapse = '-'\n) \nmetaMER_results$unique_id &lt;- stringr::str_remove_all(unique_id, \n                                                     ' ')\n\nmetaMER_results &lt;- metaMER_results |&gt; dplyr::select(unique_id, \n                                 dplyr::everything()) \n\nmetaMER_results |&gt; dplyr::tibble()\n\n# A tibble: 1,114 × 19\n   unique_id  citekey journal stimulus_genre model_category stimulus_n feature_n\n   &lt;chr&gt;      &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;          &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt;    \n 1 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 2 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 3 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 4 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 5 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 6 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 7 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 8 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 9 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n10 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n# ℹ 1,104 more rows\n# ℹ 12 more variables: participant_n &lt;chr&gt;, feature_source &lt;chr&gt;,\n#   feature_reduction_method &lt;chr&gt;, library_id &lt;chr&gt;, model_id &lt;chr&gt;,\n#   feature_id &lt;chr&gt;, data_id &lt;chr&gt;, experiment_id &lt;chr&gt;, dimension &lt;chr&gt;,\n#   measure &lt;chr&gt;, statistic &lt;chr&gt;, values &lt;dbl&gt;\n\n\n\n\n\nprint(knitr::kable(table(metaMER_results$citekey,metaMER_results$dimension)))\nprint(knitr::kable(table(metaMER_results$citekey,metaMER_results$model_id)))\nprint(knitr::kable(table(metaMER_results$citekey,metaMER_results$feature_id)))\nprint(knitr::kable(table(metaMER_results$citekey,metaMER_results$data_id)))"
  },
  {
    "objectID": "analysis/preprocessing.html#summarise-all",
    "href": "analysis/preprocessing.html#summarise-all",
    "title": "Preprocessing",
    "section": "",
    "text": "print(knitr::kable(table(metaMER_results$model_class_id)))\n\n\n\nVar1\nFreq\n\n\n\n\nFlexible Discriminants\n339\n\n\nKernel Smoothing, Additive and KNN\n54\n\n\nLinear Methods\n257\n\n\nNeural Nets\n354\n\n\nRandom Forests\n85\n\n\nUnclassified\n25\n\n\n\nprint(knitr::kable(table(metaMER_results$model_class_id,metaMER_results$model_category)))\n\n\n\n\nclassification\nregression\n\n\n\n\nFlexible Discriminants\n155\n184\n\n\nKernel Smoothing, Additive and KNN\n18\n36\n\n\nLinear Methods\n59\n198\n\n\nNeural Nets\n190\n164\n\n\nRandom Forests\n69\n16\n\n\nUnclassified\n25\n0\n\n\n\ncat(paste(\"We have\", nrow(metaMER_results), \"observations\"))\nWe have 1114 observations\ncat(paste(\"\\nWe have\", length(unique(metaMER_results$citekey)), \"studies\"))\nWe have 34 studies\ncat(paste(\"\\nWhere\", length(unique(metaMER_results$citekey[metaMER_results$model_category=='regression'])), \"are regression studies\"))\nWhere 22 are regression studies\ncat(paste(\"\\nWhere\", length(unique(metaMER_results$citekey[metaMER_results$model_category=='classification'])), \"are classification studies\"))\nWhere 12 are classification studies\n# note that we have some classification studies that also do regression and vice versa?\n# THIS IS CORRECT (updated 24 October 2024):\n# [1] \"We have 1284 observations\"\n# [1] \"We have 36 studies\"\n# [1] \"Where 22 are regression studies\"\n# [1] \"Where 14 are classification studies\"\n\n# Add a check for these properties ToDo\n2024-10-21: Update studies with multiple unique_ids due to multiple stats reported\n\nmetaMER_results &lt;- metaMER_results |&gt; \n  dplyr::filter(!(citekey == \"zhang2017fe\" & statistic == \"mean\"),\n         !(citekey == \"zhang2016br\" & statistic == \"mean\"),\n         !(citekey == \"zhang2016br\" & is.na(values)),\n         !(citekey == \"coutinho2017sh\" & measure == \"ccc\"),\n         # Include only results for energy arousal\n         !(citekey == \"wang2022cr\" & dimension == \"tension arousal\"),\n         !(citekey == \"wang2021ac\" & dimension == \"tension arousal\"),\n         !(citekey == \"deng2015em\" & dimension == \"resonance\"))\n\nDeal with repeated experiment IDs in hu2017cr\n\n# get citation keys (all currently say experiment 1)\nhu2017models &lt;- metaMER_results[str_detect(metaMER_results$citekey, \n                                           \"hu2017cr\"),]$unique_id\n\n# replace the last digit with 1:4 (representing each experiment)\nhu2017models_replacement &lt;- paste0(\nsubstr(hu2017models, \n       1, \n       nchar(hu2017models) - 1),\n1:4\n)\n\n\n# overwrite original values\nmetaMER_results[metaMER_results$unique_id %in% \n                  hu2017models,]$unique_id &lt;- hu2017models_replacement"
  },
  {
    "objectID": "analysis/preprocessing.html#homogenise-the-outcome-variable-names-to-valence-and-arousal",
    "href": "analysis/preprocessing.html#homogenise-the-outcome-variable-names-to-valence-and-arousal",
    "title": "Preprocessing",
    "section": "Homogenise the outcome variable names to valence and arousal",
    "text": "Homogenise the outcome variable names to valence and arousal\n\n\n[1] 22\n\n\n\nClean feature N field\n\n\n  33.3%   66.6% \n236.341 653.000 \n\n\n25% 50% 75% \n 72 605 653 \n\n\n 10%  50%  90% \n  18  605 3000"
  },
  {
    "objectID": "analysis/preprocessing.html#diagnostics",
    "href": "analysis/preprocessing.html#diagnostics",
    "title": "Preprocessing",
    "section": "Diagnostics",
    "text": "Diagnostics"
  },
  {
    "objectID": "analysis/preprocessing.html#select-a-summary-measure-for-valence-and-arousal-separately",
    "href": "analysis/preprocessing.html#select-a-summary-measure-for-valence-and-arousal-separately",
    "title": "Preprocessing",
    "section": "Select a summary measure for valence and arousal separately",
    "text": "Select a summary measure for valence and arousal separately\nNote: Before adding feature_n to the summary, they need to be cleaned!\n\nR_studies$citekey &lt;- factor(R_studies$citekey) # 22 unique values\nR_studies$dimension &lt;- factor(R_studies$dimension)\n\nR_summary &lt;- summarise(group_by(R_studies,dimension,citekey),valuesMean=mean(values,na.rm=TRUE),valuesMedian=median(values,na.rm=TRUE),valuesMax=max(values,na.rm=TRUE),stimulus_n=first(stimulus_n),studyREF=first(studyREF),model_class_id=first(model_class_id),feature_n=first(feature_n),journal_type=first(journal_type),feature_n=first(feature_n),feature_n_categories=first(feature_n_categories),stimulus_genre_mixed=first(stimulus_genre_mixed),feature_n_complexity_genre=first(feature_n_complexity_genre))\n\n`summarise()` has grouped output by 'dimension'. You can override using the\n`.groups` argument.\n\nprint(dim(R_summary))\n\n[1] 44 13"
  },
  {
    "objectID": "analysis/preprocessing.html#visualise-summary-on-two-dimensions",
    "href": "analysis/preprocessing.html#visualise-summary-on-two-dimensions",
    "title": "Preprocessing",
    "section": "Visualise Summary on two dimensions",
    "text": "Visualise Summary on two dimensions\nAdd variation from within the studies (alternative models)"
  },
  {
    "objectID": "analysis/preprocessing.html#plot-success-across-the-years",
    "href": "analysis/preprocessing.html#plot-success-across-the-years",
    "title": "Preprocessing",
    "section": "Plot success across the years",
    "text": "Plot success across the years"
  },
  {
    "objectID": "analysis/preprocessing.html#simple-model-complexity-metric",
    "href": "analysis/preprocessing.html#simple-model-complexity-metric",
    "title": "Preprocessing",
    "section": "Simple model complexity metric",
    "text": "Simple model complexity metric\nRatio of obs./features or just a classification based on feature n (quantiles).\n\n\n  33.3%   66.6% \n236.341 653.000"
  },
  {
    "objectID": "analysis/preprocessing.html#explore-feature_n_complexity-and-model-success",
    "href": "analysis/preprocessing.html#explore-feature_n_complexity-and-model-success",
    "title": "Preprocessing",
    "section": "Explore feature_n_complexity and model success",
    "text": "Explore feature_n_complexity and model success\nNeeds to be done from the unsummarised data (R_studies)."
  },
  {
    "objectID": "analysis/preprocessing.html#create-descriptive-table-for-the-manuscript",
    "href": "analysis/preprocessing.html#create-descriptive-table-for-the-manuscript",
    "title": "Preprocessing",
    "section": "Create descriptive table for the manuscript",
    "text": "Create descriptive table for the manuscript\n\nTR &lt;- NULL\nTR$study_n &lt;- length(unique(R_studies$citekey))\nTR$model_n &lt;- nrow(R_studies)\nt&lt;-table(R_studies$model_class_id)\nt2 &lt;- paste0(names(t),': ', as.numeric(t))\nTR$model_types_n &lt;- str_c(t2,collapse = \"\\n\")\nTR$feature_Desc &lt;- paste0('Min=',min(R_studies$feature_n,na.rm = TRUE),', Md=',median(R_studies$feature_n,na.rm = TRUE),', Max=', max(R_studies$feature_n,na.rm = TRUE))\nTR$stimulus_Desc &lt;- paste0('Min=',min(R_studies$stimulus_n,na.rm = TRUE),', Md=',median(R_studies$stimulus_n,na.rm = TRUE),', Max=', max(R_studies$stimulus_n,na.rm = TRUE))\nprint(TR)\n\n$study_n\n[1] 23\n\n$model_n\n[1] 236\n\n$model_types_n\n[1] \"Flexible Discriminants: 58\\nKernel Smoothing, Additive and KNN: 24\\nLinear Methods: 62\\nNeural Nets: 70\\nRandom Forests: 22\"\n\n$feature_Desc\n[1] \"Min=3, Md=548, Max=6670\"\n\n$stimulus_Desc\n[1] \"Min=20, Md=330, Max=2486\""
  },
  {
    "objectID": "analysis/preprocessing.html#export-as-csv",
    "href": "analysis/preprocessing.html#export-as-csv",
    "title": "Preprocessing",
    "section": "Export as csv",
    "text": "Export as csv\n\nif (export_decision == TRUE){\n  write.csv(x = R_studies,file = 'R_studies.csv')\n  write.csv(x = R_summary,file = 'R_summary.csv')\n}"
  },
  {
    "objectID": "analysis/preprocessing.html#homogenise-the-stimulus-n",
    "href": "analysis/preprocessing.html#homogenise-the-stimulus-n",
    "title": "Preprocessing",
    "section": "Homogenise the stimulus N",
    "text": "Homogenise the stimulus N"
  },
  {
    "objectID": "analysis/preprocessing.html#diagnostics-1",
    "href": "analysis/preprocessing.html#diagnostics-1",
    "title": "Preprocessing",
    "section": "Diagnostics",
    "text": "Diagnostics"
  },
  {
    "objectID": "analysis/preprocessing.html#select-a-summary-measure-for-valence-and-arousal-separately-1",
    "href": "analysis/preprocessing.html#select-a-summary-measure-for-valence-and-arousal-separately-1",
    "title": "Preprocessing",
    "section": "Select a summary measure for valence and arousal separately",
    "text": "Select a summary measure for valence and arousal separately\n\nC_studies$citekey &lt;- factor(C_studies$citekey)\n\nC_summary &lt;- summarise(group_by(C_studies,citekey),valuesMean=mean(values,na.rm=TRUE),valuesMedian=median(values,na.rm=TRUE),valuesMax=max(values,na.rm=TRUE),stimulus_n=first(stimulus_n),studyREF=first(studyREF),model_class_id=first(model_class_id), stimulus_genre_mixed=first(stimulus_genre_mixed),journal_type = first(journal_type))"
  },
  {
    "objectID": "analysis/preprocessing.html#visualise-summary",
    "href": "analysis/preprocessing.html#visualise-summary",
    "title": "Preprocessing",
    "section": "Visualise Summary",
    "text": "Visualise Summary"
  },
  {
    "objectID": "analysis/preprocessing.html#simple-model-complexity-metric-based-on-feature_n",
    "href": "analysis/preprocessing.html#simple-model-complexity-metric-based-on-feature_n",
    "title": "Preprocessing",
    "section": "Simple model complexity metric based on feature_n",
    "text": "Simple model complexity metric based on feature_n"
  },
  {
    "objectID": "analysis/preprocessing.html#explore-feature_n_complexity-and-model-success-1",
    "href": "analysis/preprocessing.html#explore-feature_n_complexity-and-model-success-1",
    "title": "Preprocessing",
    "section": "Explore feature_n_complexity and model success",
    "text": "Explore feature_n_complexity and model success\nNeeds to be done from the unsummarised data (C_studies)."
  },
  {
    "objectID": "analysis/preprocessing.html#create-descriptive-table-for-the-manuscript-1",
    "href": "analysis/preprocessing.html#create-descriptive-table-for-the-manuscript-1",
    "title": "Preprocessing",
    "section": "Create descriptive table for the manuscript",
    "text": "Create descriptive table for the manuscript\n\nTC &lt;- NULL\nTC$study_n &lt;- length(unique(C_studies$citekey))\nTC$model_n &lt;- nrow(C_studies)\nt&lt;-table(C_studies$model_class_id)\nt2 &lt;- paste0(names(t),': ', as.numeric(t))\nTC$model_types_n &lt;- str_c(t2,collapse = \"\\n\")\nTC$feature_Desc &lt;- paste0('Min=',min(C_studies$feature_n,na.rm = TRUE),', Md=',median(C_studies$feature_n,na.rm = TRUE),', Max=', max(C_studies$feature_n,na.rm = TRUE))\nTC$stimulus_Desc &lt;- paste0('Min=',min(C_studies$stimulus_n,na.rm = TRUE),', Md=',median(C_studies$stimulus_n,na.rm = TRUE),', Max=', max(C_studies$stimulus_n,na.rm = TRUE))\nprint(TC)\n\n$study_n\n[1] 14\n\n$model_n\n[1] 119\n\n$model_types_n\n[1] \"Flexible Discriminants: 37\\nKernel Smoothing, Additive and KNN: 8\\nLinear Methods: 17\\nNeural Nets: 29\\nRandom Forests: 15\\nUnclassified: 13\"\n\n$feature_Desc\n[1] \"Min=3, Md=126, Max=8904\"\n\n$stimulus_Desc\n[1] \"Min=124, Md=387, Max=5192\""
  },
  {
    "objectID": "analysis/preprocessing.html#export-as-csv-1",
    "href": "analysis/preprocessing.html#export-as-csv-1",
    "title": "Preprocessing",
    "section": "Export as csv",
    "text": "Export as csv\n\nif (export_decision == TRUE){\n  write.csv(x = C_studies,file = 'C_studies.csv')\n  write.csv(x = C_summary,file = 'C_summary.csv')\n}"
  },
  {
    "objectID": "etc/Secondary Databases.html",
    "href": "etc/Secondary Databases.html",
    "title": "Secondary Databases",
    "section": "",
    "text": "Secondary Databases\n\n\n\nIndex\nDatabase\nStim. Type\nStim. Dur.\nStim. N\nFeature N.\nPpt. N\nPpt. Expertise\nPpt. Origin\nPpt. Sampling\nPpt. Task\nFeature Source\nFeature Categories\nCitation\n\n\n\n\n1\nEMOPIA\nPiano Solo (pop music)\n30 to 40\n387\n24 (average of 20 MFCC + note length, velocity, beat note density, key)\n4 total, 1 per song (annotators, not ppts)\nnot specified\nnot specified\npresumably researchers\nclassify\nMIDI Toolbox\nRhythm, Harmony, Timbre\nHung et al. (2021)\n\n\n2\nAMG1608\npop\n30\n1608\n72\n643 MTurk, 22 Taiwan subjects\nno restrictions\nMTurk\ncrowdsource\nrate\nMIRToolbox, YAAFE\nTimbre, tonal, spectral, temporal\nChen et al. (2015)\n\n\n3\nNTUMIR\nFamous pop songs\n25\n60\n46\n99 (40 annotations per clip)\nno restrictions\ncampus\nconvenience\nrate\nMIRToolbox, Sound Description Toolbox, MA Toolbox\nMelody/harmony, spectral, temporal, rhythmic, lyrics\nYang et al. (2011)*\n\n\n4\nDEAM\npop\n58 full-length and 1744 45-second excerpts\n1802\n261\nTotal n not specified. Minimum annotations per piece: 2013-14: 10; 2015: 5 MTurk workers\nno restrictions\n2013-14: MTurk; 2015: MTurk and Lab workers\ncrowdsourcing, convenience\nrate\nOpenSMILE\nPitch, Timbre, Voice, Dynamic. Many MFCC features\nAljanaki et al. (2017)\n\n\n5\nMediaEval2013/emoMusic/1000 songs\nwestern pop of various genres\n45\n744\n6670\nmin. 10 per clip (100 qualified workers in final HIT)\nNonexperts (Mturk) + experts\nMTurk\nCrowdsourcing, presumed convenience for experts\nrate\nOpenSMILE\nPitch, Timbre, Voice, Dynamic. Many MFCC features\nSoleymani et al. (2013)\n\n\n6\nSoundtracks\nobscure film soundtracks\n5\n110\nnone?\n116 university students\nnonmusicians\ncampus\nconvenience\nrate, classify\nNA\nNA\nEerola & Vuoskoski (2011)\n\n\n7\nPSIC3839\nChinese popular\nfull? 180 s excerpts extracted for analyses\n3839\nns. About 10 feature categories. Unclear dimensionaltiy\n87\nno restrictions\ncampus\nconvenience\nrate\nLibrosa\nPitch, Timbre, Harmony, Rhythm\nLiang et al. (2022)\n\n\n8\nCH818\nChinese pop\n30\n818\n15\n3\nexperts\nChina\nconvenience\nrate\nMIRToolbox, PsySound, ChromaToolbox,Tempogram Toolbox\nDynamic, Pitch, Rhythm, Timbre, Harmony\nHu & Yang (2017)\n\n\n9\nZhang, Huang, Yang, & Xu (2015)\nChinese pop\n30\n171\n84 (dimensionality)\n10\nNonexperts\nnot specified\nnot specified\nclassify\nMAToolbox, MIRToolbox, Coversongs\nDynamics, Timbre, Rhythm\nZhang et al. 2015\n\n\n10\nPMEmo\nchoruses of top pop songs\nvariable\n794\n65 (260 dims)\n457\n366 Chinese university students (44 music majors); 47 English speakers\ncampus\nconvenience\nrate\nComParE 2013 baseline feature set\nDynamic, Timbre, Pitch (tabulated as energy-related, spectral, voicing related)\nZhang et al. (2018)\n\n\n11\nNJU-V1\nMusic clips (limited detail)\nvariable\n777\nLyric (BoW; 50 dims before filtering), MFCC, spectral contrast, chromagram\nNA (lastfm tags)\nNA\nLastFM\ncrowdsource (webscraping)\nNA\nNA\nLyric, Timbre, Harmony\nXue et al. (2015)\n\n\n12\nISMIR-2012\npopular\n30 or 60\n2904\n54 (means + sds)\nNA (lastfm tags)\nNA\nLastFM\ncrowdsource (webscraping)\nNA\nMIRToolbox\nDynamics, Rhythm, Timbre (they call this Spectral), Harmony\nSong et al. 2012**\n\n\n\n* Dataset not available online\n** Only lyrics & timestamps included in public dataset\n\n\nReferences\n\nAljanaki, A., Yang, Y. H., & Soleymani, M. (2017). Developing a benchmark for emotional analysis of music. PloS one, 12(3), e0173392.\n\n\nChen, Y. A., Yang, Y. H., Wang, J. C., & Chen, H. (2015, April). The AMG1608 dataset for music emotion recognition. In 2015 IEEE international conference on acoustics, speech and signal processing (ICASSP) (pp. 693-697). IEEE.\n\n\nEerola, T. & Vuoskoski, J. K. (2011). A comparison of the discrete and dimensional models of emotion in music. Psychology of Music, 39(1), 18-49. https://doi.org/10.1177/0305735610362821\n\n\nHu, X., & Yang, Y. H. (2017). The mood of Chinese Pop music: Representation and recognition. Journal of the Association for Information Science and Technology, 68(8), 1899-1910.\n\n\nHung, H. T., Ching, J., Doh, S., Kim, N., Nam, J., & Yang, Y. H. (2021). EMOPIA: A multi-modal pop piano dataset for emotion recognition and emotion-based music generation. arXiv preprint arXiv:2108.01374.\n\n\nSoleymani, M., Caro, M. N., Schmidt, E. M., Sha, C. Y., & Yang, Y. H. (2013, October). 1000 songs for emotional analysis of music. In Proceedings of the 2nd ACM international workshop on Crowdsourcing for multimedia (pp. 1-6).\n\n\nXu, L., Yun, Z., Sun, Z., Wen, X., Qin, X., & Qian, X. (2022). PSIC3839: Predicting the Overall Emotion and Depth of Entire Songs. In Design Studies and Intelligence Engineering (pp. 1-9). IOS Press.\n\n\nXue, H., Xue, L., & Su, F. (2015). Multimodal music mood classification by fusion of audio and lyrics. In MultiMedia Modeling: 21st International Conference, MMM 2015, Sydney, NSW, Australia, January 5-7, 2015, Proceedings, Part II 21 (pp. 26-37). Springer International Publishing.\n\n\nZhang, J. L., Huang, X. L., Yang, L. F., Xu, Y., & Sun, S. T. (2017). Feature selection and feature learning in arousal dimension of music emotion by using shrinkage methods. Multimedia systems, 23, 251-264.\n\n\nZhang, K., Zhang, H., Li, S., Yang, C., & Sun, L. (2018, June). The PMEmo dataset for music emotion recognition. In Proceedings of the 2018 acm on international conference on multimedia retrieval (pp. 135-142).\n\n\nSong, Y., Dixon, S., & Pearce, M. T. (2012, October). Evaluation of musical features for emotion classification. In ISMIR (pp. 523-528).\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "preregistration/preregistration.html",
    "href": "preregistration/preregistration.html",
    "title": "metaMER",
    "section": "",
    "text": "This preregistration is made with preregr package from https://preregr.opens.science/ that implements the BMJ published guidance for meta-analysis protocols (Shamseer et al., 2015).\nMeta-analysis Pre-registration: Music Emotion Recognition\n\nSection: Metadata\n\n\n\nTitle\n\n\ntitle\n\n\n\nMusic emotion recognition: Meta-analysis of regression and classification success of emotion ratings from audio\n\n\n\n\n\nContributors\n\n\nauthors\n\n\n\nEerola, T., Anderson, C. J.\n\n\n\n\n\nSubjects\n\n\ntarget_discipline\n\n\n\nmusic cognition, music information retrieval, music psychology\n\n\n\n\n\nTasks and roles\n\n\ntasks_and_roles\n\n\n\nequal contribution\n\n\n\n\nSection: Review methods\n\n\n\nType of review\n\n\ntype_of_review\n\n\n\nMeta-analysis\n\n\n\n\n\nReview stages\n\n\nreview_stages\n\n\n\nSearch, Screening, Extraction, Synthesis\n\n\n\n\n\nCurrent review stage\n\n\ncurrent_stage\n\n\n\nScreening\n\n\n\n\n\nStart date\n\n\nstart_date\n\n\n\n2024-05-15 2024-05-15\n\n\n\n\n\nEnd date\n\n\nend_date\n\n\n\n2024-06-30\n\n\n\n\n\nBackground\n\n\nbackground\n\n\n\nThe aim is to establish the current state of the model success in predicting emotions expressed by music from audio. We will focus on the last 10 years of research and especially the research that has predicted valence and arousal ratings from music audio. No such analysis exists and there are interesting challenges in predicting emotional content of music that relates to specificity of the music and the type of emotions and features used that would benefit from a systematic analysis.\n\n\n\n\n\nPrimary research question(s)\n\n\nprimary_research_question\n\n\n\nTo what degree can arousal and valence ratings of emotions expressed by music be predicted from audio? How are the prediction rates related to genres of music, the type of models used, the type of features, modelling design and cross-validation utilised, and the model complexity and parsimony?\n\n\n\n\n\nSecondary research question(s)\n\n\nsecondary_research_question\n\n\n\nWhat is the prediction rate related to classification of quadrants in the affective circumplex?\n\n\n\n\n\nExpectations / hypotheses\n\n\nexpectations_hypotheses\n\n\n\nPrediction of arousal ratings is generally high and robust, and in terms of the model outcome metrics (correlation), achieves at least r = 0.77 (R square of 0.60). Prediction of valence ratings from audio is more challenging and more context dependent and will achieve generally a lower prediction rate, r = 0.63 (R square 0.40)\n\n\n\n\n\nDependent variable(s) / outcome(s) / main variables\n\n\ndvs_outcomes_main_vars\n\n\n\nRegression model performance will be converted to Pearson correlation coefficients and classification model performance will be converted to Matthews correlation coefficient (MCC) when possible.\n\n\n\n\n\nIndependent variable(s) / intervention(s) / treatment(s)\n\n\nivs_intervention_treatment\n\n\n\nMusic genre, prediction type (linear or classification), feature type (based on prior work by Panda et al., 2020), model complexity (high, medium, low), model validation (exists or not)\n\n\n\n\n\nAdditional variable(s) / covariate(s)\n\n\nadditional_variables\n\n\n\nUnspecified\n\n\n\n\n\nSoftware\n\n\nsoftware\n\n\n\nR and Github repository\n\n\n\n\n\nFunding\n\n\nfunding\n\n\n\nMitacs Globalink Research Award (Mitacs & British High Commission - Ottawa, Canada)\n\n\n\n\n\nConflicts of interest\n\n\ncois\n\n\n\nThere are no identified conflicts of interests.\n\n\n\n\n\nOverlapping authorships\n\n\noverlapping_authorships\n\n\n\nNot applicable\n\n\n\n\nSection: Search strategy\n\n\n\nDatabases\n\n\ndatabases\n\n\n\nWeb of Science, Scopus, and Open Alex\n\n\n\n\n\nInterfaces\n\n\ninterfaces\n\n\n\nWeb of Science, Scopus, and Open Alex\n\n\n\n\n\nGrey literature\n\n\ngrey_literature\n\n\n\nNot included\n\n\n\n\n\nInclusion and exclusion criteria\n\n\ninclusions_exclusion_criteria\n\n\n\nSample, Phenomenon of Interest, Design, Evaluation, Research type\n\n\n\n\n\nQuery strings\n\n\nquery_strings\n\n\n\nScopus: TITLE-ABS-KEY ( valence OR arousal OR classi OR categor OR algorithm AND music  AND emotion AND recognition ) AND PUBYEAR &gt; 2013 AND PUBYEAR &lt; 2025 AND  ( LIMIT-TO ( DOCTYPE , “ar” ) )  Web of science:  (DT=(Article) AND PY=(2014-2025)) AND ALL=(music emotion recognition valence arousal)  Open Alex:  https://openalex.org/works?page=1&filter=default.search%3Amusic%20emotion%20recognition%20valence%20arousal, type%3Atypes%2Farticle,publication_year%3A2014-2024, keywords.id%3Akeywords%2Femotion-recognition, keywords.id%3Akeywords%2Faffective-computing, language%3Alanguages%2Fen, open_access.any_repository_has_fulltext%3Atrue \n\n\n\n\n\nSearch validation procedure\n\n\nsearch_validation_procedure\n\n\n\nManual checking, separate keywords searches\n\n\n\n\n\nOther search strategies\n\n\nother_search_strategies\n\n\n\nNot applied\n\n\n\n\n\nProcedures to contact authors\n\n\nprocedure_for_contacting_authors\n\n\n\nUnspecified\n\n\n\n\n\nResults of contacting authors\n\n\nresults_of_contacting_authors\n\n\n\nNot carried out\n\n\n\n\n\nSearch expiration and repetition\n\n\nsearch_expiration_and_repetition\n\n\n\nSearches were done during the active search period in late May early June 2024 and no repetition is planned.\n\n\n\n\n\nSearch strategy justification\n\n\nsearch_strategy_justification\n\n\n\nThe three major databases should be able yield a robust picture of the topic\n\n\n\n\n\nMiscellaneous search strategy details\n\n\nmisc_search_strategy_details\n\n\n\nNo alternative searches were articulated or envisaged.\n\n\n\n\nSection: Screening\n\n\n\nScreening stages\n\n\nscreening_stages\n\n\n\nWe completed screening using custom fields inserted to the bibtex file and managed with citation managers (jabref and bibdesk). To filter relevant studies, we followed a three-stage screening procedure.  In stage 1, we screened the 553 studies’ titles for relevance, removing irrelevant studies and recording exclusion criteria (see Used exclusion criteria). CA assigned 63 studies to the High Priority based on titles’ relevance, assigned 338 studies to Low Priority based on irrelevant titles, and 152 studies to Medium Priority for additional screening. In stage 2, CA assessed the 152 Medium Priority studies for relevance by screening abstracts. 95 studies’ status changed to Low Priority, whereas 30 studies’ status changed to High Priority. 27 studies remained in the Medium priority category. TE and CA evaluated the remaining 27 studies’, moving 15 to the High Priority Category and 12 to the Medium Priority Category. For studies moved to Low Priority, brief BiBTex comments summarized the rationale for exclusion. In stage 3, TE and CA independently screened Priority 1 studies for relevance, including an include, exclude, or unsure decision in a user-comment BiBTeX field.\n\n\n\n\n\nScreened fields / masking\n\n\nscreened_fields_masking\n\n\n\nWe left authors, titles, publication years, and journal names unmasked.\n\n\n\n\n\nUsed exclusion criteria\n\n\nused_exclusion_criteria\n\n\n\nWe excluded studies according to the following exclusion criteria: soundscapes/vocalisations, non-music audio, video clips, physiological markers, dance, video/movie, physiological/EEG/ECG/MEG/GSR/brain imaging/heart rate/neuroscience/brain studies, sensor data, multimodal, autism, ageing, review/systematic review/overview/survey, face emotion recognition, mental health, music therapy, schizophrenia, memory/emotion factors as IVs, recommender systems, or systems that identify the location of emotional excerpts. We included results from some studies meeting exclusion criteria (e.g., multimodal studies involving physiological measurements) if they reported separately on acoustic-only models.\n\n\n\n\n\nScreener instructions\n\n\nscreener_instructions\n\n\n\nAs described above.\n\n\n\n\n\nScreening reliability\n\n\nscreening_reliability\n\n\n\nIn the pass 1 and 2, we included a quality control check after the pass to discuss the identified categories. In the third pass, we double-coded decisions, resolving discrepancies through discussion.\n\n\n\n\n\nScreening reconciliation procedure\n\n\nscreening_reconciliation_procedure\n\n\n\nWe reconcile discrepancies through discussion, resolving “unsure” votes first, followed by discrepancies in include/exclude decisions between authors Results of this updating procedure are available in the Pass 3 comparison document.\n\n\n\n\n\nSampling and sample size\n\n\nsampling_and_sample_size\n\n\n\nWe identified and retained 553 articles from Scopus, Web of Science, and Open Alex based on the search strategy outlined above. See table at the end that details the cumulative exclusions.\n\n\n\n\n\nScreening procedure justification\n\n\nscreening_procedure_justification\n\n\n\nTo offer a broad summary of music emotion recognition tasks, we attempted to include all studies involving prediction with acoustic features. We performed screening unblinded and determined inclusion/exclusion criteria based on studies’ relevance to the task explored.\n\n\n\n\n\nData management and sharing\n\n\nscreening_data_management_and_sharing\n\n\n\nSources will be shared as (a) BibTeX library(ies) including reviewer notes.\n\n\n\n\n\nMiscellaneous screening details\n\n\nmisc_screening_details\n\n\n\nUnspecified\n\n\n\n\nSection: Extraction\n\n\n\nEntities to extract\n\n\nentities_to_extract\n\n\n\nThese are listed and defined in extraction details.\n\n\n\n\n\nExtraction stages\n\n\nextraction_stages\n\n\n\nThe data extraction will be completed in stages. In the first stage, CA will complete a pass of the collection using our initial entities to extract document. The challenges are discussed and the entities are revised.\n\n\n\n\n\nExtractor instructions\n\n\nextractor_instructions\n\n\n\nSee extraction details.\n\n\n\n\n\nExtractor blinding\n\n\nextractor_blinding\n\n\n\nBlinding was not used.\n\n\n\n\n\nExtraction reliability\n\n\nextraction_reliability\n\n\n\nCA will perform extractions; TE will verify extractions for quality assurance.\n\n\n\n\n\nExtraction reconciliation procedure\n\n\nextraction_reconciliation_procedure\n\n\n\nDiscussion and joint decision for studies where extraction proves to be challenging and issues of interpretation arise.\n\n\n\n\n\nExtraction procedure justification\n\n\nextraction_procedure_justification\n\n\n\nThese are documented in the extraction details.\n\n\n\n\n\nData management and sharing\n\n\nextraction_data_management_and_sharing\n\n\n\nWe retain the information of the studies in shared bibtex files, extraction data will be stored in ascii data files (.bibtex), and the parser for reading the data from .bibtex files to R for the analysis will be available (as quarto/markdown/R files), and all these are managed, structured, shared and documented in Github repository according to FAIR principles.\n\n\n\n\n\nMiscellaneous extraction details\n\n\nmisc_extraction_details\n\n\n\nNA\n\n\n\n\nSection: Synthesis and Quality Assessment\n\n\n\nPlanned data transformations\n\n\nplanned_data_transformations\n\n\n\nFor regression studies, we convert all metrics to Pearson correlation coefficients. For classification studies, we convert the outcomes of classification to Matthews Correlation Coefficient (MCC) from the precision, accuracy, specificity, F1 scores. Alternatively, we use Cohen’s kappa for multiple classes.\n\n\n\n\n\nMissing data\n\n\nmissing_data\n\n\n\nIf no main outcome variables are available, we exclude the study.\n\n\n\n\n\nData validation\n\n\ndata_validation\n\n\n\nNone planned beyond the staged approached already documented in extraction process.\n\n\n\n\n\nQuality assessment\n\n\nquality_assessment\n\n\n\nNot all the bias assessment tools for clinical studies are relevant for our purposes, we adapt the overall approached advocated in [Higgins et al. (2011)] (https://doi.org/10.1136/bmj.d5928).\n\n\n\n\n\nSynthesis plan\n\n\nsynthesis_plan\n\n\n\nWe analyse regression and classification studies separately, and depending on the quantity of the studies forming suitable sub-groupings based on techniques, materials or music collections/genres, we may further synthesise the results across groupings that are formed along these subsets.\n\n\n\n\n\nCriteria for conclusions / inference criteria\n\n\ncriteria_for_conclusions\n\n\n\nNA\n\n\n\n\n\nSynthesist masking\n\n\nsynthesis_masking\n\n\n\nNA\n\n\n\n\n\nSynthesis reliability\n\n\nsynthesis_reliability\n\n\n\nNA\n\n\n\n\n\nSynthesis reconciliation procedure\n\n\nsynthesis_reconciliation_procedure\n\n\n\nNA\n\n\n\n\n\nPublication bias analyses\n\n\npublication_bias\n\n\n\nWe utilise Egger’s test to assess the publication bias and potentially correct the effect size bias by selecting 10% most precise effect sizes as recommended by Van Aert, Wicherts, & Van Assen (2019).\n\n\n\n\n\nSensitivity analyses / robustness checks\n\n\nsensitivity_analysis\n\n\n\nWithin regression and classificiation tasks, we will carry out sensitivity analysis using sub-groups of studied based on type of models, and the type of journal the studies were published in.\n\n\n\n\n\nSynthesis procedure justification\n\n\nsynthesis_procedure_justification\n\n\n\nWe share our justification of the synthesis and the subsetting carried out in the manuscript but we have not formulated these in advance except for synthesizing classiciation and regression approaches separately and creating subsets within these approaches according to techniques and datasets utilised.\n\n\n\n\n\nSynthesis data management and sharing\n\n\nsynthesis_data_management_and_sharing\n\n\n\nWe share the data, procedures, definitions, the analysis scripts with the outcomes as R code in Quarto notes at Github.\n\n\n\n\n\nMiscellaneous synthesis details\n\n\nmisc_synthesis_details\n\n\n\nUnspecified"
  },
  {
    "objectID": "preregistration/preregistration.html#preregr-prereg-spec-Ya8oq9lMLd",
    "href": "preregistration/preregistration.html#preregr-prereg-spec-Ya8oq9lMLd",
    "title": "metaMER",
    "section": "Meta-analysis Pre-registration: Music Emotion Recognition",
    "text": "Meta-analysis Pre-registration: Music Emotion Recognition\n\nSection: Metadata\n\n\n\nTitle\n\n\ntitle\n\n\n\nMusic emotion recognition: Meta-analysis of regression and classification success of emotion ratings from audio\n\n\n\n\n\nContributors\n\n\nauthors\n\n\n\nEerola, T., Anderson, C. J.\n\n\n\n\n\nSubjects\n\n\ntarget_discipline\n\n\n\nmusic cognition, music information retrieval, music psychology\n\n\n\n\n\nTasks and roles\n\n\ntasks_and_roles\n\n\n\nequal contribution\n\n\n\n\nSection: Review methods\n\n\n\nType of review\n\n\ntype_of_review\n\n\n\nMeta-analysis\n\n\n\n\n\nReview stages\n\n\nreview_stages\n\n\n\nSearch, Screening, Extraction, Synthesis\n\n\n\n\n\nCurrent review stage\n\n\ncurrent_stage\n\n\n\nScreening\n\n\n\n\n\nStart date\n\n\nstart_date\n\n\n\n2024-05-15 2024-05-15\n\n\n\n\n\nEnd date\n\n\nend_date\n\n\n\n2024-06-30\n\n\n\n\n\nBackground\n\n\nbackground\n\n\n\nThe aim is to establish the current state of the model success in predicting emotions expressed by music from audio. We will focus on the last 10 years of research and especially the research that has predicted valence and arousal ratings from music audio. No such analysis exists and there are interesting challenges in predicting emotional content of music that relates to specificity of the music and the type of emotions and features used that would benefit from a systematic analysis.\n\n\n\n\n\nPrimary research question(s)\n\n\nprimary_research_question\n\n\n\nTo what degree can arousal and valence ratings of emotions expressed by music be predicted from audio? How are the prediction rates related to genres of music, the type of models used, the type of features, modelling design and cross-validation utilised, and the model complexity and parsimony?\n\n\n\n\n\nSecondary research question(s)\n\n\nsecondary_research_question\n\n\n\nWhat is the prediction rate related to classification of quadrants in the affective circumplex?\n\n\n\n\n\nExpectations / hypotheses\n\n\nexpectations_hypotheses\n\n\n\nPrediction of arousal ratings is generally high and robust, and in terms of the model outcome metrics (correlation), achieves at least r = 0.77 (R square of 0.60). Prediction of valence ratings from audio is more challenging and more context dependent and will achieve generally a lower prediction rate, r = 0.63 (R square 0.40)\n\n\n\n\n\nDependent variable(s) / outcome(s) / main variables\n\n\ndvs_outcomes_main_vars\n\n\n\nRegression model performance will be converted to Pearson correlation coefficients and classification model performance will be converted to Matthews correlation coefficient (MCC) when possible.\n\n\n\n\n\nIndependent variable(s) / intervention(s) / treatment(s)\n\n\nivs_intervention_treatment\n\n\n\nMusic genre, prediction type (linear or classification), feature type (based on prior work by Panda et al., 2020), model complexity (high, medium, low), model validation (exists or not)\n\n\n\n\n\nAdditional variable(s) / covariate(s)\n\n\nadditional_variables\n\n\n\nUnspecified\n\n\n\n\n\nSoftware\n\n\nsoftware\n\n\n\nR and Github repository\n\n\n\n\n\nFunding\n\n\nfunding\n\n\n\nMitacs Globalink Research Award (Mitacs & British High Commission - Ottawa, Canada)\n\n\n\n\n\nConflicts of interest\n\n\ncois\n\n\n\nThere are no identified conflicts of interests.\n\n\n\n\n\nOverlapping authorships\n\n\noverlapping_authorships\n\n\n\nNot applicable\n\n\n\n\nSection: Search strategy\n\n\n\nDatabases\n\n\ndatabases\n\n\n\nWeb of Science, Scopus, and Open Alex\n\n\n\n\n\nInterfaces\n\n\ninterfaces\n\n\n\nWeb of Science, Scopus, and Open Alex\n\n\n\n\n\nGrey literature\n\n\ngrey_literature\n\n\n\nNot included\n\n\n\n\n\nInclusion and exclusion criteria\n\n\ninclusions_exclusion_criteria\n\n\n\nSample, Phenomenon of Interest, Design, Evaluation, Research type\n\n\n\n\n\nQuery strings\n\n\nquery_strings\n\n\n\nScopus: TITLE-ABS-KEY ( valence OR arousal OR classi OR categor OR algorithm AND music  AND emotion AND recognition ) AND PUBYEAR &gt; 2013 AND PUBYEAR &lt; 2025 AND  ( LIMIT-TO ( DOCTYPE , “ar” ) )  Web of science:  (DT=(Article) AND PY=(2014-2025)) AND ALL=(music emotion recognition valence arousal)  Open Alex:  https://openalex.org/works?page=1&filter=default.search%3Amusic%20emotion%20recognition%20valence%20arousal, type%3Atypes%2Farticle,publication_year%3A2014-2024, keywords.id%3Akeywords%2Femotion-recognition, keywords.id%3Akeywords%2Faffective-computing, language%3Alanguages%2Fen, open_access.any_repository_has_fulltext%3Atrue \n\n\n\n\n\nSearch validation procedure\n\n\nsearch_validation_procedure\n\n\n\nManual checking, separate keywords searches\n\n\n\n\n\nOther search strategies\n\n\nother_search_strategies\n\n\n\nNot applied\n\n\n\n\n\nProcedures to contact authors\n\n\nprocedure_for_contacting_authors\n\n\n\nUnspecified\n\n\n\n\n\nResults of contacting authors\n\n\nresults_of_contacting_authors\n\n\n\nNot carried out\n\n\n\n\n\nSearch expiration and repetition\n\n\nsearch_expiration_and_repetition\n\n\n\nSearches were done during the active search period in late May early June 2024 and no repetition is planned.\n\n\n\n\n\nSearch strategy justification\n\n\nsearch_strategy_justification\n\n\n\nThe three major databases should be able yield a robust picture of the topic\n\n\n\n\n\nMiscellaneous search strategy details\n\n\nmisc_search_strategy_details\n\n\n\nNo alternative searches were articulated or envisaged.\n\n\n\n\nSection: Screening\n\n\n\nScreening stages\n\n\nscreening_stages\n\n\n\nWe completed screening using custom fields inserted to the bibtex file and managed with citation managers (jabref and bibdesk). To filter relevant studies, we followed a three-stage screening procedure.  In stage 1, we screened the 553 studies’ titles for relevance, removing irrelevant studies and recording exclusion criteria (see Used exclusion criteria). CA assigned 63 studies to the High Priority based on titles’ relevance, assigned 338 studies to Low Priority based on irrelevant titles, and 152 studies to Medium Priority for additional screening. In stage 2, CA assessed the 152 Medium Priority studies for relevance by screening abstracts. 95 studies’ status changed to Low Priority, whereas 30 studies’ status changed to High Priority. 27 studies remained in the Medium priority category. TE and CA evaluated the remaining 27 studies’, moving 15 to the High Priority Category and 12 to the Medium Priority Category. For studies moved to Low Priority, brief BiBTex comments summarized the rationale for exclusion. In stage 3, TE and CA independently screened Priority 1 studies for relevance, including an include, exclude, or unsure decision in a user-comment BiBTeX field.\n\n\n\n\n\nScreened fields / masking\n\n\nscreened_fields_masking\n\n\n\nWe left authors, titles, publication years, and journal names unmasked.\n\n\n\n\n\nUsed exclusion criteria\n\n\nused_exclusion_criteria\n\n\n\nWe excluded studies according to the following exclusion criteria: soundscapes/vocalisations, non-music audio, video clips, physiological markers, dance, video/movie, physiological/EEG/ECG/MEG/GSR/brain imaging/heart rate/neuroscience/brain studies, sensor data, multimodal, autism, ageing, review/systematic review/overview/survey, face emotion recognition, mental health, music therapy, schizophrenia, memory/emotion factors as IVs, recommender systems, or systems that identify the location of emotional excerpts. We included results from some studies meeting exclusion criteria (e.g., multimodal studies involving physiological measurements) if they reported separately on acoustic-only models.\n\n\n\n\n\nScreener instructions\n\n\nscreener_instructions\n\n\n\nAs described above.\n\n\n\n\n\nScreening reliability\n\n\nscreening_reliability\n\n\n\nIn the pass 1 and 2, we included a quality control check after the pass to discuss the identified categories. In the third pass, we double-coded decisions, resolving discrepancies through discussion.\n\n\n\n\n\nScreening reconciliation procedure\n\n\nscreening_reconciliation_procedure\n\n\n\nWe reconcile discrepancies through discussion, resolving “unsure” votes first, followed by discrepancies in include/exclude decisions between authors Results of this updating procedure are available in the Pass 3 comparison document.\n\n\n\n\n\nSampling and sample size\n\n\nsampling_and_sample_size\n\n\n\nWe identified and retained 553 articles from Scopus, Web of Science, and Open Alex based on the search strategy outlined above. See table at the end that details the cumulative exclusions.\n\n\n\n\n\nScreening procedure justification\n\n\nscreening_procedure_justification\n\n\n\nTo offer a broad summary of music emotion recognition tasks, we attempted to include all studies involving prediction with acoustic features. We performed screening unblinded and determined inclusion/exclusion criteria based on studies’ relevance to the task explored.\n\n\n\n\n\nData management and sharing\n\n\nscreening_data_management_and_sharing\n\n\n\nSources will be shared as (a) BibTeX library(ies) including reviewer notes.\n\n\n\n\n\nMiscellaneous screening details\n\n\nmisc_screening_details\n\n\n\nUnspecified\n\n\n\n\nSection: Extraction\n\n\n\nEntities to extract\n\n\nentities_to_extract\n\n\n\nThese are listed and defined in extraction details.\n\n\n\n\n\nExtraction stages\n\n\nextraction_stages\n\n\n\nThe data extraction will be completed in stages. In the first stage, CA will complete a pass of the collection using our initial entities to extract document. The challenges are discussed and the entities are revised.\n\n\n\n\n\nExtractor instructions\n\n\nextractor_instructions\n\n\n\nSee extraction details.\n\n\n\n\n\nExtractor blinding\n\n\nextractor_blinding\n\n\n\nBlinding was not used.\n\n\n\n\n\nExtraction reliability\n\n\nextraction_reliability\n\n\n\nCA will perform extractions; TE will verify extractions for quality assurance.\n\n\n\n\n\nExtraction reconciliation procedure\n\n\nextraction_reconciliation_procedure\n\n\n\nDiscussion and joint decision for studies where extraction proves to be challenging and issues of interpretation arise.\n\n\n\n\n\nExtraction procedure justification\n\n\nextraction_procedure_justification\n\n\n\nThese are documented in the extraction details.\n\n\n\n\n\nData management and sharing\n\n\nextraction_data_management_and_sharing\n\n\n\nWe retain the information of the studies in shared bibtex files, extraction data will be stored in ascii data files (.bibtex), and the parser for reading the data from .bibtex files to R for the analysis will be available (as quarto/markdown/R files), and all these are managed, structured, shared and documented in Github repository according to FAIR principles.\n\n\n\n\n\nMiscellaneous extraction details\n\n\nmisc_extraction_details\n\n\n\nNA\n\n\n\n\nSection: Synthesis and Quality Assessment\n\n\n\nPlanned data transformations\n\n\nplanned_data_transformations\n\n\n\nFor regression studies, we convert all metrics to Pearson correlation coefficients. For classification studies, we convert the outcomes of classification to Matthews Correlation Coefficient (MCC) from the precision, accuracy, specificity, F1 scores. Alternatively, we use Cohen’s kappa for multiple classes.\n\n\n\n\n\nMissing data\n\n\nmissing_data\n\n\n\nIf no main outcome variables are available, we exclude the study.\n\n\n\n\n\nData validation\n\n\ndata_validation\n\n\n\nNone planned beyond the staged approached already documented in extraction process.\n\n\n\n\n\nQuality assessment\n\n\nquality_assessment\n\n\n\nNot all the bias assessment tools for clinical studies are relevant for our purposes, we adapt the overall approached advocated in [Higgins et al. (2011)] (https://doi.org/10.1136/bmj.d5928).\n\n\n\n\n\nSynthesis plan\n\n\nsynthesis_plan\n\n\n\nWe analyse regression and classification studies separately, and depending on the quantity of the studies forming suitable sub-groupings based on techniques, materials or music collections/genres, we may further synthesise the results across groupings that are formed along these subsets.\n\n\n\n\n\nCriteria for conclusions / inference criteria\n\n\ncriteria_for_conclusions\n\n\n\nNA\n\n\n\n\n\nSynthesist masking\n\n\nsynthesis_masking\n\n\n\nNA\n\n\n\n\n\nSynthesis reliability\n\n\nsynthesis_reliability\n\n\n\nNA\n\n\n\n\n\nSynthesis reconciliation procedure\n\n\nsynthesis_reconciliation_procedure\n\n\n\nNA\n\n\n\n\n\nPublication bias analyses\n\n\npublication_bias\n\n\n\nWe utilise Egger’s test to assess the publication bias and potentially correct the effect size bias by selecting 10% most precise effect sizes as recommended by Van Aert, Wicherts, & Van Assen (2019).\n\n\n\n\n\nSensitivity analyses / robustness checks\n\n\nsensitivity_analysis\n\n\n\nWithin regression and classificiation tasks, we will carry out sensitivity analysis using sub-groups of studied based on type of models, and the type of journal the studies were published in.\n\n\n\n\n\nSynthesis procedure justification\n\n\nsynthesis_procedure_justification\n\n\n\nWe share our justification of the synthesis and the subsetting carried out in the manuscript but we have not formulated these in advance except for synthesizing classiciation and regression approaches separately and creating subsets within these approaches according to techniques and datasets utilised.\n\n\n\n\n\nSynthesis data management and sharing\n\n\nsynthesis_data_management_and_sharing\n\n\n\nWe share the data, procedures, definitions, the analysis scripts with the outcomes as R code in Quarto notes at Github.\n\n\n\n\n\nMiscellaneous synthesis details\n\n\nmisc_synthesis_details\n\n\n\nUnspecified"
  },
  {
    "objectID": "preregistration/preregistration.html#references",
    "href": "preregistration/preregistration.html#references",
    "title": "metaMER",
    "section": "References",
    "text": "References\n\nHiggins, J. P. T., Altman, D. G., Gøtzsche, P. C., Jüni, P., Moher, D., Oxman, A. D., Savović, J., Schulz, K. F., Weeks, L., & Sterne, J. A. C. (2011). The Cochrane Collaboration tool for assessing risk of bias in randomised trials. BMJ, 343. https://www.bmj.com/content/343/bmj.d5928\nPanda, R., Malheiro, R., & Paiva, R. P. (2020). Audio features for music emotion recognition: a survey. IEEE Transactions on Affective Computing, 14(1), 68-88. https://doi.org/10.1109/TAFFC.2020.3032373\nShamseer, L., Moher, D., Clarke, M., Ghersi, D., Liberati, A., Petticrew, M., Shekelle, P., & Stewart, L. A. (2015). Preferred reporting items for systematic review and meta-analysis protocols (PRISMA-P) 2015: elaboration and explanation. BMJ, 349. https://www.bmj.com/content/349/bmj.g7647"
  },
  {
    "objectID": "studies/extraction_details.html",
    "href": "studies/extraction_details.html",
    "title": "Extraction Details",
    "section": "",
    "text": "To capture relevant information from studies, we expanded BiBTeX fields for each study with additional fields. For reproducibility, these instructions provide information on the process followed for each field."
  },
  {
    "objectID": "studies/extraction_details.html#identifier",
    "href": "studies/extraction_details.html#identifier",
    "title": "Extraction Details",
    "section": "IDENTIFIER",
    "text": "IDENTIFIER\nUnique identifier of article. Contains last name of lead author, year of publication and first two letters of article title. Hyphenated last names collapsed."
  },
  {
    "objectID": "studies/extraction_details.html#author",
    "href": "studies/extraction_details.html#author",
    "title": "Extraction Details",
    "section": "AUTHOR",
    "text": "AUTHOR\nNames of all authors. Last name precedes first name and separated by comma. For multiple authors “and” precedes each listed subsequent author. E.g., Sorussa, Kanawat and Choksuriwong, Anant and Karnjanadecha, Montri"
  },
  {
    "objectID": "studies/extraction_details.html#journal",
    "href": "studies/extraction_details.html#journal",
    "title": "Extraction Details",
    "section": "JOURNAL",
    "text": "JOURNAL\nTitle of journal containing article."
  },
  {
    "objectID": "studies/extraction_details.html#note",
    "href": "studies/extraction_details.html#note",
    "title": "Extraction Details",
    "section": "NOTE",
    "text": "NOTE\nIncludes number of citing articles and open access details. E.g., Cited by: 4; All Open Access, Gold Open Access, Green Open Access"
  },
  {
    "objectID": "studies/extraction_details.html#title",
    "href": "studies/extraction_details.html#title",
    "title": "Extraction Details",
    "section": "TITLE",
    "text": "TITLE\nTitle of article."
  },
  {
    "objectID": "studies/extraction_details.html#volume",
    "href": "studies/extraction_details.html#volume",
    "title": "Extraction Details",
    "section": "VOLUME",
    "text": "VOLUME\nVolume number of publication."
  },
  {
    "objectID": "studies/extraction_details.html#year",
    "href": "studies/extraction_details.html#year",
    "title": "Extraction Details",
    "section": "YEAR",
    "text": "YEAR\nPublication year."
  },
  {
    "objectID": "studies/extraction_details.html#doi",
    "href": "studies/extraction_details.html#doi",
    "title": "Extraction Details",
    "section": "DOI",
    "text": "DOI\nDigital object identifier of article."
  },
  {
    "objectID": "studies/extraction_details.html#abstract",
    "href": "studies/extraction_details.html#abstract",
    "title": "Extraction Details",
    "section": "ABSTRACT",
    "text": "ABSTRACT\nComplete text of article abstract."
  },
  {
    "objectID": "studies/extraction_details.html#source",
    "href": "studies/extraction_details.html#source",
    "title": "Extraction Details",
    "section": "SOURCE",
    "text": "SOURCE\nDatabase article was sourced from. Scopus, Web of Science (WoS) or OpenAlex."
  },
  {
    "objectID": "studies/extraction_details.html#author_keywords",
    "href": "studies/extraction_details.html#author_keywords",
    "title": "Extraction Details",
    "section": "AUTHOR_KEYWORDS",
    "text": "AUTHOR_KEYWORDS\nCorresponding keywords for article indicated by author."
  },
  {
    "objectID": "studies/extraction_details.html#notes_authorinitials",
    "href": "studies/extraction_details.html#notes_authorinitials",
    "title": "Extraction Details",
    "section": "NOTES_AUTHORINITIALS",
    "text": "NOTES_AUTHORINITIALS\nDecision and comments by respective author"
  },
  {
    "objectID": "studies/extraction_details.html#stimulus_type",
    "href": "studies/extraction_details.html#stimulus_type",
    "title": "Extraction Details",
    "section": "STIMULUS_TYPE",
    "text": "STIMULUS_TYPE\nMetadata pertaining to stimuli employed in paradigm. Can be listed as genres of music stimuli employed, or if stimuli come from a standard database, name of standard."
  },
  {
    "objectID": "studies/extraction_details.html#stimulus_duration",
    "href": "studies/extraction_details.html#stimulus_duration",
    "title": "Extraction Details",
    "section": "STIMULUS_DURATION",
    "text": "STIMULUS_DURATION\nDuration of stimuli, if applicable. Unit of measurement (seconds, measures) specified in STIMULUS_DURATION_UNIT"
  },
  {
    "objectID": "studies/extraction_details.html#stimulus_duration_unit",
    "href": "studies/extraction_details.html#stimulus_duration_unit",
    "title": "Extraction Details",
    "section": "STIMULUS_DURATION_UNIT",
    "text": "STIMULUS_DURATION_UNIT\nUnit of measurement pertaining to STIMULUS_DURATION. E.g., seconds, measures, etc."
  },
  {
    "objectID": "studies/extraction_details.html#stimulus_n",
    "href": "studies/extraction_details.html#stimulus_n",
    "title": "Extraction Details",
    "section": "STIMULUS_N",
    "text": "STIMULUS_N\nNumber of stimuli employed in experiment. If multiple experimental conditions reported, separate \\(n\\) by conditions where possible."
  },
  {
    "objectID": "studies/extraction_details.html#feature_n",
    "href": "studies/extraction_details.html#feature_n",
    "title": "Extraction Details",
    "section": "FEATURE_N",
    "text": "FEATURE_N\nNumber of features included in data modeling (if available)."
  },
  {
    "objectID": "studies/extraction_details.html#participant_n",
    "href": "studies/extraction_details.html#participant_n",
    "title": "Extraction Details",
    "section": "PARTICIPANT_N",
    "text": "PARTICIPANT_N\nTotal number of participants in experiment."
  },
  {
    "objectID": "studies/extraction_details.html#participant_expertise",
    "href": "studies/extraction_details.html#participant_expertise",
    "title": "Extraction Details",
    "section": "PARTICIPANT_EXPERTISE",
    "text": "PARTICIPANT_EXPERTISE\nExpertise of annotators. E.g., experts, non-experts, not specified."
  },
  {
    "objectID": "studies/extraction_details.html#participant_origin",
    "href": "studies/extraction_details.html#participant_origin",
    "title": "Extraction Details",
    "section": "PARTICIPANT_ORIGIN",
    "text": "PARTICIPANT_ORIGIN\nOrigin country of participants, or online platform participants were recruited from (e.g., MTurk)"
  },
  {
    "objectID": "studies/extraction_details.html#participant_sampling",
    "href": "studies/extraction_details.html#participant_sampling",
    "title": "Extraction Details",
    "section": "PARTICIPANT_SAMPLING",
    "text": "PARTICIPANT_SAMPLING\nHow participants were recruited (e.g., convenience, random sampling, crowdsourcing)"
  },
  {
    "objectID": "studies/extraction_details.html#participant_task",
    "href": "studies/extraction_details.html#participant_task",
    "title": "Extraction Details",
    "section": "PARTICIPANT_TASK",
    "text": "PARTICIPANT_TASK\nNature of rating/classification task undertaken by participants. E.g., rate, annotate."
  },
  {
    "objectID": "studies/extraction_details.html#feature_categories",
    "href": "studies/extraction_details.html#feature_categories",
    "title": "Extraction Details",
    "section": "FEATURE_CATEGORIES",
    "text": "FEATURE_CATEGORIES\nNames of categories analyzed features pertain to, based on names in Panda (2021). Includes names of all pertinent categories: Melody, Rhythm, Timbre, Pitch, Tonality, Expressivity, Texture, Form, Vocal, High-Level"
  },
  {
    "objectID": "studies/extraction_details.html#feature_source",
    "href": "studies/extraction_details.html#feature_source",
    "title": "Extraction Details",
    "section": "FEATURE_SOURCE",
    "text": "FEATURE_SOURCE\nName(s) of feature analysis toolbox(es)."
  },
  {
    "objectID": "studies/extraction_details.html#feature_reduction_method",
    "href": "studies/extraction_details.html#feature_reduction_method",
    "title": "Extraction Details",
    "section": "FEATURE_REDUCTION_METHOD",
    "text": "FEATURE_REDUCTION_METHOD\nName(s) of feature reduction or feature selection methods employed."
  },
  {
    "objectID": "studies/extraction_details.html#model_category",
    "href": "studies/extraction_details.html#model_category",
    "title": "Extraction Details",
    "section": "MODEL_CATEGORY",
    "text": "MODEL_CATEGORY\nName of model type (regression, classification, or both)."
  },
  {
    "objectID": "studies/extraction_details.html#model_detail",
    "href": "studies/extraction_details.html#model_detail",
    "title": "Extraction Details",
    "section": "MODEL_DETAIL",
    "text": "MODEL_DETAIL\nAdditional information pertaining to predictive model, such as the name of algorithm used and other pertinent parameters. E.g., Random Forest, Commonality Analysis, Multiple Regression, Neural Networks, LDSM."
  },
  {
    "objectID": "studies/extraction_details.html#model_measure",
    "href": "studies/extraction_details.html#model_measure",
    "title": "Extraction Details",
    "section": "MODEL_MEASURE",
    "text": "MODEL_MEASURE\nMetric used in model evaluation. E.g., \\(R^2\\), \\(MSE\\), \\(CCC\\), Classification accuracy, etc."
  },
  {
    "objectID": "studies/extraction_details.html#model_complexity_parameters",
    "href": "studies/extraction_details.html#model_complexity_parameters",
    "title": "Extraction Details",
    "section": "MODEL_COMPLEXITY_PARAMETERS",
    "text": "MODEL_COMPLEXITY_PARAMETERS\nAdditional information pertaining to predictive model. E.g., training epochs: 100; n layers: 1, 2; LSTM units: 124,248."
  },
  {
    "objectID": "studies/extraction_details.html#model_rate_emotion_names",
    "href": "studies/extraction_details.html#model_rate_emotion_names",
    "title": "Extraction Details",
    "section": "MODEL_RATE_EMOTION_NAMES",
    "text": "MODEL_RATE_EMOTION_NAMES\nNames of predicted emotions. E.g., valence, arousal, happy, sad, angry, fearful, etc."
  },
  {
    "objectID": "studies/extraction_details.html#model_rate_emotion_values",
    "href": "studies/extraction_details.html#model_rate_emotion_values",
    "title": "Extraction Details",
    "section": "MODEL_RATE_EMOTION_VALUES",
    "text": "MODEL_RATE_EMOTION_VALUES\nPertinent prediction of model summaries. Report as R named arrays, including summary statistics in variables. When reporting results of multiple models, concatenate multiple entries with bind_field. When reporting results for different toolboxes or feature subsets, assign each to a new BiBTeX field with relevant identifier following final underscore. See additional details below."
  },
  {
    "objectID": "studies/extraction_details.html#model_validation",
    "href": "studies/extraction_details.html#model_validation",
    "title": "Extraction Details",
    "section": "MODEL_VALIDATION",
    "text": "MODEL_VALIDATION\nValidation method used (if applicable). E.g., 10-fold cross validation, leave one out cross validation."
  },
  {
    "objectID": "studies/extraction_details.html#classification",
    "href": "studies/extraction_details.html#classification",
    "title": "Extraction Details",
    "section": "Classification",
    "text": "Classification\nConfusion matrices can be encoded using the unflatten function, which assigns relevant meta-parameters to the model_parameters attribute of the output matrix. The function automatically builds a \\(n\\) by \\(n\\) matrix and takes individual values as arguments. Values can be specified for the first row, and are recycled in subsequent rows.\nunflatten(A = .5, B = .2, C = .3,\n          .3, .5, .2,\n          .1, .1, .8)\nSummary parameters can be extracted from the resulting matrix by calling the summarize_matrix function. This function calls on caret to extract several summary statistics at once. Including bind_field in the call ensures consistent nomenclature with other study encodings.\nbind_field(\n  'library.model.features.data.exp' = summarize_matrix(\n    unflatten(Q1=185.85,Q2=14.4,Q3=8.6,Q4=18.15,\n              23.95,190.55,7,3.5,\n              14.2,8.4,157.25,45.15,\n              24.35,1.65,45.85,153.15)\n  )\n)\nMultiple matrices in a study can be summarized by putting them in a list and using the lapply function to extract relevant statistics:\nbind_field(\n  lapply(\n    list(\n      'library.model.features.data.exp1' = unflatten(\n        Angry=.984,Happy=.007,Relax=.007,Sad=0,\n        0,.987,0,.007,\n        .008,.007,.987,0,\n        .008,0,.007,.993\n        ),\n      'library.model.features.data.exp2' = unflatten(\n        Angry=.976,Happy=.013,Relax=.014,Sad=0,\n        .008,.967,0,.02,\n        .008,.013,.98,.007,\n        .008,.007,.007,.974\n       )\n      ),\n    summarize_matrix\n  )\n)\nWhen confusion matrices are not available, encode available parameters (accuracy, precision, recall, \\(F\\) scores, etc.) using the standard nomenclature to distinguish relevant outcomes for each class:\nbind_field(\nlibrary.model.features.data.experiment = c(class_measure.summaryStat = 0, ...),\n...\n)"
  },
  {
    "objectID": "studies/library_formatter.html#load-libraries",
    "href": "studies/library_formatter.html#load-libraries",
    "title": "Library Formatter",
    "section": "Load libraries",
    "text": "Load libraries\n\n# load dplyr\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union"
  },
  {
    "objectID": "studies/library_formatter.html#read-data",
    "href": "studies/library_formatter.html#read-data",
    "title": "Library Formatter",
    "section": "Read data",
    "text": "Read data\n\n# read in bibtex library as data frame\nbib_df_ca &lt;- bib2df::bib2df(paste0(here::here(),\n                                   \"/studies/bib/Passes/\", \n                                   \"metaMER_library_third_pass_ca.bib\")\n)\n\nSome BibTeX entries may have been dropped.\n            The result could be malformed.\n            Review the .bib file and make sure every single entry starts\n            with a '@'.\n\n\nColumn `YEAR` contains character strings.\n              No coercion to numeric applied.\n\nbib_df_te &lt;- bib2df::bib2df(paste0(here::here(),\n                                   \"/studies/bib/Passes/\", \n                                   \"metaMER_library_third_pass_te.bib\")\n)\n\nSome BibTeX entries may have been dropped.\n            The result could be malformed.\n            Review the .bib file and make sure every single entry starts\n            with a '@'.\nColumn `YEAR` contains character strings.\n              No coercion to numeric applied.\n\nbib_df_ca &lt;- dplyr::filter(bib_df_ca,PRIORITY=='prio1')\nbib_df_te &lt;- dplyr::filter(bib_df_te,PRIORITY=='prio1')\nsum(bib_df_ca$BIBTEXKEY %in% bib_df_te$BIBTEXKEY)==nrow(bib_df_ca)\n\n[1] TRUE"
  },
  {
    "objectID": "studies/library_formatter.html#identify-sources",
    "href": "studies/library_formatter.html#identify-sources",
    "title": "Library Formatter",
    "section": "Identify sources",
    "text": "Identify sources\n\n# filter open_alex entries and declare source (c1 unique to database)\nbib_df_ca %&gt;% \n  filter(!is.na(C1)) %&gt;%\n  mutate(SOURCE = 'open_alex') -&gt; oa_entries\n\n# filter wos entries and declare source (unique_id unique to database)\nbib_df_ca %&gt;% \n  filter(!is.na(UNIQUE.ID)) %&gt;%\n  mutate(SOURCE = 'web_of_science') -&gt; wos_entries\n\n# filter scopus entries\nbib_df_ca %&gt;% \n  filter(SOURCE == 'Scopus') -&gt; scopus_entries\n\nscopus_entries$JOURNAL &lt;- scopus_entries$JOURNALTITLE\nscopus_entries$JOURNALTITLE &lt;- NA\n\n# bind sources\nbib_df_ca &lt;- rbind(oa_entries, wos_entries)\nbib_df_ca &lt;- rbind(bib_df_ca, scopus_entries)"
  },
  {
    "objectID": "studies/library_formatter.html#clean-up-entries",
    "href": "studies/library_formatter.html#clean-up-entries",
    "title": "Library Formatter",
    "section": "Clean up entries",
    "text": "Clean up entries\n\n# remove columns only belonging to one database\nbib_df_ca$UNIQUE.ID &lt;- NULL\nbib_df_ca$C1 &lt;- NULL\n# remove unnecessary column\nbib_df_ca$HASABSTRACT &lt;- NULL\n# relevel priority column with intuitive names\n# bib_df_ca$PRIORITY &lt;- as.factor(bib_df_ca$PRIORITY)\n#levels(bib_df_ca$PRIORITY) &lt;- c('high_priority', 'low_priority')\n# bib_df_ca$PRIORITY &lt;- plyr::revalue(bib_df_ca$PRIORITY, \n#                                     c(prio1 = 'high_priority',\n#                                       prio3 = 'low_prioirty'))\n# make casing consistent\nbib_df_ca$SOURCE &lt;- tolower(bib_df_ca$SOURCE)\n# consistent names for private notes\nnames(bib_df_ca)[names(bib_df_ca) == 'COMMENT.CAMJA'] &lt;- 'NOTES.CA'\n# after subsetting out high-priority studies, no longer need priority column\nbib_df_ca$PRIORITY &lt;- NULL\nbib_df_ca$RANKING &lt;- NULL\nbib_df_ca$MODIFICATIONDATE &lt;- NULL"
  },
  {
    "objectID": "studies/library_formatter.html#add-comments-from-second-reviewer",
    "href": "studies/library_formatter.html#add-comments-from-second-reviewer",
    "title": "Library Formatter",
    "section": "Add comments from second reviewer",
    "text": "Add comments from second reviewer\n\n# select bibkey (for merge) and notes from second reviewer\nbib_df_te &lt;- bib_df_te %&gt;% select(BIBTEXKEY, NOTES.TE)\n\nbib_df_merged &lt;- merge(bib_df_ca, \n                       bib_df_te, \n                       by = c('BIBTEXKEY'))"
  },
  {
    "objectID": "studies/library_formatter.html#drop-empty-columns",
    "href": "studies/library_formatter.html#drop-empty-columns",
    "title": "Library Formatter",
    "section": "Drop empty columns",
    "text": "Drop empty columns\n\n# identify columns entirely empty\nempty_cols &lt;- sapply(bib_df_merged, function(x) {\n  all(is.na(x))\n  }\n) \n# remove them\nbib_df_merged &lt;- bib_df_merged[ , !empty_cols]"
  },
  {
    "objectID": "studies/library_formatter.html#rewrite-bibtex-library",
    "href": "studies/library_formatter.html#rewrite-bibtex-library",
    "title": "Library Formatter",
    "section": "Rewrite BiBTeX library",
    "text": "Rewrite BiBTeX library\n\ndim(bib_df_merged)\n\n[1] 96 37\n\nbib2df::df2bib(bib_df_merged, file = 'metaMER_library_third_pass_clean.bib')"
  },
  {
    "objectID": "studies/library_formatter.html#next",
    "href": "studies/library_formatter.html#next",
    "title": "Library Formatter",
    "section": "Next",
    "text": "Next\nCompare pass 3 annotations and resolve conflicts (pass 3 comparison.qmd)"
  },
  {
    "objectID": "studies/library_parser.html",
    "href": "studies/library_parser.html",
    "title": "Library Parser",
    "section": "",
    "text": "Status: in progress.\nTODO:\n- Separate scripts and functions into separate .qmd files/directories.\n- Update model_rate_emotion_values nomenclature process for classification papers.\n- Replace rbind with custom bind function throughout"
  },
  {
    "objectID": "studies/library_parser.html#preparing-data",
    "href": "studies/library_parser.html#preparing-data",
    "title": "Library Parser",
    "section": "Preparing data",
    "text": "Preparing data\nThe follow code extracts information from the .bib library to format it as a data.frame for further processing. The code makes use of the stringr package and uses regular expressions to extract relevant parameters. First we read in the .bib file and use some string manipulations to retrieve the citation keys.\n\nlibrary(stringr)\nlibrary(knitr, include.only = 'kable')\n\n\nbib_file &lt;- read.delim('bib/extractions.bib',\n           sep = '@', header = F)\n\n# get citekeys from bibtex file:\ncitekeys &lt;- unique(bib_file$V2)\n# improve formatting\ncitekeys &lt;- str_remove(citekeys, '\\\\{')\ncitekeys &lt;- str_remove(citekeys, ',')\ncitekeys &lt;- str_remove(citekeys, '%%.*$')\ncitekeys &lt;- str_remove(citekeys, 'Article')\ncitekeys[citekeys ==''] &lt;- NA\ncitekeys &lt;- na.omit(citekeys)\n\nR reads the .bib file as a two column data.frame, with the citation key appearing in the second column and the remaining metadata appearing in the first column. When the citation key appears in the second column, the corresponding row in the first column is blank. Because of this quirk, we can index metadata matching each citation key by keeping track of blank rows in the first column. We’ll append each to a new entry of a list. The name of each list entry is the citation key; the corresponding value is the remaining unprocessed metadata.\n\n# find where new entries begin:\nnew_entries = which(bib_file$V2 != '')\n\n# loop across unique indices for each entry\nmeta_list = list()\n# loop across unique indices for each entry\nmeta_list = list()\nfor(this_entry in 1:(length(new_entries)-1))\n{\n  # get unique citekey\n  this_cite_key &lt;- citekeys[this_entry]\n  # capture lines following citekey\n  corresponding_lines &lt;- bib_file[new_entries[this_entry]:new_entries[this_entry+1]-1,]$V1\n  # store matching lines as data frame\n  corresponding_lines &lt;- data.frame(corresponding_lines)\n  # assign lines distinct name\n  names(corresponding_lines) &lt;- this_cite_key\n  # add to a list for further processing\n  meta_list &lt;- append(meta_list, corresponding_lines)\n}"
  },
  {
    "objectID": "studies/library_parser.html#extracting-relevant-.bib-fields",
    "href": "studies/library_parser.html#extracting-relevant-.bib-fields",
    "title": "Library Parser",
    "section": "Extracting Relevant .bib Fields",
    "text": "Extracting Relevant .bib Fields\nNot every bibtex field is equally useful for analysis. To facilitate data manipulation, we can save the names of the target fields separately in a .txt file, and use a regular expression to create a new column each time R finds one of the target fields in a string containing the bibtex metadata.\n\n# read in target bibtex fields\nsearch_fields &lt;- field_names &lt;- readLines('bibtex_fields.txt')\n\n# match casing in bibtex file\nfield_names &lt;- toupper(field_names)\n# add a pattern allowing us to find text between two adjacent bibtex fields\nrep_pattern &lt;- paste0(field_names[1:length(field_names)-1], '\\\\s*(.*?)\\\\s')\n# apply this same pattern to all but the last of the field names                  \nfield_names[1:length(field_names)-1] &lt;- rep_pattern\n# collapse all the new field names into a single string for string manipulation with stringr\nfield_names[length(field_names)] &lt;- paste0(field_names[length(field_names)], '.*')\nfield_names &lt;- paste0(field_names, collapse = '')"
  },
  {
    "objectID": "studies/library_parser.html#prepare-dataframe",
    "href": "studies/library_parser.html#prepare-dataframe",
    "title": "Library Parser",
    "section": "Prepare dataframe",
    "text": "Prepare dataframe\nNow we can convert our list into a data frame with the target bibtex fields. For the last field MODEL_VALIDATION, we will apply a different regex pattern which matches all characters following the field name (?&lt;=MODEL_VALIDATION).* .\n\n# create new column containing information between two adjacent target fields for all entries in list\nmeta_df &lt;- lapply(meta_list, function(x) str_match(paste0(x, collapse = ' '), field_names))\nmeta_df &lt;- lapply(meta_list, function(x) str_match(paste0(x, collapse = ' '), field_names))\n\n# collapse list entries into rows\nmeta_df &lt;- do.call('rbind', meta_df)\n# format as a data.frame\nmeta_df &lt;- data.frame(meta_df)\n# match text after final column name\nmeta_df[,ncol(meta_df)+1] &lt;- sapply(meta_df[,1], function(x) str_match(paste0(x, collapse = ' '), '(?&lt;=FINAL_NOTES).*'))\n# replace first column with citationkeys\nmeta_df[,1] &lt;- names(meta_list)\nnames(meta_df) &lt;- c('citekey', search_fields)\nnames(meta_df) &lt;- trimws(names(meta_df))"
  },
  {
    "objectID": "studies/library_parser.html#formatting",
    "href": "studies/library_parser.html#formatting",
    "title": "Library Parser",
    "section": "Formatting",
    "text": "Formatting\nFinally, we’ll perform some formatting to remove unwanted characters left over following the conversion (in progress)\n\n## remove bibtext field formatting\n# remove curly braces\nmeta_df &lt;- apply(meta_df, 2, function(x) str_remove_all(x, '\\\\{')) \nmeta_df &lt;- apply(meta_df, 2, function(x) str_remove_all(x, '\\\\},'))\n# remove first '=' (from bibtex field )\nmeta_df &lt;- apply(meta_df, 2, function(x) str_remove(x, '='))\n# remove double-commas\n#meta_df &lt;- apply(meta_df, 2, function(x) str_remove_all(x, ',,'))\n# remove comments\nmeta_df &lt;- apply(meta_df, 2, function(x) str_remove_all(x, '%%.*'))\n#meta_df &lt;- apply(meta_df, 2, function(x) str_remove_all(x, ' , '))\n# remove extra characters in final column\nmeta_df[, ncol(meta_df)] = str_remove_all(meta_df[, ncol(meta_df)], '\\\\}')\nmeta_df &lt;- as.data.frame(meta_df)\n\nExample: Evaluate model_rate_emotion_values as R code\n\nsource(paste0(here::here(), \"/R/format-study-results.R\"))\neval(parse(text = meta_df$model_rate_emotion_values[22]))\n\n                                                          arousal_r2\nvarious.svr.mixed.classical.1                                 0.7249\nvarious.sparse bayesian regression.mixed.classical.1          0.7381\nvarious.variational bayesian regression.mixed.classical.1     0.7108\n                                                          arousal_variance explained\nvarious.svr.mixed.classical.1                                                 0.7556\nvarious.sparse bayesian regression.mixed.classical.1                          0.7395\nvarious.variational bayesian regression.mixed.classical.1                     0.7415\n                                                          valence_r2\nvarious.svr.mixed.classical.1                                 0.6119\nvarious.sparse bayesian regression.mixed.classical.1          0.6296\nvarious.variational bayesian regression.mixed.classical.1     0.6328\n                                                          valence_variance explained\nvarious.svr.mixed.classical.1                                                 0.6142\nvarious.sparse bayesian regression.mixed.classical.1                          0.6376\nvarious.variational bayesian regression.mixed.classical.1                     0.6340\n                                                          resonance_r2\nvarious.svr.mixed.classical.1                                   0.5374\nvarious.sparse bayesian regression.mixed.classical.1            0.5456\nvarious.variational bayesian regression.mixed.classical.1       0.5554\n                                                          resonance_variance explained\nvarious.svr.mixed.classical.1                                                   0.5496\nvarious.sparse bayesian regression.mixed.classical.1                            0.5558\nvarious.variational bayesian regression.mixed.classical.1                       0.5630"
  },
  {
    "objectID": "studies/library_parser.html#track-excluded-studies-during-extraction",
    "href": "studies/library_parser.html#track-excluded-studies-during-extraction",
    "title": "Library Parser",
    "section": "Track Excluded Studies (During Extraction)",
    "text": "Track Excluded Studies (During Extraction)\n\nmeta_df[which(str_detect(meta_df$final_notes, '!EXCL!')),] |&gt; dplyr::tibble()\n\n# A tibble: 9 × 28\n  citekey        paradigm notes_ca notes_te emotions emotion_locus stimulus_type\n  &lt;chr&gt;          &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;         &lt;chr&gt;        \n1 \"feng2024ex\"   \" class… \" inclu… \" inclu… \"    \"   \"    \"        \"    \"       \n2 \"nag2022on\"    \" class… \" inclu… \" inclu… \" happy… \"    \"        \"    \"       \n3 \"cao2023th\"    \" regre… \" inclu… \" inclu… \" valen… \" perceived … \" million so…\n4 \"malheiro2018… \" regre… \" inclu… \" inclu… \"    \"   \"    \"        \"    \"       \n5 \"medina2020em\" \" class… \" inclu… \" inclu… \" valen… \" perceived … \" MediaEval …\n6 \"panwar2019ar\" \" regre… \" inclu… \" inclu… \"    \"   \"    \"        \"    \"       \n7 \"vempala2024p… \" regre… \" inclu… \" inclu… \" valen… \" perceived … \" classical …\n8 \"xia2022st\"    \" regre… \" inclu… \" inclu… \"   \"    \"    \"        \"   \"        \n9 \"zhang2024ap\"  \" regre… \" inclu… \" inclu… \"    \"   \"    \"        \"    \"       \n# ℹ 21 more variables: stimulus_genre &lt;chr&gt;, stimulus_duration &lt;chr&gt;,\n#   stimulus_duration_unit &lt;chr&gt;, stimulus_n &lt;chr&gt;, feature_n &lt;chr&gt;,\n#   participant_n &lt;chr&gt;, participant_expertise &lt;chr&gt;, participant_origin &lt;chr&gt;,\n#   participant_sampling &lt;chr&gt;, participant_task &lt;chr&gt;,\n#   feature_categories &lt;chr&gt;, feature_source &lt;chr&gt;,\n#   feature_reduction_method &lt;chr&gt;, model_category &lt;chr&gt;, model_detail &lt;chr&gt;,\n#   model_measure &lt;chr&gt;, model_complexity_parameters &lt;chr&gt;, …\n\n\n\nmeta_df[-which(str_detect(meta_df$final_notes, '!EXCL!')),] -&gt; included_studies\n\nincluded_studies |&gt; dplyr::tibble()\n\n# A tibble: 37 × 28\n   citekey       paradigm notes_ca notes_te emotions emotion_locus stimulus_type\n   &lt;chr&gt;         &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;         &lt;chr&gt;        \n 1 agarwal2021an \" class… \" inclu… \" inclu… \" discr… \" perceived … \" Hindi musi…\n 2 alvarez2023ri \" class… \" inclu… \" inclu… \" discr… \" perceived … \" Spotify \"  \n 3 bai2017mu     \" class… \" inclu… \" inclu… \" valen… \" perceived … \" MediaEval …\n 4 bhuvanakumar… \" class… \" inclu… \" inclu… \" quadr… \" not specif… \" EMOPIA; po…\n 5 dufour2021us  \" class… \" inclu… \" inclu… \"  c1 (… \" perceived … \" pop, disco…\n 6 hizlisoy2021… \" class… \" inclu… \" inclu… \" valen… \" perceived … \" Turkish tr…\n 7 nguyen2017an  \" class… \" inclu… \" inclu… \" 288 e… \" perceived … \" pop  \"     \n 8 panda2020no   \" class… \" inclu… \" inclu… \" valen… \" perceived … \" AllMusic  \"\n 9 sorussa2020em \" class… \" inclu… \" inclu… \" valen… \" perceived … \" DEAM  \"    \n10 yang2021an    \" class… \" inclu… \" inclu… \" happy… \" perceived … \" MediaEval …\n# ℹ 27 more rows\n# ℹ 21 more variables: stimulus_genre &lt;chr&gt;, stimulus_duration &lt;chr&gt;,\n#   stimulus_duration_unit &lt;chr&gt;, stimulus_n &lt;chr&gt;, feature_n &lt;chr&gt;,\n#   participant_n &lt;chr&gt;, participant_expertise &lt;chr&gt;, participant_origin &lt;chr&gt;,\n#   participant_sampling &lt;chr&gt;, participant_task &lt;chr&gt;,\n#   feature_categories &lt;chr&gt;, feature_source &lt;chr&gt;,\n#   feature_reduction_method &lt;chr&gt;, model_category &lt;chr&gt;, model_detail &lt;chr&gt;, …"
  },
  {
    "objectID": "studies/library_parser.html#data-frame-expansion",
    "href": "studies/library_parser.html#data-frame-expansion",
    "title": "Library Parser",
    "section": "Data Frame Expansion",
    "text": "Data Frame Expansion\nNext we want to copy the number of rows for each of the bibtex cells requiring special nesting"
  },
  {
    "objectID": "studies/library_parser.html#sanity-check",
    "href": "studies/library_parser.html#sanity-check",
    "title": "Library Parser",
    "section": "Sanity check",
    "text": "Sanity check"
  },
  {
    "objectID": "studies/library_parser.html#print-output-of-all-studies",
    "href": "studies/library_parser.html#print-output-of-all-studies",
    "title": "Library Parser",
    "section": "Print output of all studies:",
    "text": "Print output of all studies:\n\n# low-level function to extract relevant values from named array\nmodel_result_2_df &lt;- function(x) {\n  # evaluate the expression\n  x &lt;- rlang::eval_tidy(rlang::parse_expr(x))\n  # get name of fitted models from column names\n  model_names &lt;- colnames(x)\n  # print(model_names)\n  # split across model name for summary statistic (e.g., mean, sd, etc.)\n  model_statistic &lt;- str_split(model_names, '\\\\.')\n  model_statistic &lt;- unlist(lapply(model_statistic, function(x) x[2]))\n  # get values\n  model_values &lt;- as.numeric(x)\n  # names(model_values) &lt;- 'score'\n  print(model_values)\n  # get additional attributes (feature.data.exp)\n  model_attributes &lt;- rownames(x)\n  data.frame(model_attributes)\n  # get additional model details\n  model_attributes &lt;- data.frame(do.call('rbind', str_split(model_attributes, '\\\\.')))\n  names(model_attributes) &lt;- c('library_id', 'model_id', 'feature_id', 'data_id', 'experiment_id')\n  print(names(model_attributes))\n  # split across '_' to \n  model_measures &lt;- data.frame(do.call('rbind', stringr::str_split(colnames(x), '_')))\n  print(model_measures)\n  names(model_measures) &lt;- c('dimension', 'measure')\n  model_measures_split &lt;- stringr::str_split(model_measures[,'measure'], '\\\\.')\n  model_measures[,'measure'] &lt;- unlist(lapply(model_measures_split, \n                                              function(x) x[1]))\n  return(data.frame(\n             model_attributes, \n             model_measures, \n             values = model_values,\n             statistic = model_statistic))\n}\n\n# high level function to apply model_result_2_df to multiple studies\nget_study_summaries &lt;- function(df) {\n  do.call(rbind,\n          lapply(df$model_rate_emotion_values, \n                 FUN = function(x) {\n                   study_id &lt;- unique(df$citekey[which(df$model_rate_emotion_values == x)])\n                   model_results &lt;- model_result_2_df(x)\n                   return(cbind(study_id, model_results))\n                   }\n                 )\n          )\n}"
  },
  {
    "objectID": "studies/pass3_comparison.html#load-libraries",
    "href": "studies/pass3_comparison.html#load-libraries",
    "title": "Pass 3 Comparison",
    "section": "Load libraries",
    "text": "Load libraries\n\n# load libraries\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(stringr)\nlibrary(knitr)"
  },
  {
    "objectID": "studies/pass3_comparison.html#read-data",
    "href": "studies/pass3_comparison.html#read-data",
    "title": "Pass 3 Comparison",
    "section": "Read data",
    "text": "Read data\n\n# read in bibtex library as data frame\nbib_df_merged &lt;- bib2df::bib2df('metaMER_library_third_pass_clean.bib')\n\nSome BibTeX entries may have been dropped.\n            The result could be malformed.\n            Review the .bib file and make sure every single entry starts\n            with a '@'."
  },
  {
    "objectID": "studies/pass3_comparison.html#compare",
    "href": "studies/pass3_comparison.html#compare",
    "title": "Pass 3 Comparison",
    "section": "Compare",
    "text": "Compare\n\n# check dimensions are accurate\ndim(bib_df_merged)\n\n[1] 96 47\n\n# distinguish notes with author initials\nnames(bib_df_merged)[names(bib_df_merged) == 'NOTES'] &lt;- 'NOTES.CA'\nnames(bib_df_merged)[names(bib_df_merged) == 'NOTES.1'] &lt;- 'NOTES.TE'\n\n# extract decisions less comments\ncapture_group &lt;- 'include|exclude|unsure'\n\n\n# create new index to track entries\nbib_df_merged$NOTES_INDEX.CA&lt;-NA\n\n# create new column tracking decisions\nbib_df_merged$NOTES_INDEX.CA &lt;- str_extract(tolower(bib_df_merged$NOTES.CA),\n                                         capture_group)\nbib_df_merged$NOTES_INDEX.TE &lt;- str_extract(tolower(bib_df_merged$NOTES.TE),\n                                     capture_group)\n\n# check entries are consistent\nsum(is.na(bib_df_merged$NOTES_INDEX.CA))\n\n[1] 0\n\nsum(is.na(bib_df_merged$NOTES_INDEX.TE))\n\n[1] 0"
  },
  {
    "objectID": "studies/pass3_comparison.html#report-annotation-reliabilityagreement",
    "href": "studies/pass3_comparison.html#report-annotation-reliabilityagreement",
    "title": "Pass 3 Comparison",
    "section": "Report annotation reliability/agreement",
    "text": "Report annotation reliability/agreement\n\n# compare raters' decisions with confusion matrix\nt&lt;-table(bib_df_merged$NOTES_INDEX.CA,\n         bib_df_merged$NOTES_INDEX.TE)\n\n# get agreement\nt2&lt;-round(t/sum(t),2)\nag_before &lt;- sum(diag(t2))\n\n# make table\nknitr::kable(t,  \n             caption = paste('Votes before discussion. \\n\n             Rows: CA votes; cols: TE votes, Agreement = ', ag_before)\n             )\n\nTable: Votes before discussion.\n         Rows: CA votes; cols: TE votes, Agreement =  0.73\n\n\n\n\nexclude\ninclude\nunsure\n\n\n\n\nexclude\n24\n8\n2\n\n\ninclude\n4\n45\n1\n\n\nunsure\n10\n1\n1"
  },
  {
    "objectID": "studies/pass3_comparison.html#ca-unsure",
    "href": "studies/pass3_comparison.html#ca-unsure",
    "title": "Pass 3 Comparison",
    "section": "CA: unsure",
    "text": "CA: unsure\n\n# resolve unsure ones\nIND &lt;- which(bib_df_merged$NOTES_INDEX.CA=='unsure')\nresolved_index &lt;- bib_df_merged$BIBTEXKEY[IND] # 12\n# CA updates ratings:\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'deng2024an'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'hao2022re'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'he2022al'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'huang2023th'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'priscillajoy2023mu'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'shen2024re'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'wang2021mu'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'wang2021re'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'wang2022mua'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'zhang2016rea'] &lt;- 'exclude'\n\n# both CA and TE update ratings:\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'na2022mu'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.TE[bib_df_merged$BIBTEXKEY == 'na2022mu'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'tian2023mu'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.TE[bib_df_merged$BIBTEXKEY == 'tian2023mu'] &lt;- 'exclude'\n\n# resolved &lt;-c('deng2024an' = 'exclude',\n#              'hao2022re' = 'exclude',\n#              'he2022al' = 'exclude',\n#              'huang2023th' = 'exclude',\n#              'na2022mu' = 'exclude',\n#              'priscillajoy2023mu' = 'exclude',\n#              'shen2024re' = 'exclude',\n#              'tian2023mu' = 'exclude',\n#              'wang2021mu' = 'exclude',\n#              'wang2021re' = 'exclude',\n#              'wang2022mua' = 'exclude',\n#              'zhang2016rea' = 'exclude')"
  },
  {
    "objectID": "studies/pass3_comparison.html#te-unsure-in-progress",
    "href": "studies/pass3_comparison.html#te-unsure-in-progress",
    "title": "Pass 3 Comparison",
    "section": "TE: unsure (in progress)",
    "text": "TE: unsure (in progress)\n\n# update TE decision\nbib_df_merged$NOTES_INDEX.TE[bib_df_merged$BIBTEXKEY == 'tang2023ap'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.TE[bib_df_merged$BIBTEXKEY == 'xing2015em'] &lt;- 'exclude'\n\n# update TE and CA decisions\nbib_df_merged$NOTES_INDEX.TE[bib_df_merged$BIBTEXKEY == 'wang2022mu'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'wang2022mu'] &lt;- 'exclude'"
  },
  {
    "objectID": "studies/pass3_comparison.html#summary",
    "href": "studies/pass3_comparison.html#summary",
    "title": "Pass 3 Comparison",
    "section": "Summary",
    "text": "Summary\n\n\n\n\n\n\n\n\n\nStudy\nCA\nTE\n\n\n\n\n\ntang2023ap\nuses image features\nNo relevant features, lack of stimulus detail\nExclude\n\n\nxing2015em\nincludes classification task\nNo N of musical excerpts, missing information regarding data processing\nExclude\n\n\nwang2022mu\nonly reports DET and equal error rate\nAlthough they report correlation coefficients, emotions are not valence or arousal. Do report MSE of classification task\nExclude"
  },
  {
    "objectID": "studies/pass3_comparison.html#tabulate-results-after-resolving-unsures",
    "href": "studies/pass3_comparison.html#tabulate-results-after-resolving-unsures",
    "title": "Pass 3 Comparison",
    "section": "Tabulate results after resolving unsures",
    "text": "Tabulate results after resolving unsures\n\n# compare raters' decisions with confusion matrix\nt&lt;-table(bib_df_merged$NOTES_INDEX.CA,\n         bib_df_merged$NOTES_INDEX.TE)\n\n# get agreement\nt2&lt;-round(t/sum(t),2)\nag_before &lt;- sum(diag(t2))\n\n# make table\nknitr::kable(t,  \n             caption = paste('Votes after resolving unsure discrepancies. \\n\n             Rows: CA votes; cols: TE votes, Agreement = ', ag_before)\n             )\n\nTable: Votes after resolving unsure discrepancies.\n         Rows: CA votes; cols: TE votes, Agreement =  0.88\n\n\n\n\nexclude\ninclude\n\n\n\n\nexclude\n39\n8\n\n\ninclude\n4\n45"
  },
  {
    "objectID": "studies/pass3_comparison.html#ca-exclude-te-include",
    "href": "studies/pass3_comparison.html#ca-exclude-te-include",
    "title": "Pass 3 Comparison",
    "section": "CA: exclude, TE: include",
    "text": "CA: exclude, TE: include\n\n# Resolving conflicting exclude/include annotations, part 1\nIND &lt;- which(bib_df_merged$NOTES_INDEX.CA=='exclude' & \n  bib_df_merged$NOTES_INDEX.TE=='include')\n# check discrepant entries\nresolved_exclude_index &lt;- bib_df_merged$BIBTEXKEY[IND]\nresolved_exclude_index # 8\n\n[1] \"aljanaki2017de\"          \"li2024im\"               \n[3] \"pandeya2024gl\"           \"saizclar2022pr\"         \n[5] \"sanmillancastillo2022an\" \"wang2015mo\"             \n[7] \"wang2016af\"              \"yang2023ex\"             \n\n# update TE votes to exclude\nbib_df_merged$NOTES_INDEX.TE[bib_df_merged$BIBTEXKEY == 'aljanaki2017de'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.TE[bib_df_merged$BIBTEXKEY == 'li2024im'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.TE[bib_df_merged$BIBTEXKEY == 'pandeya2024gl'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.TE[bib_df_merged$BIBTEXKEY == 'sanmillancastillo2022an'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.TE[bib_df_merged$BIBTEXKEY == 'wang2015mo'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.TE[bib_df_merged$BIBTEXKEY == 'wang2016af'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.TE[bib_df_merged$BIBTEXKEY == 'yang2023ex'] &lt;- 'exclude'\n# update CA votes to include\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'saizclar2022pr'] &lt;- 'include'\n\n\n# resolved_exclude &lt;-c('aljanaki2017de' = 'exclude',\n#                      'li2024im' = 'exclude',\n#                      'pandeya2024gl' = 'exclude',\n#                      'saizclar2022pr' = 'include',\n#                      'sanmillancastillo2022an' = 'exclude',\n#                      'wang2015mo' = 'exclude',\n#                      'wang2016af' = 'exclude',\n#                      'yang2023ex' = 'exclude')"
  },
  {
    "objectID": "studies/pass3_comparison.html#summary-1",
    "href": "studies/pass3_comparison.html#summary-1",
    "title": "Pass 3 Comparison",
    "section": "Summary",
    "text": "Summary\n\nCA: exclude, TE: include\n\n\n\n\n\n\n\n\n\nStudy\nCA\nTE\nResolution/Decision\n\n\n\n\naljanaki2017de\nMultiple teams’ performance reported\nPossible to report teams as substudies\nExclude: Benchmark, does not contain original study details from reporting team\n\n\nli2024im\nNo relevant task\nReports classification accuracy and DEAM results\nExclude: No audio features reported\n\n\npandeya2024gl\nInsufficient detail for meta-analysis\nIncludes timbre and global audio features, confusion matrix included\nExclude: Reporting on music videos; quality issues in data set\n\n\nsaizclar2022pr\nNo modeling task\nModeling is based on onsets\nInclude: although no cross-validation, still performed task\n\n\nsanmillancastillo2022an\nNo music\nTask present\nExclude: No music\n\n\nwang2015mo\nNo relevant task\nNot sure of outcome measures\nExclude: No translation of distances into VA accuracy\n\n\nwang2016af\nChapter\nIncludes relevant task\nExclude: Meets exclusion criteria (not an article)\n\n\nyang2023ex\nNo relevant task\nFinal metrics missing\nExclude: Collected VA emotion ratings, but don’t use audio features to predict VA (not reported)"
  },
  {
    "objectID": "studies/pass3_comparison.html#te-exclude-ca-include",
    "href": "studies/pass3_comparison.html#te-exclude-ca-include",
    "title": "Pass 3 Comparison",
    "section": "TE: exclude, CA: include",
    "text": "TE: exclude, CA: include\n\n# Resolving conflicting exclude/include annotations, part 2\nIND &lt;- which(bib_df_merged$NOTES_INDEX.TE=='exclude' & \n               bib_df_merged$NOTES_INDEX.CA=='include')\n\n# check discrepant entries\nresolved_exclude2_index &lt;- bib_df_merged$BIBTEXKEY[IND]\nresolved_exclude2_index # 4\n\n[1] \"cunningham2021su\" \"eyben2015em\"      \"tian2023mua\"      \"tiple2022mu\"     \n\n# update CA votes\n\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'cunningham2021su'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'eyben2015em'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'tian2023mua'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'tiple2022mu'] &lt;- 'exclude'\n\n# resolved_exclude2 &lt;-c('cunningham2021su' = 'exclude',\n#                       'eyben2015em' = 'exclude',\n#                       'tian2023mua' = 'exclude',\n#                       'tiple2022mu' = 'exclude')"
  },
  {
    "objectID": "studies/pass3_comparison.html#summary-2",
    "href": "studies/pass3_comparison.html#summary-2",
    "title": "Pass 3 Comparison",
    "section": "Summary",
    "text": "Summary\n\n\n\n\n\n\n\n\n\nStudy\nTE\nCA\nResolution/Decision\n\n\n\n\ncunningham2021su\nReports on IADS (not music)\nRelevant task\nExclude: No music\n\n\neyben2015em\nFocused on laboratory singing\nRelevant task\nExclude: Laboratory singing of a scale\n\n\ntiple2022mu\nData set just includes annotation of tonic pitch\nRelevant task, but only reports overall accuracy\nExclude: Data set not sufficiently detailed for MER task"
  },
  {
    "objectID": "studies/pass3_comparison.html#update-table-after-resolving-disagreements",
    "href": "studies/pass3_comparison.html#update-table-after-resolving-disagreements",
    "title": "Pass 3 Comparison",
    "section": "Update table after resolving disagreements",
    "text": "Update table after resolving disagreements\n\n# compare raters' decisions with confusion matrix\nt&lt;-table(bib_df_merged$NOTES_INDEX.CA,\n         bib_df_merged$NOTES_INDEX.TE)\n\n# get agreement\nt2&lt;-round(t/sum(t),2)\nag_before &lt;- sum(diag(t2))\n\n# make table\nknitr::kable(t,  \n             caption = paste('Votes after resolving include vs. exclude discrepancies. \\n\n             Rows: CA votes; cols: TE votes, Agreement = ', ag_before)\n             )\n\nTable: Votes after resolving include vs. exclude discrepancies.\n         Rows: CA votes; cols: TE votes, Agreement =  1\n\n\n\n\nexclude\ninclude\n\n\n\n\nexclude\n50\n0\n\n\ninclude\n0\n46"
  },
  {
    "objectID": "studies/pass3_comparison.html#track-task-types",
    "href": "studies/pass3_comparison.html#track-task-types",
    "title": "Pass 3 Comparison",
    "section": "Track task types",
    "text": "Track task types\n\n# add column tracking task type\nbib_df_merged$PARADIGM &lt;- 'regression'\nbib_df_merged[str_detect(bib_df_merged$NOTES.CA, 'classification'),]$PARADIGM &lt;- 'classification'\n\n# sort by task\nbib_df_merged &lt;- bib_df_merged[order(bib_df_merged$PARADIGM),]\n\n# put rater notes side-by-side\nNOTES.CA &lt;- bib_df_merged$NOTES.CA\nNOTES.TE &lt;- bib_df_merged$NOTES.TE\nbib_df_merged$NOTES.CA &lt;- NULL\nbib_df_merged$NOTES.TE &lt;- NULL\nbib_df_merged$NOTES_CA&lt;-NOTES.CA\nbib_df_merged$NOTES_TE&lt;-NOTES.TE"
  },
  {
    "objectID": "studies/pass3_comparison.html#add-fields-for-annotation",
    "href": "studies/pass3_comparison.html#add-fields-for-annotation",
    "title": "Pass 3 Comparison",
    "section": "Add fields for annotation",
    "text": "Add fields for annotation\n\n# add new fields for annotating bibtex library\nbib_df_merged %&gt;% mutate(emotions = ' ',\n                         emotion_locus = ' ',\n                         stimulus_type = ' ',\n                         stimulus_duration = ' ',\n                         stimulus_duration_unit = ' ',\n                         stimulus_N = ' ',\n                         feature_N = ' ',\n                         participant_N = ' ',\n                         participant_expertise = ' ',\n                         participant_origin = ' ',\n                         participant_sampling = ' ',\n                         participant_task = ' ',\n                         feature_N = ' ',\n                         feature_categories = ' ',\n                         feature_source = ' ',\n                         feature_reduction_method = ' ',\n                         model_category = ' ',\n                         model_detail = ' ',\n                         model_measure = ' ',\n                         model_complexity_parameters = ' ',\n                         model_rate_emotion_names = ' ',\n                         model_rate_emotion_values = ' ',\n                         model_validation = ' ',\n                         final_decision = NOTES_INDEX.CA) -&gt; bib_df_merged"
  },
  {
    "objectID": "studies/pass3_comparison.html#export-bibtex-for-the-annotation",
    "href": "studies/pass3_comparison.html#export-bibtex-for-the-annotation",
    "title": "Pass 3 Comparison",
    "section": "Export bibtex for the annotation",
    "text": "Export bibtex for the annotation\n\nbib_df_merged$NOTES_INDEX.CA &lt;- NULL\nbib_df_merged$NOTES_INDEX.TE &lt;- NULL"
  },
  {
    "objectID": "studies/pass3_comparison.html#get-included-studies",
    "href": "studies/pass3_comparison.html#get-included-studies",
    "title": "Pass 3 Comparison",
    "section": "Get included studies",
    "text": "Get included studies\n\nbib_df_merged &lt;- subset(bib_df_merged, final_decision == 'include')\nbib_df_merged$final_decision &lt;- NULL"
  },
  {
    "objectID": "studies/pass3_comparison.html#write-resulting-bibtex-library",
    "href": "studies/pass3_comparison.html#write-resulting-bibtex-library",
    "title": "Pass 3 Comparison",
    "section": "Write resulting bibtex library",
    "text": "Write resulting bibtex library\n\nbib2df::df2bib(bib_df_merged, file = 'metaMER_library_template.bib')\n\nNotes:\nFor Feature classification, use this one:\nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9229494\nInsert the template the annotation fields from googledoc to the bibtex file."
  },
  {
    "objectID": "studies/search_syntax.html",
    "href": "studies/search_syntax.html",
    "title": "Search Syntax",
    "section": "",
    "text": "We first performed search through three databases using the following syntax for each.\n\n\n\n\n\n\n\n\n\nDatabase\nDate\nResults\nSearch syntax\n\n\n\n\nScopus\n12 May 2024\n227\nTITLE-ABS-KEY ( valence OR arousal OR classi OR categor OR algorithm AND music AND emotion AND recognition ) AND PUBYEAR &gt; 2013 AND PUBYEAR &lt; 2025 AND ( LIMIT-TO ( DOCTYPE , \"ar\" ) )\n\n\nWeb of Science\n12 May 2024\n142\n(DT=(Article) AND PY=(2014-2025)) AND ALL=(music emotion recognition valence arousal)\n\n\nOpen Alex\n12 May 2024\n278\nhttps://openalex.org/works?page=1&filter=default.search%3Amusic%20emotion%20recognition%20valence%20arousal,type%3Atypes%2Farticle, publication_year%3A2014-2024, keywords.id%3Akeywords%2Femotion-recognition, keywords.id%3Akeywords%2Faffective-computing, language%3Alanguages%2Fen,open_access.any_repository_has_fulltext%3Atrue"
  },
  {
    "objectID": "studies/search_syntax.html#second-pass-assessment-of-relevant-content",
    "href": "studies/search_syntax.html#second-pass-assessment-of-relevant-content",
    "title": "Search Syntax",
    "section": "Second pass: Assessment of relevant content",
    "text": "Second pass: Assessment of relevant content\nOut of the studies identified in the first pass, a closer look at the priority 2 studies using the criteria established [link to prereg] was carried out."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "README",
    "section": "",
    "text": "How well we can predict emotions in music? What is the evidence in the published literature for explaining what emotions the listeners can perceive in music when the source consists of audio examples. To what degree the results are dependent on the actual models, emotions, musical/acoustic features, or musical materials or participants?\nTo obtain answers to these questions, we have set out to record and analyse the current state of the art from the literature using a meta-analysis paradigm. We focus on Music Emotion Recognition and hence the acronym metaMER.\nThe public-facing version of the repository is available at https://tuomaseerola.github.io/metaMER/\n\n\nWe define the aims and methods in preregistration plan, which has beeb preregistered at https://osf.io/6y3dr/.\n\n\nSearch databases and criteria are documented in studies/search_syntax.qmd.\n\n\n\nData extraction is described in extraction details. See also pass3 comparison.\nThe data will be parsed to a tabular format using a custom library_parser.qmd.\n\n\n\nData analysis is covered in analysis/analysis.qmd document.\n\n\n\nThe study report is available manuscript/manuscript.qmd document."
  },
  {
    "objectID": "index.html#plan",
    "href": "index.html#plan",
    "title": "README",
    "section": "",
    "text": "We define the aims and methods in preregistration plan, which has beeb preregistered at https://osf.io/6y3dr/.\n\n\nSearch databases and criteria are documented in studies/search_syntax.qmd.\n\n\n\nData extraction is described in extraction details. See also pass3 comparison.\nThe data will be parsed to a tabular format using a custom library_parser.qmd.\n\n\n\nData analysis is covered in analysis/analysis.qmd document.\n\n\n\nThe study report is available manuscript/manuscript.qmd document."
  },
  {
    "objectID": "analysis/analysis.html",
    "href": "analysis/analysis.html",
    "title": "Analysis",
    "section": "",
    "text": "This assumes that the data has been parsed (parse-model-output.R, format-study-results.R) and preprocessed (processing.qmd).\n\n\n\n\nFor creating Table 2\n\nlibrary(dmetar,quietly = TRUE)\nlibrary(tidyverse,quietly = TRUE)\nlibrary(meta)\nlibrary(DescTools)\nlibrary(ggrepel)\n\n\n\n\nR_studies &lt;- read.csv(\"R_studies.csv\")\n#R_summary &lt;- read.csv(\"R_summary.csv\")\n\n# select regression studies with r2\n#tmp &lt;- dplyr::filter(R_summary,dimension==\"valence\")\ntmp &lt;- dplyr::filter(R_studies,dimension==\"valence\")\n#dim(tmp)\n\n#if all studies, remove two with NA values\ntmp &lt;- tmp[!is.na(tmp$values),]\n#dim(tmp)\n\n# Take all models\nm.cor &lt;- metacor(cor = values,     # values \n                 n = stimulus_n,\n                 studlab = unique_id,\n                 data = tmp,\n                 common = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"PM\",# was REML, but we switch to Paule-Mandel because Langan et al., 2019\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\n\nprint(m.cor)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 102\nNumber of observations: o = 60017\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.5832 [0.5410; 0.6226] 21.41 &lt; 0.0001\nPrediction interval         [0.0552; 0.8563]               \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.0942 [0.0715; 0.1288]; tau = 0.3070 [0.2674; 0.3589]\n I^2 = 97.7% [97.5%; 97.9%]; H = 6.58 [6.28; 6.89]\n\nTest of heterogeneity:\n       Q d.f. p-value\n 4371.49  101       0\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Paule-Mandel estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hartung-Knapp adjustment for random effects model (df = 101)\n- Prediction interval based on t-distribution (df = 101)\n- Fisher's z transformation of correlations\n\nprint(FisherZInv(m.cor$TE.random))\n\n[1] 0.5832415\n\nprint(FisherZInv(m.cor$upper.random))\n\n[1] 0.6225642\n\nprint(FisherZInv(m.cor$lower.random))\n\n[1] 0.5409809\n\n\n\n\n\n\nR_summary &lt;- read.csv(\"R_summary.csv\")\n\n# select regression studies with r2\ntmp &lt;- dplyr::filter(R_summary,dimension==\"valence\")\n#tmp &lt;- dplyr::filter(R_studies,dimension==\"valence\")\n#dim(tmp)\n\n#if all studies, remove two\n#tmp &lt;- tmp[!is.na(tmp$values),]\n#dim(tmp)\n\n## Disambiguate the studies\ntmp$studyREF[tmp$studyREF==\"Wang et al 2022\"] &lt;- c(\"Wang et al. 2022a\",\"Wang et al. 2022b\")\n\n# Max values\nm.cor &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = studyREF,#citekey, # unique_id\n                 data = tmp,\n                 common = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\n\nprint(m.cor)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 22\nNumber of observations: o = 14172\n\n                        COR            95%-CI    t  p-value\nRandom effects model 0.6685 [ 0.5599; 0.7546] 9.58 &lt; 0.0001\nPrediction interval         [-0.0120; 0.9258]              \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.1484 [0.0847; 0.3121]; tau = 0.3852 [0.2910; 0.5587]\n I^2 = 98.4% [98.0%; 98.6%]; H = 7.83 [7.15; 8.58]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1288.63   21 &lt; 0.0001\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hartung-Knapp adjustment for random effects model (df = 21)\n- Prediction interval based on t-distribution (df = 21)\n- Fisher's z transformation of correlations\n\nprint(FisherZInv(m.cor$TE.random))\n\n[1] 0.6685242\n\nprint(FisherZInv(m.cor$upper.random))\n\n[1] 0.7545765\n\nprint(FisherZInv(m.cor$lower.random))\n\n[1] 0.5598682\n\n\n\n\n\n\n\n# Method 1: Give us the Egger's test about beta coefficient from funnel\nprint(eggers.test(m.cor))\n\nEggers' test of the intercept \n============================= \n\n intercept        95% CI     t         p\n      5.05 -0.99 - 11.09 1.637 0.1171758\n\nEggers' test does not indicate the presence of funnel plot asymmetry. \n\n# Method 2: Find the impact to the results when removing those outside the 95CI\nO &lt;- find.outliers(m.cor) # 13 remaining out of 24\nprint(O)\n\nIdentified outliers (random-effects model) \n------------------------------------------ \n\"Battcock et al 2021\", \"Chen et al 2017\", \"Coutinho et al 2017\", \"Griffiths et al 2021\", \"Hu et al 2017\", \"Koh et al 2023\", \"Wang et al. 2022a\", \"Wang et al. 2022b\", \"Zhang et al 2019\", \"Zhang et al 2023\" \n \nResults with outliers removed \n----------------------------- \nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 12\nNumber of observations: o = 6150\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.6855 [0.6346; 0.7306] 20.44 &lt; 0.0001\nPrediction interval         [0.5143; 0.8042]               \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.0135 [0.0047; 0.0606]; tau = 0.1164 [0.0682; 0.2461]\n I^2 = 82.9% [71.4%; 89.7%]; H = 2.42 [1.87; 3.12]\n\nTest of heterogeneity:\n     Q d.f.  p-value\n 64.22   11 &lt; 0.0001\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hartung-Knapp adjustment for random effects model (df = 11)\n- Prediction interval based on t-distribution (df = 11)\n- Fisher's z transformation of correlations\n\n# Method 3: Leave-out-out analysis etc for individual influence (not useful here)\n#infan &lt;- InfluenceAnalysis(m.cor)\n\n# Method 4: Focus on 10% of most precise studies (Stanley, Jarrel, Doucouliagos 2010)\nthres&lt;-quantile(m.cor$seTE,0.1)\nind&lt;-m.cor$seTE&lt;=as.numeric(thres)\nm.cor10pct &lt;- update(m.cor, subset = which(ind))\n\n# Method 5: P curve analysis (Simonsohn, Simmons & Nelson, 2015)\npcurve(m.cor)\n\n\n\n\n\n\n\n\nP-curve analysis \n ----------------------- \n- Total number of provided studies: k = 22 \n- Total number of p&lt;0.05 studies included into the analysis: k = 21 (95.45%) \n- Total number of studies with p&lt;0.025: k = 21 (95.45%) \n   \nResults \n ----------------------- \n                    pBinomial   zFull pFull   zHalf pHalf\nRight-skewness test         0 -32.247     0 -31.745     0\nFlatness test               1  31.712     1  32.038     1\nNote: p-values of 0 or 1 correspond to p&lt;0.001 and p&gt;0.999, respectively.   \nPower Estimate: 99% (99%-99%)\n   \nEvidential value \n ----------------------- \n- Evidential value present: yes \n- Evidential value absent/inadequate: no \n\n\n\n\n\n\nfig2a &lt;- meta::forest(m.cor,\n       sortvar = TE,\n       prediction = FALSE, \n             print.tau2 = FALSE,\n             leftlabs = c(\"Author\", \"N\"),studlab = studyREF)\n\n\n\n\n\n\n\nfig2b &lt;- funnel(m.cor, common = FALSE, studlab=TRUE,backtransf=TRUE)\n\n\n\n\n\n\n\nlibrary(forestplot)\n\nLoading required package: grid\n\n\nLoading required package: checkmate\n\n\nLoading required package: abind\n\ndata&lt;-tibble::tibble(mean=m.cor$cor,lower=FisherZInv(m.cor$lower),upper=FisherZInv(m.cor$upper),study=m.cor$studlab,n=m.cor$n,cor=round(m.cor$cor,2))\ndata&lt;-dplyr::arrange(data,mean)\n\nfp1 &lt;- grid.grabExpr(print(data |&gt;\n  forestplot(labeltext = c(study, n, cor),\n             xlab = \"Correlation\",\n             xticks = c(0, .25,.5,.75, 1),\n             clip = c(0, 1))|&gt;\n    fp_add_header(study = \"Study\",n = \"N\",cor = expression(italic(r))) |&gt;\n    fp_append_row(mean  = m.cor$TE.common,\n                lower = m.cor$lower.common,\n                upper = m.cor$upper.common,\n                study = \"Summary\",\n                n = sum(m.cor$n),\n                cor = round(m.cor$TE.common,2),\n                is.summary = TRUE) |&gt;\n  fp_set_style(box = \"grey50\",\n               line = \"grey20\",\n               summary = \"black\",\n                txt_gp = fpTxtGp(label = list(gpar(cex = 0.80)),\n                                ticks = gpar(cex = 0.80),\n                                xlab  = gpar(cex = 0.80)))|&gt;\n    fp_decorate_graph(grid = structure( m.cor$TE.common,gp = gpar(lty = 2, col = \"grey30\")))\n)\n)\n\nsource('../etc/custom_funnel_plot.R')\nfp2 &lt;- custom_funnel_plot(m.cor)\n\ngridExtra::grid.arrange(fp1, fp2, ncol=2, widths=c(2,1),heights=c(2,1))\n\nWarning: Removed 684 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\nWarning: Removed 753 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nS &lt;- summarise(group_by(tmp,model_class_id),n=n(),obs=sum(stimulus_n))\nprint(knitr::kable(S))\n\n\n\nmodel_class_id\nn\nobs\n\n\n\n\nFlexible Discriminants\n6\n4993\n\n\nKernel Smoothing, Additive and KNN\n1\n1838\n\n\nLinear Methods\n8\n1762\n\n\nNeural Nets\n4\n2249\n\n\nRandom Forests\n3\n3330\n\n\n\n\nm.cor1 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 common = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  model_class_id,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\nprint(m.cor1)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 22\nNumber of observations: o = 14172\n\n                        COR            95%-CI    t  p-value\nRandom effects model 0.6685 [ 0.5599; 0.7546] 9.58 &lt; 0.0001\nPrediction interval         [-0.0120; 0.9258]              \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.1484 [0.0847; 0.3121]; tau = 0.3852 [0.2910; 0.5587]\n I^2 = 98.4% [98.0%; 98.6%]; H = 7.83 [7.15; 8.58]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1288.63   21 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                                                      k    COR\nmodel_class_id = Linear Methods                       8 0.7840\nmodel_class_id = Random Forests                       3 0.7503\nmodel_class_id = Kernel Smoothing, Additive and KNN   1 0.3873\nmodel_class_id = Neural Nets                          4 0.3404\nmodel_class_id = Flexible Discriminants               6 0.6555\n                                                               95%-CI  tau^2\nmodel_class_id = Linear Methods                     [ 0.6249; 0.8806] 0.1370\nmodel_class_id = Random Forests                     [ 0.2922; 0.9284] 0.0740\nmodel_class_id = Kernel Smoothing, Additive and KNN [ 0.3477; 0.4255]     --\nmodel_class_id = Neural Nets                        [-0.0970; 0.6676] 0.0761\nmodel_class_id = Flexible Discriminants             [ 0.4838; 0.7786] 0.0574\n                                                       tau      Q   I^2\nmodel_class_id = Linear Methods                     0.3701 195.78 96.4%\nmodel_class_id = Random Forests                     0.2721 163.33 98.8%\nmodel_class_id = Kernel Smoothing, Additive and KNN     --   0.00    --\nmodel_class_id = Neural Nets                        0.2759 102.54 97.1%\nmodel_class_id = Flexible Discriminants             0.2396 161.22 96.9%\n\nTest for subgroup differences (random effects model):\n                   Q d.f.  p-value\nBetween groups 45.71    4 &lt; 0.0001\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hartung-Knapp adjustment for random effects model (df = 21)\n- Prediction interval based on t-distribution (df = 21)\n- Fisher's z transformation of correlations\n\n\n\n\n\nS &lt;- summarise(group_by(tmp,journal_type),n=n(),obs=sum(stimulus_n))\nprint(knitr::kable(S))\n\n\n\njournal_type\nn\nobs\n\n\n\n\nEngineering\n13\n10002\n\n\nPsychology\n9\n4170\n\n\n\n\nm.cor2 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 common = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  journal_type,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\nprint(m.cor2)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 22\nNumber of observations: o = 14172\n\n                        COR            95%-CI    t  p-value\nRandom effects model 0.6685 [ 0.5599; 0.7546] 9.58 &lt; 0.0001\nPrediction interval         [-0.0120; 0.9258]              \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.1484 [0.0847; 0.3121]; tau = 0.3852 [0.2910; 0.5587]\n I^2 = 98.4% [98.0%; 98.6%]; H = 7.83 [7.15; 8.58]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1288.63   21 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                             k    COR           95%-CI  tau^2    tau      Q\njournal_type = Psychology    9 0.6880 [0.4683; 0.8276] 0.1830 0.4278 562.98\njournal_type = Engineering  13 0.6564 [0.5052; 0.7685] 0.1378 0.3712 627.09\n                             I^2\njournal_type = Psychology  98.6%\njournal_type = Engineering 98.1%\n\nTest for subgroup differences (random effects model):\n                  Q d.f. p-value\nBetween groups 0.10    1  0.7482\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hartung-Knapp adjustment for random effects model (df = 21)\n- Prediction interval based on t-distribution (df = 21)\n- Fisher's z transformation of correlations\n\n\n\n\n\ntmp &lt;- dplyr::filter(R_summary,dimension==\"valence\")\ntmp&lt;-tmp[!is.na(tmp$feature_n_categories),] # remove \nS &lt;- summarise(group_by(tmp,feature_n_categories),n=n(),obs=sum(stimulus_n))\nprint(knitr::kable(S))\n\n\n\nfeature_n_categories\nn\nobs\n\n\n\n\nFeature n &lt; 18\n4\n3016\n\n\nFeature n &gt; 18 & &lt; 260\n10\n4222\n\n\nFeature n &gt; 260\n7\n6190\n\n\n\n\ntmp &lt;- dplyr::filter(R_summary,dimension==\"valence\")\ntmp&lt;-tmp[!is.na(tmp$feature_n_categories),] # remove missing values\nm.cor3 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 common = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  feature_n_categories,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\nprint(m.cor3)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 21\nNumber of observations: o = 13428\n\n                        COR           95%-CI    t  p-value\nRandom effects model 0.6817 [0.5751; 0.7656] 9.80 &lt; 0.0001\nPrediction interval         [0.0238; 0.9276]              \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.1430 [0.0804; 0.3083]; tau = 0.3782 [0.2836; 0.5552]\n I^2 = 98.3% [98.0%; 98.6%]; H = 7.72 [7.03; 8.48]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1192.85   20 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                                                k    COR           95%-CI\nfeature_n_categories = Feature n &lt; 18           4 0.8165 [0.3609; 0.9575]\nfeature_n_categories = Feature n &gt; 18 & &lt; 260  10 0.5864 [0.3599; 0.7476]\nfeature_n_categories = Feature n &gt; 260          7 0.7023 [0.6122; 0.7744]\n                                               tau^2    tau      Q   I^2\nfeature_n_categories = Feature n &lt; 18         0.2295 0.4791 360.71 99.2%\nfeature_n_categories = Feature n &gt; 18 & &lt; 260 0.1542 0.3927 290.30 96.9%\nfeature_n_categories = Feature n &gt; 260        0.0285 0.1689 178.35 96.6%\n\nTest for subgroup differences (random effects model):\n                  Q d.f. p-value\nBetween groups 3.47    2  0.1761\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hartung-Knapp adjustment for random effects model (df = 20)\n- Prediction interval based on t-distribution (df = 20)\n- Fisher's z transformation of correlations\n\nS&lt;-summarise(group_by(tmp,feature_n_categories),n=n(),obs=sum(stimulus_n))\nprint(S)\n\n# A tibble: 3 × 3\n  feature_n_categories       n   obs\n  &lt;chr&gt;                  &lt;int&gt; &lt;int&gt;\n1 Feature n &lt; 18             4  3016\n2 Feature n &gt; 18 & &lt; 260    10  4222\n3 Feature n &gt; 260            7  6190\n\n\n\n\n\ntmp &lt;- dplyr::filter(R_summary,dimension==\"valence\")\ntmp&lt;-tmp[!is.na(tmp$feature_n_categories),] # removemissing values\n\nS&lt;-summarise(group_by(tmp,feature_n_complexity_genre),n=n(),obs=sum(stimulus_n))\nprint(knitr::kable(S))\n\n\n\nfeature_n_complexity_genre\nn\nobs\n\n\n\n\nHuge multigenre study\n3\n1812\n\n\nMedium single genre/multigenre study\n13\n7386\n\n\nMedium-large single genre/multigenre study\n2\n1262\n\n\nSmall single genre study\n3\n2968\n\n\n\nm.cor4 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 common = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  feature_n_complexity_genre,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\nprint(m.cor4)\nReview: MER: Regression: Valence: Summary\nNumber of studies: k = 21 Number of observations: o = 13428\n                    COR           95%-CI    t  p-value\nRandom effects model 0.6817 [0.5751; 0.7656] 9.80 &lt; 0.0001 Prediction interval [0.0238; 0.9276]\nQuantifying heterogeneity (with 95%-CIs): tau^2 = 0.1430 [0.0804; 0.3083]; tau = 0.3782 [0.2836; 0.5552] I^2 = 98.3% [98.0%; 98.6%]; H = 7.72 [7.03; 8.48]\nTest of heterogeneity: Q d.f. p-value 1192.85 20 &lt; 0.0001\nResults for subgroups (random effects model): k COR feature_n_complexity_genre = Small single genre study 3 0.8358 feature_n_complexity_genre = Medium single genre/multigenre … 13 0.6065 feature_n_complexity_genre = Huge multigenre study 3 0.6927 feature_n_complexity_genre = Medium-large single genre/multi … 2 0.7681 95%-CI feature_n_complexity_genre = Small single genre study [-0.1966; 0.9893] feature_n_complexity_genre = Medium single genre/multigenre … [ 0.4491; 0.7274] feature_n_complexity_genre = Huge multigenre study [ 0.4915; 0.8237] feature_n_complexity_genre = Medium-large single genre/multi … [-0.8767; 0.9977] tau^2 tau feature_n_complexity_genre = Small single genre study 0.3182 0.5641 feature_n_complexity_genre = Medium single genre/multigenre … 0.1174 0.3427 feature_n_complexity_genre = Huge multigenre study 0.0137 0.1170 feature_n_complexity_genre = Medium-large single genre/multi … 0.0679 0.2606 Q I^2 feature_n_complexity_genre = Small single genre study 358.17 99.4% feature_n_complexity_genre = Medium single genre/multigenre … 437.57 97.3% feature_n_complexity_genre = Huge multigenre study 14.21 85.9% feature_n_complexity_genre = Medium-large single genre/multi … 33.46 97.0%\nTest for subgroup differences (random effects model): Q d.f. p-value Between groups 3.99 3 0.2625\nDetails of meta-analysis methods: - Inverse variance method - Restricted maximum-likelihood estimator for tau^2 - Q-Profile method for confidence interval of tau^2 and tau - Calculation of I^2 based on Q - Hartung-Knapp adjustment for random effects model (df = 20) - Prediction interval based on t-distribution (df = 20) - Fisher’s z transformation of correlations\n\n\n\n\n\n\n\nR_studies &lt;- read.csv(\"R_studies.csv\")\ntmp &lt;- dplyr::filter(R_studies,dimension==\"arousal\")\n#if all studies, remove two with NA values\ntmp &lt;- tmp[!is.na(tmp$values),]\n#dim(tmp)\n\n# Take all models\nm.cor &lt;- metacor(cor = values,     # values \n                 n = stimulus_n,\n                 studlab = unique_id,\n                 data = tmp,\n                 common = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"PM\",# was REML, but we switch to Paule-Mandel because Langan et al., 2019\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Arousal: Summary\")\n\nprint(m.cor)\n\nReview:     MER: Regression: Arousal: Summary\n\nNumber of studies: k = 102\nNumber of observations: o = 60017\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.7909 [0.7700; 0.8101] 39.90 &lt; 0.0001\nPrediction interval         [0.4999; 0.9214]               \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.0692 [0.0520; 0.0955]; tau = 0.2631 [0.2280; 0.3090]\n I^2 = 96.2% [95.8%; 96.6%]; H = 5.14 [4.87; 5.43]\n\nTest of heterogeneity:\n       Q d.f. p-value\n 2666.55  101       0\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Paule-Mandel estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hartung-Knapp adjustment for random effects model (df = 101)\n- Prediction interval based on t-distribution (df = 101)\n- Fisher's z transformation of correlations\n\nprint(FisherZInv(m.cor$TE.random))\n\n[1] 0.7908857\n\nprint(FisherZInv(m.cor$upper.random))\n\n[1] 0.8100518\n\nprint(FisherZInv(m.cor$lower.random))\n\n[1] 0.7700316\n\n\n\n\n\n\nR_summary &lt;- read.csv(\"R_summary.csv\")\n\n# select regression studies with r2\ntmp &lt;- dplyr::filter(R_summary,dimension==\"arousal\")\n#tmp &lt;- dplyr::filter(R_studies,dimension==\"valence\")\n#dim(tmp)\n\n#if all studies, remove two\n#tmp &lt;- tmp[!is.na(tmp$values),]\n#dim(tmp)\n\n## Disambiguate the studies\ntmp$studyREF[tmp$studyREF==\"Wang et al 2022\"] &lt;- c(\"Wang et al. 2022a\",\"Wang et al. 2022b\")\n\n# Max values\nm.cor &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = studyREF,#citekey, # unique_id\n                 data = tmp,\n                 common = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Arousal: Summary\")\n\nprint(m.cor)\n\nReview:     MER: Regression: Arousal: Summary\n\nNumber of studies: k = 22\nNumber of observations: o = 14172\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.8087 [0.7404; 0.8604] 13.60 &lt; 0.0001\nPrediction interval         [0.3127; 0.9582]               \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.1411 [0.0805; 0.2999]; tau = 0.3756 [0.2838; 0.5476]\n I^2 = 97.9% [97.4%; 98.3%]; H = 6.90 [6.26; 7.62]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1001.16   21 &lt; 0.0001\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hartung-Knapp adjustment for random effects model (df = 21)\n- Prediction interval based on t-distribution (df = 21)\n- Fisher's z transformation of correlations\n\nprint(FisherZInv(m.cor$TE.random))\n\n[1] 0.8086765\n\nprint(FisherZInv(m.cor$upper.random))\n\n[1] 0.8604211\n\nprint(FisherZInv(m.cor$lower.random))\n\n[1] 0.7404257\n\n\n\n\n\n\n\n# Method 1: Give us the Egger's test about beta coefficient from funnel\nprint(eggers.test(m.cor))\n\nEggers' test of the intercept \n============================= \n\n intercept       95% CI     t         p\n     0.789 -4.87 - 6.45 0.273 0.7876923\n\nEggers' test does not indicate the presence of funnel plot asymmetry. \n\n# Method 2: Find the impact to the results when removing those outside the 95CI\nO &lt;- find.outliers(m.cor) # 13 remaining out of 24\nprint(O)\n\nIdentified outliers (random-effects model) \n------------------------------------------ \n\"Battcock et al 2021\", \"Coutinho et al 2017\", \"Gingras et al 2014\", \"Grekow et al 2018\", \"Koh et al 2023\", \"Orjesek et al 2022\", \"Wang et al. 2022b\", \"Zhang et al 2019\", \"Zhang et al 2023\" \n \nResults with outliers removed \n----------------------------- \nReview:     MER: Regression: Arousal: Summary\n\nNumber of studies: k = 13\nNumber of observations: o = 10613\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.8262 [0.8061; 0.8445] 42.44 &lt; 0.0001\nPrediction interval         [0.7721; 0.8684]               \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.0042 [0.0016; 0.0501]; tau = 0.0649 [0.0401; 0.2239]\n I^2 = 76.8% [60.6%; 86.4%]; H = 2.08 [1.59; 2.71]\n\nTest of heterogeneity:\n     Q d.f.  p-value\n 51.82   12 &lt; 0.0001\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hartung-Knapp adjustment for random effects model (df = 12)\n- Prediction interval based on t-distribution (df = 12)\n- Fisher's z transformation of correlations\n\n# Method 3: Leave-out-out analysis etc for individual influence (not useful here)\n#infan &lt;- InfluenceAnalysis(m.cor)\n\n# Method 4: Focus on 10% of most precise studies (Stanley, Jarrel, Doucouliagos 2010)\nthres&lt;-quantile(m.cor$seTE,0.1)\nind&lt;-m.cor$seTE&lt;=as.numeric(thres)\nm.cor10pct &lt;- update(m.cor, subset = which(ind))\n\n# Method 5: P curve analysis (Simonsohn, Simmons & Nelson, 2015)\npcurve(m.cor)\n\n\n\n\n\n\n\n\nP-curve analysis \n ----------------------- \n- Total number of provided studies: k = 22 \n- Total number of p&lt;0.05 studies included into the analysis: k = 22 (100%) \n- Total number of studies with p&lt;0.025: k = 22 (100%) \n   \nResults \n ----------------------- \n                    pBinomial   zFull pFull   zHalf pHalf\nRight-skewness test         0 -33.770     0 -33.237     0\nFlatness test               1  34.184     1  34.443     1\nNote: p-values of 0 or 1 correspond to p&lt;0.001 and p&gt;0.999, respectively.   \nPower Estimate: 99% (99%-99%)\n   \nEvidential value \n ----------------------- \n- Evidential value present: yes \n- Evidential value absent/inadequate: no \n\n\n\n\n\n\nfig2a &lt;- forest(m.cor,\n       sortvar = TE,\n       prediction = FALSE, \n             print.tau2 = FALSE,\n             leftlabs = c(\"Author\", \"N\"),studlab = studyREF)\n\n\n\n\n\n\n\nfig2b&lt;-funnel(m.cor, common = FALSE, studlab=TRUE,backtransf=TRUE)\n\n\n\n\n\n\n\nlibrary(forestplot)\ndata&lt;-tibble::tibble(mean=m.cor$cor,lower=FisherZInv(m.cor$lower),upper=FisherZInv(m.cor$upper),study=m.cor$studlab,n=m.cor$n,cor=round(m.cor$cor,2))\ndata&lt;-dplyr::arrange(data,mean)\n\nfp1 &lt;- grid.grabExpr(print(data |&gt;\n  forestplot(labeltext = c(study, n, cor),\n             xlab = \"Correlation\",\n             xticks = c(0, .25,.5,.75, 1),\n             clip = c(0, 1))|&gt;\n    fp_add_header(study = \"Study\",n = \"N\",cor = expression(italic(r))) |&gt;\n    fp_append_row(mean  = m.cor$TE.common,\n                lower = m.cor$lower.common,\n                upper = m.cor$upper.common,\n                study = \"Summary\",\n                n = sum(m.cor$n),\n                cor = round(m.cor$TE.common,2),\n                is.summary = TRUE) |&gt;\n  fp_set_style(box = \"grey50\",\n               line = \"grey20\",\n               summary = \"black\",\n                txt_gp = fpTxtGp(label = list(gpar(cex = 0.80)),\n                                ticks = gpar(cex = 0.80),\n                                xlab  = gpar(cex = 0.80)))|&gt;\n    fp_decorate_graph(grid = structure( m.cor$TE.common,gp = gpar(lty = 2, col = \"grey30\")))\n)\n)\n\nsource('../etc/custom_funnel_plot.R')\nfp2 &lt;- custom_funnel_plot(m.cor)\n\ngridExtra::grid.arrange(fp1, fp2, ncol=2, widths=c(2,1),heights=c(2,1))\n\nWarning: Removed 754 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\nWarning: Removed 954 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_hline()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nS &lt;- summarise(group_by(tmp,model_class_id),n=n(),obs=sum(stimulus_n))\nprint(knitr::kable(S))\n\n\n\nmodel_class_id\nn\nobs\n\n\n\n\nFlexible Discriminants\n6\n4993\n\n\nKernel Smoothing, Additive and KNN\n1\n1838\n\n\nLinear Methods\n8\n1762\n\n\nNeural Nets\n4\n2249\n\n\nRandom Forests\n3\n3330\n\n\n\n\nm.cor1 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 common = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  model_class_id,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\nprint(m.cor1)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 22\nNumber of observations: o = 14172\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.8087 [0.7404; 0.8604] 13.60 &lt; 0.0001\nPrediction interval         [0.3127; 0.9582]               \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.1411 [0.0805; 0.2999]; tau = 0.3756 [0.2838; 0.5476]\n I^2 = 97.9% [97.4%; 98.3%]; H = 6.90 [6.26; 7.62]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1001.16   21 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                                                      k    COR           95%-CI\nmodel_class_id = Linear Methods                       8 0.8812 [0.8079; 0.9277]\nmodel_class_id = Random Forests                       3 0.8085 [0.7334; 0.8641]\nmodel_class_id = Kernel Smoothing, Additive and KNN   1 0.8185 [0.8029; 0.8331]\nmodel_class_id = Neural Nets                          4 0.5339 [0.3281; 0.6912]\nmodel_class_id = Flexible Discriminants               6 0.8077 [0.6437; 0.9008]\n                                                     tau^2    tau      Q   I^2\nmodel_class_id = Linear Methods                     0.0846 0.2908 104.87 93.3%\nmodel_class_id = Random Forests                     0.0025 0.0505   5.77 65.4%\nmodel_class_id = Kernel Smoothing, Additive and KNN     --     --   0.00    --\nmodel_class_id = Neural Nets                        0.0190 0.1379  21.17 85.8%\nmodel_class_id = Flexible Discriminants             0.1125 0.3354 246.31 98.0%\n\nTest for subgroup differences (random effects model):\n                   Q d.f.  p-value\nBetween groups 50.47    4 &lt; 0.0001\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hartung-Knapp adjustment for random effects model (df = 21)\n- Prediction interval based on t-distribution (df = 21)\n- Fisher's z transformation of correlations\n\n\n\n\n\nS &lt;- summarise(group_by(tmp,journal_type),n=n(),obs=sum(stimulus_n))\nprint(knitr::kable(S))\n\n\n\njournal_type\nn\nobs\n\n\n\n\nEngineering\n13\n10002\n\n\nPsychology\n9\n4170\n\n\n\n\nm.cor2 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 common = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  journal_type,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\nprint(m.cor2)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 22\nNumber of observations: o = 14172\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.8087 [0.7404; 0.8604] 13.60 &lt; 0.0001\nPrediction interval         [0.3127; 0.9582]               \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.1411 [0.0805; 0.2999]; tau = 0.3756 [0.2838; 0.5476]\n I^2 = 97.9% [97.4%; 98.3%]; H = 6.90 [6.26; 7.62]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1001.16   21 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                             k    COR           95%-CI  tau^2    tau      Q\njournal_type = Psychology    9 0.8389 [0.7417; 0.9016] 0.1079 0.3286 345.30\njournal_type = Engineering  13 0.7858 [0.6693; 0.8647] 0.1655 0.4068 650.86\n                             I^2\njournal_type = Psychology  97.7%\njournal_type = Engineering 98.2%\n\nTest for subgroup differences (random effects model):\n                  Q d.f. p-value\nBetween groups 0.94    1  0.3332\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hartung-Knapp adjustment for random effects model (df = 21)\n- Prediction interval based on t-distribution (df = 21)\n- Fisher's z transformation of correlations\n\n\n\n\n\ntmp &lt;- dplyr::filter(R_summary,dimension==\"arousal\")\ntmp&lt;-tmp[!is.na(tmp$feature_n_categories),] # remove \nS &lt;- summarise(group_by(tmp,feature_n_categories),n=n(),obs=sum(stimulus_n))\nprint(knitr::kable(S))\n\n\n\nfeature_n_categories\nn\nobs\n\n\n\n\nFeature n &lt; 18\n4\n3016\n\n\nFeature n &gt; 18 & &lt; 260\n10\n4222\n\n\nFeature n &gt; 260\n7\n6190\n\n\n\n\ntmp &lt;- dplyr::filter(R_summary,dimension==\"arousal\")\ntmp&lt;-tmp[!is.na(tmp$feature_n_categories),] # remove missing values\nm.cor3 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 common = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  feature_n_categories,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\nprint(m.cor3)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 21\nNumber of observations: o = 13428\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.8182 [0.7536; 0.8672] 14.11 &lt; 0.0001\nPrediction interval         [0.3628; 0.9581]               \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.1301 [0.0731; 0.2852]; tau = 0.3607 [0.2704; 0.5341]\n I^2 = 97.5% [96.9%; 98.0%]; H = 6.28 [5.64; 6.99]\n\nTest of heterogeneity:\n      Q d.f.  p-value\n 789.02   20 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                                                k    COR           95%-CI\nfeature_n_categories = Feature n &lt; 18           4 0.8927 [0.7379; 0.9582]\nfeature_n_categories = Feature n &gt; 18 & &lt; 260  10 0.7655 [0.5885; 0.8725]\nfeature_n_categories = Feature n &gt; 260          7 0.8288 [0.7922; 0.8594]\n                                               tau^2    tau      Q   I^2\nfeature_n_categories = Feature n &lt; 18         0.0868 0.2946  62.53 95.2%\nfeature_n_categories = Feature n &gt; 18 & &lt; 260 0.2030 0.4506 435.78 97.9%\nfeature_n_categories = Feature n &gt; 260        0.0111 0.1052  43.15 86.1%\n\nTest for subgroup differences (random effects model):\n                  Q d.f. p-value\nBetween groups 4.05    2  0.1317\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hartung-Knapp adjustment for random effects model (df = 20)\n- Prediction interval based on t-distribution (df = 20)\n- Fisher's z transformation of correlations\n\nS&lt;-summarise(group_by(tmp,feature_n_categories),n=n(),obs=sum(stimulus_n))\nprint(S)\n\n# A tibble: 3 × 3\n  feature_n_categories       n   obs\n  &lt;chr&gt;                  &lt;int&gt; &lt;int&gt;\n1 Feature n &lt; 18             4  3016\n2 Feature n &gt; 18 & &lt; 260    10  4222\n3 Feature n &gt; 260            7  6190\n\n\n\n\n\ntmp &lt;- dplyr::filter(R_summary,dimension==\"arousal\")\ntmp&lt;-tmp[!is.na(tmp$feature_n_categories),] # remove missing values\n\nS&lt;-summarise(group_by(tmp,feature_n_complexity_genre),n=n(),obs=sum(stimulus_n))\nprint(knitr::kable(S))\n\n\n\nfeature_n_complexity_genre\nn\nobs\n\n\n\n\nHuge multigenre study\n3\n1812\n\n\nMedium single genre/multigenre study\n13\n7386\n\n\nMedium-large single genre/multigenre study\n2\n1262\n\n\nSmall single genre study\n3\n2968\n\n\n\nm.cor4 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 common = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  feature_n_complexity_genre,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\nprint(m.cor4)\nReview: MER: Regression: Valence: Summary\nNumber of studies: k = 21 Number of observations: o = 13428\n                    COR           95%-CI     t  p-value\nRandom effects model 0.8182 [0.7536; 0.8672] 14.11 &lt; 0.0001 Prediction interval [0.3628; 0.9581]\nQuantifying heterogeneity (with 95%-CIs): tau^2 = 0.1301 [0.0731; 0.2852]; tau = 0.3607 [0.2704; 0.5341] I^2 = 97.5% [96.9%; 98.0%]; H = 6.28 [5.64; 6.99]\nTest of heterogeneity: Q d.f. p-value 789.02 20 &lt; 0.0001\nResults for subgroups (random effects model): k COR feature_n_complexity_genre = Small single genre study 3 0.9048 feature_n_complexity_genre = Medium single genre/multigenre … 13 0.7784 feature_n_complexity_genre = Huge multigenre study 3 0.8371 feature_n_complexity_genre = Medium-large single genre/multi … 2 0.8355 95%-CI feature_n_complexity_genre = Small single genre study [0.5902; 0.9808] feature_n_complexity_genre = Medium single genre/multigenre … [0.6611; 0.8586] feature_n_complexity_genre = Huge multigenre study [0.6493; 0.9287] feature_n_complexity_genre = Medium-large single genre/multi … [0.4534; 0.9582] tau^2 tau feature_n_complexity_genre = Small single genre study 0.1046 0.3234 feature_n_complexity_genre = Medium single genre/multigenre … 0.1530 0.3912 feature_n_complexity_genre = Huge multigenre study 0.0285 0.1689 feature_n_complexity_genre = Medium-large single genre/multi … 0.0044 0.0666 Q I^2 feature_n_complexity_genre = Small single genre study 62.30 96.8% feature_n_complexity_genre = Medium single genre/multigenre … 506.15 97.6% feature_n_complexity_genre = Huge multigenre study 25.84 92.3% feature_n_complexity_genre = Medium-large single genre/multi … 3.12 68.0%\nTest for subgroup differences (random effects model): Q d.f. p-value Between groups 4.43 3 0.2186\nDetails of meta-analysis methods: - Inverse variance method - Restricted maximum-likelihood estimator for tau^2 - Q-Profile method for confidence interval of tau^2 and tau - Calculation of I^2 based on Q - Hartung-Knapp adjustment for random effects model (df = 20) - Prediction interval based on t-distribution (df = 20) - Fisher’s z transformation of correlations\n\n\n\n\n\n\nC_studies &lt;- read.csv(\"C_studies.csv\")\nC_studies &lt;- C_studies[!is.na(C_studies$values),]\n\n# yang2021an needs to be encoded for classification (currently just regression)\nC_summary &lt;- read.csv(\"C_summary.csv\")\nC_classes &lt;- read.csv(\"C_study_class_n.csv\")\n\nC_summary &lt;- merge(C_summary, C_classes)\n\nm.cor.c.all &lt;- metacor(cor = values,     # values \n                 n = stimulus_n,\n                 studlab = studyREF, # unique_id\n                 data = C_studies,\n                 common = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 backtransf = TRUE,\n                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Classification: Summary\")\n\nm.cor.c.all\n\nReview:     MER: Classification: Summary\n\nNumber of studies: k = 86\nNumber of observations: o = 80544\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.8253 [0.7908; 0.8546] 23.43 &lt; 0.0001\nPrediction interval         [0.2437; 0.9703]               \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.2137 [0.1597; 0.2940]; tau = 0.4623 [0.3996; 0.5422]\n I^2 = 99.7%; H = 17.66\n\nTest of heterogeneity:\n        Q d.f. p-value\n 26521.76   85       0\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hartung-Knapp adjustment for random effects model (df = 85)\n- Prediction interval based on t-distribution (df = 85)\n- Fisher's z transformation of correlations\n\n#m.cor_backtransformed &lt;- m.cor\n#m.cor_backtransformed$TE &lt;- FisherZInv(m.cor_backtransformed$TE)\nprint(funnel(m.cor.c.all, common = FALSE, studlab=TRUE,backtransf=TRUE))\n\n\n\n\n\n\n\n\n$xvals\n [1] 2.3799720 2.0142671 1.9772582 2.1220666 1.8827026 1.7585755 2.0196809\n [8] 1.7247148 1.5835413 1.6709175 0.9175788 2.2544044 1.6895184 1.2958523\n[15] 1.1450798 2.2112934 1.5982081 1.2848361 1.1512076 1.9404160 1.5322976\n[22] 1.1484217 1.0398896 1.8348676 1.4432431 1.0431836 0.9579293 0.5672419\n[29] 0.5295059 0.5583672 0.6136900 0.4168798 0.5609288 1.2167740 1.4470097\n[36] 1.3367938 1.5844886 1.3367938 1.4893225 1.3367938 1.6394812 0.7610522\n[43] 0.5343909 0.8332468 0.3444099 0.3809810 0.5174748 1.3253662 1.6561690\n[50] 0.6225264 1.0986123 1.0714317 1.0203278 1.0986123 1.0986123 1.0986123\n[57] 1.0986123 1.0986123 1.0986123 0.9729551 1.1568175 1.2419119 1.2211735\n[64] 1.1881364 1.1881364 1.1881364 0.7424116 0.7841811 0.7684032 0.8300447\n[71] 1.0203278 0.7009966 0.8527435 0.8722194 0.9014435 1.0986123 0.7615687\n[78] 0.9097245 0.8722194 0.8309765 0.9212749 0.9427868 0.9914972 0.9014435\n[85] 1.0302286 0.9181056\n\n$yvals\n [1] 0.01459116 0.01459116 0.01459116 0.01459116 0.01459116 0.01459116\n [7] 0.01459116 0.01459116 0.01459116 0.01388220 0.01388220 0.05103104\n[13] 0.05103104 0.05103104 0.05103104 0.05103104 0.05103104 0.05103104\n[19] 0.05103104 0.05103104 0.05103104 0.05103104 0.05103104 0.05103104\n[25] 0.05103104 0.05103104 0.05103104 0.04222003 0.04222003 0.04222003\n[31] 0.04222003 0.04222003 0.04222003 0.09090909 0.09090909 0.09090909\n[37] 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.05802589\n[43] 0.05802589 0.03338903 0.02357678 0.02357678 0.02357678 0.02357678\n[49] 0.04845016 0.04845016 0.07715167 0.07715167 0.07715167 0.07715167\n[55] 0.07715167 0.07715167 0.07715167 0.07715167 0.07715167 0.07715167\n[61] 0.07715167 0.07715167 0.07715167 0.07715167 0.07715167 0.07715167\n[67] 0.03239318 0.03239318 0.07715167 0.07715167 0.07715167 0.07715167\n[73] 0.07715167 0.07715167 0.07715167 0.07715167 0.07715167 0.07715167\n[79] 0.07715167 0.07715167 0.07715167 0.07715167 0.07715167 0.07715167\n[85] 0.07715167 0.07715167\n\n$pch\n [1] 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21\n[26] 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21\n[51] 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21\n[76] 21 21 21 21 21 21 21 21 21 21 21\n\n$text\nNULL\n\n$cex\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[39] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[77] 1 1 1 1 1 1 1 1 1 1\n\n$col\n [1] \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\"\n[10] \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\"\n[19] \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\"\n[28] \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\"\n[37] \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\"\n[46] \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\"\n[55] \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\"\n[64] \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\"\n[73] \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\"\n[82] \"black\" \"black\" \"black\" \"black\" \"black\"\n\n$bg\n [1] \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\"\n [7] \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\"\n[13] \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\"\n[19] \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\"\n[25] \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\"\n[31] \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\"\n[37] \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\"\n[43] \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\"\n[49] \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\"\n[55] \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\"\n[61] \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\"\n[67] \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\"\n[73] \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\"\n[79] \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\"\n[85] \"darkgray\" \"darkgray\"\n\n$cex.studlab\n [1] 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8\n[20] 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8\n[39] 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8\n[58] 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8\n[77] 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8\n\n$xlim\n[1] 0.3360096 2.4394713\n\n$ylim\n[1] 0.09090909 0.00000000\n\n\n\n\n\n\n# get stimulus and genre metadata for classification studies:\nC_studies |&gt;\n  group_by(citekey) |&gt;\n  summarize(feature_n = unique(feature_n),\n            feature_n_complexity = unique(feature_n_complexity),\n            stimulus_genre_mixed = unique(stimulus_genre_mixed)) -&gt; C_splits\n\n# create feature_n_complexity_genre column:\nC_splits$feature_n_complexity_genre &lt;- \"\"\n\n# define splits\nC_splits[C_splits$feature_n_complexity %in% \"Feature n &gt; 30 & &lt; 300\" &\n        C_splits$stimulus_genre_mixed == \"MultiGenre\",]$feature_n_complexity_genre &lt;- \"Medium multi-genre study\"\nC_splits[C_splits$stimulus_genre_mixed %in% \"SingleGenre\" &\n                             C_splits$feature_n_complexity %in% \"Feature n &lt; 30\" ,]$feature_n_complexity_genre &lt;- \"Small single-genre study\"\nC_splits[C_splits$feature_n_complexity == \"Feature n &gt; 300\",]$feature_n_complexity_genre &lt;- \"Huge single or multigenre study\"\nC_splits[C_splits$citekey == \"alvarez2023ri\",]$feature_n_complexity_genre &lt;- \"Small, multi-genre study\"\nC_splits[C_splits$citekey == \"zhang2016br\",]$feature_n_complexity_genre &lt;- \"Medium, single-genre study\"\n# add splits to summary:\nC_summary &lt;- left_join(C_summary, C_splits)\n\nJoining with `by = join_by(citekey, stimulus_genre_mixed)`\n\n\n\n\n\nC_summary$classes &lt;- 0\nC_summary[C_summary$n_classes &lt; 3,]$classes &lt;- \"Binary\"\nC_summary[C_summary$n_classes &gt;= 3,]$classes &lt;- \"Multiclass\"\n\n\n\n\n\n\nm.cor.c &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = studyREF, # unique_id\n                 data = C_summary,\n                 common = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 backtransf = TRUE,\n                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Classification: Summary\")\n\n\n\n\nfig3a &lt;- forest(m.cor.c,\n                sortvar = TE,\n                prediction = FALSE, \n                print.tau2 = FALSE,\n                leftlabs = c(\"Author\", \"N\"),studlab = studyREF)\n\n\n\n\n\n\n\nfig3b&lt;-funnel(m.cor.c, common = FALSE, studlab=TRUE,backtransf=TRUE)\n\n\n\n\n\n\n\nlibrary(forestplot)\ndata&lt;-tibble::tibble(mean=m.cor.c$cor,lower=FisherZInv(m.cor.c$lower),upper=FisherZInv(m.cor.c$upper),study=m.cor.c$studlab,n=m.cor.c$n,cor=round(m.cor.c$cor,2))\ndata&lt;-dplyr::arrange(data,mean)\n\nfp3 &lt;- grid.grabExpr(print(data |&gt;\n                             forestplot(labeltext = c(study, n, cor),\n                                        xlab = \"Correlation\",\n                                        xticks = c(0, .25,.5,.75, 1),\n                                        clip = c(0, 1))|&gt;\n                             fp_add_header(study = \"Study\",n = \"N\",cor = expression(italic(r))) |&gt;\n                             fp_append_row(mean  = m.cor.c$TE.common,\n                                           lower = m.cor.c$lower.common,\n                                           upper = m.cor.c$upper.common,\n                                           study = \"Summary\",\n                                           n = sum(m.cor.c$n),\n                                           cor = round(m.cor.c$TE.common,2),\n                                           is.summary = TRUE) |&gt;\n                             fp_set_style(box = \"grey50\",\n                                          line = \"grey20\",\n                                          summary = \"black\",\n                                          txt_gp = fpTxtGp(label = list(gpar(cex = 0.80)),\n                                                           ticks = gpar(cex = 0.80),\n                                                           xlab  = gpar(cex = 0.80)))|&gt;\n                             fp_decorate_graph(grid = structure( m.cor.c$TE.common,gp = gpar(lty = 2, col = \"grey30\")))\n)\n)\n\nsource('../etc/custom_funnel_plot.R')\nfp4 &lt;- custom_funnel_plot(m.cor.c)\n\ngridExtra::grid.arrange(fp3, fp4, ncol=2, widths=c(2,1),heights=c(2,1))\n\nWarning: Removed 984 rows containing missing values or values outside the scale range\n(`geom_line()`).\nRemoved 984 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_hline()`).\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(ggrepel)\ntmpdata &lt;- data.frame(SE = FisherZInv(m.cor.c$seTE), Zr = FisherZInv(m.cor.c$TE),studies=m.cor.c$studlab)\n\ntmpdata$citekey&lt;-str_replace_all(tmpdata$studies,'-.*$','')\ntmpdata$citekey&lt;-factor(tmpdata$citekey)\n\ng &lt;- ggplot(tmpdata,aes(y = SE, x = Zr,label=studies,color=citekey,fill=citekey)) +\n  geom_point(show.legend = FALSE) +\n  geom_label_repel(size=1.5,max.overlaps = 39,color=\"black\",show.legend = FALSE)+\n  ylab('Standard Error') + \n  xlab('r')+\n  scale_y_reverse()+\n#  scale_x_continuous(breaks=seq(0.0,1.0,0.25),limits=c(0,1.0))+\n#  coord_flip()+\n  theme_bw()\nprint(g)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Method 1: Give us the Egger's test about beta coefficient from funnel\nprint(eggers.test(m.cor.c))\n\nEggers' test of the intercept \n============================= \n\n intercept        95% CI      t          p\n   -18.764 -38.69 - 1.16 -1.846 0.09468325\n\nEggers' test does not indicate the presence of funnel plot asymmetry. \n\n# Method 2: Find the impact to the results when removing those outside the 95CI\nO &lt;- find.outliers(m.cor.c) # 13 remaining out of 24\nprint(O)\n\nIdentified outliers (random-effects model) \n------------------------------------------ \n\"Agarwal et al 2021\", \"Bhuvanakumar et al 2023\", \"Dufour et al 2021\", \"Hu et al 2022\", \"Nguyen et al 2017\", \"Panda et al 2020\" \n \nResults with outliers removed \n----------------------------- \nReview:     MER: Classification: Summary\n\nNumber of studies: k = 6\nNumber of observations: o = 7889\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.8941 [0.8282; 0.9356] 14.29 &lt; 0.0001\nPrediction interval         [0.6506; 0.9709]               \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.0569 [0.0199; 0.3670]; tau = 0.2385 [0.1410; 0.6058]\n I^2 = 97.7% [96.6%; 98.5%]; H = 6.63 [5.39; 8.15]\n\nTest of heterogeneity:\n      Q d.f.  p-value\n 219.67    5 &lt; 0.0001\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hartung-Knapp adjustment for random effects model (df = 5)\n- Prediction interval based on t-distribution (df = 5)\n- Fisher's z transformation of correlations\n\n# Method 3: Leave-out-out analysis etc for individual influence (not useful here)\n#infan &lt;- InfluenceAnalysis(m.cor)\n\n# Method 4: Focus on 10% of most precise studies (Stanley, Jarrel, Doucouliagos 2010)\nthres&lt;-quantile(m.cor.c$seTE,0.1)\nind&lt;-m.cor.c$seTE&lt;=as.numeric(thres)\nm.cor10pct &lt;- update(m.cor.c, subset = which(ind))\n\n# Method 5: P curve analysis (Simonsohn, Simmons & Nelson, 2015)\npcurve(m.cor.c)\n\n\n\n\n\n\n\n\nP-curve analysis \n ----------------------- \n- Total number of provided studies: k = 12 \n- Total number of p&lt;0.05 studies included into the analysis: k = 12 (100%) \n- Total number of studies with p&lt;0.025: k = 12 (100%) \n   \nResults \n ----------------------- \n                    pBinomial   zFull pFull   zHalf pHalf\nRight-skewness test         0 -26.866     0 -26.559     0\nFlatness test               1  28.149     1  28.149     1\nNote: p-values of 0 or 1 correspond to p&lt;0.001 and p&gt;0.999, respectively.   \nPower Estimate: 8% (99%-99%)\n   \nEvidential value \n ----------------------- \n- Evidential value present: yes \n- Evidential value absent/inadequate: no \n\n\n\n\n\n\n\nforest(m.cor.c.o,\n       sortvar = TE,\n       prediction = FALSE, \n             print.tau2 = FALSE,\n             leftlabs = c(\"Author\", \"N\"),studlab = citekey)\n\n\n\n\n\n\n\nfunnel(m.cor.c.o, common = FALSE, studlab=TRUE,backtransf=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nm.cor_classes &lt;- update(m.cor.c, \n       subgroup = C_summary$classes, \n       tau.common = FALSE,\n       prediction = TRUE)\n\nforest(m.cor_classes,\n       sortvar = TE,\n       prediction = FALSE, \n             print.tau2 = FALSE,\n             leftlabs = c(\"Author\", \"N\"),studlab = citekey)\n\n\n\n\n\n\n\nfunnel(m.cor, common = FALSE, studlab=TRUE,backtransf=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\nm.cor_subgroups &lt;- update(m.cor.c, \n       subgroup = stimulus_genre_mixed, \n       tau.common = FALSE,\n       prediction = TRUE)\n\nprint(m.cor_subgroups)\n#forest(m.cor_subgroups,subgroup=TRUE)\n\n\n\n\n\nm.cor_complexity &lt;- update(m.cor.c, \n       subgroup = C_summary$feature_n_complexity_genre, \n       tau.common = FALSE,\n       prediction = TRUE)\n\nprint(m.cor_complexity)\n\nReview:     MER: Classification: Summary\n\nNumber of studies: k = 12\nNumber of observations: o = 15696\n\n                        COR           95%-CI    t  p-value\nRandom effects model 0.8753 [0.7555; 0.9384] 8.07 &lt; 0.0001\nPrediction interval         [0.0256; 0.9907]              \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.3366 [0.1675; 0.9707]; tau = 0.5802 [0.4093; 0.9853]\n I^2 = 99.8%; H = 21.40\n\nTest of heterogeneity:\n       Q d.f. p-value\n 5039.29   11       0\n\nResults for subgroups (random effects model):\n                                                               k    COR\nfeature_n_complexity_genre = Medium multi-genre study          4 0.8555\nfeature_n_complexity_genre = Small, multi-genre study          1 0.9317\nfeature_n_complexity_genre = Small single-genre study          3 0.9378\nfeature_n_complexity_genre = Huge single or multigenre study   3 0.7907\nfeature_n_complexity_genre = Medium, single-genre study        1 0.8000\n                                                                        95%-CI\nfeature_n_complexity_genre = Medium multi-genre study        [ 0.0092; 0.9877]\nfeature_n_complexity_genre = Small, multi-genre study        [ 0.9280; 0.9352]\nfeature_n_complexity_genre = Small single-genre study        [ 0.4269; 0.9949]\nfeature_n_complexity_genre = Huge single or multigenre study [-0.1319; 0.9793]\nfeature_n_complexity_genre = Medium, single-genre study      [ 0.7386; 0.8482]\n                                                              tau^2    tau\nfeature_n_complexity_genre = Medium multi-genre study        0.6334 0.7959\nfeature_n_complexity_genre = Small, multi-genre study            --     --\nfeature_n_complexity_genre = Small single-genre study        0.2546 0.5046\nfeature_n_complexity_genre = Huge single or multigenre study 0.2294 0.4789\nfeature_n_complexity_genre = Medium, single-genre study          --     --\n                                                                   Q   I^2\nfeature_n_complexity_genre = Medium multi-genre study        3751.10 99.9%\nfeature_n_complexity_genre = Small, multi-genre study           0.00    --\nfeature_n_complexity_genre = Small single-genre study         140.04 98.6%\nfeature_n_complexity_genre = Huge single or multigenre study   75.79 97.4%\nfeature_n_complexity_genre = Medium, single-genre study         0.00    --\n\nTest for subgroup differences (random effects model):\n                   Q d.f.  p-value\nBetween groups 58.51    4 &lt; 0.0001\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hartung-Knapp adjustment for random effects model (df = 11)\n- Prediction interval based on t-distribution (df = 11)\n- Fisher's z transformation of correlations\n\n\n\n\n\n\nm.cor_subgroups &lt;- update(m.cor.c, \n       subgroup = model_class_id, \n       tau.common = FALSE,\n       prediction = TRUE)\n\nprint(m.cor_subgroups)\n#forest(m.cor_subgroups,subgroup=TRUE)\n\n\n\nTo show the quality differences between core and eliminated studies (in progress).\n\ntmpdata &lt;- data.frame(SE = m.cor.c$seTE, Zr = m.cor.c$TE, studies=m.cor.c$studlab)\n\ntmpdata$studyREF &lt;- substr(tmpdata$studies,1,nchar(tmpdata$studies)-2)\ntmpdata$studyREF &lt;- str_replace_all(tmpdata$studyREF,'([0-9]+)',' et al \\\\1')\ntmpdata$studyREF &lt;- str_to_sentence(tmpdata$studyREF)\ntmpdata$studyREF\n\n [1] \"Agarwal et al  et al 20\"      \"Alvarez et al  et al 20\"     \n [3] \"Bhuvanakumar et al  et al 20\" \"Dufour et al  et al 20\"      \n [5] \"Hizlisoy et al  et al 20\"     \"Hu et al  et al 20\"          \n [7] \"Nguyen et al  et al 20\"       \"Panda et al  et al 20\"       \n [9] \"Sorussa et al  et al 20\"      \"Yeh et al  et al 20\"         \n[11] \"Zhang et al  et al 20\"        \"Zhang et al  et al 20\"       \n\nestimate = m.cor.c$TE.common\nse = m.cor.c$seTE.common\nse.seq=seq(0, max(m.cor.c$cor), 0.001)\nll95 = estimate-(1.96*se.seq)\nul95 = estimate+(1.96*se.seq)\nll99 = estimate-(3.29*se.seq)\nul99 = estimate+(3.29*se.seq)\nmeanll95 = estimate-(1.96*se)\nmeanul95 = estimate+(1.96*se)\ndfCI = data.frame(ll95, ul95, ll99, ul99, se.seq, estimate, meanll95, meanul95)\n\nfp = ggplot(NULL) +\n  geom_point(aes(x = SE, y = Zr), color='grey50',data=tmpdata) +\n  geom_text_repel(aes(x = SE, y = Zr, label=studyREF), data=tmpdata,size=2.5,max.overlaps = 40)+\n  xlab('Standard Error') + ylab('Fisher\\'s z transformed correlation')+\n  geom_line(aes(x = se.seq, y = ll95), linetype = 'dotted', data = dfCI) +\n  geom_line(aes(x = se.seq, y = ul95), linetype = 'dotted', data = dfCI) +\n  geom_segment(aes(x = min(se.seq), y = meanll95, xend = max(se.seq), yend = meanll95), linetype='dotted', data=dfCI) +\n  geom_segment(aes(x = min(se.seq), y = meanul95, xend = max(se.seq), yend = meanul95), linetype='dotted', data=dfCI) +\n#  scale_x_reverse()+\n  scale_x_reverse(breaks=seq(0,0.2,0.05),limits=c(0.15,0),expand=c(0.00,0.00))+\n # scale_y_continuous(breaks=seq(0.3,1.25,0.20),limits=c(0.3,1.23))+\n  coord_flip()+\n  theme_bw()\nprint(fp)\n\nWarning: Removed 833 rows containing missing values or values outside the scale range\n(`geom_line()`).\nRemoved 833 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\nWarning: Removed 984 rows containing missing values or values outside the scale range\n(`geom_segment()`).\nRemoved 984 rows containing missing values or values outside the scale range\n(`geom_segment()`).\n\n\n\n\n\n\n\n\n\n\nIdea: visualise the distributions of the model successes within studies (done in preprocessing)"
  },
  {
    "objectID": "analysis/analysis.html#regression-studies",
    "href": "analysis/analysis.html#regression-studies",
    "title": "Analysis",
    "section": "",
    "text": "For creating Table 2\n\nlibrary(dmetar,quietly = TRUE)\nlibrary(tidyverse,quietly = TRUE)\nlibrary(meta)\nlibrary(DescTools)\nlibrary(ggrepel)\n\n\n\n\nR_studies &lt;- read.csv(\"R_studies.csv\")\n#R_summary &lt;- read.csv(\"R_summary.csv\")\n\n# select regression studies with r2\n#tmp &lt;- dplyr::filter(R_summary,dimension==\"valence\")\ntmp &lt;- dplyr::filter(R_studies,dimension==\"valence\")\n#dim(tmp)\n\n#if all studies, remove two with NA values\ntmp &lt;- tmp[!is.na(tmp$values),]\n#dim(tmp)\n\n# Take all models\nm.cor &lt;- metacor(cor = values,     # values \n                 n = stimulus_n,\n                 studlab = unique_id,\n                 data = tmp,\n                 common = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"PM\",# was REML, but we switch to Paule-Mandel because Langan et al., 2019\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\n\nprint(m.cor)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 102\nNumber of observations: o = 60017\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.5832 [0.5410; 0.6226] 21.41 &lt; 0.0001\nPrediction interval         [0.0552; 0.8563]               \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.0942 [0.0715; 0.1288]; tau = 0.3070 [0.2674; 0.3589]\n I^2 = 97.7% [97.5%; 97.9%]; H = 6.58 [6.28; 6.89]\n\nTest of heterogeneity:\n       Q d.f. p-value\n 4371.49  101       0\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Paule-Mandel estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hartung-Knapp adjustment for random effects model (df = 101)\n- Prediction interval based on t-distribution (df = 101)\n- Fisher's z transformation of correlations\n\nprint(FisherZInv(m.cor$TE.random))\n\n[1] 0.5832415\n\nprint(FisherZInv(m.cor$upper.random))\n\n[1] 0.6225642\n\nprint(FisherZInv(m.cor$lower.random))\n\n[1] 0.5409809\n\n\n\n\n\n\nR_summary &lt;- read.csv(\"R_summary.csv\")\n\n# select regression studies with r2\ntmp &lt;- dplyr::filter(R_summary,dimension==\"valence\")\n#tmp &lt;- dplyr::filter(R_studies,dimension==\"valence\")\n#dim(tmp)\n\n#if all studies, remove two\n#tmp &lt;- tmp[!is.na(tmp$values),]\n#dim(tmp)\n\n## Disambiguate the studies\ntmp$studyREF[tmp$studyREF==\"Wang et al 2022\"] &lt;- c(\"Wang et al. 2022a\",\"Wang et al. 2022b\")\n\n# Max values\nm.cor &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = studyREF,#citekey, # unique_id\n                 data = tmp,\n                 common = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\n\nprint(m.cor)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 22\nNumber of observations: o = 14172\n\n                        COR            95%-CI    t  p-value\nRandom effects model 0.6685 [ 0.5599; 0.7546] 9.58 &lt; 0.0001\nPrediction interval         [-0.0120; 0.9258]              \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.1484 [0.0847; 0.3121]; tau = 0.3852 [0.2910; 0.5587]\n I^2 = 98.4% [98.0%; 98.6%]; H = 7.83 [7.15; 8.58]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1288.63   21 &lt; 0.0001\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hartung-Knapp adjustment for random effects model (df = 21)\n- Prediction interval based on t-distribution (df = 21)\n- Fisher's z transformation of correlations\n\nprint(FisherZInv(m.cor$TE.random))\n\n[1] 0.6685242\n\nprint(FisherZInv(m.cor$upper.random))\n\n[1] 0.7545765\n\nprint(FisherZInv(m.cor$lower.random))\n\n[1] 0.5598682\n\n\n\n\n\n\n\n# Method 1: Give us the Egger's test about beta coefficient from funnel\nprint(eggers.test(m.cor))\n\nEggers' test of the intercept \n============================= \n\n intercept        95% CI     t         p\n      5.05 -0.99 - 11.09 1.637 0.1171758\n\nEggers' test does not indicate the presence of funnel plot asymmetry. \n\n# Method 2: Find the impact to the results when removing those outside the 95CI\nO &lt;- find.outliers(m.cor) # 13 remaining out of 24\nprint(O)\n\nIdentified outliers (random-effects model) \n------------------------------------------ \n\"Battcock et al 2021\", \"Chen et al 2017\", \"Coutinho et al 2017\", \"Griffiths et al 2021\", \"Hu et al 2017\", \"Koh et al 2023\", \"Wang et al. 2022a\", \"Wang et al. 2022b\", \"Zhang et al 2019\", \"Zhang et al 2023\" \n \nResults with outliers removed \n----------------------------- \nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 12\nNumber of observations: o = 6150\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.6855 [0.6346; 0.7306] 20.44 &lt; 0.0001\nPrediction interval         [0.5143; 0.8042]               \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.0135 [0.0047; 0.0606]; tau = 0.1164 [0.0682; 0.2461]\n I^2 = 82.9% [71.4%; 89.7%]; H = 2.42 [1.87; 3.12]\n\nTest of heterogeneity:\n     Q d.f.  p-value\n 64.22   11 &lt; 0.0001\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hartung-Knapp adjustment for random effects model (df = 11)\n- Prediction interval based on t-distribution (df = 11)\n- Fisher's z transformation of correlations\n\n# Method 3: Leave-out-out analysis etc for individual influence (not useful here)\n#infan &lt;- InfluenceAnalysis(m.cor)\n\n# Method 4: Focus on 10% of most precise studies (Stanley, Jarrel, Doucouliagos 2010)\nthres&lt;-quantile(m.cor$seTE,0.1)\nind&lt;-m.cor$seTE&lt;=as.numeric(thres)\nm.cor10pct &lt;- update(m.cor, subset = which(ind))\n\n# Method 5: P curve analysis (Simonsohn, Simmons & Nelson, 2015)\npcurve(m.cor)\n\n\n\n\n\n\n\n\nP-curve analysis \n ----------------------- \n- Total number of provided studies: k = 22 \n- Total number of p&lt;0.05 studies included into the analysis: k = 21 (95.45%) \n- Total number of studies with p&lt;0.025: k = 21 (95.45%) \n   \nResults \n ----------------------- \n                    pBinomial   zFull pFull   zHalf pHalf\nRight-skewness test         0 -32.247     0 -31.745     0\nFlatness test               1  31.712     1  32.038     1\nNote: p-values of 0 or 1 correspond to p&lt;0.001 and p&gt;0.999, respectively.   \nPower Estimate: 99% (99%-99%)\n   \nEvidential value \n ----------------------- \n- Evidential value present: yes \n- Evidential value absent/inadequate: no \n\n\n\n\n\n\nfig2a &lt;- meta::forest(m.cor,\n       sortvar = TE,\n       prediction = FALSE, \n             print.tau2 = FALSE,\n             leftlabs = c(\"Author\", \"N\"),studlab = studyREF)\n\n\n\n\n\n\n\nfig2b &lt;- funnel(m.cor, common = FALSE, studlab=TRUE,backtransf=TRUE)\n\n\n\n\n\n\n\nlibrary(forestplot)\n\nLoading required package: grid\n\n\nLoading required package: checkmate\n\n\nLoading required package: abind\n\ndata&lt;-tibble::tibble(mean=m.cor$cor,lower=FisherZInv(m.cor$lower),upper=FisherZInv(m.cor$upper),study=m.cor$studlab,n=m.cor$n,cor=round(m.cor$cor,2))\ndata&lt;-dplyr::arrange(data,mean)\n\nfp1 &lt;- grid.grabExpr(print(data |&gt;\n  forestplot(labeltext = c(study, n, cor),\n             xlab = \"Correlation\",\n             xticks = c(0, .25,.5,.75, 1),\n             clip = c(0, 1))|&gt;\n    fp_add_header(study = \"Study\",n = \"N\",cor = expression(italic(r))) |&gt;\n    fp_append_row(mean  = m.cor$TE.common,\n                lower = m.cor$lower.common,\n                upper = m.cor$upper.common,\n                study = \"Summary\",\n                n = sum(m.cor$n),\n                cor = round(m.cor$TE.common,2),\n                is.summary = TRUE) |&gt;\n  fp_set_style(box = \"grey50\",\n               line = \"grey20\",\n               summary = \"black\",\n                txt_gp = fpTxtGp(label = list(gpar(cex = 0.80)),\n                                ticks = gpar(cex = 0.80),\n                                xlab  = gpar(cex = 0.80)))|&gt;\n    fp_decorate_graph(grid = structure( m.cor$TE.common,gp = gpar(lty = 2, col = \"grey30\")))\n)\n)\n\nsource('../etc/custom_funnel_plot.R')\nfp2 &lt;- custom_funnel_plot(m.cor)\n\ngridExtra::grid.arrange(fp1, fp2, ncol=2, widths=c(2,1),heights=c(2,1))\n\nWarning: Removed 684 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\nWarning: Removed 753 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nS &lt;- summarise(group_by(tmp,model_class_id),n=n(),obs=sum(stimulus_n))\nprint(knitr::kable(S))\n\n\n\nmodel_class_id\nn\nobs\n\n\n\n\nFlexible Discriminants\n6\n4993\n\n\nKernel Smoothing, Additive and KNN\n1\n1838\n\n\nLinear Methods\n8\n1762\n\n\nNeural Nets\n4\n2249\n\n\nRandom Forests\n3\n3330\n\n\n\n\nm.cor1 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 common = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  model_class_id,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\nprint(m.cor1)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 22\nNumber of observations: o = 14172\n\n                        COR            95%-CI    t  p-value\nRandom effects model 0.6685 [ 0.5599; 0.7546] 9.58 &lt; 0.0001\nPrediction interval         [-0.0120; 0.9258]              \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.1484 [0.0847; 0.3121]; tau = 0.3852 [0.2910; 0.5587]\n I^2 = 98.4% [98.0%; 98.6%]; H = 7.83 [7.15; 8.58]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1288.63   21 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                                                      k    COR\nmodel_class_id = Linear Methods                       8 0.7840\nmodel_class_id = Random Forests                       3 0.7503\nmodel_class_id = Kernel Smoothing, Additive and KNN   1 0.3873\nmodel_class_id = Neural Nets                          4 0.3404\nmodel_class_id = Flexible Discriminants               6 0.6555\n                                                               95%-CI  tau^2\nmodel_class_id = Linear Methods                     [ 0.6249; 0.8806] 0.1370\nmodel_class_id = Random Forests                     [ 0.2922; 0.9284] 0.0740\nmodel_class_id = Kernel Smoothing, Additive and KNN [ 0.3477; 0.4255]     --\nmodel_class_id = Neural Nets                        [-0.0970; 0.6676] 0.0761\nmodel_class_id = Flexible Discriminants             [ 0.4838; 0.7786] 0.0574\n                                                       tau      Q   I^2\nmodel_class_id = Linear Methods                     0.3701 195.78 96.4%\nmodel_class_id = Random Forests                     0.2721 163.33 98.8%\nmodel_class_id = Kernel Smoothing, Additive and KNN     --   0.00    --\nmodel_class_id = Neural Nets                        0.2759 102.54 97.1%\nmodel_class_id = Flexible Discriminants             0.2396 161.22 96.9%\n\nTest for subgroup differences (random effects model):\n                   Q d.f.  p-value\nBetween groups 45.71    4 &lt; 0.0001\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hartung-Knapp adjustment for random effects model (df = 21)\n- Prediction interval based on t-distribution (df = 21)\n- Fisher's z transformation of correlations\n\n\n\n\n\nS &lt;- summarise(group_by(tmp,journal_type),n=n(),obs=sum(stimulus_n))\nprint(knitr::kable(S))\n\n\n\njournal_type\nn\nobs\n\n\n\n\nEngineering\n13\n10002\n\n\nPsychology\n9\n4170\n\n\n\n\nm.cor2 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 common = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  journal_type,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\nprint(m.cor2)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 22\nNumber of observations: o = 14172\n\n                        COR            95%-CI    t  p-value\nRandom effects model 0.6685 [ 0.5599; 0.7546] 9.58 &lt; 0.0001\nPrediction interval         [-0.0120; 0.9258]              \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.1484 [0.0847; 0.3121]; tau = 0.3852 [0.2910; 0.5587]\n I^2 = 98.4% [98.0%; 98.6%]; H = 7.83 [7.15; 8.58]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1288.63   21 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                             k    COR           95%-CI  tau^2    tau      Q\njournal_type = Psychology    9 0.6880 [0.4683; 0.8276] 0.1830 0.4278 562.98\njournal_type = Engineering  13 0.6564 [0.5052; 0.7685] 0.1378 0.3712 627.09\n                             I^2\njournal_type = Psychology  98.6%\njournal_type = Engineering 98.1%\n\nTest for subgroup differences (random effects model):\n                  Q d.f. p-value\nBetween groups 0.10    1  0.7482\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hartung-Knapp adjustment for random effects model (df = 21)\n- Prediction interval based on t-distribution (df = 21)\n- Fisher's z transformation of correlations\n\n\n\n\n\ntmp &lt;- dplyr::filter(R_summary,dimension==\"valence\")\ntmp&lt;-tmp[!is.na(tmp$feature_n_categories),] # remove \nS &lt;- summarise(group_by(tmp,feature_n_categories),n=n(),obs=sum(stimulus_n))\nprint(knitr::kable(S))\n\n\n\nfeature_n_categories\nn\nobs\n\n\n\n\nFeature n &lt; 18\n4\n3016\n\n\nFeature n &gt; 18 & &lt; 260\n10\n4222\n\n\nFeature n &gt; 260\n7\n6190\n\n\n\n\ntmp &lt;- dplyr::filter(R_summary,dimension==\"valence\")\ntmp&lt;-tmp[!is.na(tmp$feature_n_categories),] # remove missing values\nm.cor3 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 common = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  feature_n_categories,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\nprint(m.cor3)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 21\nNumber of observations: o = 13428\n\n                        COR           95%-CI    t  p-value\nRandom effects model 0.6817 [0.5751; 0.7656] 9.80 &lt; 0.0001\nPrediction interval         [0.0238; 0.9276]              \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.1430 [0.0804; 0.3083]; tau = 0.3782 [0.2836; 0.5552]\n I^2 = 98.3% [98.0%; 98.6%]; H = 7.72 [7.03; 8.48]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1192.85   20 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                                                k    COR           95%-CI\nfeature_n_categories = Feature n &lt; 18           4 0.8165 [0.3609; 0.9575]\nfeature_n_categories = Feature n &gt; 18 & &lt; 260  10 0.5864 [0.3599; 0.7476]\nfeature_n_categories = Feature n &gt; 260          7 0.7023 [0.6122; 0.7744]\n                                               tau^2    tau      Q   I^2\nfeature_n_categories = Feature n &lt; 18         0.2295 0.4791 360.71 99.2%\nfeature_n_categories = Feature n &gt; 18 & &lt; 260 0.1542 0.3927 290.30 96.9%\nfeature_n_categories = Feature n &gt; 260        0.0285 0.1689 178.35 96.6%\n\nTest for subgroup differences (random effects model):\n                  Q d.f. p-value\nBetween groups 3.47    2  0.1761\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hartung-Knapp adjustment for random effects model (df = 20)\n- Prediction interval based on t-distribution (df = 20)\n- Fisher's z transformation of correlations\n\nS&lt;-summarise(group_by(tmp,feature_n_categories),n=n(),obs=sum(stimulus_n))\nprint(S)\n\n# A tibble: 3 × 3\n  feature_n_categories       n   obs\n  &lt;chr&gt;                  &lt;int&gt; &lt;int&gt;\n1 Feature n &lt; 18             4  3016\n2 Feature n &gt; 18 & &lt; 260    10  4222\n3 Feature n &gt; 260            7  6190\n\n\n\n\n\ntmp &lt;- dplyr::filter(R_summary,dimension==\"valence\")\ntmp&lt;-tmp[!is.na(tmp$feature_n_categories),] # removemissing values\n\nS&lt;-summarise(group_by(tmp,feature_n_complexity_genre),n=n(),obs=sum(stimulus_n))\nprint(knitr::kable(S))\n\n\n\nfeature_n_complexity_genre\nn\nobs\n\n\n\n\nHuge multigenre study\n3\n1812\n\n\nMedium single genre/multigenre study\n13\n7386\n\n\nMedium-large single genre/multigenre study\n2\n1262\n\n\nSmall single genre study\n3\n2968\n\n\n\nm.cor4 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 common = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  feature_n_complexity_genre,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\nprint(m.cor4)\nReview: MER: Regression: Valence: Summary\nNumber of studies: k = 21 Number of observations: o = 13428\n                    COR           95%-CI    t  p-value\nRandom effects model 0.6817 [0.5751; 0.7656] 9.80 &lt; 0.0001 Prediction interval [0.0238; 0.9276]\nQuantifying heterogeneity (with 95%-CIs): tau^2 = 0.1430 [0.0804; 0.3083]; tau = 0.3782 [0.2836; 0.5552] I^2 = 98.3% [98.0%; 98.6%]; H = 7.72 [7.03; 8.48]\nTest of heterogeneity: Q d.f. p-value 1192.85 20 &lt; 0.0001\nResults for subgroups (random effects model): k COR feature_n_complexity_genre = Small single genre study 3 0.8358 feature_n_complexity_genre = Medium single genre/multigenre … 13 0.6065 feature_n_complexity_genre = Huge multigenre study 3 0.6927 feature_n_complexity_genre = Medium-large single genre/multi … 2 0.7681 95%-CI feature_n_complexity_genre = Small single genre study [-0.1966; 0.9893] feature_n_complexity_genre = Medium single genre/multigenre … [ 0.4491; 0.7274] feature_n_complexity_genre = Huge multigenre study [ 0.4915; 0.8237] feature_n_complexity_genre = Medium-large single genre/multi … [-0.8767; 0.9977] tau^2 tau feature_n_complexity_genre = Small single genre study 0.3182 0.5641 feature_n_complexity_genre = Medium single genre/multigenre … 0.1174 0.3427 feature_n_complexity_genre = Huge multigenre study 0.0137 0.1170 feature_n_complexity_genre = Medium-large single genre/multi … 0.0679 0.2606 Q I^2 feature_n_complexity_genre = Small single genre study 358.17 99.4% feature_n_complexity_genre = Medium single genre/multigenre … 437.57 97.3% feature_n_complexity_genre = Huge multigenre study 14.21 85.9% feature_n_complexity_genre = Medium-large single genre/multi … 33.46 97.0%\nTest for subgroup differences (random effects model): Q d.f. p-value Between groups 3.99 3 0.2625\nDetails of meta-analysis methods: - Inverse variance method - Restricted maximum-likelihood estimator for tau^2 - Q-Profile method for confidence interval of tau^2 and tau - Calculation of I^2 based on Q - Hartung-Knapp adjustment for random effects model (df = 20) - Prediction interval based on t-distribution (df = 20) - Fisher’s z transformation of correlations\n\n\n\n\n\n\n\nR_studies &lt;- read.csv(\"R_studies.csv\")\ntmp &lt;- dplyr::filter(R_studies,dimension==\"arousal\")\n#if all studies, remove two with NA values\ntmp &lt;- tmp[!is.na(tmp$values),]\n#dim(tmp)\n\n# Take all models\nm.cor &lt;- metacor(cor = values,     # values \n                 n = stimulus_n,\n                 studlab = unique_id,\n                 data = tmp,\n                 common = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"PM\",# was REML, but we switch to Paule-Mandel because Langan et al., 2019\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Arousal: Summary\")\n\nprint(m.cor)\n\nReview:     MER: Regression: Arousal: Summary\n\nNumber of studies: k = 102\nNumber of observations: o = 60017\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.7909 [0.7700; 0.8101] 39.90 &lt; 0.0001\nPrediction interval         [0.4999; 0.9214]               \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.0692 [0.0520; 0.0955]; tau = 0.2631 [0.2280; 0.3090]\n I^2 = 96.2% [95.8%; 96.6%]; H = 5.14 [4.87; 5.43]\n\nTest of heterogeneity:\n       Q d.f. p-value\n 2666.55  101       0\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Paule-Mandel estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hartung-Knapp adjustment for random effects model (df = 101)\n- Prediction interval based on t-distribution (df = 101)\n- Fisher's z transformation of correlations\n\nprint(FisherZInv(m.cor$TE.random))\n\n[1] 0.7908857\n\nprint(FisherZInv(m.cor$upper.random))\n\n[1] 0.8100518\n\nprint(FisherZInv(m.cor$lower.random))\n\n[1] 0.7700316\n\n\n\n\n\n\nR_summary &lt;- read.csv(\"R_summary.csv\")\n\n# select regression studies with r2\ntmp &lt;- dplyr::filter(R_summary,dimension==\"arousal\")\n#tmp &lt;- dplyr::filter(R_studies,dimension==\"valence\")\n#dim(tmp)\n\n#if all studies, remove two\n#tmp &lt;- tmp[!is.na(tmp$values),]\n#dim(tmp)\n\n## Disambiguate the studies\ntmp$studyREF[tmp$studyREF==\"Wang et al 2022\"] &lt;- c(\"Wang et al. 2022a\",\"Wang et al. 2022b\")\n\n# Max values\nm.cor &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = studyREF,#citekey, # unique_id\n                 data = tmp,\n                 common = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Arousal: Summary\")\n\nprint(m.cor)\n\nReview:     MER: Regression: Arousal: Summary\n\nNumber of studies: k = 22\nNumber of observations: o = 14172\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.8087 [0.7404; 0.8604] 13.60 &lt; 0.0001\nPrediction interval         [0.3127; 0.9582]               \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.1411 [0.0805; 0.2999]; tau = 0.3756 [0.2838; 0.5476]\n I^2 = 97.9% [97.4%; 98.3%]; H = 6.90 [6.26; 7.62]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1001.16   21 &lt; 0.0001\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hartung-Knapp adjustment for random effects model (df = 21)\n- Prediction interval based on t-distribution (df = 21)\n- Fisher's z transformation of correlations\n\nprint(FisherZInv(m.cor$TE.random))\n\n[1] 0.8086765\n\nprint(FisherZInv(m.cor$upper.random))\n\n[1] 0.8604211\n\nprint(FisherZInv(m.cor$lower.random))\n\n[1] 0.7404257\n\n\n\n\n\n\n\n# Method 1: Give us the Egger's test about beta coefficient from funnel\nprint(eggers.test(m.cor))\n\nEggers' test of the intercept \n============================= \n\n intercept       95% CI     t         p\n     0.789 -4.87 - 6.45 0.273 0.7876923\n\nEggers' test does not indicate the presence of funnel plot asymmetry. \n\n# Method 2: Find the impact to the results when removing those outside the 95CI\nO &lt;- find.outliers(m.cor) # 13 remaining out of 24\nprint(O)\n\nIdentified outliers (random-effects model) \n------------------------------------------ \n\"Battcock et al 2021\", \"Coutinho et al 2017\", \"Gingras et al 2014\", \"Grekow et al 2018\", \"Koh et al 2023\", \"Orjesek et al 2022\", \"Wang et al. 2022b\", \"Zhang et al 2019\", \"Zhang et al 2023\" \n \nResults with outliers removed \n----------------------------- \nReview:     MER: Regression: Arousal: Summary\n\nNumber of studies: k = 13\nNumber of observations: o = 10613\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.8262 [0.8061; 0.8445] 42.44 &lt; 0.0001\nPrediction interval         [0.7721; 0.8684]               \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.0042 [0.0016; 0.0501]; tau = 0.0649 [0.0401; 0.2239]\n I^2 = 76.8% [60.6%; 86.4%]; H = 2.08 [1.59; 2.71]\n\nTest of heterogeneity:\n     Q d.f.  p-value\n 51.82   12 &lt; 0.0001\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hartung-Knapp adjustment for random effects model (df = 12)\n- Prediction interval based on t-distribution (df = 12)\n- Fisher's z transformation of correlations\n\n# Method 3: Leave-out-out analysis etc for individual influence (not useful here)\n#infan &lt;- InfluenceAnalysis(m.cor)\n\n# Method 4: Focus on 10% of most precise studies (Stanley, Jarrel, Doucouliagos 2010)\nthres&lt;-quantile(m.cor$seTE,0.1)\nind&lt;-m.cor$seTE&lt;=as.numeric(thres)\nm.cor10pct &lt;- update(m.cor, subset = which(ind))\n\n# Method 5: P curve analysis (Simonsohn, Simmons & Nelson, 2015)\npcurve(m.cor)\n\n\n\n\n\n\n\n\nP-curve analysis \n ----------------------- \n- Total number of provided studies: k = 22 \n- Total number of p&lt;0.05 studies included into the analysis: k = 22 (100%) \n- Total number of studies with p&lt;0.025: k = 22 (100%) \n   \nResults \n ----------------------- \n                    pBinomial   zFull pFull   zHalf pHalf\nRight-skewness test         0 -33.770     0 -33.237     0\nFlatness test               1  34.184     1  34.443     1\nNote: p-values of 0 or 1 correspond to p&lt;0.001 and p&gt;0.999, respectively.   \nPower Estimate: 99% (99%-99%)\n   \nEvidential value \n ----------------------- \n- Evidential value present: yes \n- Evidential value absent/inadequate: no \n\n\n\n\n\n\nfig2a &lt;- forest(m.cor,\n       sortvar = TE,\n       prediction = FALSE, \n             print.tau2 = FALSE,\n             leftlabs = c(\"Author\", \"N\"),studlab = studyREF)\n\n\n\n\n\n\n\nfig2b&lt;-funnel(m.cor, common = FALSE, studlab=TRUE,backtransf=TRUE)\n\n\n\n\n\n\n\nlibrary(forestplot)\ndata&lt;-tibble::tibble(mean=m.cor$cor,lower=FisherZInv(m.cor$lower),upper=FisherZInv(m.cor$upper),study=m.cor$studlab,n=m.cor$n,cor=round(m.cor$cor,2))\ndata&lt;-dplyr::arrange(data,mean)\n\nfp1 &lt;- grid.grabExpr(print(data |&gt;\n  forestplot(labeltext = c(study, n, cor),\n             xlab = \"Correlation\",\n             xticks = c(0, .25,.5,.75, 1),\n             clip = c(0, 1))|&gt;\n    fp_add_header(study = \"Study\",n = \"N\",cor = expression(italic(r))) |&gt;\n    fp_append_row(mean  = m.cor$TE.common,\n                lower = m.cor$lower.common,\n                upper = m.cor$upper.common,\n                study = \"Summary\",\n                n = sum(m.cor$n),\n                cor = round(m.cor$TE.common,2),\n                is.summary = TRUE) |&gt;\n  fp_set_style(box = \"grey50\",\n               line = \"grey20\",\n               summary = \"black\",\n                txt_gp = fpTxtGp(label = list(gpar(cex = 0.80)),\n                                ticks = gpar(cex = 0.80),\n                                xlab  = gpar(cex = 0.80)))|&gt;\n    fp_decorate_graph(grid = structure( m.cor$TE.common,gp = gpar(lty = 2, col = \"grey30\")))\n)\n)\n\nsource('../etc/custom_funnel_plot.R')\nfp2 &lt;- custom_funnel_plot(m.cor)\n\ngridExtra::grid.arrange(fp1, fp2, ncol=2, widths=c(2,1),heights=c(2,1))\n\nWarning: Removed 754 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\nWarning: Removed 954 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_hline()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nS &lt;- summarise(group_by(tmp,model_class_id),n=n(),obs=sum(stimulus_n))\nprint(knitr::kable(S))\n\n\n\nmodel_class_id\nn\nobs\n\n\n\n\nFlexible Discriminants\n6\n4993\n\n\nKernel Smoothing, Additive and KNN\n1\n1838\n\n\nLinear Methods\n8\n1762\n\n\nNeural Nets\n4\n2249\n\n\nRandom Forests\n3\n3330\n\n\n\n\nm.cor1 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 common = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  model_class_id,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\nprint(m.cor1)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 22\nNumber of observations: o = 14172\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.8087 [0.7404; 0.8604] 13.60 &lt; 0.0001\nPrediction interval         [0.3127; 0.9582]               \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.1411 [0.0805; 0.2999]; tau = 0.3756 [0.2838; 0.5476]\n I^2 = 97.9% [97.4%; 98.3%]; H = 6.90 [6.26; 7.62]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1001.16   21 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                                                      k    COR           95%-CI\nmodel_class_id = Linear Methods                       8 0.8812 [0.8079; 0.9277]\nmodel_class_id = Random Forests                       3 0.8085 [0.7334; 0.8641]\nmodel_class_id = Kernel Smoothing, Additive and KNN   1 0.8185 [0.8029; 0.8331]\nmodel_class_id = Neural Nets                          4 0.5339 [0.3281; 0.6912]\nmodel_class_id = Flexible Discriminants               6 0.8077 [0.6437; 0.9008]\n                                                     tau^2    tau      Q   I^2\nmodel_class_id = Linear Methods                     0.0846 0.2908 104.87 93.3%\nmodel_class_id = Random Forests                     0.0025 0.0505   5.77 65.4%\nmodel_class_id = Kernel Smoothing, Additive and KNN     --     --   0.00    --\nmodel_class_id = Neural Nets                        0.0190 0.1379  21.17 85.8%\nmodel_class_id = Flexible Discriminants             0.1125 0.3354 246.31 98.0%\n\nTest for subgroup differences (random effects model):\n                   Q d.f.  p-value\nBetween groups 50.47    4 &lt; 0.0001\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hartung-Knapp adjustment for random effects model (df = 21)\n- Prediction interval based on t-distribution (df = 21)\n- Fisher's z transformation of correlations\n\n\n\n\n\nS &lt;- summarise(group_by(tmp,journal_type),n=n(),obs=sum(stimulus_n))\nprint(knitr::kable(S))\n\n\n\njournal_type\nn\nobs\n\n\n\n\nEngineering\n13\n10002\n\n\nPsychology\n9\n4170\n\n\n\n\nm.cor2 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 common = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  journal_type,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\nprint(m.cor2)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 22\nNumber of observations: o = 14172\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.8087 [0.7404; 0.8604] 13.60 &lt; 0.0001\nPrediction interval         [0.3127; 0.9582]               \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.1411 [0.0805; 0.2999]; tau = 0.3756 [0.2838; 0.5476]\n I^2 = 97.9% [97.4%; 98.3%]; H = 6.90 [6.26; 7.62]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1001.16   21 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                             k    COR           95%-CI  tau^2    tau      Q\njournal_type = Psychology    9 0.8389 [0.7417; 0.9016] 0.1079 0.3286 345.30\njournal_type = Engineering  13 0.7858 [0.6693; 0.8647] 0.1655 0.4068 650.86\n                             I^2\njournal_type = Psychology  97.7%\njournal_type = Engineering 98.2%\n\nTest for subgroup differences (random effects model):\n                  Q d.f. p-value\nBetween groups 0.94    1  0.3332\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hartung-Knapp adjustment for random effects model (df = 21)\n- Prediction interval based on t-distribution (df = 21)\n- Fisher's z transformation of correlations\n\n\n\n\n\ntmp &lt;- dplyr::filter(R_summary,dimension==\"arousal\")\ntmp&lt;-tmp[!is.na(tmp$feature_n_categories),] # remove \nS &lt;- summarise(group_by(tmp,feature_n_categories),n=n(),obs=sum(stimulus_n))\nprint(knitr::kable(S))\n\n\n\nfeature_n_categories\nn\nobs\n\n\n\n\nFeature n &lt; 18\n4\n3016\n\n\nFeature n &gt; 18 & &lt; 260\n10\n4222\n\n\nFeature n &gt; 260\n7\n6190\n\n\n\n\ntmp &lt;- dplyr::filter(R_summary,dimension==\"arousal\")\ntmp&lt;-tmp[!is.na(tmp$feature_n_categories),] # remove missing values\nm.cor3 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 common = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  feature_n_categories,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\nprint(m.cor3)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 21\nNumber of observations: o = 13428\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.8182 [0.7536; 0.8672] 14.11 &lt; 0.0001\nPrediction interval         [0.3628; 0.9581]               \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.1301 [0.0731; 0.2852]; tau = 0.3607 [0.2704; 0.5341]\n I^2 = 97.5% [96.9%; 98.0%]; H = 6.28 [5.64; 6.99]\n\nTest of heterogeneity:\n      Q d.f.  p-value\n 789.02   20 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                                                k    COR           95%-CI\nfeature_n_categories = Feature n &lt; 18           4 0.8927 [0.7379; 0.9582]\nfeature_n_categories = Feature n &gt; 18 & &lt; 260  10 0.7655 [0.5885; 0.8725]\nfeature_n_categories = Feature n &gt; 260          7 0.8288 [0.7922; 0.8594]\n                                               tau^2    tau      Q   I^2\nfeature_n_categories = Feature n &lt; 18         0.0868 0.2946  62.53 95.2%\nfeature_n_categories = Feature n &gt; 18 & &lt; 260 0.2030 0.4506 435.78 97.9%\nfeature_n_categories = Feature n &gt; 260        0.0111 0.1052  43.15 86.1%\n\nTest for subgroup differences (random effects model):\n                  Q d.f. p-value\nBetween groups 4.05    2  0.1317\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hartung-Knapp adjustment for random effects model (df = 20)\n- Prediction interval based on t-distribution (df = 20)\n- Fisher's z transformation of correlations\n\nS&lt;-summarise(group_by(tmp,feature_n_categories),n=n(),obs=sum(stimulus_n))\nprint(S)\n\n# A tibble: 3 × 3\n  feature_n_categories       n   obs\n  &lt;chr&gt;                  &lt;int&gt; &lt;int&gt;\n1 Feature n &lt; 18             4  3016\n2 Feature n &gt; 18 & &lt; 260    10  4222\n3 Feature n &gt; 260            7  6190\n\n\n\n\n\ntmp &lt;- dplyr::filter(R_summary,dimension==\"arousal\")\ntmp&lt;-tmp[!is.na(tmp$feature_n_categories),] # remove missing values\n\nS&lt;-summarise(group_by(tmp,feature_n_complexity_genre),n=n(),obs=sum(stimulus_n))\nprint(knitr::kable(S))\n\n\n\nfeature_n_complexity_genre\nn\nobs\n\n\n\n\nHuge multigenre study\n3\n1812\n\n\nMedium single genre/multigenre study\n13\n7386\n\n\nMedium-large single genre/multigenre study\n2\n1262\n\n\nSmall single genre study\n3\n2968\n\n\n\nm.cor4 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 common = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  feature_n_complexity_genre,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\nprint(m.cor4)\nReview: MER: Regression: Valence: Summary\nNumber of studies: k = 21 Number of observations: o = 13428\n                    COR           95%-CI     t  p-value\nRandom effects model 0.8182 [0.7536; 0.8672] 14.11 &lt; 0.0001 Prediction interval [0.3628; 0.9581]\nQuantifying heterogeneity (with 95%-CIs): tau^2 = 0.1301 [0.0731; 0.2852]; tau = 0.3607 [0.2704; 0.5341] I^2 = 97.5% [96.9%; 98.0%]; H = 6.28 [5.64; 6.99]\nTest of heterogeneity: Q d.f. p-value 789.02 20 &lt; 0.0001\nResults for subgroups (random effects model): k COR feature_n_complexity_genre = Small single genre study 3 0.9048 feature_n_complexity_genre = Medium single genre/multigenre … 13 0.7784 feature_n_complexity_genre = Huge multigenre study 3 0.8371 feature_n_complexity_genre = Medium-large single genre/multi … 2 0.8355 95%-CI feature_n_complexity_genre = Small single genre study [0.5902; 0.9808] feature_n_complexity_genre = Medium single genre/multigenre … [0.6611; 0.8586] feature_n_complexity_genre = Huge multigenre study [0.6493; 0.9287] feature_n_complexity_genre = Medium-large single genre/multi … [0.4534; 0.9582] tau^2 tau feature_n_complexity_genre = Small single genre study 0.1046 0.3234 feature_n_complexity_genre = Medium single genre/multigenre … 0.1530 0.3912 feature_n_complexity_genre = Huge multigenre study 0.0285 0.1689 feature_n_complexity_genre = Medium-large single genre/multi … 0.0044 0.0666 Q I^2 feature_n_complexity_genre = Small single genre study 62.30 96.8% feature_n_complexity_genre = Medium single genre/multigenre … 506.15 97.6% feature_n_complexity_genre = Huge multigenre study 25.84 92.3% feature_n_complexity_genre = Medium-large single genre/multi … 3.12 68.0%\nTest for subgroup differences (random effects model): Q d.f. p-value Between groups 4.43 3 0.2186\nDetails of meta-analysis methods: - Inverse variance method - Restricted maximum-likelihood estimator for tau^2 - Q-Profile method for confidence interval of tau^2 and tau - Calculation of I^2 based on Q - Hartung-Knapp adjustment for random effects model (df = 20) - Prediction interval based on t-distribution (df = 20) - Fisher’s z transformation of correlations"
  },
  {
    "objectID": "analysis/analysis.html#classification-studies",
    "href": "analysis/analysis.html#classification-studies",
    "title": "Analysis",
    "section": "",
    "text": "C_studies &lt;- read.csv(\"C_studies.csv\")\nC_studies &lt;- C_studies[!is.na(C_studies$values),]\n\n# yang2021an needs to be encoded for classification (currently just regression)\nC_summary &lt;- read.csv(\"C_summary.csv\")\nC_classes &lt;- read.csv(\"C_study_class_n.csv\")\n\nC_summary &lt;- merge(C_summary, C_classes)\n\nm.cor &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = studyREF, # unique_id\n                 data = C_summary,\n                 common = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 backtransf = TRUE,\n                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Classification: Summary\")\n\nprint(m.cor)\n\nReview:     MER: Classification: Summary\n\nNumber of studies: k = 12\nNumber of observations: o = 15696\n\n                        COR           95%-CI    t  p-value\nRandom effects model 0.8753 [0.7555; 0.9384] 8.07 &lt; 0.0001\nPrediction interval         [0.0256; 0.9907]              \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.3366 [0.1675; 0.9707]; tau = 0.5802 [0.4093; 0.9853]\n I^2 = 99.8%; H = 21.40\n\nTest of heterogeneity:\n       Q d.f. p-value\n 5039.29   11       0\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hartung-Knapp adjustment for random effects model (df = 11)\n- Prediction interval based on t-distribution (df = 11)\n- Fisher's z transformation of correlations\n\n#m.cor_backtransformed &lt;- m.cor\n#m.cor_backtransformed$TE &lt;- FisherZInv(m.cor_backtransformed$TE)\nprint(funnel(m.cor, common = FALSE, studlab=TRUE,backtransf=TRUE))\n\n\n\n\n\n\n\n\n$xvals\n [1] 2.3799720 1.6709175 2.2544044 0.6136900 1.6394812 0.7841811 0.7610522\n [8] 0.8332468 1.3253662 1.6561690 1.0986123 1.2419119\n\n$yvals\n [1] 0.01459116 0.01388220 0.05103104 0.04222003 0.09090909 0.03239318\n [7] 0.05802589 0.03338903 0.02357678 0.04845016 0.07715167 0.07715167\n\n$pch\n [1] 21 21 21 21 21 21 21 21 21 21 21 21\n\n$text\nNULL\n\n$cex\n [1] 1 1 1 1 1 1 1 1 1 1 1 1\n\n$col\n [1] \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\"\n[10] \"black\" \"black\" \"black\"\n\n$bg\n [1] \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\"\n [7] \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\"\n\n$cex.studlab\n [1] 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8\n\n$xlim\n[1] 0.598722 2.439471\n\n$ylim\n[1] 0.09090909 0.00000000\n\n\n\n\n\nlibrary(ggrepel)\ntmpdata &lt;- data.frame(SE = FisherZInv(m.cor$seTE), Zr = FisherZInv(m.cor$TE),studies=m.cor$studlab)\n\ntmpdata$citekey&lt;-str_replace_all(tmpdata$studies,'-.*$','')\ntmpdata$citekey&lt;-factor(tmpdata$citekey)\n\ng &lt;- ggplot(tmpdata,aes(y = SE, x = Zr,label=studies,color=citekey,fill=citekey)) +\n  geom_point(show.legend = FALSE) +\n  geom_label_repel(size=1.5,max.overlaps = 39,color=\"black\",show.legend = FALSE)+\n  ylab('Standard Error') + \n  xlab('r')+\n  scale_y_reverse()+\n#  scale_x_continuous(breaks=seq(0.0,1.0,0.25),limits=c(0,1.0))+\n#  coord_flip()+\n  theme_bw()\nprint(g)\n\n\n\n\n\n\n\n\n\n\n\n\nforest(m.cor,\n       sortvar = TE,\n       prediction = FALSE, \n             print.tau2 = FALSE,\n             leftlabs = c(\"Author\", \"N\"),studlab = citekey)\n\n\n\n\n\n\n\nfunnel(m.cor, common = FALSE, studlab=TRUE,backtransf=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\nC_summary$classes &lt;- 0\nC_summary[C_summary$n_classes &lt; 3,]$classes &lt;- \"2\"\nC_summary[C_summary$n_classes &gt;= 3,]$classes &lt;- \"&gt;2\"\n\n\n\nm.cor &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n, # could also change to n_classes\n                 studlab = studyREF, # unique_id\n                 data = C_summary,\n                 subgroup = classes,\n                 common = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 backtransf = TRUE,\n                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Classification: Summary\")\n\n\nforest(m.cor,\n       sortvar = TE,\n       prediction = FALSE, \n             print.tau2 = FALSE,\n             leftlabs = c(\"Author\", \"N\"),studlab = citekey)\n\n\n\n\n\n\n\nfunnel(m.cor, common = FALSE, studlab=TRUE,backtransf=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\nO &lt;- find.outliers(m.cor)\n# 6 datasets identified as outliers, without them the r drops to 0.5781\n#infan &lt;- InfluenceAnalysis(m.cor)\n#print(eggers.test(m.cor))\n\n\n\n\n\n\n\nTo show the quality differences between core and eliminated studies (in progress).\n\ntmpdata &lt;- data.frame(SE = m.cor$seTE, Zr = m.cor$TE, studies=m.cor$studlab)\n\ntmpdata$studyREF &lt;- substr(tmpdata$studies,1,nchar(tmpdata$studies)-2)\ntmpdata$studyREF &lt;- str_replace_all(tmpdata$studyREF,'([0-9]+)',' et al \\\\1')\ntmpdata$studyREF &lt;- str_to_sentence(tmpdata$studyREF)\ntmpdata$studyREF\n\n [1] \"Agarwal et al  et al 20\"      \"Alvarez et al  et al 20\"     \n [3] \"Bhuvanakumar et al  et al 20\" \"Dufour et al  et al 20\"      \n [5] \"Hizlisoy et al  et al 20\"     \"Hu et al  et al 20\"          \n [7] \"Nguyen et al  et al 20\"       \"Panda et al  et al 20\"       \n [9] \"Sorussa et al  et al 20\"      \"Yeh et al  et al 20\"         \n[11] \"Zhang et al  et al 20\"        \"Zhang et al  et al 20\"       \n\nestimate = m.cor$TE.common\nse = m.cor$seTE.common\nse.seq=seq(0, max(m.cor$cor), 0.001)\nll95 = estimate-(1.96*se.seq)\nul95 = estimate+(1.96*se.seq)\nll99 = estimate-(3.29*se.seq)\nul99 = estimate+(3.29*se.seq)\nmeanll95 = estimate-(1.96*se)\nmeanul95 = estimate+(1.96*se)\ndfCI = data.frame(ll95, ul95, ll99, ul99, se.seq, estimate, meanll95, meanul95)\n\nfp = ggplot(NULL) +\n  geom_point(aes(x = SE, y = Zr), color='grey50',data=tmpdata) +\n  geom_text_repel(aes(x = SE, y = Zr, label=studyREF), data=tmpdata,size=2.5,max.overlaps = 40)+\n  xlab('Standard Error') + ylab('Fisher\\'s z transformed correlation')+\n  geom_line(aes(x = se.seq, y = ll95), linetype = 'dotted', data = dfCI) +\n  geom_line(aes(x = se.seq, y = ul95), linetype = 'dotted', data = dfCI) +\n  geom_segment(aes(x = min(se.seq), y = meanll95, xend = max(se.seq), yend = meanll95), linetype='dotted', data=dfCI) +\n  geom_segment(aes(x = min(se.seq), y = meanul95, xend = max(se.seq), yend = meanul95), linetype='dotted', data=dfCI) +\n#  scale_x_reverse()+\n  scale_x_reverse(breaks=seq(0,0.2,0.05),limits=c(0.15,0),expand=c(0.00,0.00))+\n  scale_y_continuous(breaks=seq(0.3,1.25,0.20),limits=c(0.3,1.23))+\n  coord_flip()+\n  theme_bw()\nprint(fp)\n\nWarning: Removed 7 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\nWarning: Removed 7 rows containing missing values or values outside the scale range\n(`geom_text_repel()`).\n\n\nWarning: Removed 984 rows containing missing values or values outside the scale range\n(`geom_line()`).\nRemoved 984 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\nWarning: Removed 984 rows containing missing values or values outside the scale range\n(`geom_segment()`).\nRemoved 984 rows containing missing values or values outside the scale range\n(`geom_segment()`).\n\n\n\n\n\n\n\n\n\n\n\n\nadd journal_type and stimulus_genre_mixed as a grouping option\n\nm.cor_subgroups &lt;- update(m.cor, \n       subgroup = model_class_id, \n#       subgroup = journal_type, \n#       subgroup = stimulus_genre_mixed, \n       tau.common = FALSE,\n       prediction = TRUE)\n\nprint(m.cor_subgroups)\n#forest(m.cor_subgroups,subgroup=TRUE)\n\n\nIdea: visualise the distributions of the model successes within studies (done in preprocessing)"
  },
  {
    "objectID": "manuscript/manuscript.html#prediction-success-for-affect-dimensions",
    "href": "manuscript/manuscript.html#prediction-success-for-affect-dimensions",
    "title": "A Meta-Analysis of Music Emotion Recognition Studies",
    "section": "Prediction success for affect dimensions",
    "text": "Prediction success for affect dimensions\nSee analysis/analysis.qmd (updated 17/1/2025)\nSince there are many models contained within each of the studies, we will report the results in two parts; We first give an overview of the results for all models, and then we focus on the best performing models of each study. The best performing model is the model within each study with the highest correlation coefficient. This reduction is done to avoid the issue of multiple models from the same study deflating the results as majority of the models included are relative modest baseline or alternative models that do not represent the novelty or content of the article.\n\nResults for valence\nTable 2 summarises the results for all models (All) as well as best performing models (Max) for each study for valence. The summary includes the number of models and observations, the correlation coefficient and its 95% confidence interval, the t-value and p-value for the correlation, the heterogeneity statistics \\(\\tau^2\\) and \\(I^2\\), calculated through appropriate transformations (Fisher’s Z) for the correlation coefficient as part of a random-effects model using meta library (Balduzzi et al., 2019). We used Paule-Mandel estimator for between-study heterogeneity (Langan et al., 2019) and Knapp-Hartung (Knapp & Hartung, 2003) adjustments for confidence intervals. In this table we also report two subgroup analyses. One where we have divided the studies according to the number of features they contain (three categories based on quantiles to keep the group size comparable) and into five modelling techniques introduced earlier (Table 1).\nTable 2. Meta-analytic diagnostic for all regression studies predicting valence from audio. See Table 1 for the acronyms of the modelling techniques.\n\n\n\n\n\n\n\n\n\n\n\n\nConcept\nModels, obs\n\\(r\\) [95%-CI]\n\\(t\\)\n\\(p\\)\n\\(\\tau^2\\)\n\\(I^2\\)\n\n\n\n\nValence All\n102,60017\n0.583 [0.541-0.623]\n21.40\n.0001\n0.094\n97.7%\n\n\nValence Max\n22,14172\n0.669 [0.560-0.755]\n9.58\n.0001\n0.148\n98.4%\n\n\nN Features\n\n\n\n\n\n\n\n\n&lt;18 F\n5,3036\n0.811 [0.542-0.823]\n-\n-\n0.182\n98.9%\n\n\n18-260 F\n11,7042\n0.584 [0.534-0.931]\n-\n-\n0.133\n97.6%\n\n\n260+ F\n5,3494\n0.710 [0.542-0.823]\n-\n-\n0.044\n97.2%\n\n\nTechniques\n\n\n\n\n\n\n\n\nKS\n1,1838\n0.466 [-0.634-0.942]\n-\n-\n0.0185\n95.1%\n\n\nLM\n8,1762\n0.797 [0.614-0.899]\n-\n-\n0.1370\n96.4%\n\n\nSVM\n6,4993\n0.656 [0.484-0.779]\n-\n-\n0.0574\n96.9%\n\n\nNN\n4,2249\n0.393 [-0.355-0.835]\n-\n-\n0.0761\n97.1%\n\n\nTM\n3,3330\n0.750 [0.292-0.928]\n-\n-\n0.093\n98.5%\n\n\n\n\nThe results indicate that valence can generally be predicted with moderately accuracy, with the best model from each of the 22 studies achieving an average correlation of r = 0.669 (95% CI: 0.560-0.755), called “valence Max” in Table 2. However, when considering all models across these studies (n = 102), the overall prediction rate drops significantly to r = 0.583. We argue that this lower correlation is likely due to the inclusion of baseline models reported in these studies, which may not reflect the true success of the task for the purposes of our analysis.\nFurther analysis of between-study heterogeneity, as indexed by the \\(\\tau^2\\) (0.148) and Higgins & Thompson’s \\(I^2\\) statistic (Higgins & Thompson, 2002) at 98.4%, reveals substantial heterogeneity. Since \\(I^2\\) is heavily influenced by study size (with larger N leading to lower sampling error), its value may be less insightful in this context. In contrast, \\(\\tau^2\\), which is less sensitive to the number of studies and directly linked to the outcome metric (r), provides a more reliable measure of heterogeneity in this case. Also, we note that because the overall heterogeneity in the data is high, we are cautious in our interpretation of the publication bias (Van Aert et al., 2016).\nTo better understand the effects across studies and the nature of the observed heterogeneity, Figure 2 presents (A) a forest and (B) funnel plot of the random-effects model, based on the best-performing models from all studies. In terms of the forest plot, the range of prediction values (correlations) is broad, spanning from 0.13 to 0.92, with all studies except Koh et al. (2023) demonstrating evidence of positive correlations. A mean estimate of 0.67 is achieved by 15 out of the 22 models. While the confidence intervals are generally narrow due to the large sample sizes in each study, there are exceptions, such as smaller sample sizes in Beveridge & Knox (2018) (n = 20), and in Griffiths et al. (2021) (n = 40). The funnel plot in panel B of Figure 2 shows clustering at the top of the plot (studies with low standard error) and no assumed larger diversity in the correlations when the error rates increase. However, there is no clear asymmetry in the plot, verified by non-significant Egger’s test (\\(\\beta\\) = 5.05, CI95% -0.99-11.09, t = 1.64, p = 0.112, Egger et al. (1997)). Coming back to the mean of valence correlation of 0.669 by all studies and the possible impact of study heterogeneity on this estimation, we also calculated the correlation without the studies that lie outside the 95% CI for pooled effect. This left 12 studies in the data and resulted in the meta-analytical pooled correlation of 0.686 (CI95% 0.635-0.731). In other words, despite the large variation in the correlations and standard errors across the studies, this variation in itself does not seem to be a significant driver behind the overall effect.\n\n\n\n\n\n\nForest (A) and funnel (B) plots of the best valence models from all MER studies.\n\n\n\n\nTo gain insights into the factors contributing to the wide range of model success, we explored several ways of splitting the data. Table 2 presents two key splits: one based on the number of features used, which we hypothesized might influence model performance, and another based on the modeling techniques employed. In terms of feature sets, we categorized them into three groups: few features (&lt;18), a large number of features (18–260), and massive feature sets (260+). Interestingly, models (4 in total) using a relatively small number of features (&lt;18) performed best (r = 0.817, 95% CI: 0.361–0.958) compared to those utilizing larger feature sets. However, it is worth noting that the models using massive feature sets (260+, 7 studies in total) also performed well (r = 0.702), achieving better and more consistent results than the overall prediction rate (r = 0.669). This observation is supported by the lowest heterogeneity index for the massive feature set group (\\(\\tau^2\\) = 0.029), indicating more consistent results across studies. Studies with large number of features (18-260 features, 10 studies in total) delivered the worst results, r = 0.586 (95% CI: 0.360–0.748). Despite the fluctuation in the overall model accuracy between the number of features, the differences are not substantially large to pass the test of statistical significance (Q(2) = 3.47, p=.176).\n\nWhen analyzing the studies across the five modeling techniques used, the prediction do differ significantly (Q(4) = 45.7, p &lt; .0001). Notably, linear models (LM) and Support Vector Machines (SVM) were the most common, with 8 and 6 studies, respectively, allowing for more confident interpretations. Linear models achieved the highest prediction rate (r = 0.784, 95% CI: 0.625–0.881), though this may be influenced by the smaller datasets typically used in these studies. These studies also exhibited substantially higher heterogeneity (\\(\\tau^2\\) = 0.137) compared to other techniques, where \\(\\tau^2\\) values were less than half of this. While there were only 3 studies involving tree-based model (TM), these performed well, achieving r = 0.750, 95% CI: 0.292–0.928), and the relatively poor performance of the neural network (NN) models represented in four studies (r = 0.340, 95% CI: -0.097–0.668) is difficult to explain without a deeper examination of the specific model architectures and the stimuli used in these studies. Kernel smoothing and KNN models (with only 1 study represented) achieved relatively poor success as well, r = 0.383, 95% CI: 0.348–0.426).\nWe also ran the sub-grouping analyses across a combination of stimulus genres (single vs mixed) and number of the features to explore where the differences in the model prediction rates might lie. For this purpose, we grouped the studies into small single genre/multigenre studies, medium single genre/multigenre studies, and medium-large single genre/multigenre studies, and huge multigenre studies. The small single genre/multigenre studies generally performed best (r = 0.836), followed by huge multi-genre studies (r = 0.693) while the medium and medium-large sized studies performance was between close the overall average (medium-large, r = 0.768 and medium r = 0.607). The heterogeneity was lowest in the huge multigenre studies (\\(\\tau^2\\) = 0.013) and highest in the small single genre/multigenre studies (\\(\\tau^2\\) = 0.318).\n\n\nThese comparisons of sub-groupings are also influenced by other factors, such as the type of journal (psychology vs engineering) or whether the objective is to explain or predict emotions. Although the sub-groupings result in an uneven distribution of studies and observations, they still offer valuable insights. Despite these caveats, the two main sub-groupings portrayed in Table 2 enable us to identify valuable differences related to model success across the studies.\n\n\n\nResults for arousal\nMoving on the arousal, we carry out the same meta-analytical analysis applying the random-effects model to arousal. Table 3 describes the broad pattern of results in tabular format, and Figure 3 illustrates the spread and heterogeneity of all studies for arousal. The overall correlation across the studies using the best performing model out of each study (Max) is 0.809 (CI95% 0.740-0.860). If we examine all the models reported in each study, the correlation drops marginally, to 0.791 (CI95% 0.770-0.810), despite this analysis includes about four times as many models as taking the best model out of each study. For arousal, even the baseline models seem to be performing on a relative high level. However, the indicators of heterogeneity are again high (\\(\\tau^2\\) = 0.141 and \\(I^2\\)=97.9%), which suggests that summary may be misleading. However, the analysis of asymmetry does not reveal significant issues (Eggers test, \\(\\beta\\) = 0.789 95%CI -4.87-6.45, t = 0.273, p = 0.788). If we remove the studies that are outside the 95%CI in heterogeneity, leaves this 13 studies in the summary that has r = 0.826 (95%CI 0.806-0.845) with \\(\\tau^2\\) = 0.0042 and \\(I^2\\) = 76.8%. In other words, no material difference to the results obtained with all 22 studies.\nTable 3. Meta-analytic diagnostic for all regression studies predicting arousal from audio.\n\n\n\n\n\n\n\n\n\n\n\n\nConcept\nModels, obs\n\\(r\\) [95%-CI]\n\\(t\\)\n\\(p\\)\n\\(\\tau^2\\)\n\\(I^2\\)\n\n\n\n\nArousal All\n102, 60017\n0.791 [0.770-0.810]\n39.9\n0.0001\n0.069\n96.2%\n\n\nArousal Max\n22, 14172\n0.809 [0.740-0.860]\n13.6\n0.0001\n0.141\n97.9%\n\n\nN Features\n\n\n\n\n\n\n\n\n&lt;18 F\n4, 3016\n0.817 [0.361-0.958]\n\n\n0.2295\n99.2%\n\n\n18-260 F\n10, 4222\n0.586 [0.356-0.748]\n\n\n0.1542\n96.9%\n\n\n260+ F\n7, 6190\n0.702 [0.612-0.774]\n\n\n0.0285\n96.6%\n\n\nTechniques\n\n\n\n\n\n\n\n\nKS\n1, 1838\n0.819 [0.803-0.833]\n\n\n-\n-\n\n\nLM\n8, 1762\n0.881 [0.808-0.928]\n\n\n0.0846\n93.3%\n\n\nSVM\n6, 4993\n0.808 [0.644-0.901]\n\n\n0.1125\n98.0%\n\n\nNN\n4, 2249\n0.533 [0.328-0.691]\n\n\n0.0190\n85.8%\n\n\nTM\n3, 3330\n0.809 [0.733-0.864]\n\n\n0.0025\n65.4%\n\n\n\n\n\nFigure 3 presents (A) a forest and (B) funnel plot of the random-effects model of the best-performing models from all studies. Similarly to valence, the range of correlations is also wide for arousal, ranging from 0.35 to 0.95, with all studies demonstrating evidence of positive correlations. A mean estimate of 0.81 or higher is achieved by the majority (15 out of the 22 models). Due to large sample in most studies, the confidence intervals are narrow, although the exceptions (\\(N &lt; 55\\)) are clearly visible (Beveridge & Knox, 2018; Griffiths et al., 2021; Koh et al., 2023; Saiz-Clar et al., 2022; Wang et al., 2021). The funnel plot in panel B illustrates the limited range of the correlations and show heavy clustering at the top of the plot (studies with low standard error). There is no clear asymmetry in the plot, verified by non-significant Egger’s test reported above.\nThe analysis of the subdivision of studies shows that there is no significant differences between the studies using different number of features (Q(2) = 3.47, p = .176) despite the differing means (r = 0.817 for studies with less than 18 features, r = 0.586 for 18 to 260 features, and r = 0.702 for studies utilising over 260 features). The differences in the techniques, however, does show statistically significant variance between subgroups (Q(4) = 50.47, p &lt; .0001). The Neural Nets (NN) achieve poor prediction of arousal (r = 0.533) in comparison to other techniques. The caveat of this subgroup analysis is the small number of observations for five techniques. When other subgroupings were explored, such as the type of journal (Engineering with 13 studies vs Psychology with 9 studies), no significant differences were observed (Q(1) = 0.94, p = .333).\n\n\n\n\n\nForest (A) and funnel (B) plots of the best arousal models from all MER studies."
  },
  {
    "objectID": "analysis/preprocessing.html#feature-n-and-genre-split",
    "href": "analysis/preprocessing.html#feature-n-and-genre-split",
    "title": "Preprocessing",
    "section": "Feature N and genre split",
    "text": "Feature N and genre split\n\n\n   0% 33.3% 66.6% 99.9% \n    3    21    72   499 \n\n\n   0% 33.3% 66.6% 99.9% \n   15   557   653  6670"
  },
  {
    "objectID": "analysis/preprocessing.html#feature-n-and-genre-split-1",
    "href": "analysis/preprocessing.html#feature-n-and-genre-split-1",
    "title": "Preprocessing",
    "section": "Feature N and genre split",
    "text": "Feature N and genre split\n\n\n   0% 33.3% 66.6% 99.9% \n    3    21    72   499 \n\n\n   0% 33.3% 66.6% 99.9% \n   15   557   653  6670"
  },
  {
    "objectID": "analysis/analysis.html#explore-heterogeneity",
    "href": "analysis/analysis.html#explore-heterogeneity",
    "title": "Analysis",
    "section": "",
    "text": "# Method 1: Give us the Egger's test about beta coefficient from funnel\nprint(eggers.test(m.cor))\n\nEggers' test of the intercept \n============================= \n\n intercept        95% CI     t         p\n     4.997 -0.78 - 10.78 1.695 0.1042273\n\nEggers' test does not indicate the presence of funnel plot asymmetry. \n\n# Method 2: Find the impact to the results when removing those outside the 95CI\nO &lt;- find.outliers(m.cor) # 13 remaining out of 24\n\n# Method 3: Leave-out-out analysis etc for individual influence (not useful here)\n#infan &lt;- InfluenceAnalysis(m.cor)\n\n# Method 4: Focus on 10% of most precise studies (Stanley, Jarrel, Doucouliagos 2010)\nthres&lt;-quantile(m.cor$seTE,0.1)\nind&lt;-m.cor$seTE&lt;=as.numeric(thres)\nm.cor10pct &lt;- update(m.cor, subset = which(ind))\n\n# Method 5: P curve analysis (Simonsohn, Simmons & Nelson, 2015)\npcurve(m.cor)\n\n\n\n\n\n\n\n\nP-curve analysis \n ----------------------- \n- Total number of provided studies: k = 24 \n- Total number of p&lt;0.05 studies included into the analysis: k = 23 (95.83%) \n- Total number of studies with p&lt;0.025: k = 23 (95.83%) \n   \nResults \n ----------------------- \n                    pBinomial   zFull pFull   zHalf pHalf\nRight-skewness test         0 -34.047     0 -33.531     0\nFlatness test               1  33.691     1  34.002     1\nNote: p-values of 0 or 1 correspond to p&lt;0.001 and p&gt;0.999, respectively.   \nPower Estimate: 99% (99%-99%)\n   \nEvidential value \n ----------------------- \n- Evidential value present: yes \n- Evidential value absent/inadequate: no \n\n\n\n\n\n\n\ntmp &lt;- dplyr::filter(R_summary,dimension==\"valence\")\ntmp&lt;-tmp[!is.na(tmp$feature_n_categories),] # remove missing values\n\nm.cor3 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  feature_n_categories,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\nprint(m.cor3)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 23\nNumber of observations: o = 14916\n\n                        COR            95%-CI    t  p-value\nRandom effects model 0.6597 [ 0.5535; 0.7448] 9.73 &lt; 0.0001\nPrediction interval         [-0.0159; 0.9218]              \n\nQuantifying heterogeneity:\n tau^2 = 0.1444 [0.0834; 0.2986]; tau = 0.3800 [0.2889; 0.5464]\n I^2 = 98.3% [98.0%; 98.6%]; H = 7.65 [6.99; 8.38]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1288.44   22 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                                                k    COR           95%-CI\nfeature_n_categories = Feature n &gt; 260          7 0.6845 [0.5660; 0.7752]\nfeature_n_categories = Feature n &lt; 18           5 0.8111 [0.5342; 0.9308]\nfeature_n_categories = Feature n &gt; 18 & &lt; 260  11 0.5477 [0.3434; 0.7025]\n                                               tau^2    tau      Q   I^2\nfeature_n_categories = Feature n &gt; 260        0.0435 0.2085 211.87 97.2%\nfeature_n_categories = Feature n &lt; 18         0.1815 0.4260 362.55 98.9%\nfeature_n_categories = Feature n &gt; 18 & &lt; 260 0.1331 0.3648 416.81 97.6%\n\nTest for subgroup differences (random effects model):\n                  Q d.f. p-value\nBetween groups 5.73    2  0.0570\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 22)\n- Prediction interval based on t-distribution (df = 21)\n- Fisher's z transformation of correlations\n\n\n\n\n\n\nm.cor_subgroups &lt;- update(m.cor, \n       subgroup = model_class_id, \n#       subgroup = journal_type, \n#       subgroup = stimulus_genre_mixed, \n       tau.common = FALSE,\n       prediction = TRUE)\n\nprint(m.cor_subgroups)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 24\nNumber of observations: o = 15660\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.6585 [0.5574; 0.7404] 10.14 &lt; 0.0001\nPrediction interval         [0.0042; 0.9180]               \n\nQuantifying heterogeneity:\n tau^2 = 0.1376 [0.0804; 0.2802]; tau = 0.3709 [0.2836; 0.5293]\n I^2 = 98.2% [97.9%; 98.5%]; H = 7.50 [6.86; 8.20]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1294.03   23 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                                                      k    COR\nmodel_class_id = Kernel Smoothing, Additive and KNN   2 0.4662\nmodel_class_id = Random Forests                       4 0.7024\nmodel_class_id = Linear Methods                       8 0.7840\nmodel_class_id = Neural Nets                          4 0.3404\nmodel_class_id = Flexible Discriminants               6 0.6555\n                                                               95%-CI  tau^2\nmodel_class_id = Kernel Smoothing, Additive and KNN [-0.6342; 0.9424] 0.0185\nmodel_class_id = Random Forests                     [ 0.3914; 0.8694] 0.0803\nmodel_class_id = Linear Methods                     [ 0.6249; 0.8806] 0.1370\nmodel_class_id = Neural Nets                        [-0.0970; 0.6676] 0.0761\nmodel_class_id = Flexible Discriminants             [ 0.4838; 0.7786] 0.0574\n                                                       tau      Q   I^2\nmodel_class_id = Kernel Smoothing, Additive and KNN 0.1361  20.56 95.1%\nmodel_class_id = Random Forests                     0.2833 198.79 98.5%\nmodel_class_id = Linear Methods                     0.3701 195.78 96.4%\nmodel_class_id = Neural Nets                        0.2759 102.54 97.1%\nmodel_class_id = Flexible Discriminants             0.2396 161.22 96.9%\n\nTest for subgroup differences (random effects model):\n                   Q d.f. p-value\nBetween groups 18.75    4  0.0009\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 23)\n- Prediction interval based on t-distribution (df = 22)\n- Fisher's z transformation of correlations\n\n#forest(m.cor_subgroups,subgroup=TRUE)\n\n\n\n\nAdd journal_type as a grouping option. Here we have divided the journals into engineering and psychology journals.\n\nm.cor_subgroups &lt;- update(m.cor, \n       subgroup = journal_type, \n#       subgroup = journal_type, \n#       subgroup = stimulus_genre_mixed, \n       tau.common = FALSE,\n       prediction = TRUE)\n\nprint(m.cor_subgroups)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 24\nNumber of observations: o = 15660\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.6585 [0.5574; 0.7404] 10.14 &lt; 0.0001\nPrediction interval         [0.0042; 0.9180]               \n\nQuantifying heterogeneity:\n tau^2 = 0.1376 [0.0804; 0.2802]; tau = 0.3709 [0.2836; 0.5293]\n I^2 = 98.2% [97.9%; 98.5%]; H = 7.50 [6.86; 8.20]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1294.03   23 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                             k    COR           95%-CI  tau^2    tau      Q\njournal_type = Engineering  15 0.6424 [0.5112; 0.7444] 0.1208 0.3475 644.85\njournal_type = Psychology    9 0.6880 [0.4683; 0.8276] 0.1830 0.4278 562.98\n                             I^2\njournal_type = Engineering 97.8%\njournal_type = Psychology  98.6%\n\nTest for subgroup differences (random effects model):\n                  Q d.f. p-value\nBetween groups 0.23    1  0.6349\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 23)\n- Prediction interval based on t-distribution (df = 22)\n- Fisher's z transformation of correlations\n\n#forest(m.cor_subgroups,subgroup=TRUE)\n\n\n\n\nAdd stimulus_genre_mixed as a grouping option\n\nm.cor_subgroups &lt;- update(m.cor, \n       subgroup = stimulus_genre_mixed, \n#       subgroup = journal_type, \n#       subgroup = stimulus_genre_mixed, \n       tau.common = FALSE,\n       prediction = TRUE)\n\nprint(m.cor_subgroups)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 24\nNumber of observations: o = 15660\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.6585 [0.5574; 0.7404] 10.14 &lt; 0.0001\nPrediction interval         [0.0042; 0.9180]               \n\nQuantifying heterogeneity:\n tau^2 = 0.1376 [0.0804; 0.2802]; tau = 0.3709 [0.2836; 0.5293]\n I^2 = 98.2% [97.9%; 98.5%]; H = 7.50 [6.86; 8.20]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1294.03   23 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                                     k    COR           95%-CI  tau^2    tau\nstimulus_genre_mixed = MultiGenre   16 0.6505 [0.5123; 0.7558] 0.1467 0.3831\nstimulus_genre_mixed = SingleGenre   8 0.6752 [0.4651; 0.8132] 0.1374 0.3707\n                                        Q   I^2\nstimulus_genre_mixed = MultiGenre  878.20 98.3%\nstimulus_genre_mixed = SingleGenre 415.17 98.3%\n\nTest for subgroup differences (random effects model):\n                  Q d.f. p-value\nBetween groups 0.07    1  0.7910\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 23)\n- Prediction interval based on t-distribution (df = 22)\n- Fisher's z transformation of correlations\n\n#forest(m.cor_subgroups,subgroup=TRUE)\n\n\n\n\nadd feature_n_complexity_genre.\n\ntmp &lt;- dplyr::filter(R_summary,dimension==\"valence\")\ntmp&lt;-tmp[!is.na(tmp$feature_n_categories),] # remove missing values\ndim(tmp)\n\n[1] 23 14\n\nm.cor3 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  feature_n_complexity_genre,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\nprint(m.cor3)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 23\nNumber of observations: o = 14916\n\n                        COR            95%-CI    t  p-value\nRandom effects model 0.6597 [ 0.5535; 0.7448] 9.73 &lt; 0.0001\nPrediction interval         [-0.0159; 0.9218]              \n\nQuantifying heterogeneity:\n tau^2 = 0.1444 [0.0834; 0.2986]; tau = 0.3800 [0.2889; 0.5464]\n I^2 = 98.3% [98.0%; 98.6%]; H = 7.65 [6.99; 8.38]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1288.44   22 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                                                                   k    COR\nfeature_n_complexity_genre = Medium-large single genre/multi ...   4 0.6694\nfeature_n_complexity_genre = Small single genre study              3 0.8358\nfeature_n_complexity_genre = Medium single genre/multigenre  ...  14 0.5874\nfeature_n_complexity_genre = Huge multigenre study                 2 0.7203\n                                                                            95%-CI\nfeature_n_complexity_genre = Medium-large single genre/multi ... [ 0.3472; 0.8503]\nfeature_n_complexity_genre = Small single genre study            [-0.1966; 0.9893]\nfeature_n_complexity_genre = Medium single genre/multigenre  ... [ 0.4328; 0.7084]\nfeature_n_complexity_genre = Huge multigenre study               [-0.1886; 0.9645]\n                                                                  tau^2    tau\nfeature_n_complexity_genre = Medium-large single genre/multi ... 0.0779 0.2791\nfeature_n_complexity_genre = Small single genre study            0.3182 0.5641\nfeature_n_complexity_genre = Medium single genre/multigenre  ... 0.1183 0.3439\nfeature_n_complexity_genre = Huge multigenre study               0.0128 0.1131\n                                                                      Q   I^2\nfeature_n_complexity_genre = Medium-large single genre/multi ... 202.35 98.5%\nfeature_n_complexity_genre = Small single genre study            358.17 99.4%\nfeature_n_complexity_genre = Medium single genre/multigenre  ... 481.16 97.3%\nfeature_n_complexity_genre = Huge multigenre study                 6.73 85.1%\n\nTest for subgroup differences (random effects model):\n                  Q d.f. p-value\nBetween groups 4.70    3  0.1949\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 22)\n- Prediction interval based on t-distribution (df = 21)\n- Fisher's z transformation of correlations\n\n\n\n\n\n\n\n# select regression studies with r2\ntmp &lt;- dplyr::filter(R_summary,dimension==\"arousal\")\n#tmp &lt;- dplyr::filter(R_studies,dimension==\"arousal\")\ndim(tmp)\n\n[1] 24 14\n\n#tmp &lt;- tmp[!is.na(tmp$values),]\ndim(tmp)\n\n[1] 24 14\n\n#tmp&lt;-drop_na(tmp)\n\nm.cor &lt;- metacor(cor = valuesMax, \n                 n = stimulus_n,\n                 studlab = citekey,\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 backtransf = TRUE,\n                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Arousal: Summary\")\n\nprint(m.cor)\n\nReview:     MER: Regression: Arousal: Summary\n\nNumber of studies: k = 24\nNumber of observations: o = 15660\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.8070 [0.7453; 0.8550] 14.83 &lt; 0.0001\nPrediction interval         [0.3466; 0.9541]               \n\nQuantifying heterogeneity:\n tau^2 = 0.1276 [0.0746; 0.2631]; tau = 0.3571 [0.2731; 0.5130]\n I^2 = 97.7% [97.2%; 98.1%]; H = 6.60 [5.99; 7.27]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1001.16   23 &lt; 0.0001\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 23)\n- Prediction interval based on t-distribution (df = 22)\n- Fisher's z transformation of correlations"
  },
  {
    "objectID": "analysis/preprocessing.html#remove-nas",
    "href": "analysis/preprocessing.html#remove-nas",
    "title": "Preprocessing",
    "section": "Remove NAs",
    "text": "Remove NAs\n\nR_studies &lt;- R_studies[!is.na(R_studies$values),]"
  },
  {
    "objectID": "analysis/preprocessing.html#check-models-arent-double-counted",
    "href": "analysis/preprocessing.html#check-models-arent-double-counted",
    "title": "Preprocessing",
    "section": "Check models aren’t double-counted",
    "text": "Check models aren’t double-counted\n\nlength(unique(paste0(R_studies$unique_id, R_studies$dimension)))\n\n[1] 292\n\nez::ezDesign(data = R_studies, x = unique_id, y = citekey)+\n  theme(axis.text.x = element_blank(),\n        axis.title.x = element_blank())"
  },
  {
    "objectID": "analysis/preprocessing.html#create-descriptive-table-for-the-manuscript-table-1-column-1",
    "href": "analysis/preprocessing.html#create-descriptive-table-for-the-manuscript-table-1-column-1",
    "title": "Preprocessing",
    "section": "Create descriptive table for the manuscript (Table 1, column 1)",
    "text": "Create descriptive table for the manuscript (Table 1, column 1)\n\nTR &lt;- NULL\nTR$study_n &lt;- length(unique(R_studies$citekey))\nTR$model_n &lt;- nrow(R_studies)\nt&lt;-table(R_studies$model_class_id)\nt2 &lt;- paste0(names(t),': ', as.numeric(t))\nTR$model_types_n &lt;- str_c(t2,collapse = \"\\n\")\nTR$feature_Desc &lt;- paste0('Min=',min(R_studies$feature_n,na.rm = TRUE),', Md=',median(R_studies$feature_n,na.rm = TRUE),', Max=', max(R_studies$feature_n,na.rm = TRUE))\nTR$stimulus_Desc &lt;- paste0('Min=',min(R_studies$stimulus_n,na.rm = TRUE),', Md=',median(R_studies$stimulus_n,na.rm = TRUE),', Max=', max(R_studies$stimulus_n,na.rm = TRUE))\nprint(TR)\n\n$study_n\n[1] 22\n\n$model_n\n[1] 204\n\n$model_types_n\n[1] \"Flexible Discriminants: 50\\nKernel Smoothing, Additive and KNN: 12\\nLinear Methods: 62\\nNeural Nets: 66\\nRandom Forests: 14\"\n\n$feature_Desc\n[1] \"Min=3, Md=605, Max=6670\"\n\n$stimulus_Desc\n[1] \"Min=20, Md=324, Max=2486\""
  },
  {
    "objectID": "analysis/preprocessing.html#create-descriptive-table-for-the-manuscript-table-1-column-2",
    "href": "analysis/preprocessing.html#create-descriptive-table-for-the-manuscript-table-1-column-2",
    "title": "Preprocessing",
    "section": "Create descriptive table for the manuscript (Table 1, column 2)",
    "text": "Create descriptive table for the manuscript (Table 1, column 2)\nCA: I think this should be correct, though may need to update after averaging across VA for some classification studies (zhang2016, hu2022)\n\nTC &lt;- NULL\nTC$study_n &lt;- length(unique(C_studies$citekey))\nTC$model_n &lt;- nrow(C_studies)\nt&lt;-table(C_studies$model_class_id)\nt2 &lt;- paste0(names(t),': ', as.numeric(t))\nTC$model_types_n &lt;- str_c(t2,collapse = \"\\n\")\nTC$feature_Desc &lt;- paste0('Min=',min(C_studies$feature_n,na.rm = TRUE),', Md=',median(C_studies$feature_n,na.rm = TRUE),', Max=', max(C_studies$feature_n,na.rm = TRUE))\nTC$stimulus_Desc &lt;- paste0('Min=',min(C_studies$stimulus_n,na.rm = TRUE),', Md=',median(C_studies$stimulus_n,na.rm = TRUE),', Max=', max(C_studies$stimulus_n,na.rm = TRUE))\nprint(TC)\n\n$study_n\n[1] 12\n\n$model_n\n[1] 86\n\n$model_types_n\n[1] \"Flexible Discriminants: 26\\nKernel Smoothing, Additive and KNN: 2\\nLinear Methods: 13\\nNeural Nets: 25\\nRandom Forests: 10\\nUnclassified: 10\"\n\n$feature_Desc\n[1] \"Min=8, Md=126, Max=8904\"\n\n$stimulus_Desc\n[1] \"Min=124, Md=300, Max=5192\""
  },
  {
    "objectID": "analysis/preprocessing.html#average-across-valence-and-arousal-for-va-classification",
    "href": "analysis/preprocessing.html#average-across-valence-and-arousal-for-va-classification",
    "title": "Preprocessing",
    "section": "Average across valence and arousal for VA classification",
    "text": "Average across valence and arousal for VA classification\n\n#length(unique(paste0(C_studies$unique_id, C_studies$dimension)))\n\nez::ezDesign(data = C_studies, x = unique_id, y = citekey)+\n  theme(axis.text.x = element_blank(),\n        axis.title.x = element_blank())\n\n\n\n\n\n\n\n\n\nva_studies &lt;- c(\"zhang2016br\", \"hu2022de\")\n  \nva_acc &lt;- C_studies |&gt; \n  filter(citekey %in% va_studies) |&gt; \n  group_by(unique_id, measure, statistic) |&gt; \n  mutate(values = mean(values), \n         accuracy_converted_to_mcc = mean(accuracy_converted_to_mcc))\n\nva_acc$dimension &lt;- \"classification\"\n\nva_acc &lt;- va_acc |&gt; distinct()\n\nC_studies &lt;- C_studies[!C_studies$citekey %in% va_studies,]\nC_studies &lt;- rbind(C_studies, va_acc)\n\n\nRevisualize studies\n\nlength(unique(paste0(C_studies$unique_id, C_studies$dimension)))\n\n[1] 86\n\nez::ezDesign(data = C_studies, x = unique_id, y = citekey)+\n  theme(axis.text.x = element_blank(),\n        axis.title.x = element_blank())\n\n\n\n\n\n\n\n\n\nGet the number of categories in the classification task\n\ntmp &lt;- metaMER_results\ntmp2 &lt;- tmp[which(tmp$statistic=='n'),]\nno_of_classes &lt;- summarise(group_by(tmp2,citekey),first(values))\nprint(no_of_classes)\n\n# A tibble: 10 × 2\n   citekey            `first(values)`\n   &lt;chr&gt;                        &lt;dbl&gt;\n 1 agarwal2021an                    4\n 2 alvarez2023ri                    4\n 3 bhuvanakumar2023em               2\n 4 dufour2021us                     5\n 5 hizlisoy2021mu                   3\n 6 hu2022de                         2\n 7 nguyen2017an                     6\n 8 panda2020no                      4\n 9 sorussa2020em                    8\n10 yeh2014po                        4\n\nhist(no_of_classes$`first(values)`)\n\n\n\n\n\n\n\nrm(tmp,tmp2)"
  },
  {
    "objectID": "manuscript/manuscript.html#datasets",
    "href": "manuscript/manuscript.html#datasets",
    "title": "A Meta-Analysis of Music Emotion Recognition Studies",
    "section": "Datasets",
    "text": "Datasets\n\nAs we noted that several studies rely on the same datasets, summarising these could aid interpretation of the results.\nTable 5. Summary of datasets and studies utilising them.\n\n\n\n\nDataset\nStim. Type\nStim. Dur. (s)\nStim. N\nFeature N\nPpt. N\nFeature Source\nIn studies\n\n\n\n\nMediaEval\nWestern pop\n45\n744\n6669\n10/track\nOpenSMILE\nBai, Feng, et al. (2016), Bai et al. (2017), J. Yang (2021), Chin et al. (2018b), Coutinho & Schuller (2017), Markov & Matsui (2014), Medina et al. (2020), Wang, Wang, et al. (2022), Xie et al. (2020)\n\n\nDEAM\nPop\n45\n1802\n260\n5-10/track\nOpenSMILE\nSorussa et al. (2020), Orjesek et al. (2022), Panwar et al. (2019), M. Zhang et al. (2023)\n\n\nAMG1608\nPop\n30\n1608\n72\n643\nMIR Toolbox, YAAFE\nChen et al. (2017), Hu & Yang (2017), Wang, Wei, et al. (2022)\n\n\nEMOPIA\nPiano Solo (pop music)\n30-40\n387\n24\n1 annot./track\nMIDI Toolbox\nBhuvana Kumar & Kathiravan (2023)\n\n\nNTUMIR\nFamous pop songs\n25\n60\n46\n40 annot./track\nMIR Toolbox, Sound Description Toolbox, MA Toolbox\nChin et al. (2018b)\n\n\nSoundtracks\nObscure film soundtracks\n15\n110\nNA\n116\nNA\nWang, Wang, et al. (2022)\n\n\nPSIC3839\nChinese popular\n180\n3839\nNA\n87\nLibrosa\nXu et al. (2021)\n\n\nCH818\nChinese pop\n30\n818\n15\n3\nMIR Toolbox, PsySound, Chroma Toolbox, Tempogram Toolbox\nHu & Yang (2017)\n\n\nZhang et al. (2015)\nChinese pop\n30\n171\n84\n10\nMA Toolbox, MIR Toolbox, Coversongs\nJ. Zhang et al. (2016b)\n\n\nPMEmo\nPop songs\nVariable\n794\n6373\n457\nComParE 2013 baseline feature set\nM. Zhang et al. (2023)\n\n\nNJU-V1\nLimited detail\nVariable\n777\nNot reported\nNA (tags)\nNA\nAgarwal & Om (2021)\n\n\nISMIR-2012\nPopular music\n30 or 60\n2904\n54\nNA (tags)\nMIR Toolbox\nAgarwal & Om (2021)\n\n\nMIREX2009\nPopular\nFull\n297\n3\nNA\nPaulus & Klapuri (2009)\nYeh et al. (2014)\n\n\nMillion Songs Dataset\nPop\nFull\n1,000,000\n55\nNone\nEchoNest\nCao & Park (2023)\n\n\nFree Music Archive\nVarious\nVariable\n&gt;100,000\nNA\nNA\nNA\nKoh et al. (2023)\n\n\nJamendo\nVarious\nVariable\n10,000\n24\nNA\nMetadata\nHu et al. (2022)\n\n\nChinese Classical Music Dataset\nChinese classical\n~30s\n500\n557\n20\nEssentia, MIR Toolbox\nWang, Wang, et al. (2022)\n\n\n\nNotes: \\(\\dagger\\) Used in Álvarez et al. (2023)\n\nThe most frequently used 3 datasets are MediaEval (Soleymani et al., 2013), DEAM (Aljanaki et al., 2017), and AMG1608 (Chen et al., 2015). These datasets represent Western pop music, are moderate in terms of the size (containing from 744 to 1802 music excerpts) and have been manually annotated by relative large number of participants (either by experts, students, or crowdsourced workers). Two of the most popular datasets offer a large number (260 to 6669) features extracted with OpenSMILE (Eyben et al., 2010). Looking at the datasets more broadly, the diversity in the size and the features of the datasets is notable. Only two feature extraction tools are used across multiple datasets (OpenSMILE and MIR Toolbox, Lartillot & Toiviainen (2007)). However, despite this diversity, there does not seem to be a direct link between the model success rates and the features themselves, or at least separating the features from variation created by the dataset size, annotation accuracy and genre is not possible."
  },
  {
    "objectID": "analysis/analysis.html#classification-studies-overall-success",
    "href": "analysis/analysis.html#classification-studies-overall-success",
    "title": "Analysis",
    "section": "",
    "text": "C_studies &lt;- read.csv(\"C_studies.csv\")\nC_studies &lt;- C_studies[!is.na(C_studies$values),]\n\n# yang2021an needs to be encoded for classification (currently just regression)\nC_summary &lt;- read.csv(\"C_summary.csv\")\nC_classes &lt;- read.csv(\"C_study_class_n.csv\")\n\nC_summary &lt;- merge(C_summary, C_classes)\n\nm.cor.c.all &lt;- metacor(cor = values,     # values \n                 n = stimulus_n,\n                 studlab = studyREF, # unique_id\n                 data = C_studies,\n                 common = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 backtransf = TRUE,\n                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Classification: Summary\")\n\nm.cor.c.all\n\nReview:     MER: Classification: Summary\n\nNumber of studies: k = 86\nNumber of observations: o = 80544\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.8253 [0.7908; 0.8546] 23.43 &lt; 0.0001\nPrediction interval         [0.2437; 0.9703]               \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.2137 [0.1597; 0.2940]; tau = 0.4623 [0.3996; 0.5422]\n I^2 = 99.7%; H = 17.66\n\nTest of heterogeneity:\n        Q d.f. p-value\n 26521.76   85       0\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hartung-Knapp adjustment for random effects model (df = 85)\n- Prediction interval based on t-distribution (df = 85)\n- Fisher's z transformation of correlations\n\n#m.cor_backtransformed &lt;- m.cor\n#m.cor_backtransformed$TE &lt;- FisherZInv(m.cor_backtransformed$TE)\nprint(funnel(m.cor.c.all, common = FALSE, studlab=TRUE,backtransf=TRUE))\n\n\n\n\n\n\n\n\n$xvals\n [1] 2.3799720 2.0142671 1.9772582 2.1220666 1.8827026 1.7585755 2.0196809\n [8] 1.7247148 1.5835413 1.6709175 0.9175788 2.2544044 1.6895184 1.2958523\n[15] 1.1450798 2.2112934 1.5982081 1.2848361 1.1512076 1.9404160 1.5322976\n[22] 1.1484217 1.0398896 1.8348676 1.4432431 1.0431836 0.9579293 0.5672419\n[29] 0.5295059 0.5583672 0.6136900 0.4168798 0.5609288 1.2167740 1.4470097\n[36] 1.3367938 1.5844886 1.3367938 1.4893225 1.3367938 1.6394812 0.7610522\n[43] 0.5343909 0.8332468 0.3444099 0.3809810 0.5174748 1.3253662 1.6561690\n[50] 0.6225264 1.0986123 1.0714317 1.0203278 1.0986123 1.0986123 1.0986123\n[57] 1.0986123 1.0986123 1.0986123 0.9729551 1.1568175 1.2419119 1.2211735\n[64] 1.1881364 1.1881364 1.1881364 0.7424116 0.7841811 0.7684032 0.8300447\n[71] 1.0203278 0.7009966 0.8527435 0.8722194 0.9014435 1.0986123 0.7615687\n[78] 0.9097245 0.8722194 0.8309765 0.9212749 0.9427868 0.9914972 0.9014435\n[85] 1.0302286 0.9181056\n\n$yvals\n [1] 0.01459116 0.01459116 0.01459116 0.01459116 0.01459116 0.01459116\n [7] 0.01459116 0.01459116 0.01459116 0.01388220 0.01388220 0.05103104\n[13] 0.05103104 0.05103104 0.05103104 0.05103104 0.05103104 0.05103104\n[19] 0.05103104 0.05103104 0.05103104 0.05103104 0.05103104 0.05103104\n[25] 0.05103104 0.05103104 0.05103104 0.04222003 0.04222003 0.04222003\n[31] 0.04222003 0.04222003 0.04222003 0.09090909 0.09090909 0.09090909\n[37] 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.05802589\n[43] 0.05802589 0.03338903 0.02357678 0.02357678 0.02357678 0.02357678\n[49] 0.04845016 0.04845016 0.07715167 0.07715167 0.07715167 0.07715167\n[55] 0.07715167 0.07715167 0.07715167 0.07715167 0.07715167 0.07715167\n[61] 0.07715167 0.07715167 0.07715167 0.07715167 0.07715167 0.07715167\n[67] 0.03239318 0.03239318 0.07715167 0.07715167 0.07715167 0.07715167\n[73] 0.07715167 0.07715167 0.07715167 0.07715167 0.07715167 0.07715167\n[79] 0.07715167 0.07715167 0.07715167 0.07715167 0.07715167 0.07715167\n[85] 0.07715167 0.07715167\n\n$pch\n [1] 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21\n[26] 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21\n[51] 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21\n[76] 21 21 21 21 21 21 21 21 21 21 21\n\n$text\nNULL\n\n$cex\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[39] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[77] 1 1 1 1 1 1 1 1 1 1\n\n$col\n [1] \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\"\n[10] \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\"\n[19] \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\"\n[28] \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\"\n[37] \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\"\n[46] \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\"\n[55] \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\"\n[64] \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\"\n[73] \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\" \"black\"\n[82] \"black\" \"black\" \"black\" \"black\" \"black\"\n\n$bg\n [1] \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\"\n [7] \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\"\n[13] \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\"\n[19] \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\"\n[25] \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\"\n[31] \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\"\n[37] \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\"\n[43] \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\"\n[49] \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\"\n[55] \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\"\n[61] \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\"\n[67] \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\"\n[73] \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\"\n[79] \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\" \"darkgray\"\n[85] \"darkgray\" \"darkgray\"\n\n$cex.studlab\n [1] 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8\n[20] 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8\n[39] 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8\n[58] 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8\n[77] 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8\n\n$xlim\n[1] 0.3360096 2.4394713\n\n$ylim\n[1] 0.09090909 0.00000000"
  },
  {
    "objectID": "analysis/analysis.html#define-splits-for-genre-stimulus-n-combinations",
    "href": "analysis/analysis.html#define-splits-for-genre-stimulus-n-combinations",
    "title": "Analysis",
    "section": "",
    "text": "# get stimulus and genre metadata for classification studies:\nC_studies |&gt;\n  group_by(citekey) |&gt;\n  summarize(feature_n = unique(feature_n),\n            feature_n_complexity = unique(feature_n_complexity),\n            stimulus_genre_mixed = unique(stimulus_genre_mixed)) -&gt; C_splits\n\n# create feature_n_complexity_genre column:\nC_splits$feature_n_complexity_genre &lt;- \"\"\n\n# define splits\nC_splits[C_splits$feature_n_complexity %in% \"Feature n &gt; 30 & &lt; 300\" &\n        C_splits$stimulus_genre_mixed == \"MultiGenre\",]$feature_n_complexity_genre &lt;- \"Medium multi-genre study\"\nC_splits[C_splits$stimulus_genre_mixed %in% \"SingleGenre\" &\n                             C_splits$feature_n_complexity %in% \"Feature n &lt; 30\" ,]$feature_n_complexity_genre &lt;- \"Small single-genre study\"\nC_splits[C_splits$feature_n_complexity == \"Feature n &gt; 300\",]$feature_n_complexity_genre &lt;- \"Huge single or multigenre study\"\nC_splits[C_splits$citekey == \"alvarez2023ri\",]$feature_n_complexity_genre &lt;- \"Small, multi-genre study\"\nC_splits[C_splits$citekey == \"zhang2016br\",]$feature_n_complexity_genre &lt;- \"Medium, single-genre study\"\n# add splits to summary:\nC_summary &lt;- left_join(C_summary, C_splits)\n\nJoining with `by = join_by(citekey, stimulus_genre_mixed)`\n\n\n\n\n\nC_summary$classes &lt;- 0\nC_summary[C_summary$n_classes &lt; 3,]$classes &lt;- \"Binary\"\nC_summary[C_summary$n_classes &gt;= 3,]$classes &lt;- \"Multiclass\""
  },
  {
    "objectID": "analysis/analysis.html#classification-models-best-models",
    "href": "analysis/analysis.html#classification-models-best-models",
    "title": "Analysis",
    "section": "",
    "text": "m.cor.c &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = studyREF, # unique_id\n                 data = C_summary,\n                 common = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 backtransf = TRUE,\n                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Classification: Summary\")\n\n\n\n\nfig3a &lt;- forest(m.cor.c,\n                sortvar = TE,\n                prediction = FALSE, \n                print.tau2 = FALSE,\n                leftlabs = c(\"Author\", \"N\"),studlab = studyREF)\n\n\n\n\n\n\n\nfig3b&lt;-funnel(m.cor.c, common = FALSE, studlab=TRUE,backtransf=TRUE)\n\n\n\n\n\n\n\nlibrary(forestplot)\ndata&lt;-tibble::tibble(mean=m.cor.c$cor,lower=FisherZInv(m.cor.c$lower),upper=FisherZInv(m.cor.c$upper),study=m.cor.c$studlab,n=m.cor.c$n,cor=round(m.cor.c$cor,2))\ndata&lt;-dplyr::arrange(data,mean)\n\nfp3 &lt;- grid.grabExpr(print(data |&gt;\n                             forestplot(labeltext = c(study, n, cor),\n                                        xlab = \"Correlation\",\n                                        xticks = c(0, .25,.5,.75, 1),\n                                        clip = c(0, 1))|&gt;\n                             fp_add_header(study = \"Study\",n = \"N\",cor = expression(italic(r))) |&gt;\n                             fp_append_row(mean  = m.cor.c$TE.common,\n                                           lower = m.cor.c$lower.common,\n                                           upper = m.cor.c$upper.common,\n                                           study = \"Summary\",\n                                           n = sum(m.cor.c$n),\n                                           cor = round(m.cor.c$TE.common,2),\n                                           is.summary = TRUE) |&gt;\n                             fp_set_style(box = \"grey50\",\n                                          line = \"grey20\",\n                                          summary = \"black\",\n                                          txt_gp = fpTxtGp(label = list(gpar(cex = 0.80)),\n                                                           ticks = gpar(cex = 0.80),\n                                                           xlab  = gpar(cex = 0.80)))|&gt;\n                             fp_decorate_graph(grid = structure( m.cor.c$TE.common,gp = gpar(lty = 2, col = \"grey30\")))\n)\n)\n\nsource('../etc/custom_funnel_plot.R')\nfp4 &lt;- custom_funnel_plot(m.cor.c)\n\ngridExtra::grid.arrange(fp3, fp4, ncol=2, widths=c(2,1),heights=c(2,1))\n\nWarning: Removed 984 rows containing missing values or values outside the scale range\n(`geom_line()`).\nRemoved 984 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_hline()`).\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(ggrepel)\ntmpdata &lt;- data.frame(SE = FisherZInv(m.cor.c$seTE), Zr = FisherZInv(m.cor.c$TE),studies=m.cor.c$studlab)\n\ntmpdata$citekey&lt;-str_replace_all(tmpdata$studies,'-.*$','')\ntmpdata$citekey&lt;-factor(tmpdata$citekey)\n\ng &lt;- ggplot(tmpdata,aes(y = SE, x = Zr,label=studies,color=citekey,fill=citekey)) +\n  geom_point(show.legend = FALSE) +\n  geom_label_repel(size=1.5,max.overlaps = 39,color=\"black\",show.legend = FALSE)+\n  ylab('Standard Error') + \n  xlab('r')+\n  scale_y_reverse()+\n#  scale_x_continuous(breaks=seq(0.0,1.0,0.25),limits=c(0,1.0))+\n#  coord_flip()+\n  theme_bw()\nprint(g)"
  },
  {
    "objectID": "analysis/analysis.html#exploring-heterogeneity",
    "href": "analysis/analysis.html#exploring-heterogeneity",
    "title": "Analysis",
    "section": "",
    "text": "# Method 1: Give us the Egger's test about beta coefficient from funnel\nprint(eggers.test(m.cor.c))\n\nEggers' test of the intercept \n============================= \n\n intercept        95% CI      t          p\n   -18.764 -38.69 - 1.16 -1.846 0.09468325\n\nEggers' test does not indicate the presence of funnel plot asymmetry. \n\n# Method 2: Find the impact to the results when removing those outside the 95CI\nO &lt;- find.outliers(m.cor.c) # 13 remaining out of 24\nprint(O)\n\nIdentified outliers (random-effects model) \n------------------------------------------ \n\"Agarwal et al 2021\", \"Bhuvanakumar et al 2023\", \"Dufour et al 2021\", \"Hu et al 2022\", \"Nguyen et al 2017\", \"Panda et al 2020\" \n \nResults with outliers removed \n----------------------------- \nReview:     MER: Classification: Summary\n\nNumber of studies: k = 6\nNumber of observations: o = 7889\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.8941 [0.8282; 0.9356] 14.29 &lt; 0.0001\nPrediction interval         [0.6506; 0.9709]               \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.0569 [0.0199; 0.3670]; tau = 0.2385 [0.1410; 0.6058]\n I^2 = 97.7% [96.6%; 98.5%]; H = 6.63 [5.39; 8.15]\n\nTest of heterogeneity:\n      Q d.f.  p-value\n 219.67    5 &lt; 0.0001\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hartung-Knapp adjustment for random effects model (df = 5)\n- Prediction interval based on t-distribution (df = 5)\n- Fisher's z transformation of correlations\n\n# Method 3: Leave-out-out analysis etc for individual influence (not useful here)\n#infan &lt;- InfluenceAnalysis(m.cor)\n\n# Method 4: Focus on 10% of most precise studies (Stanley, Jarrel, Doucouliagos 2010)\nthres&lt;-quantile(m.cor.c$seTE,0.1)\nind&lt;-m.cor.c$seTE&lt;=as.numeric(thres)\nm.cor10pct &lt;- update(m.cor.c, subset = which(ind))\n\n# Method 5: P curve analysis (Simonsohn, Simmons & Nelson, 2015)\npcurve(m.cor.c)\n\n\n\n\n\n\n\n\nP-curve analysis \n ----------------------- \n- Total number of provided studies: k = 12 \n- Total number of p&lt;0.05 studies included into the analysis: k = 12 (100%) \n- Total number of studies with p&lt;0.025: k = 12 (100%) \n   \nResults \n ----------------------- \n                    pBinomial   zFull pFull   zHalf pHalf\nRight-skewness test         0 -26.866     0 -26.559     0\nFlatness test               1  28.149     1  28.149     1\nNote: p-values of 0 or 1 correspond to p&lt;0.001 and p&gt;0.999, respectively.   \nPower Estimate: 8% (99%-99%)\n   \nEvidential value \n ----------------------- \n- Evidential value present: yes \n- Evidential value absent/inadequate: no \n\n\n\n\n\n\n\nforest(m.cor.c.o,\n       sortvar = TE,\n       prediction = FALSE, \n             print.tau2 = FALSE,\n             leftlabs = c(\"Author\", \"N\"),studlab = citekey)\n\n\n\n\n\n\n\nfunnel(m.cor.c.o, common = FALSE, studlab=TRUE,backtransf=TRUE)"
  },
  {
    "objectID": "analysis/analysis.html#subgroup-analyses",
    "href": "analysis/analysis.html#subgroup-analyses",
    "title": "Analysis",
    "section": "",
    "text": "m.cor_classes &lt;- update(m.cor.c, \n       subgroup = C_summary$classes, \n       tau.common = FALSE,\n       prediction = TRUE)\n\nforest(m.cor_classes,\n       sortvar = TE,\n       prediction = FALSE, \n             print.tau2 = FALSE,\n             leftlabs = c(\"Author\", \"N\"),studlab = citekey)\n\n\n\n\n\n\n\nfunnel(m.cor, common = FALSE, studlab=TRUE,backtransf=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\nm.cor_subgroups &lt;- update(m.cor.c, \n       subgroup = stimulus_genre_mixed, \n       tau.common = FALSE,\n       prediction = TRUE)\n\nprint(m.cor_subgroups)\n#forest(m.cor_subgroups,subgroup=TRUE)\n\n\n\n\n\nm.cor_complexity &lt;- update(m.cor.c, \n       subgroup = C_summary$feature_n_complexity_genre, \n       tau.common = FALSE,\n       prediction = TRUE)\n\nprint(m.cor_complexity)\n\nReview:     MER: Classification: Summary\n\nNumber of studies: k = 12\nNumber of observations: o = 15696\n\n                        COR           95%-CI    t  p-value\nRandom effects model 0.8753 [0.7555; 0.9384] 8.07 &lt; 0.0001\nPrediction interval         [0.0256; 0.9907]              \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.3366 [0.1675; 0.9707]; tau = 0.5802 [0.4093; 0.9853]\n I^2 = 99.8%; H = 21.40\n\nTest of heterogeneity:\n       Q d.f. p-value\n 5039.29   11       0\n\nResults for subgroups (random effects model):\n                                                               k    COR\nfeature_n_complexity_genre = Medium multi-genre study          4 0.8555\nfeature_n_complexity_genre = Small, multi-genre study          1 0.9317\nfeature_n_complexity_genre = Small single-genre study          3 0.9378\nfeature_n_complexity_genre = Huge single or multigenre study   3 0.7907\nfeature_n_complexity_genre = Medium, single-genre study        1 0.8000\n                                                                        95%-CI\nfeature_n_complexity_genre = Medium multi-genre study        [ 0.0092; 0.9877]\nfeature_n_complexity_genre = Small, multi-genre study        [ 0.9280; 0.9352]\nfeature_n_complexity_genre = Small single-genre study        [ 0.4269; 0.9949]\nfeature_n_complexity_genre = Huge single or multigenre study [-0.1319; 0.9793]\nfeature_n_complexity_genre = Medium, single-genre study      [ 0.7386; 0.8482]\n                                                              tau^2    tau\nfeature_n_complexity_genre = Medium multi-genre study        0.6334 0.7959\nfeature_n_complexity_genre = Small, multi-genre study            --     --\nfeature_n_complexity_genre = Small single-genre study        0.2546 0.5046\nfeature_n_complexity_genre = Huge single or multigenre study 0.2294 0.4789\nfeature_n_complexity_genre = Medium, single-genre study          --     --\n                                                                   Q   I^2\nfeature_n_complexity_genre = Medium multi-genre study        3751.10 99.9%\nfeature_n_complexity_genre = Small, multi-genre study           0.00    --\nfeature_n_complexity_genre = Small single-genre study         140.04 98.6%\nfeature_n_complexity_genre = Huge single or multigenre study   75.79 97.4%\nfeature_n_complexity_genre = Medium, single-genre study         0.00    --\n\nTest for subgroup differences (random effects model):\n                   Q d.f.  p-value\nBetween groups 58.51    4 &lt; 0.0001\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hartung-Knapp adjustment for random effects model (df = 11)\n- Prediction interval based on t-distribution (df = 11)\n- Fisher's z transformation of correlations\n\n\n\n\n\n\nm.cor_subgroups &lt;- update(m.cor.c, \n       subgroup = model_class_id, \n       tau.common = FALSE,\n       prediction = TRUE)\n\nprint(m.cor_subgroups)\n#forest(m.cor_subgroups,subgroup=TRUE)\n\n\n\nTo show the quality differences between core and eliminated studies (in progress).\n\ntmpdata &lt;- data.frame(SE = m.cor.c$seTE, Zr = m.cor.c$TE, studies=m.cor.c$studlab)\n\ntmpdata$studyREF &lt;- substr(tmpdata$studies,1,nchar(tmpdata$studies)-2)\ntmpdata$studyREF &lt;- str_replace_all(tmpdata$studyREF,'([0-9]+)',' et al \\\\1')\ntmpdata$studyREF &lt;- str_to_sentence(tmpdata$studyREF)\ntmpdata$studyREF\n\n [1] \"Agarwal et al  et al 20\"      \"Alvarez et al  et al 20\"     \n [3] \"Bhuvanakumar et al  et al 20\" \"Dufour et al  et al 20\"      \n [5] \"Hizlisoy et al  et al 20\"     \"Hu et al  et al 20\"          \n [7] \"Nguyen et al  et al 20\"       \"Panda et al  et al 20\"       \n [9] \"Sorussa et al  et al 20\"      \"Yeh et al  et al 20\"         \n[11] \"Zhang et al  et al 20\"        \"Zhang et al  et al 20\"       \n\nestimate = m.cor.c$TE.common\nse = m.cor.c$seTE.common\nse.seq=seq(0, max(m.cor.c$cor), 0.001)\nll95 = estimate-(1.96*se.seq)\nul95 = estimate+(1.96*se.seq)\nll99 = estimate-(3.29*se.seq)\nul99 = estimate+(3.29*se.seq)\nmeanll95 = estimate-(1.96*se)\nmeanul95 = estimate+(1.96*se)\ndfCI = data.frame(ll95, ul95, ll99, ul99, se.seq, estimate, meanll95, meanul95)\n\nfp = ggplot(NULL) +\n  geom_point(aes(x = SE, y = Zr), color='grey50',data=tmpdata) +\n  geom_text_repel(aes(x = SE, y = Zr, label=studyREF), data=tmpdata,size=2.5,max.overlaps = 40)+\n  xlab('Standard Error') + ylab('Fisher\\'s z transformed correlation')+\n  geom_line(aes(x = se.seq, y = ll95), linetype = 'dotted', data = dfCI) +\n  geom_line(aes(x = se.seq, y = ul95), linetype = 'dotted', data = dfCI) +\n  geom_segment(aes(x = min(se.seq), y = meanll95, xend = max(se.seq), yend = meanll95), linetype='dotted', data=dfCI) +\n  geom_segment(aes(x = min(se.seq), y = meanul95, xend = max(se.seq), yend = meanul95), linetype='dotted', data=dfCI) +\n#  scale_x_reverse()+\n  scale_x_reverse(breaks=seq(0,0.2,0.05),limits=c(0.15,0),expand=c(0.00,0.00))+\n # scale_y_continuous(breaks=seq(0.3,1.25,0.20),limits=c(0.3,1.23))+\n  coord_flip()+\n  theme_bw()\nprint(fp)\n\nWarning: Removed 833 rows containing missing values or values outside the scale range\n(`geom_line()`).\nRemoved 833 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\nWarning: Removed 984 rows containing missing values or values outside the scale range\n(`geom_segment()`).\nRemoved 984 rows containing missing values or values outside the scale range\n(`geom_segment()`).\n\n\n\n\n\n\n\n\n\n\nIdea: visualise the distributions of the model successes within studies (done in preprocessing)"
  },
  {
    "objectID": "manuscript/supporting_information.html",
    "href": "manuscript/supporting_information.html",
    "title": "Supporting Information",
    "section": "",
    "text": "Supporting Information related to “A Meta-Analysis of Music Emotion Recognition Studies”."
  },
  {
    "objectID": "manuscript/supporting_information.html#datasets",
    "href": "manuscript/supporting_information.html#datasets",
    "title": "Supporting Information",
    "section": "Datasets",
    "text": "Datasets\nAs several studies rely on the same datasets, Table S1 provides a summary of these.\nTable S1. Summary of datasets and studies utilising them.\n\n\n\n\nDataset\nStim. Type\nStim. Dur. (s)\nStim. N\nFeature N\nPpt. N\nFeature Source\nIn studies\n\n\n\n\nMediaEval\nWestern pop\n45\n744\n6669\n10/track\nOpenSMILE\nBai et al. (2016), Bai et al. (2017), Yang (2021), Chin et al. (2018), Coutinho & Schuller (2017), Markov & Matsui (2014), Medina et al. (2020), Wang, Wang, et al. (2022), Xie et al. (2020)\n\n\nDEAM\nPop\n45\n1802\n260\n5-10/track\nOpenSMILE\nSorussa et al. (2020), Orjesek et al. (2022), Panwar et al. (2019), M. Zhang et al. (2023)\n\n\nAMG1608\nPop\n30\n1608\n72\n643\nMIR Toolbox, YAAFE\nChen et al. (2017), Hu & Yang (2017), Wang, Wei, et al. (2022)\n\n\nEMOPIA\nPiano Solo (pop music)\n30-40\n387\n24\n1 annot./track\nMIDI Toolbox\nBhuvana Kumar & Kathiravan (2023)\n\n\nNTUMIR\nFamous pop songs\n25\n60\n46\n40 annot./track\nMIR Toolbox, Sound Description Toolbox, MA Toolbox\nChin et al. (2018)\n\n\nSoundtracks\nObscure film soundtracks\n15\n110\nNA\n116\nNA\nWang, Wang, et al. (2022)\n\n\nPSIC3839\nChinese popular\n180\n3839\nNA\n87\nLibrosa\nXu et al. (2021)\n\n\nCH818\nChinese pop\n30\n818\n15\n3\nMIR Toolbox, PsySound, Chroma Toolbox, Tempogram Toolbox\nHu & Yang (2017)\n\n\nZhang et al. (2015)\nChinese pop\n30\n171\n84\n10\nMA Toolbox, MIR Toolbox, Coversongs\nJ. Zhang et al. (2016)\n\n\nPMEmo\nPop songs\nVariable\n794\n6373\n457\nComParE 2013 baseline feature set\nM. Zhang et al. (2023)\n\n\nNJU-V1\nLimited detail\nVariable\n777\nNot reported\nNA (tags)\nNA\nAgarwal & Om (2021)\n\n\nISMIR-2012\nPopular music\n30 or 60\n2904\n54\nNA (tags)\nMIR Toolbox\nAgarwal & Om (2021)\n\n\nMIREX2009\nPopular\nFull\n297\n3\nNA\nPaulus & Klapuri (2009)\nYeh et al. (2014)\n\n\nMillion Songs Dataset\nPop\nFull\n1,000,000\n55\nNone\nEchoNest\nCao & Park (2023)\n\n\nFree Music Archive\nVarious\nVariable\n&gt;100,000\nNA\nNA\nNA\nKoh et al. (2023)\n\n\nJamendo\nVarious\nVariable\n10,000\n24\nNA\nMetadata\nHu et al. (2022)\n\n\nChinese Classical Music Dataset\nChinese classical\n~30s\n500\n557\n20\nEssentia, MIR Toolbox\nWang, Wang, et al. (2022)\n\n\n\nNotes: \\(\\dagger\\) Used in Álvarez et al. (2023)\n\nThe most frequently used 3 datasets are MediaEval (Soleymani et al., 2013), DEAM (Aljanaki et al., 2017), and AMG1608 (Chen et al., 2015). These datasets represent Western pop music, are moderate in terms of the size (containing from 744 to 1802 music excerpts) and have been manually annotated by relative large number of participants (either by experts, students, or crowdsourced workers). Two of the most popular datasets offer a large number (260 to 6669) features extracted with OpenSMILE (Eyben et al., 2010). Looking at the datasets more broadly, the diversity in the size and the features of the datasets is notable. Only two feature extraction tools are used across multiple datasets (OpenSMILE and MIR Toolbox, Lartillot & Toiviainen (2007)). However, despite this diversity, there does not seem to be a direct link between the model success rates and the features themselves, or at least separating the features from variation created by the dataset size, annotation accuracy and genre is not possible."
  }
]