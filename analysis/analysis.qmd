# Analysis

This assumes that the data has been parsed (`parse-model-output.R`, `format-study-results.R`) and preprocessed (`processing.qmd`).

## Regression studies

### Valence: Best model

For creating Table 2

```{r}
#| warning: false
#| eval: true
library(dmetar,quietly = TRUE)
library(tidyverse,quietly = TRUE)
library(meta)
library(DescTools)
library(ggrepel)
```

#### Using all models

```{r}
R_studies <- read.csv("R_studies.csv")
#R_summary <- read.csv("R_summary.csv")

# select regression studies with r2
#tmp <- dplyr::filter(R_summary,dimension=="valence")
tmp <- dplyr::filter(R_studies,dimension=="valence")
#dim(tmp)

#if all studies, remove two with NA values
tmp <- tmp[!is.na(tmp$values),]
#dim(tmp)

# Take all models
m.cor <- metacor(cor = values,     # values 
                 n = stimulus_n,
                 studlab = unique_id,
                 data = tmp,
                 fixed = FALSE,
                 random = TRUE,
                 prediction = TRUE,
#                 backtransf = TRUE,
#                 sm = "ZCOR",
                 method.tau = "PM",# was REML, but we switch to Paule-Mandel because Langan et al., 2019
                 method.random.ci = "HK", 
                 title = "MER: Regression: Valence: Summary")

print(m.cor)

print(FisherZInv(m.cor$TE.random))
print(FisherZInv(m.cor$upper.random))
print(FisherZInv(m.cor$lower.random))

#m.cor_backtransformed <- m.cor
#m.cor_backtransformed$TE <- FisherZInv(m.cor_backtransformed$TE)
#print(funnel(m.cor_backtransformed, common = FALSE, studlab=TRUE,backtransf=TRUE))

```

#### Using the best model out of each study

```{r}
#R_studies <- read.csv("R_studies.csv")
R_summary <- read.csv("R_summary.csv")

# select regression studies with r2
tmp <- dplyr::filter(R_summary,dimension=="valence")
#tmp <- dplyr::filter(R_studies,dimension=="valence")
#dim(tmp)

#if all studies, remove two
#tmp <- tmp[!is.na(tmp$values),]
#dim(tmp)

## Disambiguate the studies
tmp$studyREF[tmp$studyREF=="Wang et al 2022"] <- c("Wang et al. 2022a","Wang et al. 2022b")

# Max values
m.cor <- metacor(cor = valuesMax,     # values 
                 n = stimulus_n,
                 studlab = studyREF,#citekey, # unique_id
                 data = tmp,
                 fixed = FALSE,
                 random = TRUE,
                 prediction = TRUE,
#                 backtransf = TRUE,
#                 sm = "ZCOR",
                 method.tau = "REML",# could be PM (Paule-Mandel) as well
                 method.random.ci = "HK", 
                 title = "MER: Regression: Valence: Summary")

print(m.cor)

print(FisherZInv(m.cor$TE.random))
print(FisherZInv(m.cor$upper.random))
print(FisherZInv(m.cor$lower.random))

#m.cor_backtransformed <- m.cor
#m.cor_backtransformed$TE <- FisherZInv(m.cor_backtransformed$TE)
#print(funnel(m.cor_backtransformed, common = FALSE, studlab=TRUE,backtransf=TRUE))

```

### Sub-division based on techniques

```{r}
m.cor1 <- metacor(cor = valuesMax,     # values 
                 n = stimulus_n,
                 studlab = citekey, # unique_id
                 data = tmp,
                 fixed = FALSE,
                 random = TRUE,
                 prediction = TRUE,
                 subgroup =  model_class_id,
#                 backtransf = TRUE,
#                 sm = "ZCOR",
                 method.tau = "REML",# could be PM (Paule-Mandel) as well
                 method.random.ci = "HK", 
                 title = "MER: Regression: Valence: Summary")
print(m.cor1)

S<-summarise(group_by(tmp,model_class_id),n=n(),obs=sum(stimulus_n))
print(S)
```


### Sub-division based on journals (engineering vs psych)

```{r}
m.cor2 <- metacor(cor = valuesMax,     # values 
                 n = stimulus_n,
                 studlab = citekey, # unique_id
                 data = tmp,
                 fixed = FALSE,
                 random = TRUE,
                 prediction = TRUE,
                 subgroup =  journal_type,
#                 backtransf = TRUE,
#                 sm = "ZCOR",
                 method.tau = "REML",# could be PM (Paule-Mandel) as well
                 method.random.ci = "HK", 
                 title = "MER: Regression: Valence: Summary")
```

### Sub-division based on N features

```{r}
tmp<-tmp[!is.na(tmp$feature_n_categories),] # remove missing values
dim(tmp)
m.cor3 <- metacor(cor = valuesMax,     # values 
                 n = stimulus_n,
                 studlab = citekey, # unique_id
                 data = tmp,
                 fixed = FALSE,
                 random = TRUE,
                 prediction = TRUE,
                 subgroup =  feature_n_categories,
#                 backtransf = TRUE,
#                 sm = "ZCOR",
                 method.tau = "REML",# could be PM (Paule-Mandel) as well
                 method.random.ci = "HK", 
                 title = "MER: Regression: Valence: Summary")
print(m.cor3)
S<-summarise(group_by(tmp,feature_n_categories),n=n(),obs=sum(stimulus_n))
print(S)

```



#### Visualise (forest and funnel plots)

```{r}
forest(m.cor,
       sortvar = TE,
       prediction = FALSE, 
             print.tau2 = FALSE,
             leftlabs = c("Author", "g", "SE"),studlab = studyREF)

#funnel(m.cor, common = FALSE, studlab=TRUE,backtransf=TRUE)


```

#### Explore qualities (in progress)

```{r}
O <- find.outliers(m.cor)
# 6 datasets identified as outliers, without them the r drops to 0.5781
infan <- InfluenceAnalysis(m.cor)
print(eggers.test(m.cor))
```


#### Re-run the analysis without the outliers

```{r}
#| eval: false
#| echo: false
outliers <- c("chen2017co-various-GMM-mfcc-AMG1608-1", "chen2017co-various-GMM-tonal-AMG1608-1", "chen2017co-various-GMM-spectral-AMG1608-1", "chen2017co-various-GMM-temporal-AMG1608-1", "chen2017co-various-GMM-mfcctonalspectraltemporal-AMG1608-1", "griffiths2021am-various-mlr-mixed-new-validation", "griffiths2021am-various-mlr-mixed-new-validation-nooutliers", "hu2017cr-various-SVR-mixed-all-1", "hu2017cr-various-SVR-mixed-all-1", "hu2017cr-various-SVR-mixed-all-1", "hu2017cr-various-SVR-mixed-all-1", "koh2023me-openSMILE-fullyconnectedNN-FreeMusicArchive-audioOnly-1", "koh2023me-openSMILE-longshorttermmemoryNN-FreeMusicArchive-audioOnly-1", "wang2022co-various-extremelyrandomizedtreeregression-mixed-western-1", "wang2022co-various-extremelyrandomizedtreeregression-mixed-western-1", "wang2022co-various-extremelyrandomizedtreeregression-mixed-chinese-1", "wang2022co-various-extremelyrandomizedtreeregression-mixed-chinese-1", "wang2022cr-various-pls-mixed-chineseClassicalEnsembles-1", "wang2022cr-various-pls-mixed-chineseClassicalSolo-1", "wang2022cr-various-pls-mixed-westernClassicalEnsembles-1", "wang2022cr-various-pls-mixed-westernClassicalSolo-1", "zhang2019us-marsyas-NuSVR-music-xing2014-1")

tmp2<-tmp[!tmp$unique_id %in% outliers,]
m.cor <- metacor(cor = values, 
                 n = stimulus_n,
                 studlab = unique_id, # unique_id
                 data = tmp2,
                 fixed = FALSE,
                 random = TRUE,
                 sm = "ZCOR",
                 prediction = TRUE,
                 backtransf = TRUE,
                 method.tau = "REML",# could be PM (Paule-Mandel) as well
                 method.random.ci = "HK", 
                 title = "MER: Regression: Valence: Summary")

print(m.cor)

fp <- funnel(m.cor, common = TRUE,studlab=FALSE)



```

#### Custom funnel plot

To show the quality differences between core and eliminated studies.

```{r}
tmpdata <- data.frame(SE = FisherZInv(m.cor$seTE), Zr = FisherZInv(m.cor$TE),studies=m.cor$studlab)
#tmpdata <- data.frame(SE = m.cor$seTE, Zr = m.cor$TE, studies=m.cor$studlab)

estimate = m.cor$TE.common
se = m.cor$seTE.common
se.seq=seq(0, max(m.cor$cor), 0.001)
ll95 = estimate-(1.96*se.seq)
ul95 = estimate+(1.96*se.seq)
ll99 = estimate-(3.29*se.seq)
ul99 = estimate+(3.29*se.seq)
meanll95 = estimate-(1.96*se)
meanul95 = estimate+(1.96*se)
dfCI = data.frame(ll95, ul95, ll99, ul99, se.seq, estimate, meanll95, meanul95)

fp = ggplot(NULL) +
  geom_point(aes(x = SE, y = Zr), color='grey50',data=tmpdata) +
  geom_text_repel(aes(x = SE, y = Zr, label=studies), data=tmpdata,size=2.5,max.overlaps = 40)+
  xlab('Standard Error') + ylab('Correlation')+
  geom_line(aes(x = se.seq, y = ll95), linetype = 'dotted', data = dfCI) +
  geom_line(aes(x = se.seq, y = ul95), linetype = 'dotted', data = dfCI) +
  geom_hline(yintercept = estimate, linetype='solid', color='grey50',linewidth=0.2) +
  scale_x_reverse(breaks=seq(0,0.2,0.05),limits=c(0.15,0),expand=c(0.00,0.00))+
  scale_y_continuous(breaks=seq(0.0,1.00,0.20),limits=c(0.0,1.00),expand=c(0.00,0.00))+
  coord_flip()+
  theme_bw()
print(fp)
```


#### Subgroup analysis according to techniques

add `journal_type` and `stimulus_genre_mixed` as a grouping option

```{r}
m.cor_subgroups <- update(m.cor, 
       subgroup = model_class_id, 
#       subgroup = journal_type, 
#       subgroup = stimulus_genre_mixed, 
       tau.common = FALSE,
       prediction = TRUE)

print(m.cor_subgroups)
#forest(m.cor_subgroups,subgroup=TRUE)
```

- Idea: visualise the distributions of the model successes within studies (done in preprocessing)


### Arousal: Best model

```{r}
#| warning: false
#| eval: true

# select regression studies with r2
tmp <- dplyr::filter(R_summary,dimension=="arousal")
#tmp <- dplyr::filter(R_studies,dimension=="arousal")
dim(tmp)
#tmp <- tmp[!is.na(tmp$values),]
dim(tmp)
#tmp<-drop_na(tmp)

m.cor <- metacor(cor = valuesMax, 
                 n = stimulus_n,
                 studlab = citekey,
                 data = tmp,
                 fixed = FALSE,
                 random = TRUE,
                 prediction = TRUE,
                 backtransf = TRUE,
                 sm = "ZCOR",
                 method.tau = "REML",# could be PM (Paule-Mandel) as well
                 method.random.ci = "HK", 
                 title = "MER: Regression: Arousal: Summary")

print(m.cor)
```
### Trimmed analysis
```{r}
O <- find.outliers(m.cor)
```



#### Visualise (forest and funnel plots)

```{r}
forest(m.cor,
       sortvar = TE,
       prediction = FALSE, 
             print.tau2 = FALSE,
             leftlabs = c("Author", "g", "SE"))
plot(eggers.test(m.cor))
```

#### Explore qualities (in progress)

```{r}
#| eval: false
meta <- metagen(valuesMax, sqrt(valuesMax), 
                data = tmp, 
                studlab = tmp$citekey, 
                comb.fixed = FALSE, 
                method.tau = "PM")
find.outliers(meta)
infan <- InfluenceAnalysis(meta)
print(eggers.test(meta))

```

#### Subgroup analysis according to techniques

```{r}
update(m.cor, 
       subgroup = model_class_id, 
       tau.common = FALSE)
m.cor_subgroups <- update(m.cor, 
       subgroup = model_class_id, 
       tau.common = FALSE)

forest(m.cor_subgroups,subgroup=TRUE)
```

- Idea: visualise the distributions of the model successes within studies (done in preprocessing)

```{r}
#| eval: false
g1 <- ggplot(tmp,aes(y=valuesMax,fill=model_class_id))+
   geom_histogram(show.legend = T)+
  facet_wrap(.~studyREF)+
   coord_flip()+
   theme_bw()
g1

# S <- summarise(group_by(tmp,citekey),maxvalue=max(values))
# g<-ggplot(S,aes(y=maxvalue))+
#   geom_histogram(bins = 14)+
#   #facet_wrap(.~studyREF)+
#   coord_flip()+
#   theme_bw()
# g
```



## Classification studies

```{r}
#| warning: false
#| eval: true

C_studies <- read.csv("C_studies.csv")
C_studies <- C_studies[!is.na(C_studies$values),]

C_summary <- read.csv("C_summary.csv")

m.cor <- metacor(cor = valuesMax,     # values 
                 n = stimulus_n,
                 studlab = studyREF, # unique_id
                 data = C_summary,
                 fixed = FALSE,
                 random = TRUE,
                 prediction = TRUE,
                 backtransf = TRUE,
                 sm = "ZCOR",
                 method.tau = "REML",# could be PM (Paule-Mandel) as well
                 method.random.ci = "HK", 
                 title = "MER: Classification: Summary")

#print(m.cor)

#m.cor_backtransformed <- m.cor
#m.cor_backtransformed$TE <- FisherZInv(m.cor_backtransformed$TE)
print(funnel(m.cor, common = FALSE, studlab=TRUE,backtransf=TRUE))

```
#### Custom plot

```{r}
library(ggrepel)
tmpdata <- data.frame(SE = FisherZInv(m.cor$seTE), Zr = FisherZInv(m.cor$TE),studies=m.cor$studlab)

tmpdata$citekey<-str_replace_all(tmpdata$studies,'-.*$','')
tmpdata$citekey<-factor(tmpdata$citekey)

g <- ggplot(tmpdata,aes(y = SE, x = Zr,label=studies,color=citekey,fill=citekey)) +
  geom_point(show.legend = FALSE) +
  geom_label_repel(size=1.5,max.overlaps = 39,color="black",show.legend = FALSE)+
  ylab('Standard Error') + 
  xlab('r')+
  scale_y_reverse()+
#  scale_x_continuous(breaks=seq(0.0,1.0,0.25),limits=c(0,1.0))+
#  coord_flip()+
  theme_bw()
print(g)
```




#### Visualise (forest and funnel plots)

```{r}
forest(m.cor,
       sortvar = TE,
       prediction = FALSE, 
             print.tau2 = FALSE,
             leftlabs = c("Author", "g", "SE"),studlab = citekey)

funnel(m.cor, common = FALSE, studlab=TRUE,backtransf=TRUE)


```

#### Explore qualities (in progress)

```{r}
O <- find.outliers(m.cor)
# 6 datasets identified as outliers, without them the r drops to 0.5781
#infan <- InfluenceAnalysis(m.cor)
#print(eggers.test(m.cor))



```


#### Re-run the analysis without the outliers

```{r}
#| eval: false
#| echo: false
outliers <- c("")

tmp2<-tmp[!tmp$unique_id %in% outliers,]
m.cor <- metacor(cor = values, 
                 n = stimulus_n,
                 studlab = unique_id, # unique_id
                 data = tmp2,
                 fixed = FALSE,
                 random = TRUE,
                 sm = "ZCOR",
                 prediction = TRUE,
                 backtransf = TRUE,
                 method.tau = "REML",# could be PM (Paule-Mandel) as well
                 method.random.ci = "HK", 
                 title = "MER: Regression: Valence: Summary")

print(m.cor)

fp <- funnel(m.cor, common = TRUE,studlab=FALSE)



```

#### Custom funnel plot

To show the quality differences between core and eliminated studies (in progress).

```{r}
#| eval: true
tmpdata <- data.frame(SE = m.cor$seTE, Zr = m.cor$TE, studies=m.cor$studlab)

tmpdata$studyREF <- substr(tmpdata$studies,1,nchar(tmpdata$studies)-2)
tmpdata$studyREF <- str_replace_all(tmpdata$studyREF,'([0-9]+)',' et al \\1')
tmpdata$studyREF <- str_to_sentence(tmpdata$studyREF)
tmpdata$studyREF

estimate = m.cor$TE.common
se = m.cor$seTE.common
se.seq=seq(0, max(m.cor$cor), 0.001)
ll95 = estimate-(1.96*se.seq)
ul95 = estimate+(1.96*se.seq)
ll99 = estimate-(3.29*se.seq)
ul99 = estimate+(3.29*se.seq)
meanll95 = estimate-(1.96*se)
meanul95 = estimate+(1.96*se)
dfCI = data.frame(ll95, ul95, ll99, ul99, se.seq, estimate, meanll95, meanul95)

fp = ggplot(NULL) +
  geom_point(aes(x = SE, y = Zr), color='grey50',data=tmpdata) +
  geom_text_repel(aes(x = SE, y = Zr, label=studyREF), data=tmpdata,size=2.5,max.overlaps = 40)+
  xlab('Standard Error') + ylab('Fisher\'s z transformed correlation')+
  geom_line(aes(x = se.seq, y = ll95), linetype = 'dotted', data = dfCI) +
  geom_line(aes(x = se.seq, y = ul95), linetype = 'dotted', data = dfCI) +
  geom_segment(aes(x = min(se.seq), y = meanll95, xend = max(se.seq), yend = meanll95), linetype='dotted', data=dfCI) +
  geom_segment(aes(x = min(se.seq), y = meanul95, xend = max(se.seq), yend = meanul95), linetype='dotted', data=dfCI) +
#  scale_x_reverse()+
  scale_x_reverse(breaks=seq(0,0.2,0.05),limits=c(0.15,0),expand=c(0.00,0.00))+
  scale_y_continuous(breaks=seq(0.3,1.25,0.20),limits=c(0.3,1.23))+
  coord_flip()+
  theme_bw()
print(fp)


```


#### Subgroup analysis according to techniques

add `journal_type` and `stimulus_genre_mixed` as a grouping option

```{r}
#| eval: false
m.cor_subgroups <- update(m.cor, 
       subgroup = model_class_id, 
#       subgroup = journal_type, 
#       subgroup = stimulus_genre_mixed, 
       tau.common = FALSE,
       prediction = TRUE)

print(m.cor_subgroups)
#forest(m.cor_subgroups,subgroup=TRUE)
```

- Idea: visualise the distributions of the model successes within studies (done in preprocessing)

