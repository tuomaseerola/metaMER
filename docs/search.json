[
  {
    "objectID": "manuscript/manuscript.html",
    "href": "manuscript/manuscript.html",
    "title": "Meta-analysis of regression and classification success of emotion ratings from audio",
    "section": "",
    "text": "Emotional engagement is a key reason why people engage with music in their every day activities, and it is also why music is increasingly being used in various health applications (Agres et al., 2021; Juslin et al., 2022). In recent years, significant advances have been made in music information retrieval, particularly in music emotion recognition (MER) tasks (Gómez-Cañón et al., 2021; Panda et al., 2023). Improvements in available features, modeling techniques, and datasets have provided the field with opportunities to enhance the accuracy and reliability of predicting annotated emotions from audio. Over the past 25 years, numerous studies have established the types of emotions that listeners perceive and recognize in music. In the last 15 years, research has increasingly focused on tracing these recognized emotions back to specific musical components, such as expressive features (Lindström et al., 2003), structural aspects of music (Anderson & Schutz, 2022; Eerola et al., 2013; Grimaud & Eerola, 2022), acoustic features (Eerola, 2011; Panda et al., 2023, 2013; Saari et al., 2015; Y. H. Yang et al., 2008), or emergent properties revealed through deep learning techniques (Er & Aydilek, 2019; Sarkar et al., 2020).\nHowever, there is no consensus on the extent to which emotions can be accurately recognized by computational models. The current literature presents a diverse and mixed picture regarding the success of models in predicting emotions within the affective circumplex – valence and arousal– (Russell, 1980) and in classifying distinct emotion categories (Fu et al., 2010)."
  },
  {
    "objectID": "manuscript/manuscript.html#aims",
    "href": "manuscript/manuscript.html#aims",
    "title": "Meta-analysis of regression and classification success of emotion ratings from audio",
    "section": "Aims",
    "text": "Aims\nOur aim is to evaluate the predictive accuracy of two models of emotional expression in music: (a) models that predict track-specific coordinates in affective circumplex space (valence and arousal), and (b) models that classify discrete emotion categories. We focus on recent to identify key factors such as modeling techniques and features that significantly affect prediction accuracy. To achieve this, we conduct a meta-analysis of journal articles published in the past 10 years. Based on existing literature, we hypothesize that arousal will be predicted with higher accuracy than valence, as valence tends to be more context-dependent and challenging to model. For emotion classification, we expect simple utilitarian emotions (e.g., fear, anger) will be easier to predict than more complex social emotions (e.g., sadness, nostalgia)."
  },
  {
    "objectID": "manuscript/manuscript.html#quality-control",
    "href": "manuscript/manuscript.html#quality-control",
    "title": "Meta-analysis of regression and classification success of emotion ratings from audio",
    "section": "Quality Control",
    "text": "Quality Control\nThe search yielded studies of variable (and occasionally questionable) quality. To mitigate potentially spurious effects resulting from the inclusion of low-quality studies, we excluded studies lacking sufficient details about stimuli, analyzed features, or model architecture. Finally, we excluded studies published in journals of questionable relevance/quality, (e.g., Mathematical Problems in Engineering ceased publication following 17 retractions published between July and September 2024)."
  },
  {
    "objectID": "manuscript/manuscript.html#study-encoding",
    "href": "manuscript/manuscript.html#study-encoding",
    "title": "Meta-analysis of regression and classification success of emotion ratings from audio",
    "section": "Study Encoding",
    "text": "Study Encoding\nTo capture key details of each study, we added additional fields to BibTeX entries for each study. Fields included information about the genre/type of stimuli employed, along with their duration and number; the number of analyzed features; and the model type, validation procedure and output measures. Additionally, we included study results using executable R code containing custom functions for meta-analysis. For complete details about our encoding procedure, see studies/extraction_details.qmd ."
  },
  {
    "objectID": "manuscript/manuscript.html#prediction-success-for-valence-and-arousal-or-affect-dimensions",
    "href": "manuscript/manuscript.html#prediction-success-for-valence-and-arousal-or-affect-dimensions",
    "title": "Meta-analysis of regression and classification success of emotion ratings from audio",
    "section": "Prediction success for valence and arousal (or affect dimensions)",
    "text": "Prediction success for valence and arousal (or affect dimensions)\nSee analysis/analysis.qmd\nSince there are many models contained within each of the studies, we will report the results in two parts; We first give an overview of the results for all models, and then we focus on the best performing models of each study. The best performing model is the model within each study with the highest correlation coefficient. This reduction is done to avoid the issue of multiple models from the same study deflating the results as majority of the models included are relative modest baseline or alternative models that do not represent the novelty or content of the article. Table 2 summarises the results for all models (All) as well as best performing models (Max) for each study. The summary includes the number of models and observations, the correlation coefficient and its 95% confidence interval, the t-value and p-value for the correlation, the heterogeneity statistics \\(\\tau^2\\) and \\(I^2\\), calculated through appropriate transformations (Fisher’s Z) for the correlation coefficient as part of a random-effects model using meta library (Balduzzi et al., 2019).\nTable 2. Meta-analytic diagnostic for all regression studies predicting valence from audio.\n\n\n\n\n\n\n\n\n\n\n\n\nConcept\nModels, obs\n\\(r\\) [95%-CI]\n\\(t\\)\n\\(p\\)\n\\(\\tau^2\\)\n\\(I^2\\)\n\n\n\n\nValence All\n120,73685\n0.567 [0.530; 0.603]\n23.7\n.0001\n0.083\n97.5%\n\n\nValence Max\n24,15660\n0.659 [0.557; 0.740]\n10.14\n.0001\n0.138\n98.2%\n\n\nN Features\n\n\n\n\n\n\n\n\n&lt;18 F\n5,3036\n0.811 [0.566; 0.775]\n-\n-\n0.182\n98.9%\n\n\n18-260 F\n11,7318\n0.548 [0.343; 0.703]\n-\n-\n0.133\n97.6%\n\n\n260+ F\n7,4562\n0.685 [0.566; 0.775]\n-\n-\n0.044\n97.2%\n\n\nTechniques\n\n\n\n\n\n\n\n\nKS\n2,2582\n0.466 [-0.634; 0.942]\n-\n-\n0.0185\n95.1%\n\n\nLM\n8,1762\n0.784 [0.625; 0.881]\n-\n-\n0.1370\n96.4%\n\n\nFD\n6,4993\n0.656 [0.484; 0.779]\n-\n-\n0.0574\n96.9%\n\n\nNN\n4,2249\n0.340 [-0.097; 0.668]\n-\n-\n0.0761\n97.1%\n\n\nRF\n4,4074\n0.702 [0.391; 0.869]\n-\n-\n0.057\n98.5%\n\n\n\n\n\n\n\n\nOTHER GROUPINGS? STIMULUS MIXED/SINGLE GENRE, PREDICTION/EXPLANATION\n\n\n\n\n\n\n\nForest plot of valence predictions from the MER models.\n\n\n\n\nSummarise the results here briefly\nMoving on the arousal, …\nTable 3. Meta-analytic diagnostic for all regression studies predicting arousal from audio.\n\n\n\n\n\n\n\n\n\n\n\n\nConcept\nModels, obs\n\\(r\\) [95%-CI]\n\\(t\\)\n\\(p\\)\n\\(\\tau^2\\)\n\\(I^2\\)\n\n\n\n\nArousal\n\n0.7959 [0.7666; 0.8218]\n29.0\n0.0001\n0.0676\n95.6%\n\n\nArousal Max\n24,15660\n0.8070 [0.7453; 0.8550]\n10.3\n0.0001\n0.155\n96.8%\n\n\nN Features\n\n\n\n\n\n\n\n\n&lt;18 F\n\n\n\n\n\n\n\n\n18-260 F\n\n\n\n\n\n\n\n\n260+ F\n\n\n\n\n\n\n\n\nTechniques\n\n\n\n\n\n\n\n\nKS\n\n\n\n\n\n\n\n\nLM\n\n\n\n\n\n\n\n\nFD\n\n\n\n\n\n\n\n\nNN\n\n\n\n\n\n\n\n\nRF\n\n\n\n\n\n\n\n\n\nFigure 2. Forest plot of arousal prediction (using Max?)\n\n\n\n\nSummarise here the pattern of results"
  },
  {
    "objectID": "manuscript/manuscript.html#classification-studies",
    "href": "manuscript/manuscript.html#classification-studies",
    "title": "Meta-analysis of regression and classification success of emotion ratings from audio",
    "section": "Classification studies",
    "text": "Classification studies\nSummary of details contained in Table 1, but summarise at least the categories predicted before moving onto the main findings.\nTable 4. Meta-analytic diagnostic for all classification studies predicting emotion categories from audio.\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nModels, obs\n\\(r\\) [95%-CI]\n\\(t\\)\n\\(p\\)\n\\(\\tau^2\\)\n\\(I^2\\)\n\n\n\n\nAll\n89,87347\n0.8074 [0.7681; 0.8407]\n21.4\n0.0001\n0.2415\n99.7%\n\n\nMax\n14,17184\n0.8564 [0.7386; 0.9234]\n8.32\n0.0001\n0.329\n99.8%\n\n\n\n\n\nHeterogeneity issues\nFigure 3. Forest plot of arousal prediction (Max?) (Unless we do some custom plotting)\n\nFigure Optional: Funnel plot (I haven’t seen this yet)"
  },
  {
    "objectID": "manuscript/manuscript.html#concise-summary-of-what-we-did-and-found",
    "href": "manuscript/manuscript.html#concise-summary-of-what-we-did-and-found",
    "title": "Meta-analysis of regression and classification success of emotion ratings from audio",
    "section": "Concise summary of what we did and found",
    "text": "Concise summary of what we did and found"
  },
  {
    "objectID": "manuscript/manuscript.html#main-outcomes",
    "href": "manuscript/manuscript.html#main-outcomes",
    "title": "Meta-analysis of regression and classification success of emotion ratings from audio",
    "section": "Main outcomes",
    "text": "Main outcomes\n\nArousal is easier to predict (r = 0.7627) than valence (r = 0.6236), as we predicted. The glass ceiling seems to be at …\nClassification …\nModel accuracy is surprisingly little affected by the number of features (?) or modelling technique (?).\nSome of the complex state-of-the-art techniques (e.g., NNs) do not deliver impressive improvements over older techniques (e.g., SVR, RF)\nVariation in study/model/data quality is large and can be seen in heterogenuity and the amount of studies eliminated"
  },
  {
    "objectID": "manuscript/manuscript.html#calls-for-actionpoints-to-improve-in-such-studies",
    "href": "manuscript/manuscript.html#calls-for-actionpoints-to-improve-in-such-studies",
    "title": "Meta-analysis of regression and classification success of emotion ratings from audio",
    "section": "Calls for action/points to improve in such studies",
    "text": "Calls for action/points to improve in such studies\n\nDocumentation the details in full (features, stimuli, model details, cross-validation)\nQuality of the underlying data (emotion ratings, classes, or even stimulus properties?\nGeneralisibility of the models (some studies such as X and Y address this by applying the models across several datasets)\nDiversity in the evaluative aspects of studies: overfitting, numerous ways of cross-validating, not sharing data or analysis scripts, not reporting in the same way\nWhat proportion of stimuli are Western music, and what genres tend to dominate?\n\n\nFunding statement\nCA was funded by Mitacs Globalink Research Award (Mitacs & British High Commission - Ottawa, Canada).\n\n\nCompeting interests statement\nThere were no competing interests.\n\n\nOpen practices statement\nStudy preregistration, data, analysis scripts and supporting information is available at Github, https://tuomaseerola.github.io/metaMER.\n\n\nAcknowledgements\nWe thank Greggs food-on-the-go retailer for sustaining the work with affordable sandwiches and coffee."
  },
  {
    "objectID": "manuscript/manuscript.html#footnotes",
    "href": "manuscript/manuscript.html#footnotes",
    "title": "Meta-analysis of regression and classification success of emotion ratings from audio",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe best-performing model to date reached 69.83 % in the 2017 competition (Park et al., 2017)@park2017representation.↩︎"
  },
  {
    "objectID": "analysis/preprocessing.html",
    "href": "analysis/preprocessing.html",
    "title": "Preprocessing",
    "section": "",
    "text": "This assumes that the data has been parsed from the BibTeX files into table and exported as CSV file.\n\n\n\nrequire(here)\nsource(here::here('R/build-df.R'))\nsource(here::here('R/format-study-results.R'))\nsource(here::here('R/parse-model-output.R'))\n\n\nlibrary(stringr) \n# get metaMER df:\nmeta_df &lt;- get_metaMER_df(path_2_studies = here::here('studies'))\n\n# get included studies\nincluded_studies &lt;- meta_df[which(\n  !stringr::str_detect(meta_df$final_notes, '!EXCL!')),] |&gt; \n  dplyr::tibble()\n\n\n\n\n# get studies re-coded (currently identifiable by presence of bind_field.)\nrecoded_studies &lt;- included_studies[which(stringr::str_detect(\n  included_studies$model_rate_emotion_values,\n                                     'bind_field')),] \n\n\n\n\n\nmetaMER_results &lt;-\ndo.call(\n  rbind,\n    lapply(1:nrow(recoded_studies),\n       function(x) get_study_results(recoded_studies[x,])\n       )\n) \n\n# add unique identifiers\n\nunique_id &lt;- apply(metaMER_results[,c('citekey',\n                        'library_id',\n                         'model_id',\n                         'feature_id',\n                         'data_id',\n                         'experiment_id')],\n                      1, \n                      paste0, \n                      collapse = '-'\n) \nmetaMER_results$unique_id &lt;- stringr::str_remove_all(unique_id, \n                                                     ' ')\n\nmetaMER_results &lt;- metaMER_results |&gt; dplyr::select(unique_id, \n                                 dplyr::everything()) \n\nmetaMER_results |&gt; dplyr::tibble()\n\n# A tibble: 1,284 × 19\n   unique_id  citekey journal stimulus_genre model_category stimulus_n feature_n\n   &lt;chr&gt;      &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;          &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt;    \n 1 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 2 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 3 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 4 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 5 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 6 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 7 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 8 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 9 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n10 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n# ℹ 1,274 more rows\n# ℹ 12 more variables: participant_n &lt;chr&gt;, feature_source &lt;chr&gt;,\n#   feature_reduction_method &lt;chr&gt;, library_id &lt;chr&gt;, model_id &lt;chr&gt;,\n#   feature_id &lt;chr&gt;, data_id &lt;chr&gt;, experiment_id &lt;chr&gt;, dimension &lt;chr&gt;,\n#   measure &lt;chr&gt;, statistic &lt;chr&gt;, values &lt;dbl&gt;\n\n\n\n\n\nprint(knitr::kable(table(metaMER_results$citekey,metaMER_results$dimension)))\nprint(knitr::kable(table(metaMER_results$citekey,metaMER_results$model_id)))\nprint(knitr::kable(table(metaMER_results$citekey,metaMER_results$feature_id)))\nprint(knitr::kable(table(metaMER_results$citekey,metaMER_results$data_id)))\n\n\n\n\n\n\n\n# Classify techniques according Hastie, Tibshirani, Friedman (2008)\n# https://www.sas.upenn.edu/~fdiebold/NoHesitations/BookAdvanced.pdf\n#\nlibrary(stringr)\nmetaMER_results$model_id &lt;- tolower(metaMER_results$model_id)\nmetaMER_results$model_class_id &lt;- 'Unclassified'\nmetaMER_results$model_class_id[str_detect(metaMER_results$model_id,'lr|lm|pls|mlr|pcr|logistic regression|2d model full|pentagon|gaussian process regression|sparse bayesian regression|variational bayesian regression|logistic regression|lda|rda|regularized discriminant analysis|reguliarized discriminant analysis')] &lt;- 'Linear Methods' # Class name from Elements of Stat..\"\n#metaMER_results$model_class_id[str_detect(metaMER_results$model_id,'logistic regression|lda|rda|regularized discriminant analysis|reguliarized discriminant analysis')] &lt;- 'Linear Classification'\n#metaMER_results$model_class_id[str_detect(metaMER_results$model_id,'mars|gam')]&lt;-'Additive Trees and Related Methods' #\nmetaMER_results$model_class_id[str_detect(metaMER_results$model_id,'rbf|gmm|local|polynomial|polygonal|knn|mars|gam')]&lt;-'Kernel Smoothing, Additive and KNN'\n#metaMER_results$model_class_id[str_detect(metaMER_results$model_id,'adaboost|gradient')]&lt;-'Boosting'\nmetaMER_results$model_class_id[str_detect(metaMER_results$model_id,'nn|gru|lstm|ltsm|long short term memory|rprop|mcan')]&lt;-'Neural Nets'\nmetaMER_results$model_class_id[str_detect(metaMER_results$model_id,'svm|svr|support vector regression|smoreg|smo ')]&lt;-'Flexible Discriminants'\n#metaMER_results$model_class_id[str_detect(metaMER_results$model_id,'knn')]&lt;-'Prototype methods'\nmetaMER_results$model_class_id[str_detect(metaMER_results$model_id,'rf|extremely randomized tree regression|random forest|adaboost|gradient')]&lt;-'Random Forests'\n#metaMER_results$model_class_id[str_detect(metaMER_results$model_id,'rf')]&lt;-'Ensemble Learning'\n\n\n\n\n\nmetaMER_results$stimulus_genre_mixed &lt;- 'SingleGenre'\nmetaMER_results$stimulus_genre_mixed[str_detect(metaMER_results$stimulus_genre,',|multi')] &lt;- 'MultiGenre' # Class name from Elements of Stat..\"\n#table(metaMER_results$stimulus_genre_mixed)\n\n\n\n\n\nmetaMER_results$journal_type &lt;- \"Engineering\"\nmetaMER_results$journal_type[str_detect(metaMER_results$journal,'Quarterly Journal of Experimental Psychology|PSYCHOLOGY OF MUSIC|PLOS ONE|JOURNAL OF NEW MUSIC RESEARCH|IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING|FRONTIERS IN PSYCHOLOGY|Frontiers in Psychology')] &lt;- 'Psychology' # Class name from Elements of Stat..\"\n\n#table(metaMER_results$journal_type)\n\n\n\n\n\nprint(knitr::kable(table(metaMER_results$model_class_id)))\n\n\n\nVar1\nFreq\n\n\n\n\nFlexible Discriminants\n379\n\n\nKernel Smoothing, Additive and KNN\n114\n\n\nLinear Methods\n257\n\n\nNeural Nets\n384\n\n\nRandom Forests\n125\n\n\nUnclassified\n25\n\n\n\nprint(knitr::kable(table(metaMER_results$model_class_id,metaMER_results$model_category)))\n\n\n\n\nclassification\nregression\n\n\n\n\nFlexible Discriminants\n177\n202\n\n\nKernel Smoothing, Additive and KNN\n18\n96\n\n\nLinear Methods\n71\n186\n\n\nNeural Nets\n270\n114\n\n\nRandom Forests\n79\n46\n\n\nUnclassified\n25\n0\n\n\n\ncat(paste(\"We have\", nrow(metaMER_results), \"observations\"))\nWe have 1284 observations\ncat(paste(\"\\nWe have\", length(unique(metaMER_results$citekey)), \"studies\"))\nWe have 36 studies\ncat(paste(\"\\nWhere\", length(unique(metaMER_results$citekey[metaMER_results$model_category=='regression'])), \"are regression studies\"))\nWhere 22 are regression studies\ncat(paste(\"\\nWhere\", length(unique(metaMER_results$citekey[metaMER_results$model_category=='classification'])), \"are classification studies\"))\nWhere 14 are classification studies\n# note that we have some classification studies that also do regression and vice versa?\n# THIS IS CORRECT (updated 12 July 2024):\n# [1] \"We have 1238 observations\"\n# [1] \"We have 37 studies\"\n# [1] \"Where 23 are regression studies\"\n# [1] \"Where 14 are classification studies\"\n\n# Add a check for these properties ToDo\n2024-10-21: Update studies with multiple unique_ids due to multiple stats reported\n\nmetaMER_results &lt;- metaMER_results |&gt; \n  dplyr::filter(!(citekey == \"zhang2017fe\" & statistic == \"mean\"),\n         !(citekey == \"zhang2016br\" & statistic == \"mean\"),\n         !(citekey == \"zhang2016br\" & is.na(values)),\n         !(citekey == \"coutinho2017sh\" & statistic == \"ccc\"),\n         # Include only results for energy arousal\n         !(citekey == \"wang2022cr\" & dimension == \"tension arousal\"),\n         !(citekey == \"wang2021ac\" & dimension == \"tension arousal\"),\n         !(citekey == \"deng2015em\" & dimension == \"resonance\"))\n\nDeal with repeated experiment IDs in hu2017cr\n\n# get citation keys (all currently say experiment 1)\nhu2017models &lt;- metaMER_results[str_detect(metaMER_results$citekey, \n                                           \"hu2017cr\"),]$unique_id\n\n# replace the last digit with 1:4 (representing each experiment)\nhu2017models_replacement &lt;- paste0(\nsubstr(hu2017models, \n       1, \n       nchar(hu2017models) - 1),\n1:4\n)\n\n# overwrite original values\nmetaMER_results[metaMER_results$unique_id %in% \n                  hu2017models,]$unique_id &lt;- hu2017models_replacement"
  },
  {
    "objectID": "analysis/preprocessing.html#read-annotated-data",
    "href": "analysis/preprocessing.html#read-annotated-data",
    "title": "Preprocessing",
    "section": "",
    "text": "require(here)\nsource(here::here('R/build-df.R'))\nsource(here::here('R/format-study-results.R'))\nsource(here::here('R/parse-model-output.R'))\n\n\nlibrary(stringr) \n# get metaMER df:\nmeta_df &lt;- get_metaMER_df(path_2_studies = here::here('studies'))\n\n# get included studies\nincluded_studies &lt;- meta_df[which(\n  !stringr::str_detect(meta_df$final_notes, '!EXCL!')),] |&gt; \n  dplyr::tibble()\n\n\n\n\n# get studies re-coded (currently identifiable by presence of bind_field.)\nrecoded_studies &lt;- included_studies[which(stringr::str_detect(\n  included_studies$model_rate_emotion_values,\n                                     'bind_field')),] \n\n\n\n\n\nmetaMER_results &lt;-\ndo.call(\n  rbind,\n    lapply(1:nrow(recoded_studies),\n       function(x) get_study_results(recoded_studies[x,])\n       )\n) \n\n# add unique identifiers\n\nunique_id &lt;- apply(metaMER_results[,c('citekey',\n                        'library_id',\n                         'model_id',\n                         'feature_id',\n                         'data_id',\n                         'experiment_id')],\n                      1, \n                      paste0, \n                      collapse = '-'\n) \nmetaMER_results$unique_id &lt;- stringr::str_remove_all(unique_id, \n                                                     ' ')\n\nmetaMER_results &lt;- metaMER_results |&gt; dplyr::select(unique_id, \n                                 dplyr::everything()) \n\nmetaMER_results |&gt; dplyr::tibble()\n\n# A tibble: 1,284 × 19\n   unique_id  citekey journal stimulus_genre model_category stimulus_n feature_n\n   &lt;chr&gt;      &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;          &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt;    \n 1 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 2 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 3 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 4 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 5 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 6 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 7 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 8 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 9 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n10 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n# ℹ 1,274 more rows\n# ℹ 12 more variables: participant_n &lt;chr&gt;, feature_source &lt;chr&gt;,\n#   feature_reduction_method &lt;chr&gt;, library_id &lt;chr&gt;, model_id &lt;chr&gt;,\n#   feature_id &lt;chr&gt;, data_id &lt;chr&gt;, experiment_id &lt;chr&gt;, dimension &lt;chr&gt;,\n#   measure &lt;chr&gt;, statistic &lt;chr&gt;, values &lt;dbl&gt;\n\n\n\n\n\nprint(knitr::kable(table(metaMER_results$citekey,metaMER_results$dimension)))\nprint(knitr::kable(table(metaMER_results$citekey,metaMER_results$model_id)))\nprint(knitr::kable(table(metaMER_results$citekey,metaMER_results$feature_id)))\nprint(knitr::kable(table(metaMER_results$citekey,metaMER_results$data_id)))\n\n\n\n\n\n\n\n# Classify techniques according Hastie, Tibshirani, Friedman (2008)\n# https://www.sas.upenn.edu/~fdiebold/NoHesitations/BookAdvanced.pdf\n#\nlibrary(stringr)\nmetaMER_results$model_id &lt;- tolower(metaMER_results$model_id)\nmetaMER_results$model_class_id &lt;- 'Unclassified'\nmetaMER_results$model_class_id[str_detect(metaMER_results$model_id,'lr|lm|pls|mlr|pcr|logistic regression|2d model full|pentagon|gaussian process regression|sparse bayesian regression|variational bayesian regression|logistic regression|lda|rda|regularized discriminant analysis|reguliarized discriminant analysis')] &lt;- 'Linear Methods' # Class name from Elements of Stat..\"\n#metaMER_results$model_class_id[str_detect(metaMER_results$model_id,'logistic regression|lda|rda|regularized discriminant analysis|reguliarized discriminant analysis')] &lt;- 'Linear Classification'\n#metaMER_results$model_class_id[str_detect(metaMER_results$model_id,'mars|gam')]&lt;-'Additive Trees and Related Methods' #\nmetaMER_results$model_class_id[str_detect(metaMER_results$model_id,'rbf|gmm|local|polynomial|polygonal|knn|mars|gam')]&lt;-'Kernel Smoothing, Additive and KNN'\n#metaMER_results$model_class_id[str_detect(metaMER_results$model_id,'adaboost|gradient')]&lt;-'Boosting'\nmetaMER_results$model_class_id[str_detect(metaMER_results$model_id,'nn|gru|lstm|ltsm|long short term memory|rprop|mcan')]&lt;-'Neural Nets'\nmetaMER_results$model_class_id[str_detect(metaMER_results$model_id,'svm|svr|support vector regression|smoreg|smo ')]&lt;-'Flexible Discriminants'\n#metaMER_results$model_class_id[str_detect(metaMER_results$model_id,'knn')]&lt;-'Prototype methods'\nmetaMER_results$model_class_id[str_detect(metaMER_results$model_id,'rf|extremely randomized tree regression|random forest|adaboost|gradient')]&lt;-'Random Forests'\n#metaMER_results$model_class_id[str_detect(metaMER_results$model_id,'rf')]&lt;-'Ensemble Learning'\n\n\n\n\n\nmetaMER_results$stimulus_genre_mixed &lt;- 'SingleGenre'\nmetaMER_results$stimulus_genre_mixed[str_detect(metaMER_results$stimulus_genre,',|multi')] &lt;- 'MultiGenre' # Class name from Elements of Stat..\"\n#table(metaMER_results$stimulus_genre_mixed)\n\n\n\n\n\nmetaMER_results$journal_type &lt;- \"Engineering\"\nmetaMER_results$journal_type[str_detect(metaMER_results$journal,'Quarterly Journal of Experimental Psychology|PSYCHOLOGY OF MUSIC|PLOS ONE|JOURNAL OF NEW MUSIC RESEARCH|IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING|FRONTIERS IN PSYCHOLOGY|Frontiers in Psychology')] &lt;- 'Psychology' # Class name from Elements of Stat..\"\n\n#table(metaMER_results$journal_type)"
  },
  {
    "objectID": "analysis/preprocessing.html#summarise-all",
    "href": "analysis/preprocessing.html#summarise-all",
    "title": "Preprocessing",
    "section": "",
    "text": "print(knitr::kable(table(metaMER_results$model_class_id)))\n\n\n\nVar1\nFreq\n\n\n\n\nFlexible Discriminants\n379\n\n\nKernel Smoothing, Additive and KNN\n114\n\n\nLinear Methods\n257\n\n\nNeural Nets\n384\n\n\nRandom Forests\n125\n\n\nUnclassified\n25\n\n\n\nprint(knitr::kable(table(metaMER_results$model_class_id,metaMER_results$model_category)))\n\n\n\n\nclassification\nregression\n\n\n\n\nFlexible Discriminants\n177\n202\n\n\nKernel Smoothing, Additive and KNN\n18\n96\n\n\nLinear Methods\n71\n186\n\n\nNeural Nets\n270\n114\n\n\nRandom Forests\n79\n46\n\n\nUnclassified\n25\n0\n\n\n\ncat(paste(\"We have\", nrow(metaMER_results), \"observations\"))\nWe have 1284 observations\ncat(paste(\"\\nWe have\", length(unique(metaMER_results$citekey)), \"studies\"))\nWe have 36 studies\ncat(paste(\"\\nWhere\", length(unique(metaMER_results$citekey[metaMER_results$model_category=='regression'])), \"are regression studies\"))\nWhere 22 are regression studies\ncat(paste(\"\\nWhere\", length(unique(metaMER_results$citekey[metaMER_results$model_category=='classification'])), \"are classification studies\"))\nWhere 14 are classification studies\n# note that we have some classification studies that also do regression and vice versa?\n# THIS IS CORRECT (updated 12 July 2024):\n# [1] \"We have 1238 observations\"\n# [1] \"We have 37 studies\"\n# [1] \"Where 23 are regression studies\"\n# [1] \"Where 14 are classification studies\"\n\n# Add a check for these properties ToDo\n2024-10-21: Update studies with multiple unique_ids due to multiple stats reported\n\nmetaMER_results &lt;- metaMER_results |&gt; \n  dplyr::filter(!(citekey == \"zhang2017fe\" & statistic == \"mean\"),\n         !(citekey == \"zhang2016br\" & statistic == \"mean\"),\n         !(citekey == \"zhang2016br\" & is.na(values)),\n         !(citekey == \"coutinho2017sh\" & statistic == \"ccc\"),\n         # Include only results for energy arousal\n         !(citekey == \"wang2022cr\" & dimension == \"tension arousal\"),\n         !(citekey == \"wang2021ac\" & dimension == \"tension arousal\"),\n         !(citekey == \"deng2015em\" & dimension == \"resonance\"))\n\nDeal with repeated experiment IDs in hu2017cr\n\n# get citation keys (all currently say experiment 1)\nhu2017models &lt;- metaMER_results[str_detect(metaMER_results$citekey, \n                                           \"hu2017cr\"),]$unique_id\n\n# replace the last digit with 1:4 (representing each experiment)\nhu2017models_replacement &lt;- paste0(\nsubstr(hu2017models, \n       1, \n       nchar(hu2017models) - 1),\n1:4\n)\n\n# overwrite original values\nmetaMER_results[metaMER_results$unique_id %in% \n                  hu2017models,]$unique_id &lt;- hu2017models_replacement"
  },
  {
    "objectID": "analysis/preprocessing.html#homogenise-the-outcome-variable-names-to-valence-and-arousal",
    "href": "analysis/preprocessing.html#homogenise-the-outcome-variable-names-to-valence-and-arousal",
    "title": "Preprocessing",
    "section": "Homogenise the outcome variable names to valence and arousal",
    "text": "Homogenise the outcome variable names to valence and arousal\n\nR_studies$dimension[str_detect(R_studies$dimension,'activation|energy arousal|tension arousal')]&lt;-'arousal' # note: there is no longer \"tension arousal\" based on decision to include only energy\nR_studies$dimension[str_detect(R_studies$dimension,'pleasantness')]&lt;-'valence'\nR_studies &lt;- dplyr::filter(R_studies,!str_detect(dimension,'av|resonance')) # relates to distances, can be omitted\n\ntable(R_studies$dimension)  \n\n\narousal valence \n    162     162 \n\n#table(R_studies$stimulus_n)  \n\n# Deal with four studies involving multiple datasets: \n\nR_studies$stimulus_n[R_studies$stimulus_n==\" emoMusic: 744, soundtracks: 360, chinese: 500 \"] &lt;- 938 # resolved from the paper\nR_studies$stimulus_n[R_studies$stimulus_n==\" 2372 (subset of PSIC3839, total n: 3839)    \"] &lt;- 2372 # resolved\nR_studies$stimulus_n[R_studies$stimulus_n==\" study 1: 20; study 2: 40) % three outliers  \"] &lt;- 40 # decided to take this from validation\nR_studies$stimulus_n[R_studies$stimulus_n==\" study 1: 100; study 2: 20\"] &lt;- 20 #\n\nR_studies$stimulus_n[R_studies$stimulus_n==\" DEAM: 744, PMEmo: 206  \"] &lt;- 744 # we have encoded this based on stronger results on DEAM compared to PMEmo.\n\nR_studies$stimulus_n[R_studies$stimulus_n==\" NTUMIR: 60, MediaEval2013: 744  \"] &lt;- 60 # we have encoded this based on stronger results on NTUMIR compared to MediaEval\n\nR_studies$stimulus_n[R_studies$stimulus_n==\" 1020; MediaEval2014: 1000: music perception database 1: 6, music perception database 2: 9, music perception database 3: 8, music perception database 4: 7   \"] &lt;- 1020\n\n# REDO with a clearer function\neliminate &lt;- str_detect(R_studies$unique_id,\"hu2017cr\") & !str_detect(R_studies$unique_id,\"all\")\nR_studies &lt;- R_studies[!eliminate,]\nR_studies$stimulus_n[R_studies$stimulus_n==\" MER60: 60, CH818: 818, AMG1608: 1608  \"] &lt;- 60+818+1608 #\n\ntable(R_studies$stimulus_n)\n\n\n   146   1838     275     324      336     40      420     431      48     54   \n      8      10       6      74       2       2       2       4       4       4 \n   744    744    744       84        20    2372    2486      40     744     938 \n     30      30      18      12       4       2       8       4       4       8 \n\nR_studies$stimulus_n &lt;- as.numeric(R_studies$stimulus_n)\n\n\nClean feature N field\n\nR_studies$feature_n[R_studies$feature_n==\" 548; after reduction, 139 for PCA and 276 for ReliefF   \"] &lt;- 548\n\nR_studies$feature_n[str_detect(R_studies$feature_n,'pre_fitting')] &lt;- 21\nR_studies$feature_n[str_detect(R_studies$feature_n,'but 15 reported')]&lt;-15\nR_studies$feature_n[str_detect(R_studies$feature_n,'50 PCA features')]&lt;-50\nR_studies$feature_n[str_detect(R_studies$feature_n,'548 dimensions. Pos')]&lt;-548\nR_studies$feature_n[str_detect(R_studies$feature_n,'60 handcrafted and')]&lt;-60 # this should be 14400+60!\nR_studies$feature_n[str_detect(R_studies$feature_n,'before_selection = 45')]&lt;-45\nR_studies$feature_n[str_detect(R_studies$feature_n,'model 4 = 388')]&lt;-388\nR_studies$feature_n[str_detect(R_studies$feature_n,'6670 in MediaEval')]&lt;-6670\nR_studies$feature_n[str_detect(R_studies$feature_n,'557 before feature')]&lt;-557\nR_studies$feature_n[str_detect(R_studies$feature_n,'not specified')]&lt;-NA\nR_studies$feature_n&lt;-as.numeric(R_studies$feature_n)\n\nquantile(R_studies$feature_n,c(0.333,0.666),na.rm = TRUE)\n\n33.3% 66.6% \n   72   653 \n\nquantile(R_studies$feature_n,c(0.25,0.500,0.750),na.rm = TRUE)\n\n25% 50% 75% \n 50 548 653 \n\nquantile(R_studies$feature_n,c(0.1,0.500,0.90),na.rm = TRUE)\n\n10% 50% 90% \n 18 548 654 \n\nR_studies$feature_n_categories &lt;-cut(R_studies$feature_n,\n                                      breaks = c(0,18,260,\n                                                 10000),\n                                      labels = c(\"Feature n &lt; 18\",\"Feature n &gt; 18 & &lt; 260\",\"Feature n &gt; 260\"))"
  },
  {
    "objectID": "analysis/preprocessing.html#diagnostics",
    "href": "analysis/preprocessing.html#diagnostics",
    "title": "Preprocessing",
    "section": "Diagnostics",
    "text": "Diagnostics\n\nlibrary(ggplot2)\n\ng1&lt;-ggplot(R_studies,aes(x=values,fill=citekey,color=dimension))+\n  geom_histogram()+\n  facet_wrap(.~model_class_id)+\n#  scale_color_manual(values = c('black','white'))+\n  theme_dark()+\n  scale_x_continuous(breaks = seq(0,1,by=.1))\n\ng1\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "analysis/preprocessing.html#select-a-summary-measure-for-valence-and-arousal-separately",
    "href": "analysis/preprocessing.html#select-a-summary-measure-for-valence-and-arousal-separately",
    "title": "Preprocessing",
    "section": "Select a summary measure for valence and arousal separately",
    "text": "Select a summary measure for valence and arousal separately\nNote: Before adding feature_n to the summary, they need to be cleaned!\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nR_studies$citekey &lt;- factor(R_studies$citekey)\nR_studies$dimension &lt;- factor(R_studies$dimension)\n\nR_summary &lt;- summarise(group_by(R_studies,dimension,citekey),valuesMean=mean(values,na.rm=TRUE),valuesMedian=median(values,na.rm=TRUE),valuesMax=max(values,na.rm=TRUE),stimulus_n=first(stimulus_n),studyREF=first(studyREF),model_class_id=first(model_class_id),feature_n=first(feature_n),journal_type=first(journal_type),feature_n=first(feature_n),feature_n_categories=first(feature_n_categories),stimulus_genre_mixed=first(stimulus_genre_mixed),feature_n_complexity_genre=first(feature_n_complexity_genre))\n\n`summarise()` has grouped output by 'dimension'. You can override using the\n`.groups` argument."
  },
  {
    "objectID": "analysis/preprocessing.html#visualise-summary-on-two-dimensions",
    "href": "analysis/preprocessing.html#visualise-summary-on-two-dimensions",
    "title": "Preprocessing",
    "section": "Visualise Summary on two dimensions",
    "text": "Visualise Summary on two dimensions\nAdd variation from within the studies (alternative models)\n\nR_summary_split &lt;- pivot_wider(R_summary,id_cols = citekey, names_from = c(dimension), values_from = valuesMax)\n\ng2 &lt;- ggplot(R_summary_split,aes(x=valence,y=arousal,label=citekey))+\n  geom_label()+\n  theme_bw()+\n  scale_x_continuous(breaks = seq(0,1,by=.1))+\n  scale_y_continuous(breaks = seq(0,1,by=.1))\n\ng2\n\n\n\n\n\n\n\n## could be more informative when done with the full data\nR_studies$citekey&lt;-factor(R_studies$citekey)\nR_studies$dimension&lt;-factor(R_studies$dimension)\n\nR_studies_split &lt;- pivot_wider(R_studies,id_cols = c(unique_id,citekey,model_class_id), names_from = c(dimension), values_from = c(values),values_fn = mean)\nR_studies_split&lt;-drop_na(R_studies_split)\n\nlibrary(ggrepel)\n\ng3 &lt;- ggplot(R_studies_split,aes(x=valence,y=arousal,label=citekey,color=model_class_id,fill=model_class_id))+\n  geom_point(size=4)+\n  geom_label_repel(size=3, max.overlaps=50,show.legend = T,color='white')+\n  scale_x_continuous(breaks = seq(0,1,by=.25),limits = c(0,1))+\n  scale_y_continuous(breaks = seq(0,1,by=.25),limits = c(0,1))+\n  theme_bw()\ng3\n\nWarning: ggrepel: 82 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps"
  },
  {
    "objectID": "analysis/preprocessing.html#plot-success-across-the-years",
    "href": "analysis/preprocessing.html#plot-success-across-the-years",
    "title": "Preprocessing",
    "section": "Plot success across the years",
    "text": "Plot success across the years\n\n# Add year!\nR_studies$year &lt;- as.numeric(str_match(R_studies$citekey,'[0-9]+'))\n\ng3 &lt;- ggplot(R_studies,aes(x=year,y=values,colour=model_class_id))+\n  geom_point(show.legend = T)+\n  facet_wrap(.~dimension)+\n  theme_bw()\ng3"
  },
  {
    "objectID": "analysis/preprocessing.html#simple-model-complexity-metric",
    "href": "analysis/preprocessing.html#simple-model-complexity-metric",
    "title": "Preprocessing",
    "section": "Simple model complexity metric",
    "text": "Simple model complexity metric\nRatio of obs./features or just a classification based on feature n (quantiles).\n\nR_studies$feature_n[R_studies$feature_n==\" 15; 23 in table, but 15 reported  \"] &lt;- 15 #resolved from the paper\n\nR_studies$feature_n[R_studies$feature_n==\" 15; 23 in table, but 15 reported  \"] &lt;- 15 #resolved\nR_studies$feature_n[R_studies$feature_n==\" before_selection = 45, after_selection = 6  \"] &lt;- 45 #resolved\nR_studies$feature_n[R_studies$feature_n==\" model 1: 52, model 2 = 68, model 3 = 260, model 4 = 388 \"] &lt;- 388 #resolved\nR_studies$feature_n[R_studies$feature_n==\" variable, 557 before feature selection \"] &lt;- 557 #resolved\n\nR_studies$feature_n[R_studies$feature_n==\" 50 PCA features \"] &lt;- 499 #resolved\n\nR_studies$feature_n[str_detect(R_studies$feature_n,'150 PCA features')] &lt;- 3000\nR_studies$feature_n[str_detect(R_studies$feature_n,'pre_fitting = 21')] &lt;- 21\nR_studies$feature_n[str_detect(R_studies$feature_n,'548 dimensions')] &lt;- 548\nR_studies$feature_n[str_detect(R_studies$feature_n,'548; after reduct')] &lt;- 548\nR_studies$feature_n[str_detect(R_studies$feature_n,'60 handcrafted and filter bank')] &lt;- 3600\nR_studies$feature_n[str_detect(R_studies$feature_n,'Features deep-learned from audio (not specified) but 1802 in DEAM')] &lt;- 260\n\n# 2024-10-21: I changed the encoding for this one to \"150 PCA features\", so updated above.\n# R_studies$feature_n[str_detect(R_studies$feature_n,'not specified')] &lt;- 3000 # under-estimation based openSmile features and the paper arguing that they have 15 stat moments\n  \nR_studies$feature_n&lt;-as.numeric(R_studies$feature_n)\n\nprint(quantile(R_studies$feature_n,c(0.333,0.666),na.rm = T))\n\n33.3% 66.6% \n   72   653 \n\n#quantile(R_studies$feature_n,c(0.25,0.50,0.75),na.rm = T)\n\n# Assign\nR_studies$feature_n_complexity &lt;- cut(R_studies$feature_n,\n                                      breaks = c(0,\n                                                 as.numeric(quantile(R_studies$feature_n,c(0.333),na.rm = T)),\n                                                 as.numeric(quantile(R_studies$feature_n,c(0.666),na.rm = T)),\n                                                 10000),\n                                      labels = c(\"Feature n &lt; 236\",\"Feature n &gt; 236 & &lt; 653\",\"Feature n &gt; 653\"))\n\n\nR_studies$feature_n_complexity &lt;- cut(R_studies$feature_n,\n                                      breaks = c(0,30,300,10000),\n                                      labels = c(\"Feature n &lt; 30\",\"Feature n &gt; 30 & &lt; 300\",\"Feature n &gt; 300\"))\n\n\n\ntable(R_studies$feature_n_complexity)\n\n\n        Feature n &lt; 30 Feature n &gt; 30 & &lt; 300        Feature n &gt; 300 \n                    40                     54                    142"
  },
  {
    "objectID": "analysis/preprocessing.html#explore-feature_n_complexity-and-model-success",
    "href": "analysis/preprocessing.html#explore-feature_n_complexity-and-model-success",
    "title": "Preprocessing",
    "section": "Explore feature_n_complexity and model success",
    "text": "Explore feature_n_complexity and model success\nNeeds to be done from the unsummarised data (R_studies).\n\n#tmp &lt;- drop_na(R_studies)\ntmp &lt;- R_studies[!is.na(R_studies$values),]\n\nlibrary(ggdist)\n\ntmp$dimension&lt;-str_to_title(tmp$dimension)\ntmp$model_class_id&lt;-factor(tmp$model_class_id,\n                           levels = c(\"Neural Nets\",\"Flexible Discriminants\", \"Kernel Smoothing, Additive and KNN\", \"Random Forests\",\"Linear Methods\"),\n                           labels = c(\"Neural\\nNets\",\"Flexible\\nDiscriminants\", \"KS\\n & KNN\", \"Random\\nForests\", \"Linear\\nMethods\"))\n\ng &lt;- ggplot(tmp,aes(x=model_class_id,y=values,color=citekey,label=citekey,shape=stimulus_genre_mixed))+\n  stat_halfeye(aes(fill=citekey),point_interval=\"mean_qi\", trim=FALSE, expand=FALSE, show.legend = FALSE,adjust = 1.25, density=\"bounded\", point_size=3,scale = 1,alpha=0.5) + \n  geom_point(alpha=0.5,show.legend = F,position = position_jitter(width = .3))+\n  #geom_label_repel(size=2,max.overlaps = 50)+\n  facet_wrap(dimension~feature_n_complexity)+\n  ylab(\"Correlation Coefficient\")+\n  xlab(\"Model Technique\")+\n  scale_y_continuous(limits = c(0,1),expand = c(0.01,0.01))+\n  geom_text_repel(aes(x = model_class_id, y = values, label = studyREF),\n             stat = \"summary\", fun = mean,show.legend = F)+\n  theme_bw()\ng\n\nWarning: Removed 55 rows containing missing values or values outside the scale range\n(`geom_slabinterval()`).\n\n\nWarning: Removed 124 rows containing missing values or values outside the scale range\n(`geom_slabinterval()`).\n\n\nWarning: Removed 61 rows containing missing values or values outside the scale range\n(`geom_slabinterval()`).\n\n\nWarning: Removed 43 rows containing missing values or values outside the scale range\n(`geom_slabinterval()`).\n\n\nWarning: ggrepel: 2 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps\n\n\nWarning: ggrepel: 15 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps\n\n\nWarning: ggrepel: 9 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps\n\n\n\n\n\n\n\n\n#ggsave(filename = 'FeatureN_regression.pdf',g,height = 7,width = 11)"
  },
  {
    "objectID": "analysis/preprocessing.html#create-descriptive-table-for-the-manuscript",
    "href": "analysis/preprocessing.html#create-descriptive-table-for-the-manuscript",
    "title": "Preprocessing",
    "section": "Create descriptive table for the manuscript",
    "text": "Create descriptive table for the manuscript\n\nTR &lt;- NULL\nTR$study_n &lt;- length(unique(R_studies$citekey))\nTR$model_n &lt;- nrow(R_studies)\nt&lt;-table(R_studies$model_class_id)\nt2 &lt;- paste0(names(t),': ', as.numeric(t))\nTR$model_types_n &lt;- str_c(t2,collapse = \"\\n\")\nTR$feature_Desc &lt;- paste0('Min=',min(R_studies$feature_n,na.rm = TRUE),', Md=',median(R_studies$feature_n,na.rm = TRUE),', Max=', max(R_studies$feature_n,na.rm = TRUE))\nTR$stimulus_Desc &lt;- paste0('Min=',min(R_studies$stimulus_n,na.rm = TRUE),', Md=',median(R_studies$stimulus_n,na.rm = TRUE),', Max=', max(R_studies$stimulus_n,na.rm = TRUE))\nprint(TR)\n\n$study_n\n[1] 23\n\n$model_n\n[1] 236\n\n$model_types_n\n[1] \"Flexible Discriminants: 58\\nKernel Smoothing, Additive and KNN: 24\\nLinear Methods: 62\\nNeural Nets: 70\\nRandom Forests: 22\"\n\n$feature_Desc\n[1] \"Min=3, Md=548, Max=6670\"\n\n$stimulus_Desc\n[1] \"Min=20, Md=330, Max=2486\""
  },
  {
    "objectID": "analysis/preprocessing.html#export-as-csv",
    "href": "analysis/preprocessing.html#export-as-csv",
    "title": "Preprocessing",
    "section": "Export as csv",
    "text": "Export as csv\n\nwrite.csv(x = R_studies,file = 'R_studies.csv')\nwrite.csv(x = R_summary,file = 'R_summary.csv')"
  },
  {
    "objectID": "analysis/preprocessing.html#homogenise-the-stimulus-n",
    "href": "analysis/preprocessing.html#homogenise-the-stimulus-n",
    "title": "Preprocessing",
    "section": "Homogenise the stimulus N",
    "text": "Homogenise the stimulus N\n\ntable(C_studies$stimulus_n)  \n\n\n                                                                                                                    387   \n                                                                                                                       16 \n                                                                                                                    124   \n                                                                                                                        8 \n                                                                                                                    171   \n                                                                                                                       48 \n                                                                                                                    1802  \n                                                                                                                        4 \n                                                                                                                    300   \n                                                                                                                        2 \n                                             429; 350 popular songs + 79 songs from the Beatles (Mirex 2009 collection)   \n                                                                                                                        2 \n 5192; 12 per user in user validation (not included here due to little information),   AcousticBrainz validation: 60000   \n                                                                                                                        2 \n                                                                                                                     744  \n                                                                                                                       15 \n                                                                                                                    744   \n                                                                                                                        2 \n                                                                                                                    900   \n                                                                                                                        1 \n                                                                                                                    956   \n                                                                                                                        4 \n                                                                              ISMIR2012: 2886, NJU_V1: 777, Hindi: 1037   \n                                                                                                                        9 \n                                                                   total: 564; unambiguous: 416, circular validation: 39  \n                                                                                                                        6 \n\n# Deal with four studies involving multiple datasets: \nC_studies$stimulus_n[C_studies$stimulus_n==\" 429; 350 popular songs + 79 songs from the Beatles (Mirex 2009 collection)  \"] &lt;- 429 # resolved from the paper\nC_studies$stimulus_n[C_studies$stimulus_n==\" 5192; 12 per user in user validation (not included here due to little information),   AcousticBrainz validation: 60000  \"] &lt;- 5192 # resolved\nC_studies$stimulus_n[C_studies$stimulus_n==\" ISMIR2012: 2886, NJU_V1: 777, Hindi: 1037  \"] &lt;- 2886+777+1037 # decided to take this from validation\nC_studies$stimulus_n[C_studies$stimulus_n==\" total: 564; unambiguous: 416, circular validation: 39 \"] &lt;- 564 # \n#table(C_studies$stimulus_n)\nC_studies$stimulus_n &lt;- as.numeric(C_studies$stimulus_n)"
  },
  {
    "objectID": "analysis/preprocessing.html#diagnostics-1",
    "href": "analysis/preprocessing.html#diagnostics-1",
    "title": "Preprocessing",
    "section": "Diagnostics",
    "text": "Diagnostics\n\nlibrary(ggplot2)\n\ng1&lt;-ggplot(C_studies,aes(x=values,fill=citekey))+\n  geom_histogram()+\n  facet_wrap(.~model_class_id)+\n  theme_dark()+\n  scale_x_continuous(breaks = seq(0,1,by=.1))\n\ng1"
  },
  {
    "objectID": "analysis/preprocessing.html#select-a-summary-measure-for-valence-and-arousal-separately-1",
    "href": "analysis/preprocessing.html#select-a-summary-measure-for-valence-and-arousal-separately-1",
    "title": "Preprocessing",
    "section": "Select a summary measure for valence and arousal separately",
    "text": "Select a summary measure for valence and arousal separately\n\nlibrary(tidyverse)\nC_studies$citekey &lt;- factor(C_studies$citekey)\n\nC_summary &lt;- summarise(group_by(C_studies,citekey),valuesMean=mean(values,na.rm=TRUE),valuesMedian=median(values,na.rm=TRUE),valuesMax=max(values,na.rm=TRUE),stimulus_n=first(stimulus_n),studyREF=first(studyREF),model_class_id=first(model_class_id), stimulus_genre_mixed=first(stimulus_genre_mixed),journal_type = first(journal_type))"
  },
  {
    "objectID": "analysis/preprocessing.html#visualise-summary",
    "href": "analysis/preprocessing.html#visualise-summary",
    "title": "Preprocessing",
    "section": "Visualise Summary",
    "text": "Visualise Summary\n\ng2 &lt;- ggplot(C_summary,aes(x=stimulus_n,y=valuesMax,label=citekey,color=stimulus_genre_mixed))+\n  geom_point()+\n  geom_label_repel(size=1.5)+\n#  coord_flip()+\n  theme_bw()\ng2\n\n\n\n\n\n\n\ng3 &lt;- ggplot(C_summary,aes(x=stimulus_n,y=valuesMax,label=citekey,color=model_class_id))+\n  geom_point()+\n  geom_label_repel(size=1.2)+\n#  coord_flip()+\n  theme_bw()\ng3\n\n\n\n\n\n\n\n## could be more informative when done with the full data\nC_studies$citekey&lt;-factor(C_studies$citekey)\n\nlibrary(ggrepel)\n\ng4 &lt;- ggplot(C_studies,aes(x=stimulus_n,y=values,label=citekey,color=model_class_id,fill=model_class_id))+\n  geom_point(size=4)+\n  geom_label_repel(size=1.2, max.overlaps=50,show.legend = T,color='white')+\n#  scale_x_continuous(breaks = seq(0,1,by=.25),limits = c(0,1))+\n#  scale_y_continuous(breaks = seq(0,1,by=.25),limits = c(0,1))+\n  theme_bw()\ng4\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_label_repel()`).\n\n\nWarning: ggrepel: 19 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps"
  },
  {
    "objectID": "analysis/preprocessing.html#simple-model-complexity-metric-based-on-feature_n",
    "href": "analysis/preprocessing.html#simple-model-complexity-metric-based-on-feature_n",
    "title": "Preprocessing",
    "section": "Simple model complexity metric based on feature_n",
    "text": "Simple model complexity metric based on feature_n\n\ntable(C_studies$feature_n)\n\n\n 'eight different non‐text‐dependent features are employed; they are rhythm, timbre,intensity, chromagram, MFCC, OSC, SSDs, and DWCH'  \n                                                                                                                                     9 \n                                                                                                                                 119   \n                                                                                                                                    32 \n                                                                                                                                 122   \n                                                                                                                                     4 \n                                                                                                                    126, retained 97   \n                                                                                                                                     6 \n                                                                                           1702; best model uses 100 after reduction   \n                                                                                                                                     1 \n                                                                                                                                  231  \n                                                                                                                                     4 \n                                                                                                                                    3  \n                                                                                                                                     2 \n                                                                                                                                 397   \n                                                                                                                                     2 \n                                                                            548 dimensions. Post-reduction: 139 (PCA), 276 (ReliefF)   \n                                                                                                                                     2 \n                                                                              548; after reduction, 139 for PCA and 276 for ReliefF    \n                                                                                                                                    15 \n                                                                                       8; 3 after shrinkage-method feature selection   \n                                                                                                                                    16 \n                                                                                                                               8904    \n                                                                                                                                     8 \n                                                                                                                    between 9 and 10   \n                                                                                                                                     2 \n                                                                  summarize feature categories, but aren't explicit about which ones   \n                                                                                                                                    16 \n\nC_studies$feature_n[str_detect(C_studies$feature_n,'eight different ')]&lt;-600 # arbitrary!\nC_studies$feature_n[str_detect(C_studies$feature_n,'126, retained 97')]&lt;-126 \nC_studies$feature_n[str_detect(C_studies$feature_n,'1702; best model uses 100 after reduction')]&lt;-1702 #  arbitrary!\nC_studies$feature_n[str_detect(C_studies$feature_n,'548; after reduction, ')] &lt;- 548 \nC_studies$feature_n[str_detect(C_studies$feature_n,'548 dimensions')] &lt;- 548 \nC_studies$feature_n[str_detect(C_studies$feature_n,'548. Post-reduction')] &lt;- 548 \nC_studies$feature_n[str_detect(C_studies$feature_n,'8; 3 after')]&lt;-8 \nC_studies$feature_n[str_detect(C_studies$feature_n,'between 9 and 10')]&lt;-10 \nC_studies$feature_n[str_detect(C_studies$feature_n,'summarize feature')]&lt;-600 # arbitrary\ntable(C_studies$feature_n)\n\n\n   119      122       231        3     397    8904          10      126 \n      32        4        4        2        2        8        2        6 \n    1702      548      600        8 \n       1       17       25       16 \n\nC_studies$feature_n &lt;- as.numeric(C_studies$feature_n)\n\nggplot(C_studies,aes(x=feature_n))+geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n#print(quantile(C_studies$feature_n,c(0.333,0.666),na.rm = TRUE))\n#quantile(R_studies$feature_n,c(0.25,0.50,0.75),na.rm = T)\n\n# Assign\nC_studies$feature_n_complexity &lt;- cut(C_studies$feature_n,\n                                      breaks = c(0,30,300,\n                                                 10000),\n                                      labels = c(\"Feature n &lt; 30\",\"Feature n &gt; 30 & &lt; 300\",\"Feature n &gt; 300\"))\ntable(C_studies$feature_n_complexity)\n\n\n        Feature n &lt; 30 Feature n &gt; 30 & &lt; 300        Feature n &gt; 300 \n                    20                     46                     53"
  },
  {
    "objectID": "analysis/preprocessing.html#explore-feature_n_complexity-and-model-success-1",
    "href": "analysis/preprocessing.html#explore-feature_n_complexity-and-model-success-1",
    "title": "Preprocessing",
    "section": "Explore feature_n_complexity and model success",
    "text": "Explore feature_n_complexity and model success\nNeeds to be done from the unsummarised data (C_studies).\n\ntmp &lt;- drop_na(C_studies)\nlibrary(ggdist)\n\ntmp$dimension&lt;-str_to_title(tmp$dimension)\ntmp$model_class_id&lt;-factor(tmp$model_class_id,\n                           levels = c(\"Neural Nets\",\"Flexible Discriminants\", \"Kernel Smoothing, Additive and KNN\", \"Random Forests\",\"Linear Methods\"),\n                           labels = c(\"Neural\\nNets\",\"Flexible\\nDiscriminants\", \"KS\\n & KNN\", \"Random\\nForests\", \"Linear\\nMethods\"))\n\ng &lt;- ggplot(tmp,aes(x=model_class_id,y=values,color=citekey,label=citekey,shape=stimulus_genre_mixed))+\n  stat_halfeye(aes(fill=citekey),point_interval=\"mean_qi\", trim=FALSE, expand=FALSE, show.legend = FALSE,adjust = 1.25, density=\"bounded\", point_size=3,scale = 1,alpha=0.5) + \n  geom_point(alpha=0.5,show.legend = F,position = position_jitter(width = .3))+\n  #geom_label_repel(size=2,max.overlaps = 50)+\n  facet_wrap(.~feature_n_complexity)+\n  ylab(\"Correlation Coefficient\")+\n  xlab(\"Model Technique\")+\n  scale_y_continuous(limits = c(0,1),expand = c(0.01,0.01))+\n  geom_text_repel(aes(x = model_class_id, y = values, label = studyREF),\n             stat = \"summary\", fun = mean,show.legend = F)+\n  theme_bw()\nprint(g)\n\nWarning: Removed 116 rows containing missing values or values outside the scale range\n(`geom_slabinterval()`).\n\n\nWarning: Removed 87 rows containing missing values or values outside the scale range\n(`geom_slabinterval()`).\n\n\nWarning: Removed 34 rows containing missing values or values outside the scale range\n(`geom_slabinterval()`).\n\n\nWarning: ggrepel: 1 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps\n\n\n\n\n\n\n\n\n#ggsave(filename = 'FeatureN_regression.pdf',g,height = 7,width = 11)"
  },
  {
    "objectID": "analysis/preprocessing.html#create-descriptive-table-for-the-manuscript-1",
    "href": "analysis/preprocessing.html#create-descriptive-table-for-the-manuscript-1",
    "title": "Preprocessing",
    "section": "Create descriptive table for the manuscript",
    "text": "Create descriptive table for the manuscript\n\nTC &lt;- NULL\nTC$study_n &lt;- length(unique(C_studies$citekey))\nTC$model_n &lt;- nrow(C_studies)\nt&lt;-table(C_studies$model_class_id)\nt2 &lt;- paste0(names(t),': ', as.numeric(t))\nTC$model_types_n &lt;- str_c(t2,collapse = \"\\n\")\nTC$feature_Desc &lt;- paste0('Min=',min(C_studies$feature_n,na.rm = TRUE),', Md=',median(C_studies$feature_n,na.rm = TRUE),', Max=', max(C_studies$feature_n,na.rm = TRUE))\nTC$stimulus_Desc &lt;- paste0('Min=',min(C_studies$stimulus_n,na.rm = TRUE),', Md=',median(C_studies$stimulus_n,na.rm = TRUE),', Max=', max(C_studies$stimulus_n,na.rm = TRUE))\nprint(TC)\n\n$study_n\n[1] 14\n\n$model_n\n[1] 119\n\n$model_types_n\n[1] \"Flexible Discriminants: 37\\nKernel Smoothing, Additive and KNN: 8\\nLinear Methods: 17\\nNeural Nets: 29\\nRandom Forests: 15\\nUnclassified: 13\"\n\n$feature_Desc\n[1] \"Min=3, Md=126, Max=8904\"\n\n$stimulus_Desc\n[1] \"Min=124, Md=387, Max=5192\""
  },
  {
    "objectID": "analysis/preprocessing.html#export-as-csv-1",
    "href": "analysis/preprocessing.html#export-as-csv-1",
    "title": "Preprocessing",
    "section": "Export as csv",
    "text": "Export as csv\n\nwrite.csv(x = C_studies,file = 'C_studies.csv')\nwrite.csv(x = C_summary,file = 'C_summary.csv')"
  },
  {
    "objectID": "etc/Secondary Databases.html",
    "href": "etc/Secondary Databases.html",
    "title": "Secondary Databases",
    "section": "",
    "text": "Secondary Databases\n\n\n\nIndex\nDatabase\nStim. Type\nStim. Dur.\nStim. N\nFeature N.\nPpt. N\nPpt. Expertise\nPpt. Origin\nPpt. Sampling\nPpt. Task\nFeature Source\nFeature Categories\nCitation\n\n\n\n\n1\nEMOPIA\nPiano Solo (pop music)\n30 to 40\n387\n24 (average of 20 MFCC + note length, velocity, beat note density, key)\n4 total, 1 per song (annotators, not ppts)\nnot specified\nnot specified\npresumably researchers\nclassify\nMIDI Toolbox\nRhythm, Harmony, Timbre\nHung et al. (2021)\n\n\n2\nAMG1608\npop\n30\n1608\n72\n643 MTurk, 22 Taiwan subjects\nno restrictions\nMTurk\ncrowdsource\nrate\nMIRToolbox, YAAFE\nTimbre, tonal, spectral, temporal\nChen et al. (2015)\n\n\n3\nNTUMIR\nFamous pop songs\n25\n60\n46\n99 (40 annotations per clip)\nno restrictions\ncampus\nconvenience\nrate\nMIRToolbox, Sound Description Toolbox, MA Toolbox\nMelody/harmony, spectral, temporal, rhythmic, lyrics\nYang et al. (2011)*\n\n\n4\nDEAM\npop\n58 full-length and 1744 45-second excerpts\n1802\n261\nTotal n not specified. Minimum annotations per piece: 2013-14: 10; 2015: 5 MTurk workers\nno restrictions\n2013-14: MTurk; 2015: MTurk and Lab workers\ncrowdsourcing, convenience\nrate\nOpenSMILE\nPitch, Timbre, Voice, Dynamic. Many MFCC features\nAljanaki et al. (2017)\n\n\n5\nMediaEval2013/emoMusic/1000 songs\nwestern pop of various genres\n45\n744\n6670\nmin. 10 per clip (100 qualified workers in final HIT)\nNonexperts (Mturk) + experts\nMTurk\nCrowdsourcing, presumed convenience for experts\nrate\nOpenSMILE\nPitch, Timbre, Voice, Dynamic. Many MFCC features\nSoleymani et al. (2013)\n\n\n6\nSoundtracks\nobscure film soundtracks\n5\n110\nnone?\n116 university students\nnonmusicians\ncampus\nconvenience\nrate, classify\nNA\nNA\nEerola & Vuoskoski (2011)\n\n\n7\nPSIC3839\nChinese popular\nfull? 180 s excerpts extracted for analyses\n3839\nns. About 10 feature categories. Unclear dimensionaltiy\n87\nno restrictions\ncampus\nconvenience\nrate\nLibrosa\nPitch, Timbre, Harmony, Rhythm\nLiang et al. (2022)\n\n\n8\nCH818\nChinese pop\n30\n818\n15\n3\nexperts\nChina\nconvenience\nrate\nMIRToolbox, PsySound, ChromaToolbox,Tempogram Toolbox\nDynamic, Pitch, Rhythm, Timbre, Harmony\nHu & Yang (2017)\n\n\n9\nZhang, Huang, Yang, & Xu (2015)\nChinese pop\n30\n171\n84 (dimensionality)\n10\nNonexperts\nnot specified\nnot specified\nclassify\nMAToolbox, MIRToolbox, Coversongs\nDynamics, Timbre, Rhythm\nZhang et al. 2015\n\n\n10\nPMEmo\nchoruses of top pop songs\nvariable\n794\n65 (260 dims)\n457\n366 Chinese university students (44 music majors); 47 English speakers\ncampus\nconvenience\nrate\nComParE 2013 baseline feature set\nDynamic, Timbre, Pitch (tabulated as energy-related, spectral, voicing related)\nZhang et al. (2018)\n\n\n11\nNJU-V1\nMusic clips (limited detail)\nvariable\n777\nLyric (BoW; 50 dims before filtering), MFCC, spectral contrast, chromagram\nNA (lastfm tags)\nNA\nLastFM\ncrowdsource (webscraping)\nNA\nNA\nLyric, Timbre, Harmony\nXue et al. (2015)\n\n\n12\nISMIR-2012\npopular\n30 or 60\n2904\n54 (means + sds)\nNA (lastfm tags)\nNA\nLastFM\ncrowdsource (webscraping)\nNA\nMIRToolbox\nDynamics, Rhythm, Timbre (they call this Spectral), Harmony\nSong et al. 2012**\n\n\n\n* Dataset not available online\n** Only lyrics & timestamps included in public dataset\n\n\nReferences\n\nAljanaki, A., Yang, Y. H., & Soleymani, M. (2017). Developing a benchmark for emotional analysis of music. PloS one, 12(3), e0173392.\n\n\nChen, Y. A., Yang, Y. H., Wang, J. C., & Chen, H. (2015, April). The AMG1608 dataset for music emotion recognition. In 2015 IEEE international conference on acoustics, speech and signal processing (ICASSP) (pp. 693-697). IEEE.\n\n\nEerola, T. & Vuoskoski, J. K. (2011). A comparison of the discrete and dimensional models of emotion in music. Psychology of Music, 39(1), 18-49. https://doi.org/10.1177/0305735610362821\n\n\nHu, X., & Yang, Y. H. (2017). The mood of Chinese Pop music: Representation and recognition. Journal of the Association for Information Science and Technology, 68(8), 1899-1910.\n\n\nHung, H. T., Ching, J., Doh, S., Kim, N., Nam, J., & Yang, Y. H. (2021). EMOPIA: A multi-modal pop piano dataset for emotion recognition and emotion-based music generation. arXiv preprint arXiv:2108.01374.\n\n\nSoleymani, M., Caro, M. N., Schmidt, E. M., Sha, C. Y., & Yang, Y. H. (2013, October). 1000 songs for emotional analysis of music. In Proceedings of the 2nd ACM international workshop on Crowdsourcing for multimedia (pp. 1-6).\n\n\nXu, L., Yun, Z., Sun, Z., Wen, X., Qin, X., & Qian, X. (2022). PSIC3839: Predicting the Overall Emotion and Depth of Entire Songs. In Design Studies and Intelligence Engineering (pp. 1-9). IOS Press.\n\n\nXue, H., Xue, L., & Su, F. (2015). Multimodal music mood classification by fusion of audio and lyrics. In MultiMedia Modeling: 21st International Conference, MMM 2015, Sydney, NSW, Australia, January 5-7, 2015, Proceedings, Part II 21 (pp. 26-37). Springer International Publishing.\n\n\nZhang, J. L., Huang, X. L., Yang, L. F., Xu, Y., & Sun, S. T. (2017). Feature selection and feature learning in arousal dimension of music emotion by using shrinkage methods. Multimedia systems, 23, 251-264.\n\n\nZhang, K., Zhang, H., Li, S., Yang, C., & Sun, L. (2018, June). The PMEmo dataset for music emotion recognition. In Proceedings of the 2018 acm on international conference on multimedia retrieval (pp. 135-142).\n\n\nSong, Y., Dixon, S., & Pearce, M. T. (2012, October). Evaluation of musical features for emotion classification. In ISMIR (pp. 523-528).\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "preregistration/preregistration.html",
    "href": "preregistration/preregistration.html",
    "title": "metaMER",
    "section": "",
    "text": "This preregistration is made with preregr package from https://preregr.opens.science/ that implements the BMJ published guidance for meta-analysis protocols (Shamseer et al., 2015).\nMeta-analysis Pre-registration: Music Emotion Recognition\n\nSection: Metadata\n\n\n\nTitle\n\n\ntitle\n\n\n\nMusic emotion recognition: Meta-analysis of regression and classification success of emotion ratings from audio\n\n\n\n\n\nContributors\n\n\nauthors\n\n\n\nEerola, T., Anderson, C. J.\n\n\n\n\n\nSubjects\n\n\ntarget_discipline\n\n\n\nmusic cognition, music information retrieval, music psychology\n\n\n\n\n\nTasks and roles\n\n\ntasks_and_roles\n\n\n\nequal contribution\n\n\n\n\nSection: Review methods\n\n\n\nType of review\n\n\ntype_of_review\n\n\n\nMeta-analysis\n\n\n\n\n\nReview stages\n\n\nreview_stages\n\n\n\nSearch, Screening, Extraction, Synthesis\n\n\n\n\n\nCurrent review stage\n\n\ncurrent_stage\n\n\n\nScreening\n\n\n\n\n\nStart date\n\n\nstart_date\n\n\n\n2024-05-15 2024-05-15\n\n\n\n\n\nEnd date\n\n\nend_date\n\n\n\n2024-06-30\n\n\n\n\n\nBackground\n\n\nbackground\n\n\n\nThe aim is to establish the current state of the model success in predicting emotions expressed by music from audio. We will focus on the last 10 years of research and especially the research that has predicted valence and arousal ratings from music audio. No such analysis exists and there are interesting challenges in predicting emotional content of music that relates to specificity of the music and the type of emotions and features used that would benefit from a systematic analysis.\n\n\n\n\n\nPrimary research question(s)\n\n\nprimary_research_question\n\n\n\nTo what degree can arousal and valence ratings of emotions expressed by music be predicted from audio? How are the prediction rates related to genres of music, the type of models used, the type of features, modelling design and cross-validation utilised, and the model complexity and parsimony?\n\n\n\n\n\nSecondary research question(s)\n\n\nsecondary_research_question\n\n\n\nWhat is the prediction rate related to classification of quadrants in the affective circumplex?\n\n\n\n\n\nExpectations / hypotheses\n\n\nexpectations_hypotheses\n\n\n\nPrediction of arousal ratings is generally high and robust, and in terms of the model outcome metrics (correlation), achieves at least r = 0.77 (R square of 0.60). Prediction of valence ratings from audio is more challenging and more context dependent and will achieve generally a lower prediction rate, r = 0.63 (R square 0.40)\n\n\n\n\n\nDependent variable(s) / outcome(s) / main variables\n\n\ndvs_outcomes_main_vars\n\n\n\nRegression model performance will be converted to Pearson correlation coefficients and classification model performance will be converted to Matthews correlation coefficient (MCC) when possible.\n\n\n\n\n\nIndependent variable(s) / intervention(s) / treatment(s)\n\n\nivs_intervention_treatment\n\n\n\nMusic genre, prediction type (linear or classification), feature type (based on prior work by Panda et al., 2020), model complexity (high, medium, low), model validation (exists or not)\n\n\n\n\n\nAdditional variable(s) / covariate(s)\n\n\nadditional_variables\n\n\n\nUnspecified\n\n\n\n\n\nSoftware\n\n\nsoftware\n\n\n\nR and Github repository\n\n\n\n\n\nFunding\n\n\nfunding\n\n\n\nMitacs Globalink Research Award (Mitacs & British High Commission - Ottawa, Canada)\n\n\n\n\n\nConflicts of interest\n\n\ncois\n\n\n\nThere are no identified conflicts of interests.\n\n\n\n\n\nOverlapping authorships\n\n\noverlapping_authorships\n\n\n\nNot applicable\n\n\n\n\nSection: Search strategy\n\n\n\nDatabases\n\n\ndatabases\n\n\n\nWeb of Science, Scopus, and Open Alex\n\n\n\n\n\nInterfaces\n\n\ninterfaces\n\n\n\nWeb of Science, Scopus, and Open Alex\n\n\n\n\n\nGrey literature\n\n\ngrey_literature\n\n\n\nNot included\n\n\n\n\n\nInclusion and exclusion criteria\n\n\ninclusions_exclusion_criteria\n\n\n\nSample, Phenomenon of Interest, Design, Evaluation, Research type\n\n\n\n\n\nQuery strings\n\n\nquery_strings\n\n\n\nScopus: TITLE-ABS-KEY ( valence OR arousal OR classi OR categor OR algorithm AND music  AND emotion AND recognition ) AND PUBYEAR &gt; 2013 AND PUBYEAR &lt; 2025 AND  ( LIMIT-TO ( DOCTYPE , “ar” ) )  Web of science:  (DT=(Article) AND PY=(2014-2025)) AND ALL=(music emotion recognition valence arousal)  Open Alex:  https://openalex.org/works?page=1&filter=default.search%3Amusic%20emotion%20recognition%20valence%20arousal, type%3Atypes%2Farticle,publication_year%3A2014-2024, keywords.id%3Akeywords%2Femotion-recognition, keywords.id%3Akeywords%2Faffective-computing, language%3Alanguages%2Fen, open_access.any_repository_has_fulltext%3Atrue \n\n\n\n\n\nSearch validation procedure\n\n\nsearch_validation_procedure\n\n\n\nManual checking, separate keywords searches\n\n\n\n\n\nOther search strategies\n\n\nother_search_strategies\n\n\n\nNot applied\n\n\n\n\n\nProcedures to contact authors\n\n\nprocedure_for_contacting_authors\n\n\n\nUnspecified\n\n\n\n\n\nResults of contacting authors\n\n\nresults_of_contacting_authors\n\n\n\nNot carried out\n\n\n\n\n\nSearch expiration and repetition\n\n\nsearch_expiration_and_repetition\n\n\n\nSearches were done during the active search period in late May early June 2024 and no repetition is planned.\n\n\n\n\n\nSearch strategy justification\n\n\nsearch_strategy_justification\n\n\n\nThe three major databases should be able yield a robust picture of the topic\n\n\n\n\n\nMiscellaneous search strategy details\n\n\nmisc_search_strategy_details\n\n\n\nNo alternative searches were articulated or envisaged.\n\n\n\n\nSection: Screening\n\n\n\nScreening stages\n\n\nscreening_stages\n\n\n\nWe completed screening using custom fields inserted to the bibtex file and managed with citation managers (jabref and bibdesk). To filter relevant studies, we followed a three-stage screening procedure.  In stage 1, we screened the 553 studies’ titles for relevance, removing irrelevant studies and recording exclusion criteria (see Used exclusion criteria). CA assigned 63 studies to the High Priority based on titles’ relevance, assigned 338 studies to Low Priority based on irrelevant titles, and 152 studies to Medium Priority for additional screening. In stage 2, CA assessed the 152 Medium Priority studies for relevance by screening abstracts. 95 studies’ status changed to Low Priority, whereas 30 studies’ status changed to High Priority. 27 studies remained in the Medium priority category. TE and CA evaluated the remaining 27 studies’, moving 15 to the High Priority Category and 12 to the Medium Priority Category. For studies moved to Low Priority, brief BiBTex comments summarized the rationale for exclusion. In stage 3, TE and CA independently screened Priority 1 studies for relevance, including an include, exclude, or unsure decision in a user-comment BiBTeX field.\n\n\n\n\n\nScreened fields / masking\n\n\nscreened_fields_masking\n\n\n\nWe left authors, titles, publication years, and journal names unmasked.\n\n\n\n\n\nUsed exclusion criteria\n\n\nused_exclusion_criteria\n\n\n\nWe excluded studies according to the following exclusion criteria: soundscapes/vocalisations, non-music audio, video clips, physiological markers, dance, video/movie, physiological/EEG/ECG/MEG/GSR/brain imaging/heart rate/neuroscience/brain studies, sensor data, multimodal, autism, ageing, review/systematic review/overview/survey, face emotion recognition, mental health, music therapy, schizophrenia, memory/emotion factors as IVs, recommender systems, or systems that identify the location of emotional excerpts. We included results from some studies meeting exclusion criteria (e.g., multimodal studies involving physiological measurements) if they reported separately on acoustic-only models.\n\n\n\n\n\nScreener instructions\n\n\nscreener_instructions\n\n\n\nAs described above.\n\n\n\n\n\nScreening reliability\n\n\nscreening_reliability\n\n\n\nIn the pass 1 and 2, we included a quality control check after the pass to discuss the identified categories. In the third pass, we double-coded decisions, resolving discrepancies through discussion.\n\n\n\n\n\nScreening reconciliation procedure\n\n\nscreening_reconciliation_procedure\n\n\n\nWe reconcile discrepancies through discussion, resolving “unsure” votes first, followed by discrepancies in include/exclude decisions between authors Results of this updating procedure are available in the Pass 3 comparison document.\n\n\n\n\n\nSampling and sample size\n\n\nsampling_and_sample_size\n\n\n\nWe identified and retained 553 articles from Scopus, Web of Science, and Open Alex based on the search strategy outlined above. See table at the end that details the cumulative exclusions.\n\n\n\n\n\nScreening procedure justification\n\n\nscreening_procedure_justification\n\n\n\nTo offer a broad summary of music emotion recognition tasks, we attempted to include all studies involving prediction with acoustic features. We performed screening unblinded and determined inclusion/exclusion criteria based on studies’ relevance to the task explored.\n\n\n\n\n\nData management and sharing\n\n\nscreening_data_management_and_sharing\n\n\n\nSources will be shared as (a) BibTeX library(ies) including reviewer notes.\n\n\n\n\n\nMiscellaneous screening details\n\n\nmisc_screening_details\n\n\n\nUnspecified\n\n\n\n\nSection: Extraction\n\n\n\nEntities to extract\n\n\nentities_to_extract\n\n\n\nThese are listed and defined in extraction details.\n\n\n\n\n\nExtraction stages\n\n\nextraction_stages\n\n\n\nThe data extraction will be completed in stages. In the first stage, CA will complete a pass of the collection using our initial entities to extract document. The challenges are discussed and the entities are revised.\n\n\n\n\n\nExtractor instructions\n\n\nextractor_instructions\n\n\n\nSee extraction details.\n\n\n\n\n\nExtractor blinding\n\n\nextractor_blinding\n\n\n\nBlinding was not used.\n\n\n\n\n\nExtraction reliability\n\n\nextraction_reliability\n\n\n\nCA will perform extractions; TE will verify extractions for quality assurance.\n\n\n\n\n\nExtraction reconciliation procedure\n\n\nextraction_reconciliation_procedure\n\n\n\nDiscussion and joint decision for studies where extraction proves to be challenging and issues of interpretation arise.\n\n\n\n\n\nExtraction procedure justification\n\n\nextraction_procedure_justification\n\n\n\nThese are documented in the extraction details.\n\n\n\n\n\nData management and sharing\n\n\nextraction_data_management_and_sharing\n\n\n\nWe retain the information of the studies in shared bibtex files, extraction data will be stored in ascii data files (.bibtex), and the parser for reading the data from .bibtex files to R for the analysis will be available (as quarto/markdown/R files), and all these are managed, structured, shared and documented in Github repository according to FAIR principles.\n\n\n\n\n\nMiscellaneous extraction details\n\n\nmisc_extraction_details\n\n\n\nNA\n\n\n\n\nSection: Synthesis and Quality Assessment\n\n\n\nPlanned data transformations\n\n\nplanned_data_transformations\n\n\n\nFor regression studies, we convert all metrics to Pearson correlation coefficients. For classification studies, we convert the outcomes of classification to Matthews Correlation Coefficient (MCC) from the precision, accuracy, specificity, F1 scores. Alternatively, we use Cohen’s kappa for multiple classes.\n\n\n\n\n\nMissing data\n\n\nmissing_data\n\n\n\nIf no main outcome variables are available, we exclude the study.\n\n\n\n\n\nData validation\n\n\ndata_validation\n\n\n\nNone planned beyond the staged approached already documented in extraction process.\n\n\n\n\n\nQuality assessment\n\n\nquality_assessment\n\n\n\nNot all the bias assessment tools for clinical studies are relevant for our purposes, we adapt the overall approached advocated in [Higgins et al. (2011)] (https://doi.org/10.1136/bmj.d5928).\n\n\n\n\n\nSynthesis plan\n\n\nsynthesis_plan\n\n\n\nWe analyse regression and classification studies separately, and depending on the quantity of the studies forming suitable sub-groupings based on techniques, materials or music collections/genres, we may further synthesise the results across groupings that are formed along these subsets.\n\n\n\n\n\nCriteria for conclusions / inference criteria\n\n\ncriteria_for_conclusions\n\n\n\nNA\n\n\n\n\n\nSynthesist masking\n\n\nsynthesis_masking\n\n\n\nNA\n\n\n\n\n\nSynthesis reliability\n\n\nsynthesis_reliability\n\n\n\nNA\n\n\n\n\n\nSynthesis reconciliation procedure\n\n\nsynthesis_reconciliation_procedure\n\n\n\nNA\n\n\n\n\n\nPublication bias analyses\n\n\npublication_bias\n\n\n\nWe utilise Egger’s test to assess the publication bias and potentially correct the effect size bias by selecting 10% most precise effect sizes as recommended by Van Aert, Wicherts, & Van Assen (2019).\n\n\n\n\n\nSensitivity analyses / robustness checks\n\n\nsensitivity_analysis\n\n\n\nWithin regression and classificiation tasks, we will carry out sensitivity analysis using sub-groups of studied based on type of models, and the type of journal the studies were published in.\n\n\n\n\n\nSynthesis procedure justification\n\n\nsynthesis_procedure_justification\n\n\n\nWe share our justification of the synthesis and the subsetting carried out in the manuscript but we have not formulated these in advance except for synthesizing classiciation and regression approaches separately and creating subsets within these approaches according to techniques and datasets utilised.\n\n\n\n\n\nSynthesis data management and sharing\n\n\nsynthesis_data_management_and_sharing\n\n\n\nWe share the data, procedures, definitions, the analysis scripts with the outcomes as R code in Quarto notes at Github.\n\n\n\n\n\nMiscellaneous synthesis details\n\n\nmisc_synthesis_details\n\n\n\nUnspecified"
  },
  {
    "objectID": "preregistration/preregistration.html#preregr-prereg-spec-Ya8oq9lMLd",
    "href": "preregistration/preregistration.html#preregr-prereg-spec-Ya8oq9lMLd",
    "title": "metaMER",
    "section": "Meta-analysis Pre-registration: Music Emotion Recognition",
    "text": "Meta-analysis Pre-registration: Music Emotion Recognition\n\nSection: Metadata\n\n\n\nTitle\n\n\ntitle\n\n\n\nMusic emotion recognition: Meta-analysis of regression and classification success of emotion ratings from audio\n\n\n\n\n\nContributors\n\n\nauthors\n\n\n\nEerola, T., Anderson, C. J.\n\n\n\n\n\nSubjects\n\n\ntarget_discipline\n\n\n\nmusic cognition, music information retrieval, music psychology\n\n\n\n\n\nTasks and roles\n\n\ntasks_and_roles\n\n\n\nequal contribution\n\n\n\n\nSection: Review methods\n\n\n\nType of review\n\n\ntype_of_review\n\n\n\nMeta-analysis\n\n\n\n\n\nReview stages\n\n\nreview_stages\n\n\n\nSearch, Screening, Extraction, Synthesis\n\n\n\n\n\nCurrent review stage\n\n\ncurrent_stage\n\n\n\nScreening\n\n\n\n\n\nStart date\n\n\nstart_date\n\n\n\n2024-05-15 2024-05-15\n\n\n\n\n\nEnd date\n\n\nend_date\n\n\n\n2024-06-30\n\n\n\n\n\nBackground\n\n\nbackground\n\n\n\nThe aim is to establish the current state of the model success in predicting emotions expressed by music from audio. We will focus on the last 10 years of research and especially the research that has predicted valence and arousal ratings from music audio. No such analysis exists and there are interesting challenges in predicting emotional content of music that relates to specificity of the music and the type of emotions and features used that would benefit from a systematic analysis.\n\n\n\n\n\nPrimary research question(s)\n\n\nprimary_research_question\n\n\n\nTo what degree can arousal and valence ratings of emotions expressed by music be predicted from audio? How are the prediction rates related to genres of music, the type of models used, the type of features, modelling design and cross-validation utilised, and the model complexity and parsimony?\n\n\n\n\n\nSecondary research question(s)\n\n\nsecondary_research_question\n\n\n\nWhat is the prediction rate related to classification of quadrants in the affective circumplex?\n\n\n\n\n\nExpectations / hypotheses\n\n\nexpectations_hypotheses\n\n\n\nPrediction of arousal ratings is generally high and robust, and in terms of the model outcome metrics (correlation), achieves at least r = 0.77 (R square of 0.60). Prediction of valence ratings from audio is more challenging and more context dependent and will achieve generally a lower prediction rate, r = 0.63 (R square 0.40)\n\n\n\n\n\nDependent variable(s) / outcome(s) / main variables\n\n\ndvs_outcomes_main_vars\n\n\n\nRegression model performance will be converted to Pearson correlation coefficients and classification model performance will be converted to Matthews correlation coefficient (MCC) when possible.\n\n\n\n\n\nIndependent variable(s) / intervention(s) / treatment(s)\n\n\nivs_intervention_treatment\n\n\n\nMusic genre, prediction type (linear or classification), feature type (based on prior work by Panda et al., 2020), model complexity (high, medium, low), model validation (exists or not)\n\n\n\n\n\nAdditional variable(s) / covariate(s)\n\n\nadditional_variables\n\n\n\nUnspecified\n\n\n\n\n\nSoftware\n\n\nsoftware\n\n\n\nR and Github repository\n\n\n\n\n\nFunding\n\n\nfunding\n\n\n\nMitacs Globalink Research Award (Mitacs & British High Commission - Ottawa, Canada)\n\n\n\n\n\nConflicts of interest\n\n\ncois\n\n\n\nThere are no identified conflicts of interests.\n\n\n\n\n\nOverlapping authorships\n\n\noverlapping_authorships\n\n\n\nNot applicable\n\n\n\n\nSection: Search strategy\n\n\n\nDatabases\n\n\ndatabases\n\n\n\nWeb of Science, Scopus, and Open Alex\n\n\n\n\n\nInterfaces\n\n\ninterfaces\n\n\n\nWeb of Science, Scopus, and Open Alex\n\n\n\n\n\nGrey literature\n\n\ngrey_literature\n\n\n\nNot included\n\n\n\n\n\nInclusion and exclusion criteria\n\n\ninclusions_exclusion_criteria\n\n\n\nSample, Phenomenon of Interest, Design, Evaluation, Research type\n\n\n\n\n\nQuery strings\n\n\nquery_strings\n\n\n\nScopus: TITLE-ABS-KEY ( valence OR arousal OR classi OR categor OR algorithm AND music  AND emotion AND recognition ) AND PUBYEAR &gt; 2013 AND PUBYEAR &lt; 2025 AND  ( LIMIT-TO ( DOCTYPE , “ar” ) )  Web of science:  (DT=(Article) AND PY=(2014-2025)) AND ALL=(music emotion recognition valence arousal)  Open Alex:  https://openalex.org/works?page=1&filter=default.search%3Amusic%20emotion%20recognition%20valence%20arousal, type%3Atypes%2Farticle,publication_year%3A2014-2024, keywords.id%3Akeywords%2Femotion-recognition, keywords.id%3Akeywords%2Faffective-computing, language%3Alanguages%2Fen, open_access.any_repository_has_fulltext%3Atrue \n\n\n\n\n\nSearch validation procedure\n\n\nsearch_validation_procedure\n\n\n\nManual checking, separate keywords searches\n\n\n\n\n\nOther search strategies\n\n\nother_search_strategies\n\n\n\nNot applied\n\n\n\n\n\nProcedures to contact authors\n\n\nprocedure_for_contacting_authors\n\n\n\nUnspecified\n\n\n\n\n\nResults of contacting authors\n\n\nresults_of_contacting_authors\n\n\n\nNot carried out\n\n\n\n\n\nSearch expiration and repetition\n\n\nsearch_expiration_and_repetition\n\n\n\nSearches were done during the active search period in late May early June 2024 and no repetition is planned.\n\n\n\n\n\nSearch strategy justification\n\n\nsearch_strategy_justification\n\n\n\nThe three major databases should be able yield a robust picture of the topic\n\n\n\n\n\nMiscellaneous search strategy details\n\n\nmisc_search_strategy_details\n\n\n\nNo alternative searches were articulated or envisaged.\n\n\n\n\nSection: Screening\n\n\n\nScreening stages\n\n\nscreening_stages\n\n\n\nWe completed screening using custom fields inserted to the bibtex file and managed with citation managers (jabref and bibdesk). To filter relevant studies, we followed a three-stage screening procedure.  In stage 1, we screened the 553 studies’ titles for relevance, removing irrelevant studies and recording exclusion criteria (see Used exclusion criteria). CA assigned 63 studies to the High Priority based on titles’ relevance, assigned 338 studies to Low Priority based on irrelevant titles, and 152 studies to Medium Priority for additional screening. In stage 2, CA assessed the 152 Medium Priority studies for relevance by screening abstracts. 95 studies’ status changed to Low Priority, whereas 30 studies’ status changed to High Priority. 27 studies remained in the Medium priority category. TE and CA evaluated the remaining 27 studies’, moving 15 to the High Priority Category and 12 to the Medium Priority Category. For studies moved to Low Priority, brief BiBTex comments summarized the rationale for exclusion. In stage 3, TE and CA independently screened Priority 1 studies for relevance, including an include, exclude, or unsure decision in a user-comment BiBTeX field.\n\n\n\n\n\nScreened fields / masking\n\n\nscreened_fields_masking\n\n\n\nWe left authors, titles, publication years, and journal names unmasked.\n\n\n\n\n\nUsed exclusion criteria\n\n\nused_exclusion_criteria\n\n\n\nWe excluded studies according to the following exclusion criteria: soundscapes/vocalisations, non-music audio, video clips, physiological markers, dance, video/movie, physiological/EEG/ECG/MEG/GSR/brain imaging/heart rate/neuroscience/brain studies, sensor data, multimodal, autism, ageing, review/systematic review/overview/survey, face emotion recognition, mental health, music therapy, schizophrenia, memory/emotion factors as IVs, recommender systems, or systems that identify the location of emotional excerpts. We included results from some studies meeting exclusion criteria (e.g., multimodal studies involving physiological measurements) if they reported separately on acoustic-only models.\n\n\n\n\n\nScreener instructions\n\n\nscreener_instructions\n\n\n\nAs described above.\n\n\n\n\n\nScreening reliability\n\n\nscreening_reliability\n\n\n\nIn the pass 1 and 2, we included a quality control check after the pass to discuss the identified categories. In the third pass, we double-coded decisions, resolving discrepancies through discussion.\n\n\n\n\n\nScreening reconciliation procedure\n\n\nscreening_reconciliation_procedure\n\n\n\nWe reconcile discrepancies through discussion, resolving “unsure” votes first, followed by discrepancies in include/exclude decisions between authors Results of this updating procedure are available in the Pass 3 comparison document.\n\n\n\n\n\nSampling and sample size\n\n\nsampling_and_sample_size\n\n\n\nWe identified and retained 553 articles from Scopus, Web of Science, and Open Alex based on the search strategy outlined above. See table at the end that details the cumulative exclusions.\n\n\n\n\n\nScreening procedure justification\n\n\nscreening_procedure_justification\n\n\n\nTo offer a broad summary of music emotion recognition tasks, we attempted to include all studies involving prediction with acoustic features. We performed screening unblinded and determined inclusion/exclusion criteria based on studies’ relevance to the task explored.\n\n\n\n\n\nData management and sharing\n\n\nscreening_data_management_and_sharing\n\n\n\nSources will be shared as (a) BibTeX library(ies) including reviewer notes.\n\n\n\n\n\nMiscellaneous screening details\n\n\nmisc_screening_details\n\n\n\nUnspecified\n\n\n\n\nSection: Extraction\n\n\n\nEntities to extract\n\n\nentities_to_extract\n\n\n\nThese are listed and defined in extraction details.\n\n\n\n\n\nExtraction stages\n\n\nextraction_stages\n\n\n\nThe data extraction will be completed in stages. In the first stage, CA will complete a pass of the collection using our initial entities to extract document. The challenges are discussed and the entities are revised.\n\n\n\n\n\nExtractor instructions\n\n\nextractor_instructions\n\n\n\nSee extraction details.\n\n\n\n\n\nExtractor blinding\n\n\nextractor_blinding\n\n\n\nBlinding was not used.\n\n\n\n\n\nExtraction reliability\n\n\nextraction_reliability\n\n\n\nCA will perform extractions; TE will verify extractions for quality assurance.\n\n\n\n\n\nExtraction reconciliation procedure\n\n\nextraction_reconciliation_procedure\n\n\n\nDiscussion and joint decision for studies where extraction proves to be challenging and issues of interpretation arise.\n\n\n\n\n\nExtraction procedure justification\n\n\nextraction_procedure_justification\n\n\n\nThese are documented in the extraction details.\n\n\n\n\n\nData management and sharing\n\n\nextraction_data_management_and_sharing\n\n\n\nWe retain the information of the studies in shared bibtex files, extraction data will be stored in ascii data files (.bibtex), and the parser for reading the data from .bibtex files to R for the analysis will be available (as quarto/markdown/R files), and all these are managed, structured, shared and documented in Github repository according to FAIR principles.\n\n\n\n\n\nMiscellaneous extraction details\n\n\nmisc_extraction_details\n\n\n\nNA\n\n\n\n\nSection: Synthesis and Quality Assessment\n\n\n\nPlanned data transformations\n\n\nplanned_data_transformations\n\n\n\nFor regression studies, we convert all metrics to Pearson correlation coefficients. For classification studies, we convert the outcomes of classification to Matthews Correlation Coefficient (MCC) from the precision, accuracy, specificity, F1 scores. Alternatively, we use Cohen’s kappa for multiple classes.\n\n\n\n\n\nMissing data\n\n\nmissing_data\n\n\n\nIf no main outcome variables are available, we exclude the study.\n\n\n\n\n\nData validation\n\n\ndata_validation\n\n\n\nNone planned beyond the staged approached already documented in extraction process.\n\n\n\n\n\nQuality assessment\n\n\nquality_assessment\n\n\n\nNot all the bias assessment tools for clinical studies are relevant for our purposes, we adapt the overall approached advocated in [Higgins et al. (2011)] (https://doi.org/10.1136/bmj.d5928).\n\n\n\n\n\nSynthesis plan\n\n\nsynthesis_plan\n\n\n\nWe analyse regression and classification studies separately, and depending on the quantity of the studies forming suitable sub-groupings based on techniques, materials or music collections/genres, we may further synthesise the results across groupings that are formed along these subsets.\n\n\n\n\n\nCriteria for conclusions / inference criteria\n\n\ncriteria_for_conclusions\n\n\n\nNA\n\n\n\n\n\nSynthesist masking\n\n\nsynthesis_masking\n\n\n\nNA\n\n\n\n\n\nSynthesis reliability\n\n\nsynthesis_reliability\n\n\n\nNA\n\n\n\n\n\nSynthesis reconciliation procedure\n\n\nsynthesis_reconciliation_procedure\n\n\n\nNA\n\n\n\n\n\nPublication bias analyses\n\n\npublication_bias\n\n\n\nWe utilise Egger’s test to assess the publication bias and potentially correct the effect size bias by selecting 10% most precise effect sizes as recommended by Van Aert, Wicherts, & Van Assen (2019).\n\n\n\n\n\nSensitivity analyses / robustness checks\n\n\nsensitivity_analysis\n\n\n\nWithin regression and classificiation tasks, we will carry out sensitivity analysis using sub-groups of studied based on type of models, and the type of journal the studies were published in.\n\n\n\n\n\nSynthesis procedure justification\n\n\nsynthesis_procedure_justification\n\n\n\nWe share our justification of the synthesis and the subsetting carried out in the manuscript but we have not formulated these in advance except for synthesizing classiciation and regression approaches separately and creating subsets within these approaches according to techniques and datasets utilised.\n\n\n\n\n\nSynthesis data management and sharing\n\n\nsynthesis_data_management_and_sharing\n\n\n\nWe share the data, procedures, definitions, the analysis scripts with the outcomes as R code in Quarto notes at Github.\n\n\n\n\n\nMiscellaneous synthesis details\n\n\nmisc_synthesis_details\n\n\n\nUnspecified"
  },
  {
    "objectID": "preregistration/preregistration.html#references",
    "href": "preregistration/preregistration.html#references",
    "title": "metaMER",
    "section": "References",
    "text": "References\n\nHiggins, J. P. T., Altman, D. G., Gøtzsche, P. C., Jüni, P., Moher, D., Oxman, A. D., Savović, J., Schulz, K. F., Weeks, L., & Sterne, J. A. C. (2011). The Cochrane Collaboration tool for assessing risk of bias in randomised trials. BMJ, 343. https://www.bmj.com/content/343/bmj.d5928\nPanda, R., Malheiro, R., & Paiva, R. P. (2020). Audio features for music emotion recognition: a survey. IEEE Transactions on Affective Computing, 14(1), 68-88. https://doi.org/10.1109/TAFFC.2020.3032373\nShamseer, L., Moher, D., Clarke, M., Ghersi, D., Liberati, A., Petticrew, M., Shekelle, P., & Stewart, L. A. (2015). Preferred reporting items for systematic review and meta-analysis protocols (PRISMA-P) 2015: elaboration and explanation. BMJ, 349. https://www.bmj.com/content/349/bmj.g7647"
  },
  {
    "objectID": "studies/extraction_details.html",
    "href": "studies/extraction_details.html",
    "title": "Extraction Details",
    "section": "",
    "text": "To capture relevant information from studies, we expanded BiBTeX fields for each study with additional fields. For reproducibility, these instructions provide information on the process followed for each field."
  },
  {
    "objectID": "studies/extraction_details.html#identifier",
    "href": "studies/extraction_details.html#identifier",
    "title": "Extraction Details",
    "section": "IDENTIFIER",
    "text": "IDENTIFIER\nUnique identifier of article. Contains last name of lead author, year of publication and first two letters of article title. Hyphenated last names collapsed."
  },
  {
    "objectID": "studies/extraction_details.html#author",
    "href": "studies/extraction_details.html#author",
    "title": "Extraction Details",
    "section": "AUTHOR",
    "text": "AUTHOR\nNames of all authors. Last name precedes first name and separated by comma. For multiple authors “and” precedes each listed subsequent author. E.g., Sorussa, Kanawat and Choksuriwong, Anant and Karnjanadecha, Montri"
  },
  {
    "objectID": "studies/extraction_details.html#journal",
    "href": "studies/extraction_details.html#journal",
    "title": "Extraction Details",
    "section": "JOURNAL",
    "text": "JOURNAL\nTitle of journal containing article."
  },
  {
    "objectID": "studies/extraction_details.html#note",
    "href": "studies/extraction_details.html#note",
    "title": "Extraction Details",
    "section": "NOTE",
    "text": "NOTE\nIncludes number of citing articles and open access details. E.g., Cited by: 4; All Open Access, Gold Open Access, Green Open Access"
  },
  {
    "objectID": "studies/extraction_details.html#title",
    "href": "studies/extraction_details.html#title",
    "title": "Extraction Details",
    "section": "TITLE",
    "text": "TITLE\nTitle of article."
  },
  {
    "objectID": "studies/extraction_details.html#volume",
    "href": "studies/extraction_details.html#volume",
    "title": "Extraction Details",
    "section": "VOLUME",
    "text": "VOLUME\nVolume number of publication."
  },
  {
    "objectID": "studies/extraction_details.html#year",
    "href": "studies/extraction_details.html#year",
    "title": "Extraction Details",
    "section": "YEAR",
    "text": "YEAR\nPublication year."
  },
  {
    "objectID": "studies/extraction_details.html#doi",
    "href": "studies/extraction_details.html#doi",
    "title": "Extraction Details",
    "section": "DOI",
    "text": "DOI\nDigital object identifier of article."
  },
  {
    "objectID": "studies/extraction_details.html#abstract",
    "href": "studies/extraction_details.html#abstract",
    "title": "Extraction Details",
    "section": "ABSTRACT",
    "text": "ABSTRACT\nComplete text of article abstract."
  },
  {
    "objectID": "studies/extraction_details.html#source",
    "href": "studies/extraction_details.html#source",
    "title": "Extraction Details",
    "section": "SOURCE",
    "text": "SOURCE\nDatabase article was sourced from. Scopus, Web of Science (WoS) or OpenAlex."
  },
  {
    "objectID": "studies/extraction_details.html#author_keywords",
    "href": "studies/extraction_details.html#author_keywords",
    "title": "Extraction Details",
    "section": "AUTHOR_KEYWORDS",
    "text": "AUTHOR_KEYWORDS\nCorresponding keywords for article indicated by author."
  },
  {
    "objectID": "studies/extraction_details.html#notes_authorinitials",
    "href": "studies/extraction_details.html#notes_authorinitials",
    "title": "Extraction Details",
    "section": "NOTES_AUTHORINITIALS",
    "text": "NOTES_AUTHORINITIALS\nDecision and comments by respective author"
  },
  {
    "objectID": "studies/extraction_details.html#stimulus_type",
    "href": "studies/extraction_details.html#stimulus_type",
    "title": "Extraction Details",
    "section": "STIMULUS_TYPE",
    "text": "STIMULUS_TYPE\nMetadata pertaining to stimuli employed in paradigm. Can be listed as genres of music stimuli employed, or if stimuli come from a standard database, name of standard."
  },
  {
    "objectID": "studies/extraction_details.html#stimulus_duration",
    "href": "studies/extraction_details.html#stimulus_duration",
    "title": "Extraction Details",
    "section": "STIMULUS_DURATION",
    "text": "STIMULUS_DURATION\nDuration of stimuli, if applicable. Unit of measurement (seconds, measures) specified in STIMULUS_DURATION_UNIT"
  },
  {
    "objectID": "studies/extraction_details.html#stimulus_duration_unit",
    "href": "studies/extraction_details.html#stimulus_duration_unit",
    "title": "Extraction Details",
    "section": "STIMULUS_DURATION_UNIT",
    "text": "STIMULUS_DURATION_UNIT\nUnit of measurement pertaining to STIMULUS_DURATION. E.g., seconds, measures, etc."
  },
  {
    "objectID": "studies/extraction_details.html#stimulus_n",
    "href": "studies/extraction_details.html#stimulus_n",
    "title": "Extraction Details",
    "section": "STIMULUS_N",
    "text": "STIMULUS_N\nNumber of stimuli employed in experiment. If multiple experimental conditions reported, separate \\(n\\) by conditions where possible."
  },
  {
    "objectID": "studies/extraction_details.html#feature_n",
    "href": "studies/extraction_details.html#feature_n",
    "title": "Extraction Details",
    "section": "FEATURE_N",
    "text": "FEATURE_N\nNumber of features included in data modeling (if available)."
  },
  {
    "objectID": "studies/extraction_details.html#participant_n",
    "href": "studies/extraction_details.html#participant_n",
    "title": "Extraction Details",
    "section": "PARTICIPANT_N",
    "text": "PARTICIPANT_N\nTotal number of participants in experiment."
  },
  {
    "objectID": "studies/extraction_details.html#participant_expertise",
    "href": "studies/extraction_details.html#participant_expertise",
    "title": "Extraction Details",
    "section": "PARTICIPANT_EXPERTISE",
    "text": "PARTICIPANT_EXPERTISE\nExpertise of annotators. E.g., experts, non-experts, not specified."
  },
  {
    "objectID": "studies/extraction_details.html#participant_origin",
    "href": "studies/extraction_details.html#participant_origin",
    "title": "Extraction Details",
    "section": "PARTICIPANT_ORIGIN",
    "text": "PARTICIPANT_ORIGIN\nOrigin country of participants, or online platform participants were recruited from (e.g., MTurk)"
  },
  {
    "objectID": "studies/extraction_details.html#participant_sampling",
    "href": "studies/extraction_details.html#participant_sampling",
    "title": "Extraction Details",
    "section": "PARTICIPANT_SAMPLING",
    "text": "PARTICIPANT_SAMPLING\nHow participants were recruited (e.g., convenience, random sampling, crowdsourcing)"
  },
  {
    "objectID": "studies/extraction_details.html#participant_task",
    "href": "studies/extraction_details.html#participant_task",
    "title": "Extraction Details",
    "section": "PARTICIPANT_TASK",
    "text": "PARTICIPANT_TASK\nNature of rating/classification task undertaken by participants. E.g., rate, annotate."
  },
  {
    "objectID": "studies/extraction_details.html#feature_categories",
    "href": "studies/extraction_details.html#feature_categories",
    "title": "Extraction Details",
    "section": "FEATURE_CATEGORIES",
    "text": "FEATURE_CATEGORIES\nNames of categories analyzed features pertain to, based on names in Panda (2021). Includes names of all pertinent categories: Melody, Rhythm, Timbre, Pitch, Tonality, Expressivity, Texture, Form, Vocal, High-Level"
  },
  {
    "objectID": "studies/extraction_details.html#feature_source",
    "href": "studies/extraction_details.html#feature_source",
    "title": "Extraction Details",
    "section": "FEATURE_SOURCE",
    "text": "FEATURE_SOURCE\nName(s) of feature analysis toolbox(es)."
  },
  {
    "objectID": "studies/extraction_details.html#feature_reduction_method",
    "href": "studies/extraction_details.html#feature_reduction_method",
    "title": "Extraction Details",
    "section": "FEATURE_REDUCTION_METHOD",
    "text": "FEATURE_REDUCTION_METHOD\nName(s) of feature reduction or feature selection methods employed."
  },
  {
    "objectID": "studies/extraction_details.html#model_category",
    "href": "studies/extraction_details.html#model_category",
    "title": "Extraction Details",
    "section": "MODEL_CATEGORY",
    "text": "MODEL_CATEGORY\nName of model type (regression, classification, or both)."
  },
  {
    "objectID": "studies/extraction_details.html#model_detail",
    "href": "studies/extraction_details.html#model_detail",
    "title": "Extraction Details",
    "section": "MODEL_DETAIL",
    "text": "MODEL_DETAIL\nAdditional information pertaining to predictive model, such as the name of algorithm used and other pertinent parameters. E.g., Random Forest, Commonality Analysis, Multiple Regression, Neural Networks, LDSM."
  },
  {
    "objectID": "studies/extraction_details.html#model_measure",
    "href": "studies/extraction_details.html#model_measure",
    "title": "Extraction Details",
    "section": "MODEL_MEASURE",
    "text": "MODEL_MEASURE\nMetric used in model evaluation. E.g., \\(R^2\\), \\(MSE\\), \\(CCC\\), Classification accuracy, etc."
  },
  {
    "objectID": "studies/extraction_details.html#model_complexity_parameters",
    "href": "studies/extraction_details.html#model_complexity_parameters",
    "title": "Extraction Details",
    "section": "MODEL_COMPLEXITY_PARAMETERS",
    "text": "MODEL_COMPLEXITY_PARAMETERS\nAdditional information pertaining to predictive model. E.g., training epochs: 100; n layers: 1, 2; LSTM units: 124,248."
  },
  {
    "objectID": "studies/extraction_details.html#model_rate_emotion_names",
    "href": "studies/extraction_details.html#model_rate_emotion_names",
    "title": "Extraction Details",
    "section": "MODEL_RATE_EMOTION_NAMES",
    "text": "MODEL_RATE_EMOTION_NAMES\nNames of predicted emotions. E.g., valence, arousal, happy, sad, angry, fearful, etc."
  },
  {
    "objectID": "studies/extraction_details.html#model_rate_emotion_values",
    "href": "studies/extraction_details.html#model_rate_emotion_values",
    "title": "Extraction Details",
    "section": "MODEL_RATE_EMOTION_VALUES",
    "text": "MODEL_RATE_EMOTION_VALUES\nPertinent prediction of model summaries. Report as R named arrays, including summary statistics in variables. When reporting results of multiple models, concatenate multiple entries with bind_field. When reporting results for different toolboxes or feature subsets, assign each to a new BiBTeX field with relevant identifier following final underscore. See additional details below."
  },
  {
    "objectID": "studies/extraction_details.html#model_validation",
    "href": "studies/extraction_details.html#model_validation",
    "title": "Extraction Details",
    "section": "MODEL_VALIDATION",
    "text": "MODEL_VALIDATION\nValidation method used (if applicable). E.g., 10-fold cross validation, leave one out cross validation."
  },
  {
    "objectID": "studies/extraction_details.html#classification",
    "href": "studies/extraction_details.html#classification",
    "title": "Extraction Details",
    "section": "Classification",
    "text": "Classification\nConfusion matrices can be encoded using the unflatten function, which assigns relevant meta-parameters to the model_parameters attribute of the output matrix. The function automatically builds a \\(n\\) by \\(n\\) matrix and takes individual values as arguments. Values can be specified for the first row, and are recycled in subsequent rows.\nunflatten(A = .5, B = .2, C = .3,\n          .3, .5, .2,\n          .1, .1, .8)\nSummary parameters can be extracted from the resulting matrix by calling the summarize_matrix function. This function calls on caret to extract several summary statistics at once. Including bind_field in the call ensures consistent nomenclature with other study encodings.\nbind_field(\n  'library.model.features.data.exp' = summarize_matrix(\n    unflatten(Q1=185.85,Q2=14.4,Q3=8.6,Q4=18.15,\n              23.95,190.55,7,3.5,\n              14.2,8.4,157.25,45.15,\n              24.35,1.65,45.85,153.15)\n  )\n)\nMultiple matrices in a study can be summarized by putting them in a list and using the lapply function to extract relevant statistics:\nbind_field(\n  lapply(\n    list(\n      'library.model.features.data.exp1' = unflatten(\n        Angry=.984,Happy=.007,Relax=.007,Sad=0,\n        0,.987,0,.007,\n        .008,.007,.987,0,\n        .008,0,.007,.993\n        ),\n      'library.model.features.data.exp2' = unflatten(\n        Angry=.976,Happy=.013,Relax=.014,Sad=0,\n        .008,.967,0,.02,\n        .008,.013,.98,.007,\n        .008,.007,.007,.974\n       )\n      ),\n    summarize_matrix\n  )\n)\nWhen confusion matrices are not available, encode available parameters (accuracy, precision, recall, \\(F\\) scores, etc.) using the standard nomenclature to distinguish relevant outcomes for each class:\nbind_field(\nlibrary.model.features.data.experiment = c(class_measure.summaryStat = 0, ...),\n...\n)"
  },
  {
    "objectID": "studies/library_formatter.html#load-libraries",
    "href": "studies/library_formatter.html#load-libraries",
    "title": "Library Formatter",
    "section": "Load libraries",
    "text": "Load libraries\n\n# load dplyr\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union"
  },
  {
    "objectID": "studies/library_formatter.html#read-data",
    "href": "studies/library_formatter.html#read-data",
    "title": "Library Formatter",
    "section": "Read data",
    "text": "Read data\n\n# read in bibtex library as data frame\nbib_df_ca &lt;- bib2df::bib2df(paste0(here::here(),\n                                   \"/studies/bib/Passes/\", \n                                   \"metaMER_library_third_pass_ca.bib\")\n)\n\nSome BibTeX entries may have been dropped.\n            The result could be malformed.\n            Review the .bib file and make sure every single entry starts\n            with a '@'.\n\n\nColumn `YEAR` contains character strings.\n              No coercion to numeric applied.\n\nbib_df_te &lt;- bib2df::bib2df(paste0(here::here(),\n                                   \"/studies/bib/Passes/\", \n                                   \"metaMER_library_third_pass_te.bib\")\n)\n\nSome BibTeX entries may have been dropped.\n            The result could be malformed.\n            Review the .bib file and make sure every single entry starts\n            with a '@'.\nColumn `YEAR` contains character strings.\n              No coercion to numeric applied.\n\nbib_df_ca &lt;- dplyr::filter(bib_df_ca,PRIORITY=='prio1')\nbib_df_te &lt;- dplyr::filter(bib_df_te,PRIORITY=='prio1')\nsum(bib_df_ca$BIBTEXKEY %in% bib_df_te$BIBTEXKEY)==nrow(bib_df_ca)\n\n[1] TRUE"
  },
  {
    "objectID": "studies/library_formatter.html#identify-sources",
    "href": "studies/library_formatter.html#identify-sources",
    "title": "Library Formatter",
    "section": "Identify sources",
    "text": "Identify sources\n\n# filter open_alex entries and declare source (c1 unique to database)\nbib_df_ca %&gt;% \n  filter(!is.na(C1)) %&gt;%\n  mutate(SOURCE = 'open_alex') -&gt; oa_entries\n\n# filter wos entries and declare source (unique_id unique to database)\nbib_df_ca %&gt;% \n  filter(!is.na(UNIQUE.ID)) %&gt;%\n  mutate(SOURCE = 'web_of_science') -&gt; wos_entries\n\n# filter scopus entries\nbib_df_ca %&gt;% \n  filter(SOURCE == 'Scopus') -&gt; scopus_entries\n\nscopus_entries$JOURNAL &lt;- scopus_entries$JOURNALTITLE\nscopus_entries$JOURNALTITLE &lt;- NA\n\n# bind sources\nbib_df_ca &lt;- rbind(oa_entries, wos_entries)\nbib_df_ca &lt;- rbind(bib_df_ca, scopus_entries)"
  },
  {
    "objectID": "studies/library_formatter.html#clean-up-entries",
    "href": "studies/library_formatter.html#clean-up-entries",
    "title": "Library Formatter",
    "section": "Clean up entries",
    "text": "Clean up entries\n\n# remove columns only belonging to one database\nbib_df_ca$UNIQUE.ID &lt;- NULL\nbib_df_ca$C1 &lt;- NULL\n# remove unnecessary column\nbib_df_ca$HASABSTRACT &lt;- NULL\n# relevel priority column with intuitive names\n# bib_df_ca$PRIORITY &lt;- as.factor(bib_df_ca$PRIORITY)\n#levels(bib_df_ca$PRIORITY) &lt;- c('high_priority', 'low_priority')\n# bib_df_ca$PRIORITY &lt;- plyr::revalue(bib_df_ca$PRIORITY, \n#                                     c(prio1 = 'high_priority',\n#                                       prio3 = 'low_prioirty'))\n# make casing consistent\nbib_df_ca$SOURCE &lt;- tolower(bib_df_ca$SOURCE)\n# consistent names for private notes\nnames(bib_df_ca)[names(bib_df_ca) == 'COMMENT.CAMJA'] &lt;- 'NOTES.CA'\n# after subsetting out high-priority studies, no longer need priority column\nbib_df_ca$PRIORITY &lt;- NULL\nbib_df_ca$RANKING &lt;- NULL\nbib_df_ca$MODIFICATIONDATE &lt;- NULL"
  },
  {
    "objectID": "studies/library_formatter.html#add-comments-from-second-reviewer",
    "href": "studies/library_formatter.html#add-comments-from-second-reviewer",
    "title": "Library Formatter",
    "section": "Add comments from second reviewer",
    "text": "Add comments from second reviewer\n\n# select bibkey (for merge) and notes from second reviewer\nbib_df_te &lt;- bib_df_te %&gt;% select(BIBTEXKEY, NOTES.TE)\n\nbib_df_merged &lt;- merge(bib_df_ca, \n                       bib_df_te, \n                       by = c('BIBTEXKEY'))"
  },
  {
    "objectID": "studies/library_formatter.html#drop-empty-columns",
    "href": "studies/library_formatter.html#drop-empty-columns",
    "title": "Library Formatter",
    "section": "Drop empty columns",
    "text": "Drop empty columns\n\n# identify columns entirely empty\nempty_cols &lt;- sapply(bib_df_merged, function(x) {\n  all(is.na(x))\n  }\n) \n# remove them\nbib_df_merged &lt;- bib_df_merged[ , !empty_cols]"
  },
  {
    "objectID": "studies/library_formatter.html#rewrite-bibtex-library",
    "href": "studies/library_formatter.html#rewrite-bibtex-library",
    "title": "Library Formatter",
    "section": "Rewrite BiBTeX library",
    "text": "Rewrite BiBTeX library\n\ndim(bib_df_merged)\n\n[1] 96 37\n\nbib2df::df2bib(bib_df_merged, file = 'metaMER_library_third_pass_clean.bib')"
  },
  {
    "objectID": "studies/library_formatter.html#next",
    "href": "studies/library_formatter.html#next",
    "title": "Library Formatter",
    "section": "Next",
    "text": "Next\nCompare pass 3 annotations and resolve conflicts (pass 3 comparison.qmd)"
  },
  {
    "objectID": "studies/library_parser.html",
    "href": "studies/library_parser.html",
    "title": "Library Parser",
    "section": "",
    "text": "Status: in progress.\nTODO:\n- Separate scripts and functions into separate .qmd files/directories.\n- Update model_rate_emotion_values nomenclature process for classification papers.\n- Replace rbind with custom bind function throughout"
  },
  {
    "objectID": "studies/library_parser.html#preparing-data",
    "href": "studies/library_parser.html#preparing-data",
    "title": "Library Parser",
    "section": "Preparing data",
    "text": "Preparing data\nThe follow code extracts information from the .bib library to format it as a data.frame for further processing. The code makes use of the stringr package and uses regular expressions to extract relevant parameters. First we read in the .bib file and use some string manipulations to retrieve the citation keys.\n\nlibrary(stringr)\nlibrary(knitr, include.only = 'kable')\n\n\nbib_file &lt;- read.delim('bib/extractions.bib',\n           sep = '@', header = F)\n\n# get citekeys from bibtex file:\ncitekeys &lt;- unique(bib_file$V2)\n# improve formatting\ncitekeys &lt;- str_remove(citekeys, '\\\\{')\ncitekeys &lt;- str_remove(citekeys, ',')\ncitekeys &lt;- str_remove(citekeys, '%%.*$')\ncitekeys &lt;- str_remove(citekeys, 'Article')\ncitekeys[citekeys ==''] &lt;- NA\ncitekeys &lt;- na.omit(citekeys)\n\nR reads the .bib file as a two column data.frame, with the citation key appearing in the second column and the remaining metadata appearing in the first column. When the citation key appears in the second column, the corresponding row in the first column is blank. Because of this quirk, we can index metadata matching each citation key by keeping track of blank rows in the first column. We’ll append each to a new entry of a list. The name of each list entry is the citation key; the corresponding value is the remaining unprocessed metadata.\n\n# find where new entries begin:\nnew_entries = which(bib_file$V2 != '')\n\n# loop across unique indices for each entry\nmeta_list = list()\n# loop across unique indices for each entry\nmeta_list = list()\nfor(this_entry in 1:(length(new_entries)-1))\n{\n  # get unique citekey\n  this_cite_key &lt;- citekeys[this_entry]\n  # capture lines following citekey\n  corresponding_lines &lt;- bib_file[new_entries[this_entry]:new_entries[this_entry+1]-1,]$V1\n  # store matching lines as data frame\n  corresponding_lines &lt;- data.frame(corresponding_lines)\n  # assign lines distinct name\n  names(corresponding_lines) &lt;- this_cite_key\n  # add to a list for further processing\n  meta_list &lt;- append(meta_list, corresponding_lines)\n}"
  },
  {
    "objectID": "studies/library_parser.html#extracting-relevant-.bib-fields",
    "href": "studies/library_parser.html#extracting-relevant-.bib-fields",
    "title": "Library Parser",
    "section": "Extracting Relevant .bib Fields",
    "text": "Extracting Relevant .bib Fields\nNot every bibtex field is equally useful for analysis. To facilitate data manipulation, we can save the names of the target fields separately in a .txt file, and use a regular expression to create a new column each time R finds one of the target fields in a string containing the bibtex metadata.\n\n# read in target bibtex fields\nsearch_fields &lt;- field_names &lt;- readLines('bibtex_fields.txt')\n\n# match casing in bibtex file\nfield_names &lt;- toupper(field_names)\n# add a pattern allowing us to find text between two adjacent bibtex fields\nrep_pattern &lt;- paste0(field_names[1:length(field_names)-1], '\\\\s*(.*?)\\\\s')\n# apply this same pattern to all but the last of the field names                  \nfield_names[1:length(field_names)-1] &lt;- rep_pattern\n# collapse all the new field names into a single string for string manipulation with stringr\nfield_names[length(field_names)] &lt;- paste0(field_names[length(field_names)], '.*')\nfield_names &lt;- paste0(field_names, collapse = '')"
  },
  {
    "objectID": "studies/library_parser.html#prepare-dataframe",
    "href": "studies/library_parser.html#prepare-dataframe",
    "title": "Library Parser",
    "section": "Prepare dataframe",
    "text": "Prepare dataframe\nNow we can convert our list into a data frame with the target bibtex fields. For the last field MODEL_VALIDATION, we will apply a different regex pattern which matches all characters following the field name (?&lt;=MODEL_VALIDATION).* .\n\n# create new column containing information between two adjacent target fields for all entries in list\nmeta_df &lt;- lapply(meta_list, function(x) str_match(paste0(x, collapse = ' '), field_names))\nmeta_df &lt;- lapply(meta_list, function(x) str_match(paste0(x, collapse = ' '), field_names))\n\n# collapse list entries into rows\nmeta_df &lt;- do.call('rbind', meta_df)\n# format as a data.frame\nmeta_df &lt;- data.frame(meta_df)\n# match text after final column name\nmeta_df[,ncol(meta_df)+1] &lt;- sapply(meta_df[,1], function(x) str_match(paste0(x, collapse = ' '), '(?&lt;=FINAL_NOTES).*'))\n# replace first column with citationkeys\nmeta_df[,1] &lt;- names(meta_list)\nnames(meta_df) &lt;- c('citekey', search_fields)\nnames(meta_df) &lt;- trimws(names(meta_df))"
  },
  {
    "objectID": "studies/library_parser.html#formatting",
    "href": "studies/library_parser.html#formatting",
    "title": "Library Parser",
    "section": "Formatting",
    "text": "Formatting\nFinally, we’ll perform some formatting to remove unwanted characters left over following the conversion (in progress)\n\n## remove bibtext field formatting\n# remove curly braces\nmeta_df &lt;- apply(meta_df, 2, function(x) str_remove_all(x, '\\\\{')) \nmeta_df &lt;- apply(meta_df, 2, function(x) str_remove_all(x, '\\\\},'))\n# remove first '=' (from bibtex field )\nmeta_df &lt;- apply(meta_df, 2, function(x) str_remove(x, '='))\n# remove double-commas\n#meta_df &lt;- apply(meta_df, 2, function(x) str_remove_all(x, ',,'))\n# remove comments\nmeta_df &lt;- apply(meta_df, 2, function(x) str_remove_all(x, '%%.*'))\n#meta_df &lt;- apply(meta_df, 2, function(x) str_remove_all(x, ' , '))\n# remove extra characters in final column\nmeta_df[, ncol(meta_df)] = str_remove_all(meta_df[, ncol(meta_df)], '\\\\}')\nmeta_df &lt;- as.data.frame(meta_df)\n\nExample: Evaluate model_rate_emotion_values as R code\n\nsource(paste0(here::here(), \"/R/format-study-results.R\"))\neval(parse(text = meta_df$model_rate_emotion_values[22]))\n\n                                                          arousal_r2\nvarious.svr.mixed.classical.1                                 0.7249\nvarious.sparse bayesian regression.mixed.classical.1          0.7381\nvarious.variational bayesian regression.mixed.classical.1     0.7108\n                                                          arousal_variance explained\nvarious.svr.mixed.classical.1                                                 0.7556\nvarious.sparse bayesian regression.mixed.classical.1                          0.7395\nvarious.variational bayesian regression.mixed.classical.1                     0.7415\n                                                          valence_r2\nvarious.svr.mixed.classical.1                                 0.6119\nvarious.sparse bayesian regression.mixed.classical.1          0.6296\nvarious.variational bayesian regression.mixed.classical.1     0.6328\n                                                          valence_variance explained\nvarious.svr.mixed.classical.1                                                 0.6142\nvarious.sparse bayesian regression.mixed.classical.1                          0.6376\nvarious.variational bayesian regression.mixed.classical.1                     0.6340\n                                                          resonance_r2\nvarious.svr.mixed.classical.1                                   0.5374\nvarious.sparse bayesian regression.mixed.classical.1            0.5456\nvarious.variational bayesian regression.mixed.classical.1       0.5554\n                                                          resonance_variance explained\nvarious.svr.mixed.classical.1                                                   0.5496\nvarious.sparse bayesian regression.mixed.classical.1                            0.5558\nvarious.variational bayesian regression.mixed.classical.1                       0.5630"
  },
  {
    "objectID": "studies/library_parser.html#track-excluded-studies-during-extraction",
    "href": "studies/library_parser.html#track-excluded-studies-during-extraction",
    "title": "Library Parser",
    "section": "Track Excluded Studies (During Extraction)",
    "text": "Track Excluded Studies (During Extraction)\n\nmeta_df[which(str_detect(meta_df$final_notes, '!EXCL!')),] |&gt; dplyr::tibble()\n\n# A tibble: 9 × 28\n  citekey        paradigm notes_ca notes_te emotions emotion_locus stimulus_type\n  &lt;chr&gt;          &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;         &lt;chr&gt;        \n1 \"feng2024ex\"   \" class… \" inclu… \" inclu… \"    \"   \"    \"        \"    \"       \n2 \"nag2022on\"    \" class… \" inclu… \" inclu… \" happy… \"    \"        \"    \"       \n3 \"cao2023th\"    \" regre… \" inclu… \" inclu… \" valen… \" perceived … \" million so…\n4 \"malheiro2018… \" regre… \" inclu… \" inclu… \"    \"   \"    \"        \"    \"       \n5 \"medina2020em\" \" class… \" inclu… \" inclu… \" valen… \" perceived … \" MediaEval …\n6 \"panwar2019ar\" \" regre… \" inclu… \" inclu… \"    \"   \"    \"        \"    \"       \n7 \"vempala2024p… \" regre… \" inclu… \" inclu… \" valen… \" perceived … \" classical …\n8 \"xia2022st\"    \" regre… \" inclu… \" inclu… \"   \"    \"    \"        \"   \"        \n9 \"zhang2024ap\"  \" regre… \" inclu… \" inclu… \"    \"   \"    \"        \"    \"       \n# ℹ 21 more variables: stimulus_genre &lt;chr&gt;, stimulus_duration &lt;chr&gt;,\n#   stimulus_duration_unit &lt;chr&gt;, stimulus_n &lt;chr&gt;, feature_n &lt;chr&gt;,\n#   participant_n &lt;chr&gt;, participant_expertise &lt;chr&gt;, participant_origin &lt;chr&gt;,\n#   participant_sampling &lt;chr&gt;, participant_task &lt;chr&gt;,\n#   feature_categories &lt;chr&gt;, feature_source &lt;chr&gt;,\n#   feature_reduction_method &lt;chr&gt;, model_category &lt;chr&gt;, model_detail &lt;chr&gt;,\n#   model_measure &lt;chr&gt;, model_complexity_parameters &lt;chr&gt;, …\n\n\n\nmeta_df[-which(str_detect(meta_df$final_notes, '!EXCL!')),] -&gt; included_studies\n\nincluded_studies |&gt; dplyr::tibble()\n\n# A tibble: 37 × 28\n   citekey       paradigm notes_ca notes_te emotions emotion_locus stimulus_type\n   &lt;chr&gt;         &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;         &lt;chr&gt;        \n 1 agarwal2021an \" class… \" inclu… \" inclu… \" discr… \" perceived … \" Hindi musi…\n 2 alvarez2023ri \" class… \" inclu… \" inclu… \" discr… \" perceived … \" Spotify \"  \n 3 bai2017mu     \" class… \" inclu… \" inclu… \" valen… \" perceived … \" MediaEval …\n 4 bhuvanakumar… \" class… \" inclu… \" inclu… \" quadr… \" not specif… \" EMOPIA; po…\n 5 dufour2021us  \" class… \" inclu… \" inclu… \"  c1 (… \" perceived … \" pop, disco…\n 6 hizlisoy2021… \" class… \" inclu… \" inclu… \" valen… \" perceived … \" Turkish tr…\n 7 nguyen2017an  \" class… \" inclu… \" inclu… \" 288 e… \" perceived … \" pop  \"     \n 8 panda2020no   \" class… \" inclu… \" inclu… \" valen… \" perceived … \" AllMusic  \"\n 9 sorussa2020em \" class… \" inclu… \" inclu… \" valen… \" perceived … \" DEAM  \"    \n10 yang2021an    \" class… \" inclu… \" inclu… \" happy… \" perceived … \" MediaEval …\n# ℹ 27 more rows\n# ℹ 21 more variables: stimulus_genre &lt;chr&gt;, stimulus_duration &lt;chr&gt;,\n#   stimulus_duration_unit &lt;chr&gt;, stimulus_n &lt;chr&gt;, feature_n &lt;chr&gt;,\n#   participant_n &lt;chr&gt;, participant_expertise &lt;chr&gt;, participant_origin &lt;chr&gt;,\n#   participant_sampling &lt;chr&gt;, participant_task &lt;chr&gt;,\n#   feature_categories &lt;chr&gt;, feature_source &lt;chr&gt;,\n#   feature_reduction_method &lt;chr&gt;, model_category &lt;chr&gt;, model_detail &lt;chr&gt;, …"
  },
  {
    "objectID": "studies/library_parser.html#data-frame-expansion",
    "href": "studies/library_parser.html#data-frame-expansion",
    "title": "Library Parser",
    "section": "Data Frame Expansion",
    "text": "Data Frame Expansion\nNext we want to copy the number of rows for each of the bibtex cells requiring special nesting"
  },
  {
    "objectID": "studies/library_parser.html#sanity-check",
    "href": "studies/library_parser.html#sanity-check",
    "title": "Library Parser",
    "section": "Sanity check",
    "text": "Sanity check"
  },
  {
    "objectID": "studies/library_parser.html#print-output-of-all-studies",
    "href": "studies/library_parser.html#print-output-of-all-studies",
    "title": "Library Parser",
    "section": "Print output of all studies:",
    "text": "Print output of all studies:\n\n# low-level function to extract relevant values from named array\nmodel_result_2_df &lt;- function(x) {\n  # evaluate the expression\n  x &lt;- rlang::eval_tidy(rlang::parse_expr(x))\n  # get name of fitted models from column names\n  model_names &lt;- colnames(x)\n  # print(model_names)\n  # split across model name for summary statistic (e.g., mean, sd, etc.)\n  model_statistic &lt;- str_split(model_names, '\\\\.')\n  model_statistic &lt;- unlist(lapply(model_statistic, function(x) x[2]))\n  # get values\n  model_values &lt;- as.numeric(x)\n  # names(model_values) &lt;- 'score'\n  print(model_values)\n  # get additional attributes (feature.data.exp)\n  model_attributes &lt;- rownames(x)\n  data.frame(model_attributes)\n  # get additional model details\n  model_attributes &lt;- data.frame(do.call('rbind', str_split(model_attributes, '\\\\.')))\n  names(model_attributes) &lt;- c('library_id', 'model_id', 'feature_id', 'data_id', 'experiment_id')\n  print(names(model_attributes))\n  # split across '_' to \n  model_measures &lt;- data.frame(do.call('rbind', stringr::str_split(colnames(x), '_')))\n  print(model_measures)\n  names(model_measures) &lt;- c('dimension', 'measure')\n  model_measures_split &lt;- stringr::str_split(model_measures[,'measure'], '\\\\.')\n  model_measures[,'measure'] &lt;- unlist(lapply(model_measures_split, \n                                              function(x) x[1]))\n  return(data.frame(\n             model_attributes, \n             model_measures, \n             values = model_values,\n             statistic = model_statistic))\n}\n\n# high level function to apply model_result_2_df to multiple studies\nget_study_summaries &lt;- function(df) {\n  do.call(rbind,\n          lapply(df$model_rate_emotion_values, \n                 FUN = function(x) {\n                   study_id &lt;- unique(df$citekey[which(df$model_rate_emotion_values == x)])\n                   model_results &lt;- model_result_2_df(x)\n                   return(cbind(study_id, model_results))\n                   }\n                 )\n          )\n}"
  },
  {
    "objectID": "studies/pass3_comparison.html#load-libraries",
    "href": "studies/pass3_comparison.html#load-libraries",
    "title": "Pass 3 Comparison",
    "section": "Load libraries",
    "text": "Load libraries\n\n# load libraries\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(stringr)\nlibrary(knitr)"
  },
  {
    "objectID": "studies/pass3_comparison.html#read-data",
    "href": "studies/pass3_comparison.html#read-data",
    "title": "Pass 3 Comparison",
    "section": "Read data",
    "text": "Read data\n\n# read in bibtex library as data frame\nbib_df_merged &lt;- bib2df::bib2df('metaMER_library_third_pass_clean.bib')\n\nSome BibTeX entries may have been dropped.\n            The result could be malformed.\n            Review the .bib file and make sure every single entry starts\n            with a '@'."
  },
  {
    "objectID": "studies/pass3_comparison.html#compare",
    "href": "studies/pass3_comparison.html#compare",
    "title": "Pass 3 Comparison",
    "section": "Compare",
    "text": "Compare\n\n# check dimensions are accurate\ndim(bib_df_merged)\n\n[1] 96 47\n\n# distinguish notes with author initials\nnames(bib_df_merged)[names(bib_df_merged) == 'NOTES'] &lt;- 'NOTES.CA'\nnames(bib_df_merged)[names(bib_df_merged) == 'NOTES.1'] &lt;- 'NOTES.TE'\n\n# extract decisions less comments\ncapture_group &lt;- 'include|exclude|unsure'\n\n\n# create new index to track entries\nbib_df_merged$NOTES_INDEX.CA&lt;-NA\n\n# create new column tracking decisions\nbib_df_merged$NOTES_INDEX.CA &lt;- str_extract(tolower(bib_df_merged$NOTES.CA),\n                                         capture_group)\nbib_df_merged$NOTES_INDEX.TE &lt;- str_extract(tolower(bib_df_merged$NOTES.TE),\n                                     capture_group)\n\n# check entries are consistent\nsum(is.na(bib_df_merged$NOTES_INDEX.CA))\n\n[1] 0\n\nsum(is.na(bib_df_merged$NOTES_INDEX.TE))\n\n[1] 0"
  },
  {
    "objectID": "studies/pass3_comparison.html#report-annotation-reliabilityagreement",
    "href": "studies/pass3_comparison.html#report-annotation-reliabilityagreement",
    "title": "Pass 3 Comparison",
    "section": "Report annotation reliability/agreement",
    "text": "Report annotation reliability/agreement\n\n# compare raters' decisions with confusion matrix\nt&lt;-table(bib_df_merged$NOTES_INDEX.CA,\n         bib_df_merged$NOTES_INDEX.TE)\n\n# get agreement\nt2&lt;-round(t/sum(t),2)\nag_before &lt;- sum(diag(t2))\n\n# make table\nknitr::kable(t,  \n             caption = paste('Votes before discussion. \\n\n             Rows: CA votes; cols: TE votes, Agreement = ', ag_before)\n             )\n\nTable: Votes before discussion.\n         Rows: CA votes; cols: TE votes, Agreement =  0.73\n\n\n\n\nexclude\ninclude\nunsure\n\n\n\n\nexclude\n24\n8\n2\n\n\ninclude\n4\n45\n1\n\n\nunsure\n10\n1\n1"
  },
  {
    "objectID": "studies/pass3_comparison.html#ca-unsure",
    "href": "studies/pass3_comparison.html#ca-unsure",
    "title": "Pass 3 Comparison",
    "section": "CA: unsure",
    "text": "CA: unsure\n\n# resolve unsure ones\nIND &lt;- which(bib_df_merged$NOTES_INDEX.CA=='unsure')\nresolved_index &lt;- bib_df_merged$BIBTEXKEY[IND] # 12\n# CA updates ratings:\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'deng2024an'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'hao2022re'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'he2022al'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'huang2023th'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'priscillajoy2023mu'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'shen2024re'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'wang2021mu'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'wang2021re'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'wang2022mua'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'zhang2016rea'] &lt;- 'exclude'\n\n# both CA and TE update ratings:\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'na2022mu'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.TE[bib_df_merged$BIBTEXKEY == 'na2022mu'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'tian2023mu'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.TE[bib_df_merged$BIBTEXKEY == 'tian2023mu'] &lt;- 'exclude'\n\n# resolved &lt;-c('deng2024an' = 'exclude',\n#              'hao2022re' = 'exclude',\n#              'he2022al' = 'exclude',\n#              'huang2023th' = 'exclude',\n#              'na2022mu' = 'exclude',\n#              'priscillajoy2023mu' = 'exclude',\n#              'shen2024re' = 'exclude',\n#              'tian2023mu' = 'exclude',\n#              'wang2021mu' = 'exclude',\n#              'wang2021re' = 'exclude',\n#              'wang2022mua' = 'exclude',\n#              'zhang2016rea' = 'exclude')"
  },
  {
    "objectID": "studies/pass3_comparison.html#te-unsure-in-progress",
    "href": "studies/pass3_comparison.html#te-unsure-in-progress",
    "title": "Pass 3 Comparison",
    "section": "TE: unsure (in progress)",
    "text": "TE: unsure (in progress)\n\n# update TE decision\nbib_df_merged$NOTES_INDEX.TE[bib_df_merged$BIBTEXKEY == 'tang2023ap'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.TE[bib_df_merged$BIBTEXKEY == 'xing2015em'] &lt;- 'exclude'\n\n# update TE and CA decisions\nbib_df_merged$NOTES_INDEX.TE[bib_df_merged$BIBTEXKEY == 'wang2022mu'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'wang2022mu'] &lt;- 'exclude'"
  },
  {
    "objectID": "studies/pass3_comparison.html#summary",
    "href": "studies/pass3_comparison.html#summary",
    "title": "Pass 3 Comparison",
    "section": "Summary",
    "text": "Summary\n\n\n\n\n\n\n\n\n\nStudy\nCA\nTE\n\n\n\n\n\ntang2023ap\nuses image features\nNo relevant features, lack of stimulus detail\nExclude\n\n\nxing2015em\nincludes classification task\nNo N of musical excerpts, missing information regarding data processing\nExclude\n\n\nwang2022mu\nonly reports DET and equal error rate\nAlthough they report correlation coefficients, emotions are not valence or arousal. Do report MSE of classification task\nExclude"
  },
  {
    "objectID": "studies/pass3_comparison.html#tabulate-results-after-resolving-unsures",
    "href": "studies/pass3_comparison.html#tabulate-results-after-resolving-unsures",
    "title": "Pass 3 Comparison",
    "section": "Tabulate results after resolving unsures",
    "text": "Tabulate results after resolving unsures\n\n# compare raters' decisions with confusion matrix\nt&lt;-table(bib_df_merged$NOTES_INDEX.CA,\n         bib_df_merged$NOTES_INDEX.TE)\n\n# get agreement\nt2&lt;-round(t/sum(t),2)\nag_before &lt;- sum(diag(t2))\n\n# make table\nknitr::kable(t,  \n             caption = paste('Votes after resolving unsure discrepancies. \\n\n             Rows: CA votes; cols: TE votes, Agreement = ', ag_before)\n             )\n\nTable: Votes after resolving unsure discrepancies.\n         Rows: CA votes; cols: TE votes, Agreement =  0.88\n\n\n\n\nexclude\ninclude\n\n\n\n\nexclude\n39\n8\n\n\ninclude\n4\n45"
  },
  {
    "objectID": "studies/pass3_comparison.html#ca-exclude-te-include",
    "href": "studies/pass3_comparison.html#ca-exclude-te-include",
    "title": "Pass 3 Comparison",
    "section": "CA: exclude, TE: include",
    "text": "CA: exclude, TE: include\n\n# Resolving conflicting exclude/include annotations, part 1\nIND &lt;- which(bib_df_merged$NOTES_INDEX.CA=='exclude' & \n  bib_df_merged$NOTES_INDEX.TE=='include')\n# check discrepant entries\nresolved_exclude_index &lt;- bib_df_merged$BIBTEXKEY[IND]\nresolved_exclude_index # 8\n\n[1] \"aljanaki2017de\"          \"li2024im\"               \n[3] \"pandeya2024gl\"           \"saizclar2022pr\"         \n[5] \"sanmillancastillo2022an\" \"wang2015mo\"             \n[7] \"wang2016af\"              \"yang2023ex\"             \n\n# update TE votes to exclude\nbib_df_merged$NOTES_INDEX.TE[bib_df_merged$BIBTEXKEY == 'aljanaki2017de'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.TE[bib_df_merged$BIBTEXKEY == 'li2024im'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.TE[bib_df_merged$BIBTEXKEY == 'pandeya2024gl'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.TE[bib_df_merged$BIBTEXKEY == 'sanmillancastillo2022an'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.TE[bib_df_merged$BIBTEXKEY == 'wang2015mo'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.TE[bib_df_merged$BIBTEXKEY == 'wang2016af'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.TE[bib_df_merged$BIBTEXKEY == 'yang2023ex'] &lt;- 'exclude'\n# update CA votes to include\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'saizclar2022pr'] &lt;- 'include'\n\n\n# resolved_exclude &lt;-c('aljanaki2017de' = 'exclude',\n#                      'li2024im' = 'exclude',\n#                      'pandeya2024gl' = 'exclude',\n#                      'saizclar2022pr' = 'include',\n#                      'sanmillancastillo2022an' = 'exclude',\n#                      'wang2015mo' = 'exclude',\n#                      'wang2016af' = 'exclude',\n#                      'yang2023ex' = 'exclude')"
  },
  {
    "objectID": "studies/pass3_comparison.html#summary-1",
    "href": "studies/pass3_comparison.html#summary-1",
    "title": "Pass 3 Comparison",
    "section": "Summary",
    "text": "Summary\n\nCA: exclude, TE: include\n\n\n\n\n\n\n\n\n\nStudy\nCA\nTE\nResolution/Decision\n\n\n\n\naljanaki2017de\nMultiple teams’ performance reported\nPossible to report teams as substudies\nExclude: Benchmark, does not contain original study details from reporting team\n\n\nli2024im\nNo relevant task\nReports classification accuracy and DEAM results\nExclude: No audio features reported\n\n\npandeya2024gl\nInsufficient detail for meta-analysis\nIncludes timbre and global audio features, confusion matrix included\nExclude: Reporting on music videos; quality issues in data set\n\n\nsaizclar2022pr\nNo modeling task\nModeling is based on onsets\nInclude: although no cross-validation, still performed task\n\n\nsanmillancastillo2022an\nNo music\nTask present\nExclude: No music\n\n\nwang2015mo\nNo relevant task\nNot sure of outcome measures\nExclude: No translation of distances into VA accuracy\n\n\nwang2016af\nChapter\nIncludes relevant task\nExclude: Meets exclusion criteria (not an article)\n\n\nyang2023ex\nNo relevant task\nFinal metrics missing\nExclude: Collected VA emotion ratings, but don’t use audio features to predict VA (not reported)"
  },
  {
    "objectID": "studies/pass3_comparison.html#te-exclude-ca-include",
    "href": "studies/pass3_comparison.html#te-exclude-ca-include",
    "title": "Pass 3 Comparison",
    "section": "TE: exclude, CA: include",
    "text": "TE: exclude, CA: include\n\n# Resolving conflicting exclude/include annotations, part 2\nIND &lt;- which(bib_df_merged$NOTES_INDEX.TE=='exclude' & \n               bib_df_merged$NOTES_INDEX.CA=='include')\n\n# check discrepant entries\nresolved_exclude2_index &lt;- bib_df_merged$BIBTEXKEY[IND]\nresolved_exclude2_index # 4\n\n[1] \"cunningham2021su\" \"eyben2015em\"      \"tian2023mua\"      \"tiple2022mu\"     \n\n# update CA votes\n\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'cunningham2021su'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'eyben2015em'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'tian2023mua'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'tiple2022mu'] &lt;- 'exclude'\n\n# resolved_exclude2 &lt;-c('cunningham2021su' = 'exclude',\n#                       'eyben2015em' = 'exclude',\n#                       'tian2023mua' = 'exclude',\n#                       'tiple2022mu' = 'exclude')"
  },
  {
    "objectID": "studies/pass3_comparison.html#summary-2",
    "href": "studies/pass3_comparison.html#summary-2",
    "title": "Pass 3 Comparison",
    "section": "Summary",
    "text": "Summary\n\n\n\n\n\n\n\n\n\nStudy\nTE\nCA\nResolution/Decision\n\n\n\n\ncunningham2021su\nReports on IADS (not music)\nRelevant task\nExclude: No music\n\n\neyben2015em\nFocused on laboratory singing\nRelevant task\nExclude: Laboratory singing of a scale\n\n\ntiple2022mu\nData set just includes annotation of tonic pitch\nRelevant task, but only reports overall accuracy\nExclude: Data set not sufficiently detailed for MER task"
  },
  {
    "objectID": "studies/pass3_comparison.html#update-table-after-resolving-disagreements",
    "href": "studies/pass3_comparison.html#update-table-after-resolving-disagreements",
    "title": "Pass 3 Comparison",
    "section": "Update table after resolving disagreements",
    "text": "Update table after resolving disagreements\n\n# compare raters' decisions with confusion matrix\nt&lt;-table(bib_df_merged$NOTES_INDEX.CA,\n         bib_df_merged$NOTES_INDEX.TE)\n\n# get agreement\nt2&lt;-round(t/sum(t),2)\nag_before &lt;- sum(diag(t2))\n\n# make table\nknitr::kable(t,  \n             caption = paste('Votes after resolving include vs. exclude discrepancies. \\n\n             Rows: CA votes; cols: TE votes, Agreement = ', ag_before)\n             )\n\nTable: Votes after resolving include vs. exclude discrepancies.\n         Rows: CA votes; cols: TE votes, Agreement =  1\n\n\n\n\nexclude\ninclude\n\n\n\n\nexclude\n50\n0\n\n\ninclude\n0\n46"
  },
  {
    "objectID": "studies/pass3_comparison.html#track-task-types",
    "href": "studies/pass3_comparison.html#track-task-types",
    "title": "Pass 3 Comparison",
    "section": "Track task types",
    "text": "Track task types\n\n# add column tracking task type\nbib_df_merged$PARADIGM &lt;- 'regression'\nbib_df_merged[str_detect(bib_df_merged$NOTES.CA, 'classification'),]$PARADIGM &lt;- 'classification'\n\n# sort by task\nbib_df_merged &lt;- bib_df_merged[order(bib_df_merged$PARADIGM),]\n\n# put rater notes side-by-side\nNOTES.CA &lt;- bib_df_merged$NOTES.CA\nNOTES.TE &lt;- bib_df_merged$NOTES.TE\nbib_df_merged$NOTES.CA &lt;- NULL\nbib_df_merged$NOTES.TE &lt;- NULL\nbib_df_merged$NOTES_CA&lt;-NOTES.CA\nbib_df_merged$NOTES_TE&lt;-NOTES.TE"
  },
  {
    "objectID": "studies/pass3_comparison.html#add-fields-for-annotation",
    "href": "studies/pass3_comparison.html#add-fields-for-annotation",
    "title": "Pass 3 Comparison",
    "section": "Add fields for annotation",
    "text": "Add fields for annotation\n\n# add new fields for annotating bibtex library\nbib_df_merged %&gt;% mutate(emotions = ' ',\n                         emotion_locus = ' ',\n                         stimulus_type = ' ',\n                         stimulus_duration = ' ',\n                         stimulus_duration_unit = ' ',\n                         stimulus_N = ' ',\n                         feature_N = ' ',\n                         participant_N = ' ',\n                         participant_expertise = ' ',\n                         participant_origin = ' ',\n                         participant_sampling = ' ',\n                         participant_task = ' ',\n                         feature_N = ' ',\n                         feature_categories = ' ',\n                         feature_source = ' ',\n                         feature_reduction_method = ' ',\n                         model_category = ' ',\n                         model_detail = ' ',\n                         model_measure = ' ',\n                         model_complexity_parameters = ' ',\n                         model_rate_emotion_names = ' ',\n                         model_rate_emotion_values = ' ',\n                         model_validation = ' ',\n                         final_decision = NOTES_INDEX.CA) -&gt; bib_df_merged"
  },
  {
    "objectID": "studies/pass3_comparison.html#export-bibtex-for-the-annotation",
    "href": "studies/pass3_comparison.html#export-bibtex-for-the-annotation",
    "title": "Pass 3 Comparison",
    "section": "Export bibtex for the annotation",
    "text": "Export bibtex for the annotation\n\nbib_df_merged$NOTES_INDEX.CA &lt;- NULL\nbib_df_merged$NOTES_INDEX.TE &lt;- NULL"
  },
  {
    "objectID": "studies/pass3_comparison.html#get-included-studies",
    "href": "studies/pass3_comparison.html#get-included-studies",
    "title": "Pass 3 Comparison",
    "section": "Get included studies",
    "text": "Get included studies\n\nbib_df_merged &lt;- subset(bib_df_merged, final_decision == 'include')\nbib_df_merged$final_decision &lt;- NULL"
  },
  {
    "objectID": "studies/pass3_comparison.html#write-resulting-bibtex-library",
    "href": "studies/pass3_comparison.html#write-resulting-bibtex-library",
    "title": "Pass 3 Comparison",
    "section": "Write resulting bibtex library",
    "text": "Write resulting bibtex library\n\nbib2df::df2bib(bib_df_merged, file = 'metaMER_library_template.bib')\n\nNotes:\nFor Feature classification, use this one:\nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9229494\nInsert the template the annotation fields from googledoc to the bibtex file."
  },
  {
    "objectID": "studies/search_syntax.html",
    "href": "studies/search_syntax.html",
    "title": "Search Syntax",
    "section": "",
    "text": "We first performed search through three databases using the following syntax for each.\n\n\n\n\n\n\n\n\n\nDatabase\nDate\nResults\nSearch syntax\n\n\n\n\nScopus\n12 May 2024\n227\nTITLE-ABS-KEY ( valence OR arousal OR classi OR categor OR algorithm AND music AND emotion AND recognition ) AND PUBYEAR &gt; 2013 AND PUBYEAR &lt; 2025 AND ( LIMIT-TO ( DOCTYPE , \"ar\" ) )\n\n\nWeb of Science\n12 May 2024\n142\n(DT=(Article) AND PY=(2014-2025)) AND ALL=(music emotion recognition valence arousal)\n\n\nOpen Alex\n12 May 2024\n278\nhttps://openalex.org/works?page=1&filter=default.search%3Amusic%20emotion%20recognition%20valence%20arousal,type%3Atypes%2Farticle, publication_year%3A2014-2024, keywords.id%3Akeywords%2Femotion-recognition, keywords.id%3Akeywords%2Faffective-computing, language%3Alanguages%2Fen,open_access.any_repository_has_fulltext%3Atrue"
  },
  {
    "objectID": "studies/search_syntax.html#second-pass-assessment-of-relevant-content",
    "href": "studies/search_syntax.html#second-pass-assessment-of-relevant-content",
    "title": "Search Syntax",
    "section": "Second pass: Assessment of relevant content",
    "text": "Second pass: Assessment of relevant content\nOut of the studies identified in the first pass, a closer look at the priority 2 studies using the criteria established [link to prereg] was carried out."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "README",
    "section": "",
    "text": "How well we can predict emotions in music? What is the evidence in the published literature for explaining what emotions the listeners can perceive in music when the source consists of audio examples. To what degree the results are dependent on the actual models, emotions, musical/acoustic features, or musical materials or participants?\nTo obtain answers to these questions, we have set out to record and analyse the current state of the art from the literature using a meta-analysis paradigm. We focus on Music Emotion Recognition and hence the acronym metaMER.\nThe public-facing version of the repository is available at https://tuomaseerola.github.io/metaMER/\n\n\nWe define the aims and methods in preregistration plan, which has beeb preregistered at https://osf.io/6y3dr/.\n\n\nSearch databases and criteria are documented in studies/search_syntax.qmd.\n\n\n\nData extraction is described in extraction details. See also pass3 comparison.\nThe data will be parsed to a tabular format using a custom library_parser.qmd.\n\n\n\nData analysis is covered in analysis/analysis.qmd document.\n\n\n\nThe study report is available manuscript/manuscript.qmd document."
  },
  {
    "objectID": "index.html#plan",
    "href": "index.html#plan",
    "title": "README",
    "section": "",
    "text": "We define the aims and methods in preregistration plan, which has beeb preregistered at https://osf.io/6y3dr/.\n\n\nSearch databases and criteria are documented in studies/search_syntax.qmd.\n\n\n\nData extraction is described in extraction details. See also pass3 comparison.\nThe data will be parsed to a tabular format using a custom library_parser.qmd.\n\n\n\nData analysis is covered in analysis/analysis.qmd document.\n\n\n\nThe study report is available manuscript/manuscript.qmd document."
  },
  {
    "objectID": "analysis/analysis.html",
    "href": "analysis/analysis.html",
    "title": "Analysis",
    "section": "",
    "text": "This assumes that the data has been parsed (parse-model-output.R, format-study-results.R) and preprocessed (processing.qmd).\n\n\n\n\nFor creating Table 2\n\nlibrary(dmetar,quietly = TRUE)\nlibrary(tidyverse,quietly = TRUE)\nlibrary(meta)\nlibrary(DescTools)\nlibrary(ggrepel)\n\n\n\n\nR_studies &lt;- read.csv(\"R_studies.csv\")\n#R_summary &lt;- read.csv(\"R_summary.csv\")\n\n# select regression studies with r2\n#tmp &lt;- dplyr::filter(R_summary,dimension==\"valence\")\ntmp &lt;- dplyr::filter(R_studies,dimension==\"valence\")\n#dim(tmp)\n\n#if all studies, remove two with NA values\ntmp &lt;- tmp[!is.na(tmp$values),]\n#dim(tmp)\n\n# Take all models\nm.cor &lt;- metacor(cor = values,     # values \n                 n = stimulus_n,\n                 studlab = unique_id,\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"PM\",# was REML, but we switch to Paule-Mandel because Langan et al., 2019\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\n\nprint(m.cor)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 118\nNumber of observations: o = 71645\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.5734 [0.5365; 0.6081] 24.24 &lt; 0.0001\nPrediction interval         [0.0853; 0.8395]               \n\nQuantifying heterogeneity:\n tau^2 = 0.0812 [0.0627; 0.1087]; tau = 0.2850 [0.2503; 0.3297]\n I^2 = 97.3% [97.0%; 97.5%]; H = 6.05 [5.78; 6.34]\n\nTest of heterogeneity:\n       Q d.f. p-value\n 4286.61  117       0\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Paule-Mandel estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 117)\n- Prediction interval based on t-distribution (df = 116)\n- Fisher's z transformation of correlations\n\nprint(FisherZInv(m.cor$TE.random))\n\n[1] 0.5733695\n\nprint(FisherZInv(m.cor$upper.random))\n\n[1] 0.608064\n\nprint(FisherZInv(m.cor$lower.random))\n\n[1] 0.5364891\n\n\n\n\n\n\nR_summary &lt;- read.csv(\"R_summary.csv\")\n\n# select regression studies with r2\ntmp &lt;- dplyr::filter(R_summary,dimension==\"valence\")\n#tmp &lt;- dplyr::filter(R_studies,dimension==\"valence\")\n#dim(tmp)\n\n#if all studies, remove two\n#tmp &lt;- tmp[!is.na(tmp$values),]\n#dim(tmp)\n\n## Disambiguate the studies\ntmp$studyREF[tmp$studyREF==\"Wang et al 2022\"] &lt;- c(\"Wang et al. 2022a\",\"Wang et al. 2022b\")\n\n# Max values\nm.cor &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = studyREF,#citekey, # unique_id\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\n\nprint(m.cor)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 23\nNumber of observations: o = 14640\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.6739 [0.5782; 0.7513] 10.73 &lt; 0.0001\nPrediction interval         [0.0659; 0.9170]               \n\nQuantifying heterogeneity:\n tau^2 = 0.1249 [0.0720; 0.2617]; tau = 0.3534 [0.2683; 0.5115]\n I^2 = 97.9% [97.4%; 98.3%]; H = 6.86 [6.23; 7.56]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1036.47   22 &lt; 0.0001\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 22)\n- Prediction interval based on t-distribution (df = 21)\n- Fisher's z transformation of correlations\n\nprint(FisherZInv(m.cor$TE.random))\n\n[1] 0.6738887\n\nprint(FisherZInv(m.cor$upper.random))\n\n[1] 0.7513007\n\nprint(FisherZInv(m.cor$lower.random))\n\n[1] 0.5781846\n\n\n\n\n\n\n\n# Method 1: Give us the Egger's test about beta coefficient from funnel\nprint(eggers.test(m.cor))\n\nEggers' test of the intercept \n============================= \n\n intercept        95% CI     t          p\n     4.769 -0.48 - 10.02 1.781 0.08942195\n\nEggers' test does not indicate the presence of funnel plot asymmetry. \n\n# Method 2: Find the impact to the results when removing those outside the 95CI\nO &lt;- find.outliers(m.cor) # 13 remaining out of 24\nprint(O)\n\nIdentified outliers (random-effects model) \n------------------------------------------ \n\"Battcock et al 2021\", \"Chen et al 2017\", \"Griffiths et al 2021\", \"Hu et al 2017\", \"Koh et al 2023\", \"Wang et al. 2022a\", \"Wang et al. 2022b\", \"Zhang et al 2019\", \"Zhang et al 2023\" \n \nResults with outliers removed \n----------------------------- \nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 14\nNumber of observations: o = 7638\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.6645 [0.6094; 0.7132] 18.63 &lt; 0.0001\nPrediction interval         [0.4468; 0.8079]               \n\nQuantifying heterogeneity:\n tau^2 = 0.0198 [0.0083; 0.0656]; tau = 0.1406 [0.0908; 0.2562]\n I^2 = 87.3% [80.3%; 91.8%]; H = 2.80 [2.26; 3.48]\n\nTest of heterogeneity:\n      Q d.f.  p-value\n 102.16   13 &lt; 0.0001\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 13)\n- Prediction interval based on t-distribution (df = 12)\n- Fisher's z transformation of correlations\n\n# Method 3: Leave-out-out analysis etc for individual influence (not useful here)\n#infan &lt;- InfluenceAnalysis(m.cor)\n\n# Method 4: Focus on 10% of most precise studies (Stanley, Jarrel, Doucouliagos 2010)\nthres&lt;-quantile(m.cor$seTE,0.1)\nind&lt;-m.cor$seTE&lt;=as.numeric(thres)\nm.cor10pct &lt;- update(m.cor, subset = which(ind))\n\n# Method 5: P curve analysis (Simonsohn, Simmons & Nelson, 2015)\npcurve(m.cor)\n\n\n\n\n\n\n\n\nP-curve analysis \n ----------------------- \n- Total number of provided studies: k = 23 \n- Total number of p&lt;0.05 studies included into the analysis: k = 22 (95.65%) \n- Total number of studies with p&lt;0.025: k = 22 (95.65%) \n   \nResults \n ----------------------- \n                    pBinomial   zFull pFull   zHalf pHalf\nRight-skewness test         0 -33.754     0 -33.255     0\nFlatness test               1  33.628     1  33.907     1\nNote: p-values of 0 or 1 correspond to p&lt;0.001 and p&gt;0.999, respectively.   \nPower Estimate: 99% (99%-99%)\n   \nEvidential value \n ----------------------- \n- Evidential value present: yes \n- Evidential value absent/inadequate: no \n\n\n\n\n\n\nfig2a &lt;- forest(m.cor,\n       sortvar = TE,\n       prediction = FALSE, \n             print.tau2 = FALSE,\n             leftlabs = c(\"Author\", \"g\", \"SE\"),studlab = studyREF)\n\n\n\n\n\n\n\nfig2b&lt;-funnel(m.cor, common = FALSE, studlab=TRUE,backtransf=TRUE)\n\n\n\n\n\n\n\nlibrary(forestplot)\n\nLoading required package: grid\n\n\nLoading required package: checkmate\n\n\nLoading required package: abind\n\ndata&lt;-tibble::tibble(mean=m.cor$cor,lower=FisherZInv(m.cor$lower),upper=FisherZInv(m.cor$upper),study=m.cor$studlab,n=m.cor$n,cor=round(m.cor$cor,2))\ndata&lt;-dplyr::arrange(data,mean)\n\nfp1 &lt;- grid.grabExpr(print(data |&gt;\n  forestplot(labeltext = c(study, n, cor),\n             xlab = \"Correlation\",\n             xticks = c(0, .25,.5,.75, 1),\n             clip = c(0, 1))|&gt;\n    fp_add_header(study = \"Study\",n = \"N\",cor = expression(italic(r))) |&gt;\n    fp_append_row(mean  = m.cor$TE.common,\n                lower = m.cor$lower.common,\n                upper = m.cor$upper.common,\n                study = \"Summary\",\n                n = sum(m.cor$n),\n                cor = round(m.cor$TE.common,2),\n                is.summary = TRUE) |&gt;\n  fp_set_style(box = \"grey50\",\n               line = \"grey20\",\n               summary = \"black\",\n                txt_gp = fpTxtGp(label = list(gpar(cex = 0.80)),\n                                ticks = gpar(cex = 0.80),\n                                xlab  = gpar(cex = 0.80)))|&gt;\n    fp_decorate_graph(grid = structure( m.cor$TE.common,gp = gpar(lty = 2, col = \"grey30\")))\n)\n)\n\nsource('../etc/custom_funnel_plot.R')\nfp2 &lt;- custom_funnel_plot(m.cor)\n\ngridExtra::grid.arrange(fp1, fp2, ncol=2, widths=c(2,1),heights=c(2,1))\n\nWarning: Removed 684 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\nWarning: Removed 767 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nS &lt;- summarise(group_by(tmp,model_class_id),n=n(),obs=sum(stimulus_n))\nprint(knitr::kable(S))\n\n\n\nmodel_class_id\nn\nobs\n\n\n\n\nFlexible Discriminants\n6\n4993\n\n\nKernel Smoothing, Additive and KNN\n2\n2582\n\n\nLinear Methods\n8\n1762\n\n\nNeural Nets\n3\n1229\n\n\nRandom Forests\n4\n4074\n\n\n\n\nm.cor1 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  model_class_id,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\nprint(m.cor1)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 23\nNumber of observations: o = 14640\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.6739 [0.5782; 0.7513] 10.73 &lt; 0.0001\nPrediction interval         [0.0659; 0.9170]               \n\nQuantifying heterogeneity:\n tau^2 = 0.1249 [0.0720; 0.2617]; tau = 0.3534 [0.2683; 0.5115]\n I^2 = 97.9% [97.4%; 98.3%]; H = 6.86 [6.23; 7.56]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1036.47   22 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                                                      k    COR\nmodel_class_id = Kernel Smoothing, Additive and KNN   2 0.4662\nmodel_class_id = Random Forests                       4 0.7024\nmodel_class_id = Linear Methods                       8 0.7840\nmodel_class_id = Flexible Discriminants               6 0.6555\nmodel_class_id = Neural Nets                          3 0.3933\n                                                               95%-CI  tau^2\nmodel_class_id = Kernel Smoothing, Additive and KNN [-0.6342; 0.9424] 0.0185\nmodel_class_id = Random Forests                     [ 0.3914; 0.8694] 0.0803\nmodel_class_id = Linear Methods                     [ 0.6249; 0.8806] 0.1370\nmodel_class_id = Flexible Discriminants             [ 0.4838; 0.7786] 0.0574\nmodel_class_id = Neural Nets                        [-0.3553; 0.8345] 0.0929\n                                                       tau      Q   I^2\nmodel_class_id = Kernel Smoothing, Additive and KNN 0.1361  20.56 95.1%\nmodel_class_id = Random Forests                     0.2833 198.79 98.5%\nmodel_class_id = Linear Methods                     0.3701 195.78 96.4%\nmodel_class_id = Flexible Discriminants             0.2396 161.22 96.9%\nmodel_class_id = Neural Nets                        0.3049  56.87 96.5%\n\nTest for subgroup differences (random effects model):\n                   Q d.f. p-value\nBetween groups 15.09    4  0.0045\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 22)\n- Prediction interval based on t-distribution (df = 21)\n- Fisher's z transformation of correlations\n\n\n\n\n\nS &lt;- summarise(group_by(tmp,journal_type),n=n(),obs=sum(stimulus_n))\nprint(knitr::kable(S))\n\n\n\njournal_type\nn\nobs\n\n\n\n\nEngineering\n15\n11490\n\n\nPsychology\n8\n3150\n\n\n\n\nm.cor2 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  journal_type,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\nprint(m.cor2)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 23\nNumber of observations: o = 14640\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.6739 [0.5782; 0.7513] 10.73 &lt; 0.0001\nPrediction interval         [0.0659; 0.9170]               \n\nQuantifying heterogeneity:\n tau^2 = 0.1249 [0.0720; 0.2617]; tau = 0.3534 [0.2683; 0.5115]\n I^2 = 97.9% [97.4%; 98.3%]; H = 6.86 [6.23; 7.56]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1036.47   22 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                             k    COR           95%-CI  tau^2    tau      Q\njournal_type = Engineering  15 0.6424 [0.5112; 0.7444] 0.1208 0.3475 644.85\njournal_type = Psychology    8 0.7323 [0.5491; 0.8484] 0.1334 0.3653 385.42\n                             I^2\njournal_type = Engineering 97.8%\njournal_type = Psychology  98.2%\n\nTest for subgroup differences (random effects model):\n                  Q d.f. p-value\nBetween groups 1.11    1  0.2919\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 22)\n- Prediction interval based on t-distribution (df = 21)\n- Fisher's z transformation of correlations\n\n\n\n\n\ntmp &lt;- dplyr::filter(R_summary,dimension==\"valence\")\ntmp&lt;-tmp[!is.na(tmp$feature_n_categories),] # remove \nS &lt;- summarise(group_by(tmp,feature_n_categories),n=n(),obs=sum(stimulus_n))\nprint(knitr::kable(S))\n\n\n\nfeature_n_categories\nn\nobs\n\n\n\n\nFeature n &lt; 18\n5\n3036\n\n\nFeature n &gt; 18 & &lt; 260\n11\n7042\n\n\nFeature n &gt; 260\n7\n4562\n\n\n\n\ntmp &lt;- dplyr::filter(R_summary,dimension==\"valence\")\ntmp&lt;-tmp[!is.na(tmp$feature_n_categories),] # remove missing values\nm.cor3 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  feature_n_categories,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\nprint(m.cor3)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 23\nNumber of observations: o = 14640\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.6739 [0.5782; 0.7513] 10.73 &lt; 0.0001\nPrediction interval         [0.0659; 0.9170]               \n\nQuantifying heterogeneity:\n tau^2 = 0.1249 [0.0720; 0.2617]; tau = 0.3534 [0.2683; 0.5115]\n I^2 = 97.9% [97.4%; 98.3%]; H = 6.86 [6.23; 7.56]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1036.47   22 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                                                k    COR           95%-CI\nfeature_n_categories = Feature n &gt; 260          7 0.6845 [0.5660; 0.7752]\nfeature_n_categories = Feature n &lt; 18           5 0.8111 [0.5342; 0.9308]\nfeature_n_categories = Feature n &gt; 18 & &lt; 260  11 0.5843 [0.4076; 0.7187]\n                                               tau^2    tau      Q   I^2\nfeature_n_categories = Feature n &gt; 260        0.0435 0.2085 211.87 97.2%\nfeature_n_categories = Feature n &lt; 18         0.1815 0.4260 362.55 98.9%\nfeature_n_categories = Feature n &gt; 18 & &lt; 260 0.1089 0.3300 295.76 96.6%\n\nTest for subgroup differences (random effects model):\n                  Q d.f. p-value\nBetween groups 4.66    2  0.0974\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 22)\n- Prediction interval based on t-distribution (df = 21)\n- Fisher's z transformation of correlations\n\nS&lt;-summarise(group_by(tmp,feature_n_categories),n=n(),obs=sum(stimulus_n))\nprint(S)\n\n# A tibble: 3 × 3\n  feature_n_categories       n   obs\n  &lt;chr&gt;                  &lt;int&gt; &lt;int&gt;\n1 Feature n &lt; 18             5  3036\n2 Feature n &gt; 18 & &lt; 260    11  7042\n3 Feature n &gt; 260            7  4562\n\n\n\n\n\ntmp &lt;- dplyr::filter(R_summary,dimension==\"valence\")\ntmp&lt;-tmp[!is.na(tmp$feature_n_categories),] # removemissing values\n\nS&lt;-summarise(group_by(tmp,feature_n_complexity_genre),n=n(),obs=sum(stimulus_n))\nprint(knitr::kable(S))\n\n\n\nfeature_n_complexity_genre\nn\nobs\n\n\n\n\nHuge multigenre study\n2\n1068\n\n\nMedium single genre/multigenre study\n14\n7854\n\n\nMedium-large single genre/multigenre study\n4\n2750\n\n\nSmall single genre study\n3\n2968\n\n\n\nm.cor4 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  feature_n_complexity_genre,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\nprint(m.cor4)\nReview: MER: Regression: Valence: Summary\nNumber of studies: k = 23 Number of observations: o = 14640\n                    COR           95%-CI     t  p-value\nRandom effects model 0.6739 [0.5782; 0.7513] 10.73 &lt; 0.0001 Prediction interval [0.0659; 0.9170]\nQuantifying heterogeneity: tau^2 = 0.1249 [0.0720; 0.2617]; tau = 0.3534 [0.2683; 0.5115] I^2 = 97.9% [97.4%; 98.3%]; H = 6.86 [6.23; 7.56]\nTest of heterogeneity: Q d.f. p-value 1036.47 22 &lt; 0.0001\nResults for subgroups (random effects model): k COR feature_n_complexity_genre = Medium-large single genre/multi … 4 0.6694 feature_n_complexity_genre = Small single genre study 3 0.8358 feature_n_complexity_genre = Medium single genre/multigenre … 14 0.6142 feature_n_complexity_genre = Huge multigenre study 2 0.7203 95%-CI feature_n_complexity_genre = Medium-large single genre/multi … [ 0.3472; 0.8503] feature_n_complexity_genre = Small single genre study [-0.1966; 0.9893] feature_n_complexity_genre = Medium single genre/multigenre … [ 0.4814; 0.7194] feature_n_complexity_genre = Huge multigenre study [-0.1886; 0.9645] tau^2 tau feature_n_complexity_genre = Medium-large single genre/multi … 0.0779 0.2791 feature_n_complexity_genre = Small single genre study 0.3182 0.5641 feature_n_complexity_genre = Medium single genre/multigenre … 0.0937 0.3061 feature_n_complexity_genre = Huge multigenre study 0.0128 0.1131 Q I^2 feature_n_complexity_genre = Medium-large single genre/multi … 202.35 98.5% feature_n_complexity_genre = Small single genre study 358.17 99.4% feature_n_complexity_genre = Medium single genre/multigenre … 332.50 96.1% feature_n_complexity_genre = Huge multigenre study 6.73 85.1%\nTest for subgroup differences (random effects model): Q d.f. p-value Between groups 3.84 3 0.2798\nDetails on meta-analytical method: - Inverse variance method - Restricted maximum-likelihood estimator for tau^2 - Q-Profile method for confidence interval of tau^2 and tau - Hartung-Knapp adjustment for random effects model (df = 22) - Prediction interval based on t-distribution (df = 21) - Fisher’s z transformation of correlations\n\n\n\n\n\n\n\nR_studies &lt;- read.csv(\"R_studies.csv\")\ntmp &lt;- dplyr::filter(R_studies,dimension==\"arousal\")\n#if all studies, remove two with NA values\ntmp &lt;- tmp[!is.na(tmp$values),]\n#dim(tmp)\n\n# Take all models\nm.cor &lt;- metacor(cor = values,     # values \n                 n = stimulus_n,\n                 studlab = unique_id,\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"PM\",# was REML, but we switch to Paule-Mandel because Langan et al., 2019\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Arousal: Summary\")\n\nprint(m.cor)\n\nReview:     MER: Regression: Arousal: Summary\n\nNumber of studies: k = 118\nNumber of observations: o = 71645\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.7867 [0.7686; 0.8036] 45.88 &lt; 0.0001\nPrediction interval         [0.5219; 0.9133]               \n\nQuantifying heterogeneity:\n tau^2 = 0.0592 [0.0452; 0.0800]; tau = 0.2432 [0.2125; 0.2828]\n I^2 = 95.5% [95.0%; 96.0%]; H = 4.72 [4.47; 4.98]\n\nTest of heterogeneity:\n       Q d.f. p-value\n 2603.78  117       0\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Paule-Mandel estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 117)\n- Prediction interval based on t-distribution (df = 116)\n- Fisher's z transformation of correlations\n\nprint(FisherZInv(m.cor$TE.random))\n\n[1] 0.7867472\n\nprint(FisherZInv(m.cor$upper.random))\n\n[1] 0.8036063\n\nprint(FisherZInv(m.cor$lower.random))\n\n[1] 0.7686265\n\n\n\n\n\n\nR_summary &lt;- read.csv(\"R_summary.csv\")\n\n# select regression studies with r2\ntmp &lt;- dplyr::filter(R_summary,dimension==\"arousal\")\n#tmp &lt;- dplyr::filter(R_studies,dimension==\"valence\")\n#dim(tmp)\n\n#if all studies, remove two\n#tmp &lt;- tmp[!is.na(tmp$values),]\n#dim(tmp)\n\n## Disambiguate the studies\ntmp$studyREF[tmp$studyREF==\"Wang et al 2022\"] &lt;- c(\"Wang et al. 2022a\",\"Wang et al. 2022b\")\n\n# Max values\nm.cor &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = studyREF,#citekey, # unique_id\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Arousal: Summary\")\n\nprint(m.cor)\n\nReview:     MER: Regression: Arousal: Summary\n\nNumber of studies: k = 23\nNumber of observations: o = 14640\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.8154 [0.7567; 0.8611] 15.33 &lt; 0.0001\nPrediction interval         [0.3897; 0.9540]               \n\nQuantifying heterogeneity:\n tau^2 = 0.1183 [0.0683; 0.2510]; tau = 0.3440 [0.2613; 0.5010]\n I^2 = 97.0% [96.2%; 97.6%]; H = 5.75 [5.16; 6.41]\n\nTest of heterogeneity:\n      Q d.f.  p-value\n 728.54   22 &lt; 0.0001\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 22)\n- Prediction interval based on t-distribution (df = 21)\n- Fisher's z transformation of correlations\n\nprint(FisherZInv(m.cor$TE.random))\n\n[1] 0.8154411\n\nprint(FisherZInv(m.cor$upper.random))\n\n[1] 0.8611292\n\nprint(FisherZInv(m.cor$lower.random))\n\n[1] 0.7566868\n\n\n\n\n\n\n\n# Method 1: Give us the Egger's test about beta coefficient from funnel\nprint(eggers.test(m.cor))\n\nEggers' test of the intercept \n============================= \n\n intercept       95% CI     t         p\n     0.548 -4.17 - 5.26 0.228 0.8220788\n\nEggers' test does not indicate the presence of funnel plot asymmetry. \n\n# Method 2: Find the impact to the results when removing those outside the 95CI\nO &lt;- find.outliers(m.cor) # 13 remaining out of 24\nprint(O)\n\nIdentified outliers (random-effects model) \n------------------------------------------ \n\"Battcock et al 2021\", \"Gingras et al 2014\", \"Grekow et al 2018\", \"Koh et al 2023\", \"Orjesek et al 2022\", \"Wang et al. 2022b\", \"Zhang et al 2019\", \"Zhang et al 2023\" \n \nResults with outliers removed \n----------------------------- \nReview:     MER: Regression: Arousal: Summary\n\nNumber of studies: k = 15\nNumber of observations: o = 12101\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.8208 [0.8018; 0.8381] 44.79 &lt; 0.0001\nPrediction interval         [0.7639; 0.8650]               \n\nQuantifying heterogeneity:\n tau^2 = 0.0046 [0.0021; 0.0415]; tau = 0.0675 [0.0453; 0.2036]\n I^2 = 77.3% [62.9%; 86.1%]; H = 2.10 [1.64; 2.69]\n\nTest of heterogeneity:\n     Q d.f.  p-value\n 61.74   14 &lt; 0.0001\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 14)\n- Prediction interval based on t-distribution (df = 13)\n- Fisher's z transformation of correlations\n\n# Method 3: Leave-out-out analysis etc for individual influence (not useful here)\n#infan &lt;- InfluenceAnalysis(m.cor)\n\n# Method 4: Focus on 10% of most precise studies (Stanley, Jarrel, Doucouliagos 2010)\nthres&lt;-quantile(m.cor$seTE,0.1)\nind&lt;-m.cor$seTE&lt;=as.numeric(thres)\nm.cor10pct &lt;- update(m.cor, subset = which(ind))\n\n# Method 5: P curve analysis (Simonsohn, Simmons & Nelson, 2015)\npcurve(m.cor)\n\n\n\n\n\n\n\n\nP-curve analysis \n ----------------------- \n- Total number of provided studies: k = 23 \n- Total number of p&lt;0.05 studies included into the analysis: k = 23 (100%) \n- Total number of studies with p&lt;0.025: k = 23 (100%) \n   \nResults \n ----------------------- \n                    pBinomial   zFull pFull   zHalf pHalf\nRight-skewness test         0 -34.645     0 -34.105     0\nFlatness test               1  35.127     1  35.380     1\nNote: p-values of 0 or 1 correspond to p&lt;0.001 and p&gt;0.999, respectively.   \nPower Estimate: 99% (99%-99%)\n   \nEvidential value \n ----------------------- \n- Evidential value present: yes \n- Evidential value absent/inadequate: no \n\n\n\n\n\n\nfig2a &lt;- forest(m.cor,\n       sortvar = TE,\n       prediction = FALSE, \n             print.tau2 = FALSE,\n             leftlabs = c(\"Author\", \"g\", \"SE\"),studlab = studyREF)\n\n\n\n\n\n\n\nfig2b&lt;-funnel(m.cor, common = FALSE, studlab=TRUE,backtransf=TRUE)\n\n\n\n\n\n\n\nlibrary(forestplot)\ndata&lt;-tibble::tibble(mean=m.cor$cor,lower=FisherZInv(m.cor$lower),upper=FisherZInv(m.cor$upper),study=m.cor$studlab,n=m.cor$n,cor=round(m.cor$cor,2))\ndata&lt;-dplyr::arrange(data,mean)\n\nfp1 &lt;- grid.grabExpr(print(data |&gt;\n  forestplot(labeltext = c(study, n, cor),\n             xlab = \"Correlation\",\n             xticks = c(0, .25,.5,.75, 1),\n             clip = c(0, 1))|&gt;\n    fp_add_header(study = \"Study\",n = \"N\",cor = expression(italic(r))) |&gt;\n    fp_append_row(mean  = m.cor$TE.common,\n                lower = m.cor$lower.common,\n                upper = m.cor$upper.common,\n                study = \"Summary\",\n                n = sum(m.cor$n),\n                cor = round(m.cor$TE.common,2),\n                is.summary = TRUE) |&gt;\n  fp_set_style(box = \"grey50\",\n               line = \"grey20\",\n               summary = \"black\",\n                txt_gp = fpTxtGp(label = list(gpar(cex = 0.80)),\n                                ticks = gpar(cex = 0.80),\n                                xlab  = gpar(cex = 0.80)))|&gt;\n    fp_decorate_graph(grid = structure( m.cor$TE.common,gp = gpar(lty = 2, col = \"grey30\")))\n)\n)\n\nsource('../etc/custom_funnel_plot.R')\nfp2 &lt;- custom_funnel_plot(m.cor)\n\ngridExtra::grid.arrange(fp1, fp2, ncol=2, widths=c(2,1),heights=c(2,1))\n\nWarning: Removed 771 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\nWarning: Removed 954 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_hline()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nS &lt;- summarise(group_by(tmp,model_class_id),n=n(),obs=sum(stimulus_n))\nprint(knitr::kable(S))\n\n\n\nmodel_class_id\nn\nobs\n\n\n\n\nFlexible Discriminants\n6\n4993\n\n\nKernel Smoothing, Additive and KNN\n2\n2582\n\n\nLinear Methods\n8\n1762\n\n\nNeural Nets\n3\n1229\n\n\nRandom Forests\n4\n4074\n\n\n\n\nm.cor1 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  model_class_id,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\nprint(m.cor1)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 23\nNumber of observations: o = 14640\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.8154 [0.7567; 0.8611] 15.33 &lt; 0.0001\nPrediction interval         [0.3897; 0.9540]               \n\nQuantifying heterogeneity:\n tau^2 = 0.1183 [0.0683; 0.2510]; tau = 0.3440 [0.2613; 0.5010]\n I^2 = 97.0% [96.2%; 97.6%]; H = 5.75 [5.16; 6.41]\n\nTest of heterogeneity:\n      Q d.f.  p-value\n 728.54   22 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                                                      k    COR           95%-CI\nmodel_class_id = Kernel Smoothing, Additive and KNN   2 0.8068 [0.5493; 0.9244]\nmodel_class_id = Random Forests                       4 0.8024 [0.7672; 0.8327]\nmodel_class_id = Linear Methods                       8 0.8812 [0.8079; 0.9277]\nmodel_class_id = Flexible Discriminants               6 0.8077 [0.6437; 0.9008]\nmodel_class_id = Neural Nets                          3 0.5329 [0.0822; 0.8027]\n                                                     tau^2    tau      Q   I^2\nmodel_class_id = Kernel Smoothing, Additive and KNN 0.0022 0.0470   3.33 70.0%\nmodel_class_id = Random Forests                     0.0012 0.0348   6.34 52.7%\nmodel_class_id = Linear Methods                     0.0846 0.2908 104.87 93.3%\nmodel_class_id = Flexible Discriminants             0.1125 0.3354 246.31 98.0%\nmodel_class_id = Neural Nets                        0.0344 0.1856  19.40 89.7%\n\nTest for subgroup differences (random effects model):\n                   Q d.f.  p-value\nBetween groups 24.84    4 &lt; 0.0001\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 22)\n- Prediction interval based on t-distribution (df = 21)\n- Fisher's z transformation of correlations\n\n\n\n\n\nS &lt;- summarise(group_by(tmp,journal_type),n=n(),obs=sum(stimulus_n))\nprint(knitr::kable(S))\n\n\n\njournal_type\nn\nobs\n\n\n\n\nEngineering\n15\n11490\n\n\nPsychology\n8\n3150\n\n\n\n\nm.cor2 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  journal_type,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\nprint(m.cor2)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 23\nNumber of observations: o = 14640\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.8154 [0.7567; 0.8611] 15.33 &lt; 0.0001\nPrediction interval         [0.3897; 0.9540]               \n\nQuantifying heterogeneity:\n tau^2 = 0.1183 [0.0683; 0.2510]; tau = 0.3440 [0.2613; 0.5010]\n I^2 = 97.0% [96.2%; 97.6%]; H = 5.75 [5.16; 6.41]\n\nTest of heterogeneity:\n      Q d.f.  p-value\n 728.54   22 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                             k    COR           95%-CI  tau^2    tau      Q\njournal_type = Engineering  15 0.7866 [0.6911; 0.8551] 0.1401 0.3743 651.05\njournal_type = Psychology    8 0.8628 [0.8028; 0.9054] 0.0405 0.2013  45.81\n                             I^2\njournal_type = Engineering 97.8%\njournal_type = Psychology  84.7%\n\nTest for subgroup differences (random effects model):\n                  Q d.f. p-value\nBetween groups 3.47    1  0.0624\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 22)\n- Prediction interval based on t-distribution (df = 21)\n- Fisher's z transformation of correlations\n\n\n\n\n\ntmp &lt;- dplyr::filter(R_summary,dimension==\"valence\")\ntmp&lt;-tmp[!is.na(tmp$feature_n_categories),] # remove \nS &lt;- summarise(group_by(tmp,feature_n_categories),n=n(),obs=sum(stimulus_n))\nprint(knitr::kable(S))\n\n\n\nfeature_n_categories\nn\nobs\n\n\n\n\nFeature n &lt; 18\n5\n3036\n\n\nFeature n &gt; 18 & &lt; 260\n11\n7042\n\n\nFeature n &gt; 260\n7\n4562\n\n\n\n\ntmp &lt;- dplyr::filter(R_summary,dimension==\"valence\")\ntmp&lt;-tmp[!is.na(tmp$feature_n_categories),] # remove missing values\nm.cor3 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  feature_n_categories,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\nprint(m.cor3)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 23\nNumber of observations: o = 14640\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.6739 [0.5782; 0.7513] 10.73 &lt; 0.0001\nPrediction interval         [0.0659; 0.9170]               \n\nQuantifying heterogeneity:\n tau^2 = 0.1249 [0.0720; 0.2617]; tau = 0.3534 [0.2683; 0.5115]\n I^2 = 97.9% [97.4%; 98.3%]; H = 6.86 [6.23; 7.56]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1036.47   22 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                                                k    COR           95%-CI\nfeature_n_categories = Feature n &gt; 260          7 0.6845 [0.5660; 0.7752]\nfeature_n_categories = Feature n &lt; 18           5 0.8111 [0.5342; 0.9308]\nfeature_n_categories = Feature n &gt; 18 & &lt; 260  11 0.5843 [0.4076; 0.7187]\n                                               tau^2    tau      Q   I^2\nfeature_n_categories = Feature n &gt; 260        0.0435 0.2085 211.87 97.2%\nfeature_n_categories = Feature n &lt; 18         0.1815 0.4260 362.55 98.9%\nfeature_n_categories = Feature n &gt; 18 & &lt; 260 0.1089 0.3300 295.76 96.6%\n\nTest for subgroup differences (random effects model):\n                  Q d.f. p-value\nBetween groups 4.66    2  0.0974\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 22)\n- Prediction interval based on t-distribution (df = 21)\n- Fisher's z transformation of correlations\n\nS&lt;-summarise(group_by(tmp,feature_n_categories),n=n(),obs=sum(stimulus_n))\nprint(S)\n\n# A tibble: 3 × 3\n  feature_n_categories       n   obs\n  &lt;chr&gt;                  &lt;int&gt; &lt;int&gt;\n1 Feature n &lt; 18             5  3036\n2 Feature n &gt; 18 & &lt; 260    11  7042\n3 Feature n &gt; 260            7  4562\n\n\n\n\n\ntmp &lt;- dplyr::filter(R_summary,dimension==\"valence\")\ntmp&lt;-tmp[!is.na(tmp$feature_n_categories),] # removemissing values\n\nS&lt;-summarise(group_by(tmp,feature_n_complexity_genre),n=n(),obs=sum(stimulus_n))\nprint(knitr::kable(S))\n\n\n\nfeature_n_complexity_genre\nn\nobs\n\n\n\n\nHuge multigenre study\n2\n1068\n\n\nMedium single genre/multigenre study\n14\n7854\n\n\nMedium-large single genre/multigenre study\n4\n2750\n\n\nSmall single genre study\n3\n2968\n\n\n\nm.cor4 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  feature_n_complexity_genre,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\nprint(m.cor4)\nReview: MER: Regression: Valence: Summary\nNumber of studies: k = 23 Number of observations: o = 14640\n                    COR           95%-CI     t  p-value\nRandom effects model 0.6739 [0.5782; 0.7513] 10.73 &lt; 0.0001 Prediction interval [0.0659; 0.9170]\nQuantifying heterogeneity: tau^2 = 0.1249 [0.0720; 0.2617]; tau = 0.3534 [0.2683; 0.5115] I^2 = 97.9% [97.4%; 98.3%]; H = 6.86 [6.23; 7.56]\nTest of heterogeneity: Q d.f. p-value 1036.47 22 &lt; 0.0001\nResults for subgroups (random effects model): k COR feature_n_complexity_genre = Medium-large single genre/multi … 4 0.6694 feature_n_complexity_genre = Small single genre study 3 0.8358 feature_n_complexity_genre = Medium single genre/multigenre … 14 0.6142 feature_n_complexity_genre = Huge multigenre study 2 0.7203 95%-CI feature_n_complexity_genre = Medium-large single genre/multi … [ 0.3472; 0.8503] feature_n_complexity_genre = Small single genre study [-0.1966; 0.9893] feature_n_complexity_genre = Medium single genre/multigenre … [ 0.4814; 0.7194] feature_n_complexity_genre = Huge multigenre study [-0.1886; 0.9645] tau^2 tau feature_n_complexity_genre = Medium-large single genre/multi … 0.0779 0.2791 feature_n_complexity_genre = Small single genre study 0.3182 0.5641 feature_n_complexity_genre = Medium single genre/multigenre … 0.0937 0.3061 feature_n_complexity_genre = Huge multigenre study 0.0128 0.1131 Q I^2 feature_n_complexity_genre = Medium-large single genre/multi … 202.35 98.5% feature_n_complexity_genre = Small single genre study 358.17 99.4% feature_n_complexity_genre = Medium single genre/multigenre … 332.50 96.1% feature_n_complexity_genre = Huge multigenre study 6.73 85.1%\nTest for subgroup differences (random effects model): Q d.f. p-value Between groups 3.84 3 0.2798\nDetails on meta-analytical method: - Inverse variance method - Restricted maximum-likelihood estimator for tau^2 - Q-Profile method for confidence interval of tau^2 and tau - Hartung-Knapp adjustment for random effects model (df = 22) - Prediction interval based on t-distribution (df = 21) - Fisher’s z transformation of correlations\n\n\n\n\n\n\nC_studies &lt;- read.csv(\"C_studies.csv\")\nC_studies &lt;- C_studies[!is.na(C_studies$values),]\n\nC_summary &lt;- read.csv(\"C_summary.csv\")\n\nm.cor &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = studyREF, # unique_id\n                 data = C_summary,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 backtransf = TRUE,\n                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Classification: Summary\")\n\n#print(m.cor)\n\n#m.cor_backtransformed &lt;- m.cor\n#m.cor_backtransformed$TE &lt;- FisherZInv(m.cor_backtransformed$TE)\nprint(funnel(m.cor, common = FALSE, studlab=TRUE,backtransf=TRUE))\n\n\n\n\n\n\n\n\n$xlim\n[1] 0.598722 2.439471\n\n$ylim\n[1] 0.09090909 0.00000000\n\n\n\n\n\nlibrary(ggrepel)\ntmpdata &lt;- data.frame(SE = FisherZInv(m.cor$seTE), Zr = FisherZInv(m.cor$TE),studies=m.cor$studlab)\n\ntmpdata$citekey&lt;-str_replace_all(tmpdata$studies,'-.*$','')\ntmpdata$citekey&lt;-factor(tmpdata$citekey)\n\ng &lt;- ggplot(tmpdata,aes(y = SE, x = Zr,label=studies,color=citekey,fill=citekey)) +\n  geom_point(show.legend = FALSE) +\n  geom_label_repel(size=1.5,max.overlaps = 39,color=\"black\",show.legend = FALSE)+\n  ylab('Standard Error') + \n  xlab('r')+\n  scale_y_reverse()+\n#  scale_x_continuous(breaks=seq(0.0,1.0,0.25),limits=c(0,1.0))+\n#  coord_flip()+\n  theme_bw()\nprint(g)\n\n\n\n\n\n\n\n\n\n\n\n\nforest(m.cor,\n       sortvar = TE,\n       prediction = FALSE, \n             print.tau2 = FALSE,\n             leftlabs = c(\"Author\", \"g\", \"SE\"),studlab = citekey)\n\n\n\n\n\n\n\nfunnel(m.cor, common = FALSE, studlab=TRUE,backtransf=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\nO &lt;- find.outliers(m.cor)\n# 6 datasets identified as outliers, without them the r drops to 0.5781\n#infan &lt;- InfluenceAnalysis(m.cor)\n#print(eggers.test(m.cor))\n\n\n\n\n\n\n\nTo show the quality differences between core and eliminated studies (in progress).\n\ntmpdata &lt;- data.frame(SE = m.cor$seTE, Zr = m.cor$TE, studies=m.cor$studlab)\n\ntmpdata$studyREF &lt;- substr(tmpdata$studies,1,nchar(tmpdata$studies)-2)\ntmpdata$studyREF &lt;- str_replace_all(tmpdata$studyREF,'([0-9]+)',' et al \\\\1')\ntmpdata$studyREF &lt;- str_to_sentence(tmpdata$studyREF)\ntmpdata$studyREF\n\n [1] \"Agarwal et al  et al 20\"      \"Alvarez et al  et al 20\"     \n [3] \"Bai et al  et al 20\"          \"Bai et al  et al 20\"         \n [5] \"Bhuvanakumar et al  et al 20\" \"Dufour et al  et al 20\"      \n [7] \"Hizlisoy et al  et al 20\"     \"Hu et al  et al 20\"          \n [9] \"Nguyen et al  et al 20\"       \"Panda et al  et al 20\"       \n[11] \"Sorussa et al  et al 20\"      \"Yeh et al  et al 20\"         \n[13] \"Zhang et al  et al 20\"        \"Zhang et al  et al 20\"       \n\nestimate = m.cor$TE.common\nse = m.cor$seTE.common\nse.seq=seq(0, max(m.cor$cor), 0.001)\nll95 = estimate-(1.96*se.seq)\nul95 = estimate+(1.96*se.seq)\nll99 = estimate-(3.29*se.seq)\nul99 = estimate+(3.29*se.seq)\nmeanll95 = estimate-(1.96*se)\nmeanul95 = estimate+(1.96*se)\ndfCI = data.frame(ll95, ul95, ll99, ul99, se.seq, estimate, meanll95, meanul95)\n\nfp = ggplot(NULL) +\n  geom_point(aes(x = SE, y = Zr), color='grey50',data=tmpdata) +\n  geom_text_repel(aes(x = SE, y = Zr, label=studyREF), data=tmpdata,size=2.5,max.overlaps = 40)+\n  xlab('Standard Error') + ylab('Fisher\\'s z transformed correlation')+\n  geom_line(aes(x = se.seq, y = ll95), linetype = 'dotted', data = dfCI) +\n  geom_line(aes(x = se.seq, y = ul95), linetype = 'dotted', data = dfCI) +\n  geom_segment(aes(x = min(se.seq), y = meanll95, xend = max(se.seq), yend = meanll95), linetype='dotted', data=dfCI) +\n  geom_segment(aes(x = min(se.seq), y = meanul95, xend = max(se.seq), yend = meanul95), linetype='dotted', data=dfCI) +\n#  scale_x_reverse()+\n  scale_x_reverse(breaks=seq(0,0.2,0.05),limits=c(0.15,0),expand=c(0.00,0.00))+\n  scale_y_continuous(breaks=seq(0.3,1.25,0.20),limits=c(0.3,1.23))+\n  coord_flip()+\n  theme_bw()\nprint(fp)\n\nWarning: Removed 8 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\nWarning: Removed 8 rows containing missing values or values outside the scale range\n(`geom_text_repel()`).\n\n\nWarning: Removed 984 rows containing missing values or values outside the scale range\n(`geom_line()`).\nRemoved 984 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\nWarning: Removed 984 rows containing missing values or values outside the scale range\n(`geom_segment()`).\nRemoved 984 rows containing missing values or values outside the scale range\n(`geom_segment()`).\n\n\n\n\n\n\n\n\n\n\n\n\nadd journal_type and stimulus_genre_mixed as a grouping option\n\nm.cor_subgroups &lt;- update(m.cor, \n       subgroup = model_class_id, \n#       subgroup = journal_type, \n#       subgroup = stimulus_genre_mixed, \n       tau.common = FALSE,\n       prediction = TRUE)\n\nprint(m.cor_subgroups)\n#forest(m.cor_subgroups,subgroup=TRUE)\n\n\nIdea: visualise the distributions of the model successes within studies (done in preprocessing)"
  },
  {
    "objectID": "analysis/analysis.html#regression-studies",
    "href": "analysis/analysis.html#regression-studies",
    "title": "Analysis",
    "section": "",
    "text": "For creating Table 2\n\nlibrary(dmetar,quietly = TRUE)\nlibrary(tidyverse,quietly = TRUE)\nlibrary(meta)\nlibrary(DescTools)\nlibrary(ggrepel)\n\n\n\n\nR_studies &lt;- read.csv(\"R_studies.csv\")\n#R_summary &lt;- read.csv(\"R_summary.csv\")\n\n# select regression studies with r2\n#tmp &lt;- dplyr::filter(R_summary,dimension==\"valence\")\ntmp &lt;- dplyr::filter(R_studies,dimension==\"valence\")\n#dim(tmp)\n\n#if all studies, remove two with NA values\ntmp &lt;- tmp[!is.na(tmp$values),]\n#dim(tmp)\n\n# Take all models\nm.cor &lt;- metacor(cor = values,     # values \n                 n = stimulus_n,\n                 studlab = unique_id,\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"PM\",# was REML, but we switch to Paule-Mandel because Langan et al., 2019\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\n\nprint(m.cor)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 118\nNumber of observations: o = 71645\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.5734 [0.5365; 0.6081] 24.24 &lt; 0.0001\nPrediction interval         [0.0853; 0.8395]               \n\nQuantifying heterogeneity:\n tau^2 = 0.0812 [0.0627; 0.1087]; tau = 0.2850 [0.2503; 0.3297]\n I^2 = 97.3% [97.0%; 97.5%]; H = 6.05 [5.78; 6.34]\n\nTest of heterogeneity:\n       Q d.f. p-value\n 4286.61  117       0\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Paule-Mandel estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 117)\n- Prediction interval based on t-distribution (df = 116)\n- Fisher's z transformation of correlations\n\nprint(FisherZInv(m.cor$TE.random))\n\n[1] 0.5733695\n\nprint(FisherZInv(m.cor$upper.random))\n\n[1] 0.608064\n\nprint(FisherZInv(m.cor$lower.random))\n\n[1] 0.5364891\n\n\n\n\n\n\nR_summary &lt;- read.csv(\"R_summary.csv\")\n\n# select regression studies with r2\ntmp &lt;- dplyr::filter(R_summary,dimension==\"valence\")\n#tmp &lt;- dplyr::filter(R_studies,dimension==\"valence\")\n#dim(tmp)\n\n#if all studies, remove two\n#tmp &lt;- tmp[!is.na(tmp$values),]\n#dim(tmp)\n\n## Disambiguate the studies\ntmp$studyREF[tmp$studyREF==\"Wang et al 2022\"] &lt;- c(\"Wang et al. 2022a\",\"Wang et al. 2022b\")\n\n# Max values\nm.cor &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = studyREF,#citekey, # unique_id\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\n\nprint(m.cor)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 23\nNumber of observations: o = 14640\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.6739 [0.5782; 0.7513] 10.73 &lt; 0.0001\nPrediction interval         [0.0659; 0.9170]               \n\nQuantifying heterogeneity:\n tau^2 = 0.1249 [0.0720; 0.2617]; tau = 0.3534 [0.2683; 0.5115]\n I^2 = 97.9% [97.4%; 98.3%]; H = 6.86 [6.23; 7.56]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1036.47   22 &lt; 0.0001\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 22)\n- Prediction interval based on t-distribution (df = 21)\n- Fisher's z transformation of correlations\n\nprint(FisherZInv(m.cor$TE.random))\n\n[1] 0.6738887\n\nprint(FisherZInv(m.cor$upper.random))\n\n[1] 0.7513007\n\nprint(FisherZInv(m.cor$lower.random))\n\n[1] 0.5781846\n\n\n\n\n\n\n\n# Method 1: Give us the Egger's test about beta coefficient from funnel\nprint(eggers.test(m.cor))\n\nEggers' test of the intercept \n============================= \n\n intercept        95% CI     t          p\n     4.769 -0.48 - 10.02 1.781 0.08942195\n\nEggers' test does not indicate the presence of funnel plot asymmetry. \n\n# Method 2: Find the impact to the results when removing those outside the 95CI\nO &lt;- find.outliers(m.cor) # 13 remaining out of 24\nprint(O)\n\nIdentified outliers (random-effects model) \n------------------------------------------ \n\"Battcock et al 2021\", \"Chen et al 2017\", \"Griffiths et al 2021\", \"Hu et al 2017\", \"Koh et al 2023\", \"Wang et al. 2022a\", \"Wang et al. 2022b\", \"Zhang et al 2019\", \"Zhang et al 2023\" \n \nResults with outliers removed \n----------------------------- \nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 14\nNumber of observations: o = 7638\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.6645 [0.6094; 0.7132] 18.63 &lt; 0.0001\nPrediction interval         [0.4468; 0.8079]               \n\nQuantifying heterogeneity:\n tau^2 = 0.0198 [0.0083; 0.0656]; tau = 0.1406 [0.0908; 0.2562]\n I^2 = 87.3% [80.3%; 91.8%]; H = 2.80 [2.26; 3.48]\n\nTest of heterogeneity:\n      Q d.f.  p-value\n 102.16   13 &lt; 0.0001\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 13)\n- Prediction interval based on t-distribution (df = 12)\n- Fisher's z transformation of correlations\n\n# Method 3: Leave-out-out analysis etc for individual influence (not useful here)\n#infan &lt;- InfluenceAnalysis(m.cor)\n\n# Method 4: Focus on 10% of most precise studies (Stanley, Jarrel, Doucouliagos 2010)\nthres&lt;-quantile(m.cor$seTE,0.1)\nind&lt;-m.cor$seTE&lt;=as.numeric(thres)\nm.cor10pct &lt;- update(m.cor, subset = which(ind))\n\n# Method 5: P curve analysis (Simonsohn, Simmons & Nelson, 2015)\npcurve(m.cor)\n\n\n\n\n\n\n\n\nP-curve analysis \n ----------------------- \n- Total number of provided studies: k = 23 \n- Total number of p&lt;0.05 studies included into the analysis: k = 22 (95.65%) \n- Total number of studies with p&lt;0.025: k = 22 (95.65%) \n   \nResults \n ----------------------- \n                    pBinomial   zFull pFull   zHalf pHalf\nRight-skewness test         0 -33.754     0 -33.255     0\nFlatness test               1  33.628     1  33.907     1\nNote: p-values of 0 or 1 correspond to p&lt;0.001 and p&gt;0.999, respectively.   \nPower Estimate: 99% (99%-99%)\n   \nEvidential value \n ----------------------- \n- Evidential value present: yes \n- Evidential value absent/inadequate: no \n\n\n\n\n\n\nfig2a &lt;- forest(m.cor,\n       sortvar = TE,\n       prediction = FALSE, \n             print.tau2 = FALSE,\n             leftlabs = c(\"Author\", \"g\", \"SE\"),studlab = studyREF)\n\n\n\n\n\n\n\nfig2b&lt;-funnel(m.cor, common = FALSE, studlab=TRUE,backtransf=TRUE)\n\n\n\n\n\n\n\nlibrary(forestplot)\n\nLoading required package: grid\n\n\nLoading required package: checkmate\n\n\nLoading required package: abind\n\ndata&lt;-tibble::tibble(mean=m.cor$cor,lower=FisherZInv(m.cor$lower),upper=FisherZInv(m.cor$upper),study=m.cor$studlab,n=m.cor$n,cor=round(m.cor$cor,2))\ndata&lt;-dplyr::arrange(data,mean)\n\nfp1 &lt;- grid.grabExpr(print(data |&gt;\n  forestplot(labeltext = c(study, n, cor),\n             xlab = \"Correlation\",\n             xticks = c(0, .25,.5,.75, 1),\n             clip = c(0, 1))|&gt;\n    fp_add_header(study = \"Study\",n = \"N\",cor = expression(italic(r))) |&gt;\n    fp_append_row(mean  = m.cor$TE.common,\n                lower = m.cor$lower.common,\n                upper = m.cor$upper.common,\n                study = \"Summary\",\n                n = sum(m.cor$n),\n                cor = round(m.cor$TE.common,2),\n                is.summary = TRUE) |&gt;\n  fp_set_style(box = \"grey50\",\n               line = \"grey20\",\n               summary = \"black\",\n                txt_gp = fpTxtGp(label = list(gpar(cex = 0.80)),\n                                ticks = gpar(cex = 0.80),\n                                xlab  = gpar(cex = 0.80)))|&gt;\n    fp_decorate_graph(grid = structure( m.cor$TE.common,gp = gpar(lty = 2, col = \"grey30\")))\n)\n)\n\nsource('../etc/custom_funnel_plot.R')\nfp2 &lt;- custom_funnel_plot(m.cor)\n\ngridExtra::grid.arrange(fp1, fp2, ncol=2, widths=c(2,1),heights=c(2,1))\n\nWarning: Removed 684 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\nWarning: Removed 767 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nS &lt;- summarise(group_by(tmp,model_class_id),n=n(),obs=sum(stimulus_n))\nprint(knitr::kable(S))\n\n\n\nmodel_class_id\nn\nobs\n\n\n\n\nFlexible Discriminants\n6\n4993\n\n\nKernel Smoothing, Additive and KNN\n2\n2582\n\n\nLinear Methods\n8\n1762\n\n\nNeural Nets\n3\n1229\n\n\nRandom Forests\n4\n4074\n\n\n\n\nm.cor1 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  model_class_id,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\nprint(m.cor1)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 23\nNumber of observations: o = 14640\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.6739 [0.5782; 0.7513] 10.73 &lt; 0.0001\nPrediction interval         [0.0659; 0.9170]               \n\nQuantifying heterogeneity:\n tau^2 = 0.1249 [0.0720; 0.2617]; tau = 0.3534 [0.2683; 0.5115]\n I^2 = 97.9% [97.4%; 98.3%]; H = 6.86 [6.23; 7.56]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1036.47   22 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                                                      k    COR\nmodel_class_id = Kernel Smoothing, Additive and KNN   2 0.4662\nmodel_class_id = Random Forests                       4 0.7024\nmodel_class_id = Linear Methods                       8 0.7840\nmodel_class_id = Flexible Discriminants               6 0.6555\nmodel_class_id = Neural Nets                          3 0.3933\n                                                               95%-CI  tau^2\nmodel_class_id = Kernel Smoothing, Additive and KNN [-0.6342; 0.9424] 0.0185\nmodel_class_id = Random Forests                     [ 0.3914; 0.8694] 0.0803\nmodel_class_id = Linear Methods                     [ 0.6249; 0.8806] 0.1370\nmodel_class_id = Flexible Discriminants             [ 0.4838; 0.7786] 0.0574\nmodel_class_id = Neural Nets                        [-0.3553; 0.8345] 0.0929\n                                                       tau      Q   I^2\nmodel_class_id = Kernel Smoothing, Additive and KNN 0.1361  20.56 95.1%\nmodel_class_id = Random Forests                     0.2833 198.79 98.5%\nmodel_class_id = Linear Methods                     0.3701 195.78 96.4%\nmodel_class_id = Flexible Discriminants             0.2396 161.22 96.9%\nmodel_class_id = Neural Nets                        0.3049  56.87 96.5%\n\nTest for subgroup differences (random effects model):\n                   Q d.f. p-value\nBetween groups 15.09    4  0.0045\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 22)\n- Prediction interval based on t-distribution (df = 21)\n- Fisher's z transformation of correlations\n\n\n\n\n\nS &lt;- summarise(group_by(tmp,journal_type),n=n(),obs=sum(stimulus_n))\nprint(knitr::kable(S))\n\n\n\njournal_type\nn\nobs\n\n\n\n\nEngineering\n15\n11490\n\n\nPsychology\n8\n3150\n\n\n\n\nm.cor2 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  journal_type,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\nprint(m.cor2)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 23\nNumber of observations: o = 14640\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.6739 [0.5782; 0.7513] 10.73 &lt; 0.0001\nPrediction interval         [0.0659; 0.9170]               \n\nQuantifying heterogeneity:\n tau^2 = 0.1249 [0.0720; 0.2617]; tau = 0.3534 [0.2683; 0.5115]\n I^2 = 97.9% [97.4%; 98.3%]; H = 6.86 [6.23; 7.56]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1036.47   22 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                             k    COR           95%-CI  tau^2    tau      Q\njournal_type = Engineering  15 0.6424 [0.5112; 0.7444] 0.1208 0.3475 644.85\njournal_type = Psychology    8 0.7323 [0.5491; 0.8484] 0.1334 0.3653 385.42\n                             I^2\njournal_type = Engineering 97.8%\njournal_type = Psychology  98.2%\n\nTest for subgroup differences (random effects model):\n                  Q d.f. p-value\nBetween groups 1.11    1  0.2919\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 22)\n- Prediction interval based on t-distribution (df = 21)\n- Fisher's z transformation of correlations\n\n\n\n\n\ntmp &lt;- dplyr::filter(R_summary,dimension==\"valence\")\ntmp&lt;-tmp[!is.na(tmp$feature_n_categories),] # remove \nS &lt;- summarise(group_by(tmp,feature_n_categories),n=n(),obs=sum(stimulus_n))\nprint(knitr::kable(S))\n\n\n\nfeature_n_categories\nn\nobs\n\n\n\n\nFeature n &lt; 18\n5\n3036\n\n\nFeature n &gt; 18 & &lt; 260\n11\n7042\n\n\nFeature n &gt; 260\n7\n4562\n\n\n\n\ntmp &lt;- dplyr::filter(R_summary,dimension==\"valence\")\ntmp&lt;-tmp[!is.na(tmp$feature_n_categories),] # remove missing values\nm.cor3 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  feature_n_categories,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\nprint(m.cor3)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 23\nNumber of observations: o = 14640\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.6739 [0.5782; 0.7513] 10.73 &lt; 0.0001\nPrediction interval         [0.0659; 0.9170]               \n\nQuantifying heterogeneity:\n tau^2 = 0.1249 [0.0720; 0.2617]; tau = 0.3534 [0.2683; 0.5115]\n I^2 = 97.9% [97.4%; 98.3%]; H = 6.86 [6.23; 7.56]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1036.47   22 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                                                k    COR           95%-CI\nfeature_n_categories = Feature n &gt; 260          7 0.6845 [0.5660; 0.7752]\nfeature_n_categories = Feature n &lt; 18           5 0.8111 [0.5342; 0.9308]\nfeature_n_categories = Feature n &gt; 18 & &lt; 260  11 0.5843 [0.4076; 0.7187]\n                                               tau^2    tau      Q   I^2\nfeature_n_categories = Feature n &gt; 260        0.0435 0.2085 211.87 97.2%\nfeature_n_categories = Feature n &lt; 18         0.1815 0.4260 362.55 98.9%\nfeature_n_categories = Feature n &gt; 18 & &lt; 260 0.1089 0.3300 295.76 96.6%\n\nTest for subgroup differences (random effects model):\n                  Q d.f. p-value\nBetween groups 4.66    2  0.0974\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 22)\n- Prediction interval based on t-distribution (df = 21)\n- Fisher's z transformation of correlations\n\nS&lt;-summarise(group_by(tmp,feature_n_categories),n=n(),obs=sum(stimulus_n))\nprint(S)\n\n# A tibble: 3 × 3\n  feature_n_categories       n   obs\n  &lt;chr&gt;                  &lt;int&gt; &lt;int&gt;\n1 Feature n &lt; 18             5  3036\n2 Feature n &gt; 18 & &lt; 260    11  7042\n3 Feature n &gt; 260            7  4562\n\n\n\n\n\ntmp &lt;- dplyr::filter(R_summary,dimension==\"valence\")\ntmp&lt;-tmp[!is.na(tmp$feature_n_categories),] # removemissing values\n\nS&lt;-summarise(group_by(tmp,feature_n_complexity_genre),n=n(),obs=sum(stimulus_n))\nprint(knitr::kable(S))\n\n\n\nfeature_n_complexity_genre\nn\nobs\n\n\n\n\nHuge multigenre study\n2\n1068\n\n\nMedium single genre/multigenre study\n14\n7854\n\n\nMedium-large single genre/multigenre study\n4\n2750\n\n\nSmall single genre study\n3\n2968\n\n\n\nm.cor4 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  feature_n_complexity_genre,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\nprint(m.cor4)\nReview: MER: Regression: Valence: Summary\nNumber of studies: k = 23 Number of observations: o = 14640\n                    COR           95%-CI     t  p-value\nRandom effects model 0.6739 [0.5782; 0.7513] 10.73 &lt; 0.0001 Prediction interval [0.0659; 0.9170]\nQuantifying heterogeneity: tau^2 = 0.1249 [0.0720; 0.2617]; tau = 0.3534 [0.2683; 0.5115] I^2 = 97.9% [97.4%; 98.3%]; H = 6.86 [6.23; 7.56]\nTest of heterogeneity: Q d.f. p-value 1036.47 22 &lt; 0.0001\nResults for subgroups (random effects model): k COR feature_n_complexity_genre = Medium-large single genre/multi … 4 0.6694 feature_n_complexity_genre = Small single genre study 3 0.8358 feature_n_complexity_genre = Medium single genre/multigenre … 14 0.6142 feature_n_complexity_genre = Huge multigenre study 2 0.7203 95%-CI feature_n_complexity_genre = Medium-large single genre/multi … [ 0.3472; 0.8503] feature_n_complexity_genre = Small single genre study [-0.1966; 0.9893] feature_n_complexity_genre = Medium single genre/multigenre … [ 0.4814; 0.7194] feature_n_complexity_genre = Huge multigenre study [-0.1886; 0.9645] tau^2 tau feature_n_complexity_genre = Medium-large single genre/multi … 0.0779 0.2791 feature_n_complexity_genre = Small single genre study 0.3182 0.5641 feature_n_complexity_genre = Medium single genre/multigenre … 0.0937 0.3061 feature_n_complexity_genre = Huge multigenre study 0.0128 0.1131 Q I^2 feature_n_complexity_genre = Medium-large single genre/multi … 202.35 98.5% feature_n_complexity_genre = Small single genre study 358.17 99.4% feature_n_complexity_genre = Medium single genre/multigenre … 332.50 96.1% feature_n_complexity_genre = Huge multigenre study 6.73 85.1%\nTest for subgroup differences (random effects model): Q d.f. p-value Between groups 3.84 3 0.2798\nDetails on meta-analytical method: - Inverse variance method - Restricted maximum-likelihood estimator for tau^2 - Q-Profile method for confidence interval of tau^2 and tau - Hartung-Knapp adjustment for random effects model (df = 22) - Prediction interval based on t-distribution (df = 21) - Fisher’s z transformation of correlations\n\n\n\n\n\n\n\nR_studies &lt;- read.csv(\"R_studies.csv\")\ntmp &lt;- dplyr::filter(R_studies,dimension==\"arousal\")\n#if all studies, remove two with NA values\ntmp &lt;- tmp[!is.na(tmp$values),]\n#dim(tmp)\n\n# Take all models\nm.cor &lt;- metacor(cor = values,     # values \n                 n = stimulus_n,\n                 studlab = unique_id,\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"PM\",# was REML, but we switch to Paule-Mandel because Langan et al., 2019\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Arousal: Summary\")\n\nprint(m.cor)\n\nReview:     MER: Regression: Arousal: Summary\n\nNumber of studies: k = 118\nNumber of observations: o = 71645\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.7867 [0.7686; 0.8036] 45.88 &lt; 0.0001\nPrediction interval         [0.5219; 0.9133]               \n\nQuantifying heterogeneity:\n tau^2 = 0.0592 [0.0452; 0.0800]; tau = 0.2432 [0.2125; 0.2828]\n I^2 = 95.5% [95.0%; 96.0%]; H = 4.72 [4.47; 4.98]\n\nTest of heterogeneity:\n       Q d.f. p-value\n 2603.78  117       0\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Paule-Mandel estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 117)\n- Prediction interval based on t-distribution (df = 116)\n- Fisher's z transformation of correlations\n\nprint(FisherZInv(m.cor$TE.random))\n\n[1] 0.7867472\n\nprint(FisherZInv(m.cor$upper.random))\n\n[1] 0.8036063\n\nprint(FisherZInv(m.cor$lower.random))\n\n[1] 0.7686265\n\n\n\n\n\n\nR_summary &lt;- read.csv(\"R_summary.csv\")\n\n# select regression studies with r2\ntmp &lt;- dplyr::filter(R_summary,dimension==\"arousal\")\n#tmp &lt;- dplyr::filter(R_studies,dimension==\"valence\")\n#dim(tmp)\n\n#if all studies, remove two\n#tmp &lt;- tmp[!is.na(tmp$values),]\n#dim(tmp)\n\n## Disambiguate the studies\ntmp$studyREF[tmp$studyREF==\"Wang et al 2022\"] &lt;- c(\"Wang et al. 2022a\",\"Wang et al. 2022b\")\n\n# Max values\nm.cor &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = studyREF,#citekey, # unique_id\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Arousal: Summary\")\n\nprint(m.cor)\n\nReview:     MER: Regression: Arousal: Summary\n\nNumber of studies: k = 23\nNumber of observations: o = 14640\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.8154 [0.7567; 0.8611] 15.33 &lt; 0.0001\nPrediction interval         [0.3897; 0.9540]               \n\nQuantifying heterogeneity:\n tau^2 = 0.1183 [0.0683; 0.2510]; tau = 0.3440 [0.2613; 0.5010]\n I^2 = 97.0% [96.2%; 97.6%]; H = 5.75 [5.16; 6.41]\n\nTest of heterogeneity:\n      Q d.f.  p-value\n 728.54   22 &lt; 0.0001\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 22)\n- Prediction interval based on t-distribution (df = 21)\n- Fisher's z transformation of correlations\n\nprint(FisherZInv(m.cor$TE.random))\n\n[1] 0.8154411\n\nprint(FisherZInv(m.cor$upper.random))\n\n[1] 0.8611292\n\nprint(FisherZInv(m.cor$lower.random))\n\n[1] 0.7566868\n\n\n\n\n\n\n\n# Method 1: Give us the Egger's test about beta coefficient from funnel\nprint(eggers.test(m.cor))\n\nEggers' test of the intercept \n============================= \n\n intercept       95% CI     t         p\n     0.548 -4.17 - 5.26 0.228 0.8220788\n\nEggers' test does not indicate the presence of funnel plot asymmetry. \n\n# Method 2: Find the impact to the results when removing those outside the 95CI\nO &lt;- find.outliers(m.cor) # 13 remaining out of 24\nprint(O)\n\nIdentified outliers (random-effects model) \n------------------------------------------ \n\"Battcock et al 2021\", \"Gingras et al 2014\", \"Grekow et al 2018\", \"Koh et al 2023\", \"Orjesek et al 2022\", \"Wang et al. 2022b\", \"Zhang et al 2019\", \"Zhang et al 2023\" \n \nResults with outliers removed \n----------------------------- \nReview:     MER: Regression: Arousal: Summary\n\nNumber of studies: k = 15\nNumber of observations: o = 12101\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.8208 [0.8018; 0.8381] 44.79 &lt; 0.0001\nPrediction interval         [0.7639; 0.8650]               \n\nQuantifying heterogeneity:\n tau^2 = 0.0046 [0.0021; 0.0415]; tau = 0.0675 [0.0453; 0.2036]\n I^2 = 77.3% [62.9%; 86.1%]; H = 2.10 [1.64; 2.69]\n\nTest of heterogeneity:\n     Q d.f.  p-value\n 61.74   14 &lt; 0.0001\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 14)\n- Prediction interval based on t-distribution (df = 13)\n- Fisher's z transformation of correlations\n\n# Method 3: Leave-out-out analysis etc for individual influence (not useful here)\n#infan &lt;- InfluenceAnalysis(m.cor)\n\n# Method 4: Focus on 10% of most precise studies (Stanley, Jarrel, Doucouliagos 2010)\nthres&lt;-quantile(m.cor$seTE,0.1)\nind&lt;-m.cor$seTE&lt;=as.numeric(thres)\nm.cor10pct &lt;- update(m.cor, subset = which(ind))\n\n# Method 5: P curve analysis (Simonsohn, Simmons & Nelson, 2015)\npcurve(m.cor)\n\n\n\n\n\n\n\n\nP-curve analysis \n ----------------------- \n- Total number of provided studies: k = 23 \n- Total number of p&lt;0.05 studies included into the analysis: k = 23 (100%) \n- Total number of studies with p&lt;0.025: k = 23 (100%) \n   \nResults \n ----------------------- \n                    pBinomial   zFull pFull   zHalf pHalf\nRight-skewness test         0 -34.645     0 -34.105     0\nFlatness test               1  35.127     1  35.380     1\nNote: p-values of 0 or 1 correspond to p&lt;0.001 and p&gt;0.999, respectively.   \nPower Estimate: 99% (99%-99%)\n   \nEvidential value \n ----------------------- \n- Evidential value present: yes \n- Evidential value absent/inadequate: no \n\n\n\n\n\n\nfig2a &lt;- forest(m.cor,\n       sortvar = TE,\n       prediction = FALSE, \n             print.tau2 = FALSE,\n             leftlabs = c(\"Author\", \"g\", \"SE\"),studlab = studyREF)\n\n\n\n\n\n\n\nfig2b&lt;-funnel(m.cor, common = FALSE, studlab=TRUE,backtransf=TRUE)\n\n\n\n\n\n\n\nlibrary(forestplot)\ndata&lt;-tibble::tibble(mean=m.cor$cor,lower=FisherZInv(m.cor$lower),upper=FisherZInv(m.cor$upper),study=m.cor$studlab,n=m.cor$n,cor=round(m.cor$cor,2))\ndata&lt;-dplyr::arrange(data,mean)\n\nfp1 &lt;- grid.grabExpr(print(data |&gt;\n  forestplot(labeltext = c(study, n, cor),\n             xlab = \"Correlation\",\n             xticks = c(0, .25,.5,.75, 1),\n             clip = c(0, 1))|&gt;\n    fp_add_header(study = \"Study\",n = \"N\",cor = expression(italic(r))) |&gt;\n    fp_append_row(mean  = m.cor$TE.common,\n                lower = m.cor$lower.common,\n                upper = m.cor$upper.common,\n                study = \"Summary\",\n                n = sum(m.cor$n),\n                cor = round(m.cor$TE.common,2),\n                is.summary = TRUE) |&gt;\n  fp_set_style(box = \"grey50\",\n               line = \"grey20\",\n               summary = \"black\",\n                txt_gp = fpTxtGp(label = list(gpar(cex = 0.80)),\n                                ticks = gpar(cex = 0.80),\n                                xlab  = gpar(cex = 0.80)))|&gt;\n    fp_decorate_graph(grid = structure( m.cor$TE.common,gp = gpar(lty = 2, col = \"grey30\")))\n)\n)\n\nsource('../etc/custom_funnel_plot.R')\nfp2 &lt;- custom_funnel_plot(m.cor)\n\ngridExtra::grid.arrange(fp1, fp2, ncol=2, widths=c(2,1),heights=c(2,1))\n\nWarning: Removed 771 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\nWarning: Removed 954 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_hline()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nS &lt;- summarise(group_by(tmp,model_class_id),n=n(),obs=sum(stimulus_n))\nprint(knitr::kable(S))\n\n\n\nmodel_class_id\nn\nobs\n\n\n\n\nFlexible Discriminants\n6\n4993\n\n\nKernel Smoothing, Additive and KNN\n2\n2582\n\n\nLinear Methods\n8\n1762\n\n\nNeural Nets\n3\n1229\n\n\nRandom Forests\n4\n4074\n\n\n\n\nm.cor1 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  model_class_id,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\nprint(m.cor1)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 23\nNumber of observations: o = 14640\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.8154 [0.7567; 0.8611] 15.33 &lt; 0.0001\nPrediction interval         [0.3897; 0.9540]               \n\nQuantifying heterogeneity:\n tau^2 = 0.1183 [0.0683; 0.2510]; tau = 0.3440 [0.2613; 0.5010]\n I^2 = 97.0% [96.2%; 97.6%]; H = 5.75 [5.16; 6.41]\n\nTest of heterogeneity:\n      Q d.f.  p-value\n 728.54   22 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                                                      k    COR           95%-CI\nmodel_class_id = Kernel Smoothing, Additive and KNN   2 0.8068 [0.5493; 0.9244]\nmodel_class_id = Random Forests                       4 0.8024 [0.7672; 0.8327]\nmodel_class_id = Linear Methods                       8 0.8812 [0.8079; 0.9277]\nmodel_class_id = Flexible Discriminants               6 0.8077 [0.6437; 0.9008]\nmodel_class_id = Neural Nets                          3 0.5329 [0.0822; 0.8027]\n                                                     tau^2    tau      Q   I^2\nmodel_class_id = Kernel Smoothing, Additive and KNN 0.0022 0.0470   3.33 70.0%\nmodel_class_id = Random Forests                     0.0012 0.0348   6.34 52.7%\nmodel_class_id = Linear Methods                     0.0846 0.2908 104.87 93.3%\nmodel_class_id = Flexible Discriminants             0.1125 0.3354 246.31 98.0%\nmodel_class_id = Neural Nets                        0.0344 0.1856  19.40 89.7%\n\nTest for subgroup differences (random effects model):\n                   Q d.f.  p-value\nBetween groups 24.84    4 &lt; 0.0001\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 22)\n- Prediction interval based on t-distribution (df = 21)\n- Fisher's z transformation of correlations\n\n\n\n\n\nS &lt;- summarise(group_by(tmp,journal_type),n=n(),obs=sum(stimulus_n))\nprint(knitr::kable(S))\n\n\n\njournal_type\nn\nobs\n\n\n\n\nEngineering\n15\n11490\n\n\nPsychology\n8\n3150\n\n\n\n\nm.cor2 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  journal_type,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\nprint(m.cor2)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 23\nNumber of observations: o = 14640\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.8154 [0.7567; 0.8611] 15.33 &lt; 0.0001\nPrediction interval         [0.3897; 0.9540]               \n\nQuantifying heterogeneity:\n tau^2 = 0.1183 [0.0683; 0.2510]; tau = 0.3440 [0.2613; 0.5010]\n I^2 = 97.0% [96.2%; 97.6%]; H = 5.75 [5.16; 6.41]\n\nTest of heterogeneity:\n      Q d.f.  p-value\n 728.54   22 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                             k    COR           95%-CI  tau^2    tau      Q\njournal_type = Engineering  15 0.7866 [0.6911; 0.8551] 0.1401 0.3743 651.05\njournal_type = Psychology    8 0.8628 [0.8028; 0.9054] 0.0405 0.2013  45.81\n                             I^2\njournal_type = Engineering 97.8%\njournal_type = Psychology  84.7%\n\nTest for subgroup differences (random effects model):\n                  Q d.f. p-value\nBetween groups 3.47    1  0.0624\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 22)\n- Prediction interval based on t-distribution (df = 21)\n- Fisher's z transformation of correlations\n\n\n\n\n\ntmp &lt;- dplyr::filter(R_summary,dimension==\"valence\")\ntmp&lt;-tmp[!is.na(tmp$feature_n_categories),] # remove \nS &lt;- summarise(group_by(tmp,feature_n_categories),n=n(),obs=sum(stimulus_n))\nprint(knitr::kable(S))\n\n\n\nfeature_n_categories\nn\nobs\n\n\n\n\nFeature n &lt; 18\n5\n3036\n\n\nFeature n &gt; 18 & &lt; 260\n11\n7042\n\n\nFeature n &gt; 260\n7\n4562\n\n\n\n\ntmp &lt;- dplyr::filter(R_summary,dimension==\"valence\")\ntmp&lt;-tmp[!is.na(tmp$feature_n_categories),] # remove missing values\nm.cor3 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  feature_n_categories,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\nprint(m.cor3)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 23\nNumber of observations: o = 14640\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.6739 [0.5782; 0.7513] 10.73 &lt; 0.0001\nPrediction interval         [0.0659; 0.9170]               \n\nQuantifying heterogeneity:\n tau^2 = 0.1249 [0.0720; 0.2617]; tau = 0.3534 [0.2683; 0.5115]\n I^2 = 97.9% [97.4%; 98.3%]; H = 6.86 [6.23; 7.56]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1036.47   22 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                                                k    COR           95%-CI\nfeature_n_categories = Feature n &gt; 260          7 0.6845 [0.5660; 0.7752]\nfeature_n_categories = Feature n &lt; 18           5 0.8111 [0.5342; 0.9308]\nfeature_n_categories = Feature n &gt; 18 & &lt; 260  11 0.5843 [0.4076; 0.7187]\n                                               tau^2    tau      Q   I^2\nfeature_n_categories = Feature n &gt; 260        0.0435 0.2085 211.87 97.2%\nfeature_n_categories = Feature n &lt; 18         0.1815 0.4260 362.55 98.9%\nfeature_n_categories = Feature n &gt; 18 & &lt; 260 0.1089 0.3300 295.76 96.6%\n\nTest for subgroup differences (random effects model):\n                  Q d.f. p-value\nBetween groups 4.66    2  0.0974\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 22)\n- Prediction interval based on t-distribution (df = 21)\n- Fisher's z transformation of correlations\n\nS&lt;-summarise(group_by(tmp,feature_n_categories),n=n(),obs=sum(stimulus_n))\nprint(S)\n\n# A tibble: 3 × 3\n  feature_n_categories       n   obs\n  &lt;chr&gt;                  &lt;int&gt; &lt;int&gt;\n1 Feature n &lt; 18             5  3036\n2 Feature n &gt; 18 & &lt; 260    11  7042\n3 Feature n &gt; 260            7  4562\n\n\n\n\n\ntmp &lt;- dplyr::filter(R_summary,dimension==\"valence\")\ntmp&lt;-tmp[!is.na(tmp$feature_n_categories),] # removemissing values\n\nS&lt;-summarise(group_by(tmp,feature_n_complexity_genre),n=n(),obs=sum(stimulus_n))\nprint(knitr::kable(S))\n\n\n\nfeature_n_complexity_genre\nn\nobs\n\n\n\n\nHuge multigenre study\n2\n1068\n\n\nMedium single genre/multigenre study\n14\n7854\n\n\nMedium-large single genre/multigenre study\n4\n2750\n\n\nSmall single genre study\n3\n2968\n\n\n\nm.cor4 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  feature_n_complexity_genre,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\nprint(m.cor4)\nReview: MER: Regression: Valence: Summary\nNumber of studies: k = 23 Number of observations: o = 14640\n                    COR           95%-CI     t  p-value\nRandom effects model 0.6739 [0.5782; 0.7513] 10.73 &lt; 0.0001 Prediction interval [0.0659; 0.9170]\nQuantifying heterogeneity: tau^2 = 0.1249 [0.0720; 0.2617]; tau = 0.3534 [0.2683; 0.5115] I^2 = 97.9% [97.4%; 98.3%]; H = 6.86 [6.23; 7.56]\nTest of heterogeneity: Q d.f. p-value 1036.47 22 &lt; 0.0001\nResults for subgroups (random effects model): k COR feature_n_complexity_genre = Medium-large single genre/multi … 4 0.6694 feature_n_complexity_genre = Small single genre study 3 0.8358 feature_n_complexity_genre = Medium single genre/multigenre … 14 0.6142 feature_n_complexity_genre = Huge multigenre study 2 0.7203 95%-CI feature_n_complexity_genre = Medium-large single genre/multi … [ 0.3472; 0.8503] feature_n_complexity_genre = Small single genre study [-0.1966; 0.9893] feature_n_complexity_genre = Medium single genre/multigenre … [ 0.4814; 0.7194] feature_n_complexity_genre = Huge multigenre study [-0.1886; 0.9645] tau^2 tau feature_n_complexity_genre = Medium-large single genre/multi … 0.0779 0.2791 feature_n_complexity_genre = Small single genre study 0.3182 0.5641 feature_n_complexity_genre = Medium single genre/multigenre … 0.0937 0.3061 feature_n_complexity_genre = Huge multigenre study 0.0128 0.1131 Q I^2 feature_n_complexity_genre = Medium-large single genre/multi … 202.35 98.5% feature_n_complexity_genre = Small single genre study 358.17 99.4% feature_n_complexity_genre = Medium single genre/multigenre … 332.50 96.1% feature_n_complexity_genre = Huge multigenre study 6.73 85.1%\nTest for subgroup differences (random effects model): Q d.f. p-value Between groups 3.84 3 0.2798\nDetails on meta-analytical method: - Inverse variance method - Restricted maximum-likelihood estimator for tau^2 - Q-Profile method for confidence interval of tau^2 and tau - Hartung-Knapp adjustment for random effects model (df = 22) - Prediction interval based on t-distribution (df = 21) - Fisher’s z transformation of correlations"
  },
  {
    "objectID": "analysis/analysis.html#classification-studies",
    "href": "analysis/analysis.html#classification-studies",
    "title": "Analysis",
    "section": "",
    "text": "C_studies &lt;- read.csv(\"C_studies.csv\")\nC_studies &lt;- C_studies[!is.na(C_studies$values),]\n\nC_summary &lt;- read.csv(\"C_summary.csv\")\n\nm.cor &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = studyREF, # unique_id\n                 data = C_summary,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 backtransf = TRUE,\n                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Classification: Summary\")\n\n#print(m.cor)\n\n#m.cor_backtransformed &lt;- m.cor\n#m.cor_backtransformed$TE &lt;- FisherZInv(m.cor_backtransformed$TE)\nprint(funnel(m.cor, common = FALSE, studlab=TRUE,backtransf=TRUE))\n\n\n\n\n\n\n\n\n$xlim\n[1] 0.598722 2.439471\n\n$ylim\n[1] 0.09090909 0.00000000\n\n\n\n\n\nlibrary(ggrepel)\ntmpdata &lt;- data.frame(SE = FisherZInv(m.cor$seTE), Zr = FisherZInv(m.cor$TE),studies=m.cor$studlab)\n\ntmpdata$citekey&lt;-str_replace_all(tmpdata$studies,'-.*$','')\ntmpdata$citekey&lt;-factor(tmpdata$citekey)\n\ng &lt;- ggplot(tmpdata,aes(y = SE, x = Zr,label=studies,color=citekey,fill=citekey)) +\n  geom_point(show.legend = FALSE) +\n  geom_label_repel(size=1.5,max.overlaps = 39,color=\"black\",show.legend = FALSE)+\n  ylab('Standard Error') + \n  xlab('r')+\n  scale_y_reverse()+\n#  scale_x_continuous(breaks=seq(0.0,1.0,0.25),limits=c(0,1.0))+\n#  coord_flip()+\n  theme_bw()\nprint(g)\n\n\n\n\n\n\n\n\n\n\n\n\nforest(m.cor,\n       sortvar = TE,\n       prediction = FALSE, \n             print.tau2 = FALSE,\n             leftlabs = c(\"Author\", \"g\", \"SE\"),studlab = citekey)\n\n\n\n\n\n\n\nfunnel(m.cor, common = FALSE, studlab=TRUE,backtransf=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\nO &lt;- find.outliers(m.cor)\n# 6 datasets identified as outliers, without them the r drops to 0.5781\n#infan &lt;- InfluenceAnalysis(m.cor)\n#print(eggers.test(m.cor))\n\n\n\n\n\n\n\nTo show the quality differences between core and eliminated studies (in progress).\n\ntmpdata &lt;- data.frame(SE = m.cor$seTE, Zr = m.cor$TE, studies=m.cor$studlab)\n\ntmpdata$studyREF &lt;- substr(tmpdata$studies,1,nchar(tmpdata$studies)-2)\ntmpdata$studyREF &lt;- str_replace_all(tmpdata$studyREF,'([0-9]+)',' et al \\\\1')\ntmpdata$studyREF &lt;- str_to_sentence(tmpdata$studyREF)\ntmpdata$studyREF\n\n [1] \"Agarwal et al  et al 20\"      \"Alvarez et al  et al 20\"     \n [3] \"Bai et al  et al 20\"          \"Bai et al  et al 20\"         \n [5] \"Bhuvanakumar et al  et al 20\" \"Dufour et al  et al 20\"      \n [7] \"Hizlisoy et al  et al 20\"     \"Hu et al  et al 20\"          \n [9] \"Nguyen et al  et al 20\"       \"Panda et al  et al 20\"       \n[11] \"Sorussa et al  et al 20\"      \"Yeh et al  et al 20\"         \n[13] \"Zhang et al  et al 20\"        \"Zhang et al  et al 20\"       \n\nestimate = m.cor$TE.common\nse = m.cor$seTE.common\nse.seq=seq(0, max(m.cor$cor), 0.001)\nll95 = estimate-(1.96*se.seq)\nul95 = estimate+(1.96*se.seq)\nll99 = estimate-(3.29*se.seq)\nul99 = estimate+(3.29*se.seq)\nmeanll95 = estimate-(1.96*se)\nmeanul95 = estimate+(1.96*se)\ndfCI = data.frame(ll95, ul95, ll99, ul99, se.seq, estimate, meanll95, meanul95)\n\nfp = ggplot(NULL) +\n  geom_point(aes(x = SE, y = Zr), color='grey50',data=tmpdata) +\n  geom_text_repel(aes(x = SE, y = Zr, label=studyREF), data=tmpdata,size=2.5,max.overlaps = 40)+\n  xlab('Standard Error') + ylab('Fisher\\'s z transformed correlation')+\n  geom_line(aes(x = se.seq, y = ll95), linetype = 'dotted', data = dfCI) +\n  geom_line(aes(x = se.seq, y = ul95), linetype = 'dotted', data = dfCI) +\n  geom_segment(aes(x = min(se.seq), y = meanll95, xend = max(se.seq), yend = meanll95), linetype='dotted', data=dfCI) +\n  geom_segment(aes(x = min(se.seq), y = meanul95, xend = max(se.seq), yend = meanul95), linetype='dotted', data=dfCI) +\n#  scale_x_reverse()+\n  scale_x_reverse(breaks=seq(0,0.2,0.05),limits=c(0.15,0),expand=c(0.00,0.00))+\n  scale_y_continuous(breaks=seq(0.3,1.25,0.20),limits=c(0.3,1.23))+\n  coord_flip()+\n  theme_bw()\nprint(fp)\n\nWarning: Removed 8 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\nWarning: Removed 8 rows containing missing values or values outside the scale range\n(`geom_text_repel()`).\n\n\nWarning: Removed 984 rows containing missing values or values outside the scale range\n(`geom_line()`).\nRemoved 984 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\nWarning: Removed 984 rows containing missing values or values outside the scale range\n(`geom_segment()`).\nRemoved 984 rows containing missing values or values outside the scale range\n(`geom_segment()`).\n\n\n\n\n\n\n\n\n\n\n\n\nadd journal_type and stimulus_genre_mixed as a grouping option\n\nm.cor_subgroups &lt;- update(m.cor, \n       subgroup = model_class_id, \n#       subgroup = journal_type, \n#       subgroup = stimulus_genre_mixed, \n       tau.common = FALSE,\n       prediction = TRUE)\n\nprint(m.cor_subgroups)\n#forest(m.cor_subgroups,subgroup=TRUE)\n\n\nIdea: visualise the distributions of the model successes within studies (done in preprocessing)"
  },
  {
    "objectID": "manuscript/manuscript.html#prediction-success-for-affect-dimensions",
    "href": "manuscript/manuscript.html#prediction-success-for-affect-dimensions",
    "title": "Meta-analysis of regression and classification success of emotion ratings from audio",
    "section": "Prediction success for affect dimensions",
    "text": "Prediction success for affect dimensions\nSee analysis/analysis.qmd\nSince there are many models contained within each of the studies, we will report the results in two parts; We first give an overview of the results for all models, and then we focus on the best performing models of each study. The best performing model is the model within each study with the highest correlation coefficient. This reduction is done to avoid the issue of multiple models from the same study deflating the results as majority of the models included are relative modest baseline or alternative models that do not represent the novelty or content of the article.\n\nResults for valence\nTable 2 summarises the results for all models (All) as well as best performing models (Max) for each study for valence. The summary includes the number of models and observations, the correlation coefficient and its 95% confidence interval, the t-value and p-value for the correlation, the heterogeneity statistics \\(\\tau^2\\) and \\(I^2\\), calculated through appropriate transformations (Fisher’s Z) for the correlation coefficient as part of a random-effects model using meta library (Balduzzi et al., 2019). We used Paule-Mandel estimator for between-study heterogeneity (Langan et al., 2019) and Knapp-Hartung (Knapp & Hartung, 2003) adjustments for confidence intervals. In this table we also report two subgroup analyses. One where we have divided the studies according to the number of features they contain (three categories based on quantiles to keep the group size comparable) and into five modelling techniques introduced earlier (Table 1).\nTable 2. Meta-analytic diagnostic for all regression studies predicting valence from audio. See Table 1 for the acronyms of the modelling techniques.\n\n\n\n\n\n\n\n\n\n\n\n\nConcept\nModels, obs\n\\(r\\) [95%-CI]\n\\(t\\)\n\\(p\\)\n\\(\\tau^2\\)\n\\(I^2\\)\n\n\n\n\nValence All\n120,73685\n0.567 [0.530; 0.603]\n23.7\n.0001\n0.083\n97.5%\n\n\nValence Max\n24,15660\n0.659 [0.557; 0.740]\n10.14\n.0001\n0.138\n98.2%\n\n\nN Features\n\n\n\n\n\n\n\n\n&lt;18 F\n5,3036\n0.811 [0.566; 0.???]\n-\n-\n0.182\n98.9%\n\n\n18-260 F\n11,7318\n0.548 [0.343; 0.703]\n-\n-\n0.133\n97.6%\n\n\n260+ F\n7,4562\n0.685 [0.566; 0.775]\n-\n-\n0.044\n97.2%\n\n\nTechniques\n\n\n\n\n\n\n\n\nKS\n2,2582\n0.466 [-0.634; 0.942]\n-\n-\n0.0185\n95.1%\n\n\nLM\n8,1762\n0.784 [0.625; 0.881]\n-\n-\n0.1370\n96.4%\n\n\nFD\n6,4993\n0.656 [0.484; 0.779]\n-\n-\n0.0574\n96.9%\n\n\nNN\n4,2249\n0.340 [-0.097; 0.668]\n-\n-\n0.0761\n97.1%\n\n\nRF\n4,4074\n0.702 [0.391; 0.869]\n-\n-\n0.057\n98.5%\n\n\n\nThe results indicate that valence can generally be predicted with moderately accuracy, with the best model from each of the 24 studies achieving an average correlation of r = 0.658 (95% CI: 0.557-0.740), called “valence Max” in Table 2. However, when considering all models across these studies (n = 120), the overall prediction rate drops significantly to r = 0.567. We argue that this lower correlation is likely due to the inclusion of baseline models reported in these studies, which may not reflect the true success of the task for the purposes of our analysis.\nFurther analysis of between-study heterogeneity, as indexed by the \\(\\tau^2\\) (0.138) and Higgins & Thompson’s \\(I^2\\) statistic (Higgins & Thompson, 2002) at 98.2%, reveals substantial heterogeneity. Since \\(I^2\\) is heavily influenced by study size (with larger N leading to lower sampling error), its value may be less insightful in this context. In contrast, \\(\\tau^2\\), which is less sensitive to the number of studies and directly linked to the outcome metric (r), provides a more reliable measure of heterogeneity in this case. Also, we note that because the overall heterogeneity in the data is high, we are cautious in our interpretation of the publication bias (Van Aert et al., 2016).\nTo better understand the effects across studies and the nature of the observed heterogeneity, Figure 2 presents (A) a forest and (B) funnel plot of the random-effects model, based on the best-performing models from all studies. In terms of the forest plot, the range of prediction values (correlations) is broad, spanning from 0.13 to 0.92, with all studies except Koh et al. (2023) demonstrating evidence of positive correlations. A mean estimate of 0.66 is achieved by 15 out of the 24 models. While the confidence intervals are generally narrow due to the large sample sizes in each study, there are exceptions, such as smaller sample sizes in Beveridge & Knox (2018) (n = 20), Saiz-Clar et al. (2022) (n = 40), and in Griffiths et al. (2021) (n = 40). The funnel plot in panel B of Figure 2 shows clustering at the top of the plot (studies with low standard error) and no assumed larger diversity in the correlations when the error rates increase. However, there is no clear asymmetry in the plot, verified by non-significant Egger’s test (\\(\\beta\\)=5.00, CI95% -0.78-10.78, t = 1.70, p = 0.104, Egger et al. (1997)). Coming back to the mean of valence correlation of 0.66 by all studies and the possible impact of study heterogeneity on this estimation, we also calculated the correlation without the studies that lie outside the 95% CI for pooled effect. This left 13 studies in the data and resulted in the meta-analytical pooled correlation of 0.649 (CI95% 0.598-0.695). In other words, despite the large variation in the correlations and standard errors across the studies, this variation in itself does not seem to be a significant driver behind the overall effect.\n\n\n\n\n\nForest (A) and funnel (B) plots of the best valence models from all MER studies.\n\n\n\n\nTo gain insights into the factors contributing to the wide range of model success, we explored several ways of splitting the data. Table 2 presents two key splits: one based on the number of features used, which we hypothesized might influence model performance, and another based on the modeling techniques employed. In terms of feature sets, we categorized them into three groups: few features (&lt;18), a large number of features (18–260), and massive feature sets (260+). Interestingly, models using a relatively small number of features (&lt;18) performed best (r = 0.881, 95% CI: 0.566–0.???) compared to those utilizing larger feature sets. However, it is worth noting that the models using massive feature sets (260+) also performed well (r = 0.685), achieving better and more consistent results than the overall prediction rate (r = 0.659). This observation is supported by the lowest heterogeneity index for the massive feature set group (\\(\\tau^2\\) = 0.044), indicating more consistent results across studies.\nWhen analyzing the studies across the five modeling techniques used. Notably, linear models (LM) and flexible discriminants (FD) were the most common, with 8 and 6 studies, respectively, allowing for more confident interpretations. Linear models achieved the highest prediction rate (r = 0.784, 95% CI: 0.625–0.881), though this may be influenced by the smaller datasets typically used in these studies. These studies also exhibited substantially higher heterogeneity (\\(\\tau^2\\) = 0.137) compared to other techniques, where \\(\\tau^2\\) values were less than half of this. Flexible discriminants performed at a similar level to the overall model average (r = 0.656, 95% CI: 0.484–0.779). The relatively poor performance of the neural network (NN) models (r = 0.340, 95% CI: -0.097–0.668) is difficult to explain without a deeper examination of the specific model architectures and the stimuli used in these studies.\nWe also ran the sub-grouping analyses across a combination of stimulus genres (single vs mixed) and number of the features to explore where the differences in the model prediction rates might lie. For this purpose, we grouped the studies into small single genre/multigenre studies, medium single genre/multigenre studies, and medium-large single genre/multigenre studies, and huge multigenre studies. The small single genre/multigenre studies generally performed best (r = 0.836, 95% CI: -0.197-0.989), followed by huge multi-genre studies (r = 0.720, 95% CI: -0.189-0.965) while the medium and medium-large sized studies performance was between close the overall average (medium-large, r = 0.669, 95% CI: 0.347-0.850 and medium r = 0.587, 95% CI: 0.433-0.708). The heterogeneity was lowest in the huge multigenre studies (\\(\\tau^2\\) = 0.013) and highest in the small single genre/multigenre studies (\\(\\tau^2\\) = 0.318).\n\n\nThese comparisons of sub-groupings are also influenced by other factors, such as the type of journal (psychology vs engineering) or whether the objective is to explain or predict emotions. Although the sub-groupings result in an uneven distribution of studies and observations, they still offer valuable insights. Despite these caveats, the two main sub-groupings portrayed in Table 2 enable us to identify valuable differences related to model success across the studies.\n\n\nResults for arousal\nMoving on the arousal, we carry out the same meta-analytical analysis applying the random-effects model to arousal. Table 3 describes the broad pattern of results in tabular format, and Figure 3 illustrates the spread and heterogeneity of all studies for arousal. The overall correlation across the studies using the best performing model out of each study (Max) is 0.807 (CI95% 0.745-0.855). If we examine all the models reported in each study, the correlation drops marginally, to 0.784 (CI95% 0.765-0.801), despite this analysis includes about five times as many models as taking the best model out of each study. For arousal, even the baseline models seem to be performing on a relative high level. However, the indicators of heterogeneity are again high (\\(\\tau^2\\) = 0.155 and \\(I^2\\)=96.8%), which suggests that summary may be misleading. However, the analysis of asymmetry does not reveal significant issues (Eggers test, \\(\\beta\\) = 0.787 95%CI -4.61-6.18, t = 0.286, p = 0.778). If we remove the studies that are outside the 95%CI in heterogeneity, leaves this 14 studies in the summary that has r = 0.8182 (95%CI 0.802-0.833) with \\(\\tau^2\\) = 0.0038 and \\(I^2\\) = 76.0%. In other words, no material difference to the results obtained with all 24 studies.\nTable 3. Meta-analytic diagnostic for all regression studies predicting arousal from audio.\n\n\n\n\n\n\n\n\n\n\n\n\nConcept\nModels, obs\n\\(r\\) [95%-CI]\n\\(t\\)\n\\(p\\)\n\\(\\tau^2\\)\n\\(I^2\\)\n\n\n\n\nArousal All\n126, 74365\n0.7837 [0.7652-0.8009]\n45.2\n0.0001\n0.064\n96.3%\n\n\nArousal Max\n24, 15660\n0.8070 [0.7453-0.8550]\n14.8\n0.0001\n0.128\n97.7%\n\n\nN Features\n\n\n\n\n\n\n\n\n&lt;18 F\n5, 3036\n0.8111 [0.5342-0.9308]\n\n\n0.1815\n98.9%\n\n\n18-260 F\n11, 7318\n0.5477 [0.3434-0.7025]\n\n\n0.1331\n97.6%\n\n\n260+ F\n7, 4562\n0.6845 [0.5660-0.7752]\n\n\n0.0435\n97.2%\n\n\nTechniques\n\n\n\n\n\n\n\n\nKS\n2, 2582\n0.8068 [0.5493-0.9244]\n\n\n0.0022\n70.0%\n\n\nLM\n8, 1762\n0.8812 [0.8079-0.9277]\n\n\n0.0846\n93.3%\n\n\nFD\n6, 4993\n0.8077 [0.6437-0.9008]\n\n\n0.1125\n98.0%\n\n\nNN\n4, 2249\n0.5339 [0.3281-0.6912]\n\n\n0.0190\n85.8%\n\n\nRF\n4, 4074\n0.8024 [0.7672-0.8327]\n\n\n0.0012\n52.7%\n\n\n\nThe forest plot in Figure 3 reveals\nThe subdivision of studies shows…\n\n\n\n\n\nForest (A) and funnel (B) plots of the best arousal models from all MER studies."
  },
  {
    "objectID": "analysis/preprocessing.html#feature-n-and-genre-split",
    "href": "analysis/preprocessing.html#feature-n-and-genre-split",
    "title": "Preprocessing",
    "section": "Feature N and genre split",
    "text": "Feature N and genre split\n\nquantile(subset(R_studies,stimulus_genre_mixed=='SingleGenre')$feature_n,probs = seq(0,1,0.333))\n\n   0% 33.3% 66.6% 99.9% \n    3    21    72   201 \n\nquantile(subset(R_studies,stimulus_genre_mixed=='MultiGenre')$feature_n,na.rm=TRUE,probs = seq(0,1,0.333))\n\n   0% 33.3% 66.6% 99.9% \n   15   388   653  6670 \n\n# a combination of the two\nR_studies$feature_n_complexity_genre &lt;- cut(R_studies$feature_n,\n                                      breaks = c(0,15,501,653,10000),\n                                      labels = c(\"Small single genre study\",\"Medium single genre/multigenre study\",\"Medium-large single genre/multigenre study\",\"Huge multigenre study\"))\ntable(R_studies$feature_n_complexity_genre)\n\n\n                  Small single genre study \n                                        18 \n      Medium single genre/multigenre study \n                                        92 \nMedium-large single genre/multigenre study \n                                        94 \n                     Huge multigenre study \n                                        32"
  },
  {
    "objectID": "analysis/preprocessing.html#feature-n-and-genre-split-1",
    "href": "analysis/preprocessing.html#feature-n-and-genre-split-1",
    "title": "Preprocessing",
    "section": "Feature N and genre split",
    "text": "Feature N and genre split\n\nquantile(subset(R_studies,stimulus_genre_mixed=='SingleGenre')$feature_n,probs = seq(0,1,0.333))\n\n   0% 33.3% 66.6% 99.9% \n    3    21    72   201 \n\nquantile(subset(R_studies,stimulus_genre_mixed=='MultiGenre')$feature_n,na.rm=TRUE,probs = seq(0,1,0.333))\n\n   0% 33.3% 66.6% 99.9% \n   15   388   653  6670 \n\n# a combination of the two\nR_studies$feature_n_complexity_genre &lt;- cut(R_studies$feature_n,\n                                      breaks = c(0,15,501,653,10000),\n                                      labels = c(\"Small single genre study\",\"Medium single genre/multigenre study\",\"Medium-large single genre/multigenre study\",\"Huge multigenre study\"))\ntable(R_studies$feature_n_complexity_genre)\n\n\n                  Small single genre study \n                                        18 \n      Medium single genre/multigenre study \n                                        92 \nMedium-large single genre/multigenre study \n                                        94 \n                     Huge multigenre study \n                                        32"
  },
  {
    "objectID": "analysis/analysis.html#explore-heterogeneity",
    "href": "analysis/analysis.html#explore-heterogeneity",
    "title": "Analysis",
    "section": "",
    "text": "# Method 1: Give us the Egger's test about beta coefficient from funnel\nprint(eggers.test(m.cor))\n\nEggers' test of the intercept \n============================= \n\n intercept        95% CI     t         p\n     4.997 -0.78 - 10.78 1.695 0.1042273\n\nEggers' test does not indicate the presence of funnel plot asymmetry. \n\n# Method 2: Find the impact to the results when removing those outside the 95CI\nO &lt;- find.outliers(m.cor) # 13 remaining out of 24\n\n# Method 3: Leave-out-out analysis etc for individual influence (not useful here)\n#infan &lt;- InfluenceAnalysis(m.cor)\n\n# Method 4: Focus on 10% of most precise studies (Stanley, Jarrel, Doucouliagos 2010)\nthres&lt;-quantile(m.cor$seTE,0.1)\nind&lt;-m.cor$seTE&lt;=as.numeric(thres)\nm.cor10pct &lt;- update(m.cor, subset = which(ind))\n\n# Method 5: P curve analysis (Simonsohn, Simmons & Nelson, 2015)\npcurve(m.cor)\n\n\n\n\n\n\n\n\nP-curve analysis \n ----------------------- \n- Total number of provided studies: k = 24 \n- Total number of p&lt;0.05 studies included into the analysis: k = 23 (95.83%) \n- Total number of studies with p&lt;0.025: k = 23 (95.83%) \n   \nResults \n ----------------------- \n                    pBinomial   zFull pFull   zHalf pHalf\nRight-skewness test         0 -34.047     0 -33.531     0\nFlatness test               1  33.691     1  34.002     1\nNote: p-values of 0 or 1 correspond to p&lt;0.001 and p&gt;0.999, respectively.   \nPower Estimate: 99% (99%-99%)\n   \nEvidential value \n ----------------------- \n- Evidential value present: yes \n- Evidential value absent/inadequate: no \n\n\n\n\n\n\n\ntmp &lt;- dplyr::filter(R_summary,dimension==\"valence\")\ntmp&lt;-tmp[!is.na(tmp$feature_n_categories),] # remove missing values\n\nm.cor3 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  feature_n_categories,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\nprint(m.cor3)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 23\nNumber of observations: o = 14916\n\n                        COR            95%-CI    t  p-value\nRandom effects model 0.6597 [ 0.5535; 0.7448] 9.73 &lt; 0.0001\nPrediction interval         [-0.0159; 0.9218]              \n\nQuantifying heterogeneity:\n tau^2 = 0.1444 [0.0834; 0.2986]; tau = 0.3800 [0.2889; 0.5464]\n I^2 = 98.3% [98.0%; 98.6%]; H = 7.65 [6.99; 8.38]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1288.44   22 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                                                k    COR           95%-CI\nfeature_n_categories = Feature n &gt; 260          7 0.6845 [0.5660; 0.7752]\nfeature_n_categories = Feature n &lt; 18           5 0.8111 [0.5342; 0.9308]\nfeature_n_categories = Feature n &gt; 18 & &lt; 260  11 0.5477 [0.3434; 0.7025]\n                                               tau^2    tau      Q   I^2\nfeature_n_categories = Feature n &gt; 260        0.0435 0.2085 211.87 97.2%\nfeature_n_categories = Feature n &lt; 18         0.1815 0.4260 362.55 98.9%\nfeature_n_categories = Feature n &gt; 18 & &lt; 260 0.1331 0.3648 416.81 97.6%\n\nTest for subgroup differences (random effects model):\n                  Q d.f. p-value\nBetween groups 5.73    2  0.0570\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 22)\n- Prediction interval based on t-distribution (df = 21)\n- Fisher's z transformation of correlations\n\n\n\n\n\n\nm.cor_subgroups &lt;- update(m.cor, \n       subgroup = model_class_id, \n#       subgroup = journal_type, \n#       subgroup = stimulus_genre_mixed, \n       tau.common = FALSE,\n       prediction = TRUE)\n\nprint(m.cor_subgroups)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 24\nNumber of observations: o = 15660\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.6585 [0.5574; 0.7404] 10.14 &lt; 0.0001\nPrediction interval         [0.0042; 0.9180]               \n\nQuantifying heterogeneity:\n tau^2 = 0.1376 [0.0804; 0.2802]; tau = 0.3709 [0.2836; 0.5293]\n I^2 = 98.2% [97.9%; 98.5%]; H = 7.50 [6.86; 8.20]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1294.03   23 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                                                      k    COR\nmodel_class_id = Kernel Smoothing, Additive and KNN   2 0.4662\nmodel_class_id = Random Forests                       4 0.7024\nmodel_class_id = Linear Methods                       8 0.7840\nmodel_class_id = Neural Nets                          4 0.3404\nmodel_class_id = Flexible Discriminants               6 0.6555\n                                                               95%-CI  tau^2\nmodel_class_id = Kernel Smoothing, Additive and KNN [-0.6342; 0.9424] 0.0185\nmodel_class_id = Random Forests                     [ 0.3914; 0.8694] 0.0803\nmodel_class_id = Linear Methods                     [ 0.6249; 0.8806] 0.1370\nmodel_class_id = Neural Nets                        [-0.0970; 0.6676] 0.0761\nmodel_class_id = Flexible Discriminants             [ 0.4838; 0.7786] 0.0574\n                                                       tau      Q   I^2\nmodel_class_id = Kernel Smoothing, Additive and KNN 0.1361  20.56 95.1%\nmodel_class_id = Random Forests                     0.2833 198.79 98.5%\nmodel_class_id = Linear Methods                     0.3701 195.78 96.4%\nmodel_class_id = Neural Nets                        0.2759 102.54 97.1%\nmodel_class_id = Flexible Discriminants             0.2396 161.22 96.9%\n\nTest for subgroup differences (random effects model):\n                   Q d.f. p-value\nBetween groups 18.75    4  0.0009\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 23)\n- Prediction interval based on t-distribution (df = 22)\n- Fisher's z transformation of correlations\n\n#forest(m.cor_subgroups,subgroup=TRUE)\n\n\n\n\nAdd journal_type as a grouping option. Here we have divided the journals into engineering and psychology journals.\n\nm.cor_subgroups &lt;- update(m.cor, \n       subgroup = journal_type, \n#       subgroup = journal_type, \n#       subgroup = stimulus_genre_mixed, \n       tau.common = FALSE,\n       prediction = TRUE)\n\nprint(m.cor_subgroups)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 24\nNumber of observations: o = 15660\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.6585 [0.5574; 0.7404] 10.14 &lt; 0.0001\nPrediction interval         [0.0042; 0.9180]               \n\nQuantifying heterogeneity:\n tau^2 = 0.1376 [0.0804; 0.2802]; tau = 0.3709 [0.2836; 0.5293]\n I^2 = 98.2% [97.9%; 98.5%]; H = 7.50 [6.86; 8.20]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1294.03   23 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                             k    COR           95%-CI  tau^2    tau      Q\njournal_type = Engineering  15 0.6424 [0.5112; 0.7444] 0.1208 0.3475 644.85\njournal_type = Psychology    9 0.6880 [0.4683; 0.8276] 0.1830 0.4278 562.98\n                             I^2\njournal_type = Engineering 97.8%\njournal_type = Psychology  98.6%\n\nTest for subgroup differences (random effects model):\n                  Q d.f. p-value\nBetween groups 0.23    1  0.6349\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 23)\n- Prediction interval based on t-distribution (df = 22)\n- Fisher's z transformation of correlations\n\n#forest(m.cor_subgroups,subgroup=TRUE)\n\n\n\n\nAdd stimulus_genre_mixed as a grouping option\n\nm.cor_subgroups &lt;- update(m.cor, \n       subgroup = stimulus_genre_mixed, \n#       subgroup = journal_type, \n#       subgroup = stimulus_genre_mixed, \n       tau.common = FALSE,\n       prediction = TRUE)\n\nprint(m.cor_subgroups)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 24\nNumber of observations: o = 15660\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.6585 [0.5574; 0.7404] 10.14 &lt; 0.0001\nPrediction interval         [0.0042; 0.9180]               \n\nQuantifying heterogeneity:\n tau^2 = 0.1376 [0.0804; 0.2802]; tau = 0.3709 [0.2836; 0.5293]\n I^2 = 98.2% [97.9%; 98.5%]; H = 7.50 [6.86; 8.20]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1294.03   23 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                                     k    COR           95%-CI  tau^2    tau\nstimulus_genre_mixed = MultiGenre   16 0.6505 [0.5123; 0.7558] 0.1467 0.3831\nstimulus_genre_mixed = SingleGenre   8 0.6752 [0.4651; 0.8132] 0.1374 0.3707\n                                        Q   I^2\nstimulus_genre_mixed = MultiGenre  878.20 98.3%\nstimulus_genre_mixed = SingleGenre 415.17 98.3%\n\nTest for subgroup differences (random effects model):\n                  Q d.f. p-value\nBetween groups 0.07    1  0.7910\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 23)\n- Prediction interval based on t-distribution (df = 22)\n- Fisher's z transformation of correlations\n\n#forest(m.cor_subgroups,subgroup=TRUE)\n\n\n\n\nadd feature_n_complexity_genre.\n\ntmp &lt;- dplyr::filter(R_summary,dimension==\"valence\")\ntmp&lt;-tmp[!is.na(tmp$feature_n_categories),] # remove missing values\ndim(tmp)\n\n[1] 23 14\n\nm.cor3 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  feature_n_complexity_genre,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\nprint(m.cor3)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 23\nNumber of observations: o = 14916\n\n                        COR            95%-CI    t  p-value\nRandom effects model 0.6597 [ 0.5535; 0.7448] 9.73 &lt; 0.0001\nPrediction interval         [-0.0159; 0.9218]              \n\nQuantifying heterogeneity:\n tau^2 = 0.1444 [0.0834; 0.2986]; tau = 0.3800 [0.2889; 0.5464]\n I^2 = 98.3% [98.0%; 98.6%]; H = 7.65 [6.99; 8.38]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1288.44   22 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                                                                   k    COR\nfeature_n_complexity_genre = Medium-large single genre/multi ...   4 0.6694\nfeature_n_complexity_genre = Small single genre study              3 0.8358\nfeature_n_complexity_genre = Medium single genre/multigenre  ...  14 0.5874\nfeature_n_complexity_genre = Huge multigenre study                 2 0.7203\n                                                                            95%-CI\nfeature_n_complexity_genre = Medium-large single genre/multi ... [ 0.3472; 0.8503]\nfeature_n_complexity_genre = Small single genre study            [-0.1966; 0.9893]\nfeature_n_complexity_genre = Medium single genre/multigenre  ... [ 0.4328; 0.7084]\nfeature_n_complexity_genre = Huge multigenre study               [-0.1886; 0.9645]\n                                                                  tau^2    tau\nfeature_n_complexity_genre = Medium-large single genre/multi ... 0.0779 0.2791\nfeature_n_complexity_genre = Small single genre study            0.3182 0.5641\nfeature_n_complexity_genre = Medium single genre/multigenre  ... 0.1183 0.3439\nfeature_n_complexity_genre = Huge multigenre study               0.0128 0.1131\n                                                                      Q   I^2\nfeature_n_complexity_genre = Medium-large single genre/multi ... 202.35 98.5%\nfeature_n_complexity_genre = Small single genre study            358.17 99.4%\nfeature_n_complexity_genre = Medium single genre/multigenre  ... 481.16 97.3%\nfeature_n_complexity_genre = Huge multigenre study                 6.73 85.1%\n\nTest for subgroup differences (random effects model):\n                  Q d.f. p-value\nBetween groups 4.70    3  0.1949\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 22)\n- Prediction interval based on t-distribution (df = 21)\n- Fisher's z transformation of correlations\n\n\n\n\n\n\n\n# select regression studies with r2\ntmp &lt;- dplyr::filter(R_summary,dimension==\"arousal\")\n#tmp &lt;- dplyr::filter(R_studies,dimension==\"arousal\")\ndim(tmp)\n\n[1] 24 14\n\n#tmp &lt;- tmp[!is.na(tmp$values),]\ndim(tmp)\n\n[1] 24 14\n\n#tmp&lt;-drop_na(tmp)\n\nm.cor &lt;- metacor(cor = valuesMax, \n                 n = stimulus_n,\n                 studlab = citekey,\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 backtransf = TRUE,\n                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Arousal: Summary\")\n\nprint(m.cor)\n\nReview:     MER: Regression: Arousal: Summary\n\nNumber of studies: k = 24\nNumber of observations: o = 15660\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.8070 [0.7453; 0.8550] 14.83 &lt; 0.0001\nPrediction interval         [0.3466; 0.9541]               \n\nQuantifying heterogeneity:\n tau^2 = 0.1276 [0.0746; 0.2631]; tau = 0.3571 [0.2731; 0.5130]\n I^2 = 97.7% [97.2%; 98.1%]; H = 6.60 [5.99; 7.27]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1001.16   23 &lt; 0.0001\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 23)\n- Prediction interval based on t-distribution (df = 22)\n- Fisher's z transformation of correlations"
  },
  {
    "objectID": "analysis/preprocessing.html#remove-nas",
    "href": "analysis/preprocessing.html#remove-nas",
    "title": "Preprocessing",
    "section": "Remove NAs",
    "text": "Remove NAs\n\nR_studies &lt;- R_studies[!is.na(R_studies$values),]"
  },
  {
    "objectID": "analysis/preprocessing.html#check-models-arent-double-counted",
    "href": "analysis/preprocessing.html#check-models-arent-double-counted",
    "title": "Preprocessing",
    "section": "Check models aren’t double-counted",
    "text": "Check models aren’t double-counted\n\nlength(unique(paste0(R_studies$unique_id, R_studies$dimension)))\n\n[1] 324\n\nez::ezDesign(data = R_studies, x = unique_id, y = citekey)"
  }
]