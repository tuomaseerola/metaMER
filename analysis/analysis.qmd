# Analysis

This assumes that the data has been parsed from the BibTeX files into table and exported as CSV file.

## Read annotated data

- Update 2024-06-19
- [ ] CA TODO later (if at all): find better way to read in functions

```{r}
require(here)
source(here::here('R/build-df.R'))
source(here::here('R/format-study-results.R'))
source(here::here('R/parse-model-output.R'))
```

- [ ] CA ToDo: Check the warning reported here

```{r}
# get metaMER df:
meta_df <- get_metaMER_df(path_2_studies = here::here('studies'))

# get included studies
included_studies <- meta_df[which(
  !stringr::str_detect(meta_df$final_notes, '!EXCL!')),] |> 
  dplyr::tibble()

```
### Recoded


```{r}
# get studies re-coded (currently identifiable by presence of bind_field.)
recoded_studies <- included_studies[which(stringr::str_detect(
  included_studies$model_rate_emotion_values,
                                     'bind_field')),] 

```

Maybe limit the verbosity of `get_study_results` below

```{r}
metaMER_results <-
do.call(
  rbind,
    lapply(1:nrow(recoded_studies),
       function(x) get_study_results(recoded_studies[x,])
       )
) 

# add unique identifiers

unique_id <- apply(metaMER_results[,c('citekey',
                        'library_id',
                         'model_id',
                         'feature_id',
                         'data_id',
                         'experiment_id')],
                      1, 
                      paste0, 
                      collapse = '-'
) 
metaMER_results$unique_id <- stringr::str_remove_all(unique_id, 
                                                     ' ')

metaMER_results <- metaMER_results |> dplyr::select(unique_id, 
                                 dplyr::everything()) 

metaMER_results |> dplyr::tibble()

```


## Summarise annotated data

```{r}
#| eval: true
#| output: asis

print(knitr::kable(table(metaMER_results$citekey,metaMER_results$dimension)))
print(knitr::kable(table(metaMER_results$citekey,metaMER_results$model_id)))
print(knitr::kable(table(metaMER_results$citekey,metaMER_results$feature_id)))
print(knitr::kable(table(metaMER_results$citekey,metaMER_results$data_id)))

```


## Analysis notes

- [x] Issue 1: We need unique identifiers for each input component (combine: `study` + `model` + `feature` + `data` + `experiment` that would have be unique id)
- [x] Issue 2: We `stimulus_N`
- [x] Issue 3: measure vs statistic?
- [x] Issue 4: We need to classify the modelling techniques into fewer number of techniques (example given, but no principles defined)
- [ ] Issue 5: We could polish citekey into ref (xu2021us to Xu 2021 et al., ) for nicer plotting output (can be done with `str_replace`)

- [ ] If the _number of stimuli_ varies, divide either to separate experiments or use the largest value (see below for ad-hoc solution).

### Regression studies

#### Valence

```{r}
#| warning: false
#| eval: true
library(dmetar)
library(tidyverse)
library(meta)

# select regression studies with r2
tmp <- dplyr::filter(metaMER_results,dimension=="valence" & measure=="r2")

# Temporary clarification of N
tmp$stimulus_n[tmp$stimulus_n==" emoMusic: 1000, soundtracks: 360, chinese: 500 "]<-1000
tmp$stimulus_n[tmp$stimulus_n==" 2372 (subset of PSIC3839, total n: 3839)    "]<-2372
tmp$stimulus_n[tmp$stimulus_n==" study 1: 20; study 2: 40) % three outliers  "]<-40
tmp$stimulus_n <- as.numeric(tmp$stimulus_n)

#sqrt(tmp$values) # convert from R^2 to r
#tmp$stimulus_n <- 100 # ad-hoc for now

m.cor <- metacor(cor = sqrt(values), 
                 n = stimulus_n,
                 studlab = citekey,
                 data = tmp,
                 fixed = FALSE,
                 random = TRUE,
                 sm = "ZCOR",
                 method.tau = "REML",# could be PM (Paule-Mandel) as well
                 method.random.ci = "HK", 
                 title = "MER: Regression: Valence: All")

print(m.cor)
```

## Explore qualities

```{r}
meta <- metagen(values, sqrt(values), 
                data = tmp, 
                studlab = tmp$citekey, 
                comb.fixed = FALSE, 
                method.tau = "PM")
find.outliers(meta)
infan <- InfluenceAnalysis(meta)
print(eggers.test(meta))

```

## Sub-group analysis (based on model type)

```{r}
#| eval: true

# divide models into random forests, SVM and MLR
tmp$model_class_id <- 'MLR/PLS'
tmp$model_class_id[str_detect(tmp$model_id,'RFR|extremely randomized tree regression')]<-'RF'
tmp$model_class_id[str_detect(tmp$model_id,'svm|SVR')]<-'SVM'
table(tmp$model_class_id)
meta <- metagen(values, sqrt(values), # Fix the TE.se 
                data = tmp, 
                studlab = tmp$citekey, 
                comb.fixed = FALSE, 
                method.tau = "PM")

subgroup.analysis.mixed.effects(x = meta, 
                                subgroups = tmp$model_class_id)
```

## Visualise

```{r}
plot(m.cor)
plot(eggers.test(meta))

```