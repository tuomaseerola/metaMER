[
  {
    "objectID": "manuscript/manuscript.html",
    "href": "manuscript/manuscript.html",
    "title": "Meta-analysis of regression and classification success of emotion ratings from audio",
    "section": "",
    "text": "Emotional expression is one of the central reasons why people engage with music.\nGreat advances in music information retrieval have been made in recent years. The available features, modelling techniques and datasets have given scholars opportunities to refine the accuracy and reliability of predicting annotated emotions from audio.\nNumerous studies over the last 25 years have established what emotions listeners perceive and recognise in music (Gómez-Cañón et al., 2021). In the last 15 years, it has become possible to trace the recognised emotions to musical contents such as expressive features (Lindström et al., 2003), structural aspects of music (Anderson & Schutz, 2022; Eerola et al., 2013; Grimaud & Eerola, 2022), or acoustic features (Eerola, 2011; R. Panda et al., 2013; Saari et al., 2015; Y. H. Yang et al., 2008) or emergent properties identified through deep learning (Er & Aydilek, 2019; Sarkar et al., 2020).\n\nHowever, there is no consensus on to what degree emotions can be recognised by computational models and the literature to date paints a diverse picture of success for concepts in affective circumplex – valence and arousal– (Russell, 1980) and classifying various emotion categories (Fu et al., 2010)."
  },
  {
    "objectID": "manuscript/manuscript.html#aims",
    "href": "manuscript/manuscript.html#aims",
    "title": "Meta-analysis of regression and classification success of emotion ratings from audio",
    "section": "Aims",
    "text": "Aims\n\nOur aim is to establish the level of predictive accuracy for both models of emotional expression that can account for track-specific coordinates in affective circumple space (valence and arousal) and classification of emotion categories based on available and recent studies.\nWe seek to identify the types of issues (modelling techniques, features, and musical qualities used) that significantly influence the prediction rates.\nTo achieve these aims, we carry out a meta-analysis focused on journal articles published in the last 10 years.\nWe outline broad hypotheses such as arousal being predicted to a higher degree than valence, which is more challenging and more context dependent than arousal. For classification, simple utilitarian emotions (e.g., fear, anger) will be easier to predict than complex social emotions (e.g., sadness, nostalgia)."
  },
  {
    "objectID": "manuscript/manuscript.html#quality-control",
    "href": "manuscript/manuscript.html#quality-control",
    "title": "Meta-analysis of regression and classification success of emotion ratings from audio",
    "section": "Quality Control",
    "text": "Quality Control\nThe search yielded studies of variable (and occasionally questionable) quality. To mitigate potentially spurious effects resulting from the inclusion of low-quality studies, we excluded studies lacking sufficient details about stimuli, analyzed features, or model architecture. Finally, we excluded studies published in journals of questionable relevance/quality, (e.g., Mathematical Problems in Engineering ceased publication following 17 retractions published between July and September 2024)."
  },
  {
    "objectID": "manuscript/manuscript.html#study-encoding",
    "href": "manuscript/manuscript.html#study-encoding",
    "title": "Meta-analysis of regression and classification success of emotion ratings from audio",
    "section": "Study Encoding",
    "text": "Study Encoding\nTo capture key details of each study, we added additional fields to BibTeX entries for each study. Fields included information about the genre/type of stimuli employed, along with their duration and number; the number of analyzed features; and the model type, validation procedure and output measures. Additionally, we included study results using executable R code containing custom functions for meta-analysis. For complete details about our encoding procedure, see studies/extraction_details.qmd ."
  },
  {
    "objectID": "manuscript/manuscript.html#prediction-success-for-valence-and-arousal-or-affect-dimensions",
    "href": "manuscript/manuscript.html#prediction-success-for-valence-and-arousal-or-affect-dimensions",
    "title": "Meta-analysis of regression and classification success of emotion ratings from audio",
    "section": "Prediction success for valence and arousal (or affect dimensions)",
    "text": "Prediction success for valence and arousal (or affect dimensions)\nSee analysis/analysis.qmd\nSince there are many models contained within each of the studies, we will report the results in two parts; We first give an overview of the results for all models, and then we focus on the best performing models of each study. The best performing model is the model within each study with the highest correlation coefficient. This reduction is done to avoid the issue of multiple models from the same study deflating the results as majority of the models included are relative modest baseline or alternative models that do not represent the novelty or content of the article. Table 2 summarises the results for all models (All) as well as best performing models (Max) for each study. The summary includes the number of models and observations, the correlation coefficient and its 95% confidence interval, the t-value and p-value for the correlation, the heterogeneity statistics \\(\\tau^2\\) and \\(I^2\\), calculated through appropriate transformations (Fisher’s Z) for the correlation coefficient as part of a random-effects model using meta library (Balduzzi et al., 2019).\nTable 2. Meta-analytic diagnostic for all regression studies predicting valence from audio.\n\n\n\n\n\n\n\n\n\n\n\n\nConcept\nModels, obs\n\\(r\\) [95%-CI]\n\\(t\\)\n\\(p\\)\n\\(\\tau^2\\)\n\\(I^2\\)\n\n\n\n\nValence All\n120,73685\n0.567 [0.530; 0.603]\n23.7\n.0001\n0.083\n97.5%\n\n\nValence Max\n24,15660\n0.659 [0.557; 0.740]\n10.14\n.0001\n0.138\n98.2%\n\n\nN Features\n\n\n\n\n\n\n\n\n&lt;18 F\n5,3036\n0.811 [0.566; 0.775]\n-\n-\n0.182\n98.9%\n\n\n18-260 F\n11,7318\n0.548 [0.343; 0.703]\n-\n-\n0.133\n97.6%\n\n\n260+ F\n7,4562\n0.685 [0.566; 0.775]\n-\n-\n0.044\n97.2%\n\n\nTechniques\n\n\n\n\n\n\n\n\nKS\n2,2582\n0.466 [-0.634; 0.942]\n-\n-\n0.0185\n95.1%\n\n\nLM\n8,1762\n0.784 [0.625; 0.881]\n-\n-\n0.1370\n96.4%\n\n\nFD\n6,4993\n0.656 [0.484; 0.779]\n-\n-\n0.0574\n96.9%\n\n\nNN\n4,2249\n0.340 [-0.097; 0.668]\n-\n-\n0.0761\n97.1%\n\n\nRF\n4,4074\n0.702 [0.391; 0.869]\n-\n-\n0.057\n98.5%\n\n\n\n\n\n\n\n\nOTHER GROUPINGS? STIMULUS MIXED/SINGLE GENRE, PREDICTION/EXPLANATION\n\n\n\n\n\n\n\nForest plot of valence predictions from the MER models.\n\n\n\n\nSummarise the results here briefly\nMoving on the arousal, …\nTable 3. Meta-analytic diagnostic for all regression studies predicting arousal from audio.\n\n\n\n\n\n\n\n\n\n\n\n\nConcept\nModels, obs\n\\(r\\) [95%-CI]\n\\(t\\)\n\\(p\\)\n\\(\\tau^2\\)\n\\(I^2\\)\n\n\n\n\nArousal\n\n0.7959 [0.7666; 0.8218]\n29.0\n0.0001\n0.0676\n95.6%\n\n\nArousal Max\n24,15660\n0.8070 [0.7453; 0.8550]\n10.3\n0.0001\n0.155\n96.8%\n\n\nN Features\n\n\n\n\n\n\n\n\n&lt;18 F\n\n\n\n\n\n\n\n\n18-260 F\n\n\n\n\n\n\n\n\n260+ F\n\n\n\n\n\n\n\n\nTechniques\n\n\n\n\n\n\n\n\nKS\n\n\n\n\n\n\n\n\nLM\n\n\n\n\n\n\n\n\nFD\n\n\n\n\n\n\n\n\nNN\n\n\n\n\n\n\n\n\nRF\n\n\n\n\n\n\n\n\n\nFigure 2. Forest plot of arousal prediction (using Max?)\n\n\n\n\nSummarise here the pattern of results"
  },
  {
    "objectID": "manuscript/manuscript.html#classification-studies",
    "href": "manuscript/manuscript.html#classification-studies",
    "title": "Meta-analysis of regression and classification success of emotion ratings from audio",
    "section": "Classification studies",
    "text": "Classification studies\nSummary of details contained in Table 1, but summarise at least the categories predicted before moving onto the main findings.\nTable 4. Meta-analytic diagnostic for all classification studies predicting emotion categories from audio.\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nModels, obs\n\\(r\\) [95%-CI]\n\\(t\\)\n\\(p\\)\n\\(\\tau^2\\)\n\\(I^2\\)\n\n\n\n\nAll\n89,87347\n0.8074 [0.7681; 0.8407]\n21.4\n0.0001\n0.2415\n99.7%\n\n\nMax\n14,17184\n0.8564 [0.7386; 0.9234]\n8.32\n0.0001\n0.329\n99.8%\n\n\n\n\n\nHeterogeneity issues\nFigure 3. Forest plot of arousal prediction (Max?) (Unless we do some custom plotting)\n\nFigure Optional: Funnel plot (I haven’t seen this yet)"
  },
  {
    "objectID": "manuscript/manuscript.html#concise-summary-of-what-we-did-and-found",
    "href": "manuscript/manuscript.html#concise-summary-of-what-we-did-and-found",
    "title": "Meta-analysis of regression and classification success of emotion ratings from audio",
    "section": "Concise summary of what we did and found",
    "text": "Concise summary of what we did and found"
  },
  {
    "objectID": "manuscript/manuscript.html#main-outcomes",
    "href": "manuscript/manuscript.html#main-outcomes",
    "title": "Meta-analysis of regression and classification success of emotion ratings from audio",
    "section": "Main outcomes",
    "text": "Main outcomes\n\nArousal is easier to predict (r = 0.7627) than valence (r = 0.6236), as we predicted. The glass ceiling seems to be at …\nClassification …\nModel accuracy is surprisingly little affected by the number of features (?) or modelling technique (?).\nSome of the complex state-of-the-art techniques (e.g., NNs) do not deliver impressive improvements over older techniques (e.g., SVR, RF)\nVariation in study/model/data quality is large and can be seen in heterogenuity and the amount of studies eliminated"
  },
  {
    "objectID": "manuscript/manuscript.html#calls-for-actionpoints-to-improve-in-such-studies",
    "href": "manuscript/manuscript.html#calls-for-actionpoints-to-improve-in-such-studies",
    "title": "Meta-analysis of regression and classification success of emotion ratings from audio",
    "section": "Calls for action/points to improve in such studies",
    "text": "Calls for action/points to improve in such studies\n\nDocumentation the details in full (features, stimuli, model details, cross-validation)\nQuality of the underlying data (emotion ratings, classes, or even stimulus properties?\nGeneralisibility of the models (some studies such as X and Y address this by applying the models across several datasets)\nDiversity in the evaluative aspects of studies: overfitting, numerous ways of cross-validating, not sharing data or analysis scripts, not reporting in the same way\nWhat proportion of stimuli are Western music, and what genres tend to dominate?\n\n\nFunding statement\nCA was funded by Mitacs Globalink Research Award (Mitacs & British High Commission - Ottawa, Canada).\n\n\nCompeting interests statement\nThere were no competing interests.\n\n\nOpen practices statement\nStudy preregistration, data, analysis scripts and supporting information is available at Github, https://tuomaseerola.github.io/metaMER.\n\n\nAcknowledgements\nWe thank Greggs food-on-the-go retailer for sustaining the work with affordable sandwiches and coffee."
  },
  {
    "objectID": "manuscript/manuscript.html#footnotes",
    "href": "manuscript/manuscript.html#footnotes",
    "title": "Meta-analysis of regression and classification success of emotion ratings from audio",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe best-performing model to date reached 69.83 % in the 2017 competition (Park et al., 2017)@park2017representation.↩︎"
  },
  {
    "objectID": "analysis/preprocessing.html",
    "href": "analysis/preprocessing.html",
    "title": "Preprocessing",
    "section": "",
    "text": "This assumes that the data has been parsed from the BibTeX files into table and exported as CSV file.\n\n\n\nrequire(here)\nsource(here::here('R/build-df.R'))\nsource(here::here('R/format-study-results.R'))\nsource(here::here('R/parse-model-output.R'))\n\n\nlibrary(stringr) \n# get metaMER df:\nmeta_df &lt;- get_metaMER_df(path_2_studies = here::here('studies'))\n\n# get included studies\nincluded_studies &lt;- meta_df[which(\n  !stringr::str_detect(meta_df$final_notes, '!EXCL!')),] |&gt; \n  dplyr::tibble()\n\n\n\n\n# get studies re-coded (currently identifiable by presence of bind_field.)\nrecoded_studies &lt;- included_studies[which(stringr::str_detect(\n  included_studies$model_rate_emotion_values,\n                                     'bind_field')),] \n\n\n\n\n\nmetaMER_results &lt;-\ndo.call(\n  rbind,\n    lapply(1:nrow(recoded_studies),\n       function(x) get_study_results(recoded_studies[x,])\n       )\n) \n\n# add unique identifiers\n\nunique_id &lt;- apply(metaMER_results[,c('citekey',\n                        'library_id',\n                         'model_id',\n                         'feature_id',\n                         'data_id',\n                         'experiment_id')],\n                      1, \n                      paste0, \n                      collapse = '-'\n) \nmetaMER_results$unique_id &lt;- stringr::str_remove_all(unique_id, \n                                                     ' ')\n\nmetaMER_results &lt;- metaMER_results |&gt; dplyr::select(unique_id, \n                                 dplyr::everything()) \n\nmetaMER_results |&gt; dplyr::tibble()\n\n# A tibble: 1,278 × 19\n   unique_id  citekey journal stimulus_genre model_category stimulus_n feature_n\n   &lt;chr&gt;      &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;          &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt;    \n 1 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 2 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 3 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 4 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 5 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 6 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 7 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 8 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 9 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n10 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n# ℹ 1,268 more rows\n# ℹ 12 more variables: participant_n &lt;chr&gt;, feature_source &lt;chr&gt;,\n#   feature_reduction_method &lt;chr&gt;, library_id &lt;chr&gt;, model_id &lt;chr&gt;,\n#   feature_id &lt;chr&gt;, data_id &lt;chr&gt;, experiment_id &lt;chr&gt;, dimension &lt;chr&gt;,\n#   measure &lt;chr&gt;, statistic &lt;chr&gt;, values &lt;dbl&gt;\n\n\n\n\n\nprint(knitr::kable(table(metaMER_results$citekey,metaMER_results$dimension)))\nprint(knitr::kable(table(metaMER_results$citekey,metaMER_results$model_id)))\nprint(knitr::kable(table(metaMER_results$citekey,metaMER_results$feature_id)))\nprint(knitr::kable(table(metaMER_results$citekey,metaMER_results$data_id)))\n\n\n\n\n\n\n\n# Classify techniques according Hastie, Tibshirani, Friedman (2008)\n# https://www.sas.upenn.edu/~fdiebold/NoHesitations/BookAdvanced.pdf\n#\nlibrary(stringr)\nmetaMER_results$model_id &lt;- tolower(metaMER_results$model_id)\nmetaMER_results$model_class_id &lt;- 'Unclassified'\nmetaMER_results$model_class_id[str_detect(metaMER_results$model_id,'lr|lm|pls|mlr|pcr|logistic regression|2d model full|pentagon|gaussian process regression|sparse bayesian regression|variational bayesian regression|logistic regression|lda|rda|regularized discriminant analysis|reguliarized discriminant analysis')] &lt;- 'Linear Methods' # Class name from Elements of Stat..\"\n#metaMER_results$model_class_id[str_detect(metaMER_results$model_id,'logistic regression|lda|rda|regularized discriminant analysis|reguliarized discriminant analysis')] &lt;- 'Linear Classification'\n#metaMER_results$model_class_id[str_detect(metaMER_results$model_id,'mars|gam')]&lt;-'Additive Trees and Related Methods' #\nmetaMER_results$model_class_id[str_detect(metaMER_results$model_id,'rbf|gmm|local|polynomial|polygonal|knn|mars|gam')]&lt;-'Kernel Smoothing, Additive and KNN'\n#metaMER_results$model_class_id[str_detect(metaMER_results$model_id,'adaboost|gradient')]&lt;-'Boosting'\nmetaMER_results$model_class_id[str_detect(metaMER_results$model_id,'nn|gru|lstm|ltsm|long short term memory|rprop|mcan')]&lt;-'Neural Nets'\nmetaMER_results$model_class_id[str_detect(metaMER_results$model_id,'svm|svr|support vector regression|smoreg|smo ')]&lt;-'Flexible Discriminants'\n#metaMER_results$model_class_id[str_detect(metaMER_results$model_id,'knn')]&lt;-'Prototype methods'\nmetaMER_results$model_class_id[str_detect(metaMER_results$model_id,'rf|extremely randomized tree regression|random forest|adaboost|gradient')]&lt;-'Random Forests'\n#metaMER_results$model_class_id[str_detect(metaMER_results$model_id,'rf')]&lt;-'Ensemble Learning'\n\n\n\n\n\nmetaMER_results$stimulus_genre_mixed &lt;- 'SingleGenre'\nmetaMER_results$stimulus_genre_mixed[str_detect(metaMER_results$stimulus_genre,',|multi')] &lt;- 'MultiGenre' # Class name from Elements of Stat..\"\n#table(metaMER_results$stimulus_genre_mixed)\n\n\n\n\n\nmetaMER_results$journal_type &lt;- \"Engineering\"\nmetaMER_results$journal_type[str_detect(metaMER_results$journal,'Quarterly Journal of Experimental Psychology|PSYCHOLOGY OF MUSIC|PLOS ONE|JOURNAL OF NEW MUSIC RESEARCH|IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING|FRONTIERS IN PSYCHOLOGY|Frontiers in Psychology')] &lt;- 'Psychology' # Class name from Elements of Stat..\"\n\n#table(metaMER_results$journal_type)\n\n\n\n\n\nprint(knitr::kable(table(metaMER_results$model_class_id)))\n\n\n\nVar1\nFreq\n\n\n\n\nFlexible Discriminants\n399\n\n\nKernel Smoothing, Additive and KNN\n114\n\n\nLinear Methods\n250\n\n\nNeural Nets\n387\n\n\nRandom Forests\n128\n\n\n\nprint(knitr::kable(table(metaMER_results$model_class_id,metaMER_results$model_category)))\n\n\n\n\nclassification\nregression\n\n\n\n\nFlexible Discriminants\n173\n226\n\n\nKernel Smoothing, Additive and KNN\n18\n96\n\n\nLinear Methods\n76\n174\n\n\nNeural Nets\n265\n122\n\n\nRandom Forests\n74\n54\n\n\n\ncat(paste(\"We have\", nrow(metaMER_results), \"observations\"))\nWe have 1278 observations\ncat(paste(\"\\nWe have\", length(unique(metaMER_results$citekey)), \"studies\"))\nWe have 37 studies\ncat(paste(\"\\nWhere\", length(unique(metaMER_results$citekey[metaMER_results$model_category=='regression'])), \"are regression studies\"))\nWhere 23 are regression studies\ncat(paste(\"\\nWhere\", length(unique(metaMER_results$citekey[metaMER_results$model_category=='classification'])), \"are classification studies\"))\nWhere 14 are classification studies\n# note that we have some classification studies that also do regression and vice versa?\n# THIS IS CORRECT (updated 12 July 2024):\n# [1] \"We have 1238 observations\"\n# [1] \"We have 37 studies\"\n# [1] \"Where 23 are regression studies\"\n# [1] \"Where 14 are classification studies\"\n\n# Add a check for these properties ToDo"
  },
  {
    "objectID": "analysis/preprocessing.html#read-annotated-data",
    "href": "analysis/preprocessing.html#read-annotated-data",
    "title": "Preprocessing",
    "section": "",
    "text": "require(here)\nsource(here::here('R/build-df.R'))\nsource(here::here('R/format-study-results.R'))\nsource(here::here('R/parse-model-output.R'))\n\n\nlibrary(stringr) \n# get metaMER df:\nmeta_df &lt;- get_metaMER_df(path_2_studies = here::here('studies'))\n\n# get included studies\nincluded_studies &lt;- meta_df[which(\n  !stringr::str_detect(meta_df$final_notes, '!EXCL!')),] |&gt; \n  dplyr::tibble()\n\n\n\n\n# get studies re-coded (currently identifiable by presence of bind_field.)\nrecoded_studies &lt;- included_studies[which(stringr::str_detect(\n  included_studies$model_rate_emotion_values,\n                                     'bind_field')),] \n\n\n\n\n\nmetaMER_results &lt;-\ndo.call(\n  rbind,\n    lapply(1:nrow(recoded_studies),\n       function(x) get_study_results(recoded_studies[x,])\n       )\n) \n\n# add unique identifiers\n\nunique_id &lt;- apply(metaMER_results[,c('citekey',\n                        'library_id',\n                         'model_id',\n                         'feature_id',\n                         'data_id',\n                         'experiment_id')],\n                      1, \n                      paste0, \n                      collapse = '-'\n) \nmetaMER_results$unique_id &lt;- stringr::str_remove_all(unique_id, \n                                                     ' ')\n\nmetaMER_results &lt;- metaMER_results |&gt; dplyr::select(unique_id, \n                                 dplyr::everything()) \n\nmetaMER_results |&gt; dplyr::tibble()\n\n# A tibble: 1,278 × 19\n   unique_id  citekey journal stimulus_genre model_category stimulus_n feature_n\n   &lt;chr&gt;      &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;          &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt;    \n 1 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 2 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 3 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 4 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 5 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 6 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 7 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 8 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n 9 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n10 agarwal20… agarwa… \"   IE… \" popular, hi… classification \" ISMIR20… \" 'eight…\n# ℹ 1,268 more rows\n# ℹ 12 more variables: participant_n &lt;chr&gt;, feature_source &lt;chr&gt;,\n#   feature_reduction_method &lt;chr&gt;, library_id &lt;chr&gt;, model_id &lt;chr&gt;,\n#   feature_id &lt;chr&gt;, data_id &lt;chr&gt;, experiment_id &lt;chr&gt;, dimension &lt;chr&gt;,\n#   measure &lt;chr&gt;, statistic &lt;chr&gt;, values &lt;dbl&gt;\n\n\n\n\n\nprint(knitr::kable(table(metaMER_results$citekey,metaMER_results$dimension)))\nprint(knitr::kable(table(metaMER_results$citekey,metaMER_results$model_id)))\nprint(knitr::kable(table(metaMER_results$citekey,metaMER_results$feature_id)))\nprint(knitr::kable(table(metaMER_results$citekey,metaMER_results$data_id)))\n\n\n\n\n\n\n\n# Classify techniques according Hastie, Tibshirani, Friedman (2008)\n# https://www.sas.upenn.edu/~fdiebold/NoHesitations/BookAdvanced.pdf\n#\nlibrary(stringr)\nmetaMER_results$model_id &lt;- tolower(metaMER_results$model_id)\nmetaMER_results$model_class_id &lt;- 'Unclassified'\nmetaMER_results$model_class_id[str_detect(metaMER_results$model_id,'lr|lm|pls|mlr|pcr|logistic regression|2d model full|pentagon|gaussian process regression|sparse bayesian regression|variational bayesian regression|logistic regression|lda|rda|regularized discriminant analysis|reguliarized discriminant analysis')] &lt;- 'Linear Methods' # Class name from Elements of Stat..\"\n#metaMER_results$model_class_id[str_detect(metaMER_results$model_id,'logistic regression|lda|rda|regularized discriminant analysis|reguliarized discriminant analysis')] &lt;- 'Linear Classification'\n#metaMER_results$model_class_id[str_detect(metaMER_results$model_id,'mars|gam')]&lt;-'Additive Trees and Related Methods' #\nmetaMER_results$model_class_id[str_detect(metaMER_results$model_id,'rbf|gmm|local|polynomial|polygonal|knn|mars|gam')]&lt;-'Kernel Smoothing, Additive and KNN'\n#metaMER_results$model_class_id[str_detect(metaMER_results$model_id,'adaboost|gradient')]&lt;-'Boosting'\nmetaMER_results$model_class_id[str_detect(metaMER_results$model_id,'nn|gru|lstm|ltsm|long short term memory|rprop|mcan')]&lt;-'Neural Nets'\nmetaMER_results$model_class_id[str_detect(metaMER_results$model_id,'svm|svr|support vector regression|smoreg|smo ')]&lt;-'Flexible Discriminants'\n#metaMER_results$model_class_id[str_detect(metaMER_results$model_id,'knn')]&lt;-'Prototype methods'\nmetaMER_results$model_class_id[str_detect(metaMER_results$model_id,'rf|extremely randomized tree regression|random forest|adaboost|gradient')]&lt;-'Random Forests'\n#metaMER_results$model_class_id[str_detect(metaMER_results$model_id,'rf')]&lt;-'Ensemble Learning'\n\n\n\n\n\nmetaMER_results$stimulus_genre_mixed &lt;- 'SingleGenre'\nmetaMER_results$stimulus_genre_mixed[str_detect(metaMER_results$stimulus_genre,',|multi')] &lt;- 'MultiGenre' # Class name from Elements of Stat..\"\n#table(metaMER_results$stimulus_genre_mixed)\n\n\n\n\n\nmetaMER_results$journal_type &lt;- \"Engineering\"\nmetaMER_results$journal_type[str_detect(metaMER_results$journal,'Quarterly Journal of Experimental Psychology|PSYCHOLOGY OF MUSIC|PLOS ONE|JOURNAL OF NEW MUSIC RESEARCH|IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING|FRONTIERS IN PSYCHOLOGY|Frontiers in Psychology')] &lt;- 'Psychology' # Class name from Elements of Stat..\"\n\n#table(metaMER_results$journal_type)"
  },
  {
    "objectID": "analysis/preprocessing.html#summarise-all",
    "href": "analysis/preprocessing.html#summarise-all",
    "title": "Preprocessing",
    "section": "",
    "text": "print(knitr::kable(table(metaMER_results$model_class_id)))\n\n\n\nVar1\nFreq\n\n\n\n\nFlexible Discriminants\n399\n\n\nKernel Smoothing, Additive and KNN\n114\n\n\nLinear Methods\n250\n\n\nNeural Nets\n387\n\n\nRandom Forests\n128\n\n\n\nprint(knitr::kable(table(metaMER_results$model_class_id,metaMER_results$model_category)))\n\n\n\n\nclassification\nregression\n\n\n\n\nFlexible Discriminants\n173\n226\n\n\nKernel Smoothing, Additive and KNN\n18\n96\n\n\nLinear Methods\n76\n174\n\n\nNeural Nets\n265\n122\n\n\nRandom Forests\n74\n54\n\n\n\ncat(paste(\"We have\", nrow(metaMER_results), \"observations\"))\nWe have 1278 observations\ncat(paste(\"\\nWe have\", length(unique(metaMER_results$citekey)), \"studies\"))\nWe have 37 studies\ncat(paste(\"\\nWhere\", length(unique(metaMER_results$citekey[metaMER_results$model_category=='regression'])), \"are regression studies\"))\nWhere 23 are regression studies\ncat(paste(\"\\nWhere\", length(unique(metaMER_results$citekey[metaMER_results$model_category=='classification'])), \"are classification studies\"))\nWhere 14 are classification studies\n# note that we have some classification studies that also do regression and vice versa?\n# THIS IS CORRECT (updated 12 July 2024):\n# [1] \"We have 1238 observations\"\n# [1] \"We have 37 studies\"\n# [1] \"Where 23 are regression studies\"\n# [1] \"Where 14 are classification studies\"\n\n# Add a check for these properties ToDo"
  },
  {
    "objectID": "analysis/preprocessing.html#homogenise-the-outcome-variable-names-to-valence-and-arousal",
    "href": "analysis/preprocessing.html#homogenise-the-outcome-variable-names-to-valence-and-arousal",
    "title": "Preprocessing",
    "section": "Homogenise the outcome variable names to valence and arousal",
    "text": "Homogenise the outcome variable names to valence and arousal\n\nR_studies$dimension[str_detect(R_studies$dimension,'activation|energy arousal|tension arousal')]&lt;-'arousal'\nR_studies$dimension[str_detect(R_studies$dimension,'pleasantness')]&lt;-'valence'\nR_studies &lt;- dplyr::filter(R_studies,!str_detect(dimension,'av|resonance')) # relates to distances, can be omitted\n\ntable(R_studies$dimension)  \n\n\narousal valence \n    176     170 \n\n#table(R_studies$stimulus_n)  \n\n# Deal with four studies involving multiple datasets: \n\nR_studies$stimulus_n[R_studies$stimulus_n==\" emoMusic: 744, soundtracks: 360, chinese: 500 \"] &lt;- 938 # resolved from the paper\nR_studies$stimulus_n[R_studies$stimulus_n==\" 2372 (subset of PSIC3839, total n: 3839)    \"] &lt;- 2372 # resolved\nR_studies$stimulus_n[R_studies$stimulus_n==\" study 1: 20; study 2: 40) % three outliers  \"] &lt;- 40 # decided to take this from validation\nR_studies$stimulus_n[R_studies$stimulus_n==\" study 1: 100; study 2: 20\"] &lt;- 20 #\n\nR_studies$stimulus_n[R_studies$stimulus_n==\" DEAM: 744, PMEmo: 206  \"] &lt;- 744 # we have encoded this based on stronger results on DEAM compared to PMEmo.\n\nR_studies$stimulus_n[R_studies$stimulus_n==\" NTUMIR: 60, MediaEval2013: 744  \"] &lt;- 60 # we have encoded this based on stronger results on NTUMIR compared to MediaEval\n\nR_studies$stimulus_n[R_studies$stimulus_n==\" 1020; MediaEval2014: 1000: music perception database 1: 6, music perception database 2: 9, music perception database 3: 8, music perception database 4: 7   \"] &lt;- 1020\n\n# REDO with a clearer function\neliminate &lt;- str_detect(R_studies$unique_id,\"hu2017cr\") & !str_detect(R_studies$unique_id,\"all\")\nR_studies &lt;- R_studies[!eliminate,]\nR_studies$stimulus_n[R_studies$stimulus_n==\" MER60: 60, CH818: 818, AMG1608: 1608  \"] &lt;- 60+818+1608 #\n\ntable(R_studies$stimulus_n)\n\n\n   146   1838     275     324      336     40      420     431      48     54   \n     12      10       6      74       2       2       2       4       6       4 \n   744    744    744       84      1020      20    2372    2486      40     744 \n     30      30      18      24       4       4       2       8       4       4 \n    938 \n      8 \n\nR_studies$stimulus_n &lt;- as.numeric(R_studies$stimulus_n)\n\n\nClean feature N field\n\nR_studies$feature_n[R_studies$feature_n==\" 548; after reduction, 139 for PCA and 276 for ReliefF   \"] &lt;- 548\n\nR_studies$feature_n[str_detect(R_studies$feature_n,'pre_fitting')] &lt;- 21\nR_studies$feature_n[str_detect(R_studies$feature_n,'but 15 reported')]&lt;-15\nR_studies$feature_n[str_detect(R_studies$feature_n,'50 PCA features')]&lt;-50\nR_studies$feature_n[str_detect(R_studies$feature_n,'548 dimensions. Pos')]&lt;-548\nR_studies$feature_n[str_detect(R_studies$feature_n,'60 handcrafted and')]&lt;-60 # this should be 14400+60!\nR_studies$feature_n[str_detect(R_studies$feature_n,'before_selection = 45')]&lt;-45\nR_studies$feature_n[str_detect(R_studies$feature_n,'model 4 = 388')]&lt;-388\nR_studies$feature_n[str_detect(R_studies$feature_n,'6670 in MediaEval')]&lt;-6670\nR_studies$feature_n[str_detect(R_studies$feature_n,'557 before feature')]&lt;-557\nR_studies$feature_n[str_detect(R_studies$feature_n,'not specified')]&lt;-NA\nR_studies$feature_n&lt;-as.numeric(R_studies$feature_n)\n\nquantile(R_studies$feature_n,c(0.333,0.666),na.rm = TRUE)\n\n  33.3%   66.6% \n106.046 653.000 \n\nquantile(R_studies$feature_n,c(0.25,0.500,0.750),na.rm = TRUE)\n\n25% 50% 75% \n 45 548 653 \n\nquantile(R_studies$feature_n,c(0.1,0.500,0.90),na.rm = TRUE)\n\n10% 50% 90% \n 16 548 654 \n\nR_studies$feature_n_categories &lt;-cut(R_studies$feature_n,\n                                      breaks = c(0,18,260,\n                                                 10000),\n                                      labels = c(\"Feature n &lt; 18\",\"Feature n &gt; 18 & &lt; 260\",\"Feature n &gt; 260\"))"
  },
  {
    "objectID": "analysis/preprocessing.html#diagnostics",
    "href": "analysis/preprocessing.html#diagnostics",
    "title": "Preprocessing",
    "section": "Diagnostics",
    "text": "Diagnostics\n\nlibrary(ggplot2)\n\ng1&lt;-ggplot(R_studies,aes(x=values,fill=citekey,color=dimension))+\n  geom_histogram()+\n  facet_wrap(.~model_class_id)+\n#  scale_color_manual(values = c('black','white'))+\n  theme_dark()+\n  scale_x_continuous(breaks = seq(0,1,by=.1))\n\ng1\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 12 rows containing non-finite outside the scale range\n(`stat_bin()`)."
  },
  {
    "objectID": "analysis/preprocessing.html#select-a-summary-measure-for-valence-and-arousal-separately",
    "href": "analysis/preprocessing.html#select-a-summary-measure-for-valence-and-arousal-separately",
    "title": "Preprocessing",
    "section": "Select a summary measure for valence and arousal separately",
    "text": "Select a summary measure for valence and arousal separately\nNote: Before adding feature_n to the summary, they need to be cleaned!\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nR_studies$citekey &lt;- factor(R_studies$citekey)\nR_studies$dimension &lt;- factor(R_studies$dimension)\n\nR_summary &lt;- summarise(group_by(R_studies,dimension,citekey),valuesMean=mean(values,na.rm=TRUE),valuesMedian=median(values,na.rm=TRUE),valuesMax=max(values,na.rm=TRUE),stimulus_n=first(stimulus_n),studyREF=first(studyREF),model_class_id=first(model_class_id),feature_n=first(feature_n),journal_type=first(journal_type),feature_n=first(feature_n),feature_n_categories=first(feature_n_categories),stimulus_genre_mixed=first(stimulus_genre_mixed))\n\n`summarise()` has grouped output by 'dimension'. You can override using the\n`.groups` argument."
  },
  {
    "objectID": "analysis/preprocessing.html#visualise-summary-on-two-dimensions",
    "href": "analysis/preprocessing.html#visualise-summary-on-two-dimensions",
    "title": "Preprocessing",
    "section": "Visualise Summary on two dimensions",
    "text": "Visualise Summary on two dimensions\nAdd variation from within the studies (alternative models)\n\nR_summary_split &lt;- pivot_wider(R_summary,id_cols = citekey, names_from = c(dimension), values_from = valuesMax)\n\ng2 &lt;- ggplot(R_summary_split,aes(x=valence,y=arousal,label=citekey))+\n  geom_label()+\n  theme_bw()+\n  scale_x_continuous(breaks = seq(0,1,by=.1))+\n  scale_y_continuous(breaks = seq(0,1,by=.1))\n\ng2\n\n\n\n## could be more informative when done with the full data\nR_studies$citekey&lt;-factor(R_studies$citekey)\nR_studies$dimension&lt;-factor(R_studies$dimension)\n\nR_studies_split &lt;- pivot_wider(R_studies,id_cols = c(unique_id,citekey,model_class_id), names_from = c(dimension), values_from = c(values),values_fn = mean)\nR_studies_split&lt;-drop_na(R_studies_split)\n\nlibrary(ggrepel)\n\ng3 &lt;- ggplot(R_studies_split,aes(x=valence,y=arousal,label=citekey,color=model_class_id,fill=model_class_id))+\n  geom_point(size=4)+\n  geom_label_repel(size=3, max.overlaps=50,show.legend = T,color='white')+\n  scale_x_continuous(breaks = seq(0,1,by=.25),limits = c(0,1))+\n  scale_y_continuous(breaks = seq(0,1,by=.25),limits = c(0,1))+\n  theme_bw()\ng3\n\nWarning: ggrepel: 69 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps"
  },
  {
    "objectID": "analysis/preprocessing.html#plot-success-across-the-years",
    "href": "analysis/preprocessing.html#plot-success-across-the-years",
    "title": "Preprocessing",
    "section": "Plot success across the years",
    "text": "Plot success across the years\n\n# Add year!\nR_studies$year &lt;- as.numeric(str_match(R_studies$citekey,'[0-9]+'))\n\ng3 &lt;- ggplot(R_studies,aes(x=year,y=values,colour=model_class_id))+\n  geom_point(show.legend = T)+\n  facet_wrap(.~dimension)+\n  theme_bw()\ng3\n\nWarning: Removed 12 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "analysis/preprocessing.html#simple-model-complexity-metric",
    "href": "analysis/preprocessing.html#simple-model-complexity-metric",
    "title": "Preprocessing",
    "section": "Simple model complexity metric",
    "text": "Simple model complexity metric\nRatio of obs./features or just a classification based on feature n (quantiles).\n\nR_studies$feature_n[R_studies$feature_n==\" 15; 23 in table, but 15 reported  \"] &lt;- 15 #resolved from the paper\n\nR_studies$feature_n[R_studies$feature_n==\" 15; 23 in table, but 15 reported  \"] &lt;- 15 #resolved\nR_studies$feature_n[R_studies$feature_n==\" before_selection = 45, after_selection = 6  \"] &lt;- 45 #resolved\nR_studies$feature_n[R_studies$feature_n==\" model 1: 52, model 2 = 68, model 3 = 260, model 4 = 388 \"] &lt;- 388 #resolved\nR_studies$feature_n[R_studies$feature_n==\" variable, 557 before feature selection \"] &lt;- 557 #resolved\n\nR_studies$feature_n[R_studies$feature_n==\" 50 PCA features \"] &lt;- 499 #resolved\n\nR_studies$feature_n[str_detect(R_studies$feature_n,'pre_fitting = 21')] &lt;- 21\nR_studies$feature_n[str_detect(R_studies$feature_n,'548 dimensions')] &lt;- 548\nR_studies$feature_n[str_detect(R_studies$feature_n,'548; after reduct')] &lt;- 548\nR_studies$feature_n[str_detect(R_studies$feature_n,'60 handcrafted and filter bank')] &lt;- 3600\nR_studies$feature_n[str_detect(R_studies$feature_n,'Features deep-learned from audio (not specified) but 1802 in DEAM')] &lt;- 260\n\nR_studies$feature_n[str_detect(R_studies$feature_n,'not specified')] &lt;- 3000 # under-estimation based openSmile features and the paper arguing that they have 15 stat moments\n  \nR_studies$feature_n&lt;-as.numeric(R_studies$feature_n)\n\nprint(quantile(R_studies$feature_n,c(0.333,0.666),na.rm = T))\n\n  33.3%   66.6% \n106.046 653.000 \n\n#quantile(R_studies$feature_n,c(0.25,0.50,0.75),na.rm = T)\n\n# Assign\nR_studies$feature_n_complexity &lt;- cut(R_studies$feature_n,\n                                      breaks = c(0,\n                                                 as.numeric(quantile(R_studies$feature_n,c(0.333),na.rm = T)),\n                                                 as.numeric(quantile(R_studies$feature_n,c(0.666),na.rm = T)),\n                                                 10000),\n                                      labels = c(\"Feature n &lt; 236\",\"Feature n &gt; 236 & &lt; 653\",\"Feature n &gt; 653\"))\n\n\nR_studies$feature_n_complexity &lt;- cut(R_studies$feature_n,\n                                      breaks = c(0,30,300,10000),\n                                      labels = c(\"Feature n &lt; 30\",\"Feature n &gt; 30 & &lt; 300\",\"Feature n &gt; 300\"))\n\n\n\ntable(R_studies$feature_n_complexity)\n\n\n        Feature n &lt; 30 Feature n &gt; 30 & &lt; 300        Feature n &gt; 300 \n                    58                     40                    142"
  },
  {
    "objectID": "analysis/preprocessing.html#explore-feature_n_complexity-and-model-success",
    "href": "analysis/preprocessing.html#explore-feature_n_complexity-and-model-success",
    "title": "Preprocessing",
    "section": "Explore feature_n_complexity and model success",
    "text": "Explore feature_n_complexity and model success\nNeeds to be done from the unsummarised data (R_studies).\n\n#tmp &lt;- drop_na(R_studies)\ntmp &lt;- R_studies[!is.na(R_studies$values),]\n\nlibrary(ggdist)\n\ntmp$dimension&lt;-str_to_title(tmp$dimension)\ntmp$model_class_id&lt;-factor(tmp$model_class_id,\n                           levels = c(\"Neural Nets\",\"Flexible Discriminants\", \"Kernel Smoothing, Additive and KNN\", \"Random Forests\",\"Linear Methods\"),\n                           labels = c(\"Neural\\nNets\",\"Flexible\\nDiscriminants\", \"KS\\n & KNN\", \"Random\\nForests\", \"Linear\\nMethods\"))\n\ng &lt;- ggplot(tmp,aes(x=model_class_id,y=values,color=citekey,label=citekey,shape=stimulus_genre_mixed))+\n  stat_halfeye(aes(fill=citekey),point_interval=\"mean_qi\", trim=FALSE, expand=FALSE, show.legend = FALSE,adjust = 1.25, density=\"bounded\", point_size=3,scale = 1,alpha=0.5) + \n  geom_point(alpha=0.5,show.legend = F,position = position_jitter(width = .3))+\n  #geom_label_repel(size=2,max.overlaps = 50)+\n  facet_wrap(dimension~feature_n_complexity)+\n  ylab(\"Correlation Coefficient\")+\n  xlab(\"Model Technique\")+\n  scale_y_continuous(limits = c(0,1),expand = c(0.01,0.01))+\n  geom_text_repel(aes(x = model_class_id, y = values, label = studyREF),\n             stat = \"summary\", fun = mean,show.legend = F)+\n  theme_bw()\ng\n\nWarning: Removed 72 rows containing missing values or values outside the scale range\n(`geom_slabinterval()`).\n\n\nWarning: Removed 124 rows containing missing values or values outside the scale range\n(`geom_slabinterval()`).\n\n\nWarning: Removed 61 rows containing missing values or values outside the scale range\n(`geom_slabinterval()`).\n\n\nWarning: Removed 43 rows containing missing values or values outside the scale range\n(`geom_slabinterval()`).\n\n\nWarning: ggrepel: 4 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps\n\n\nWarning: ggrepel: 14 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps\n\n\nWarning: ggrepel: 16 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps\n\n\n\n\n#ggsave(filename = 'FeatureN_regression.pdf',g,height = 7,width = 11)"
  },
  {
    "objectID": "analysis/preprocessing.html#create-descriptive-table-for-the-manuscript",
    "href": "analysis/preprocessing.html#create-descriptive-table-for-the-manuscript",
    "title": "Preprocessing",
    "section": "Create descriptive table for the manuscript",
    "text": "Create descriptive table for the manuscript\n\nTR &lt;- NULL\nTR$study_n &lt;- length(unique(R_studies$citekey))\nTR$model_n &lt;- nrow(R_studies)\nt&lt;-table(R_studies$model_class_id)\nt2 &lt;- paste0(names(t),': ', as.numeric(t))\nTR$model_types_n &lt;- str_c(t2,collapse = \"\\n\")\nTR$feature_Desc &lt;- paste0('Min=',min(R_studies$feature_n,na.rm = TRUE),', Md=',median(R_studies$feature_n,na.rm = TRUE),', Max=', max(R_studies$feature_n,na.rm = TRUE))\nTR$stimulus_Desc &lt;- paste0('Min=',min(R_studies$stimulus_n,na.rm = TRUE),', Md=',median(R_studies$stimulus_n,na.rm = TRUE),', Max=', max(R_studies$stimulus_n,na.rm = TRUE))\nprint(TR)\n\n$study_n\n[1] 24\n\n$model_n\n[1] 258\n\n$model_types_n\n[1] \"Flexible Discriminants: 64\\nKernel Smoothing, Additive and KNN: 24\\nLinear Methods: 74\\nNeural Nets: 74\\nRandom Forests: 22\"\n\n$feature_Desc\n[1] \"Min=3, Md=548, Max=6670\"\n\n$stimulus_Desc\n[1] \"Min=20, Md=324, Max=2486\""
  },
  {
    "objectID": "analysis/preprocessing.html#export-as-csv",
    "href": "analysis/preprocessing.html#export-as-csv",
    "title": "Preprocessing",
    "section": "Export as csv",
    "text": "Export as csv\n\nwrite.csv(x = R_studies,file = 'R_studies.csv')\nwrite.csv(x = R_summary,file = 'R_summary.csv')"
  },
  {
    "objectID": "analysis/preprocessing.html#homogenise-the-stimulus-n",
    "href": "analysis/preprocessing.html#homogenise-the-stimulus-n",
    "title": "Preprocessing",
    "section": "Homogenise the stimulus N",
    "text": "Homogenise the stimulus N\n\ntable(C_studies$stimulus_n)  \n\n\n                                                                                                                    387   \n                                                                                                                       16 \n                                                                                                                    124   \n                                                                                                                        8 \n                                                                                                                    171   \n                                                                                                                       37 \n                                                                                                                    1802  \n                                                                                                                        4 \n                                                                                                                    300   \n                                                                                                                        2 \n                                             429; 350 popular songs + 79 songs from the Beatles (Mirex 2009 collection)   \n                                                                                                                        2 \n 5192; 12 per user in user validation (not included here due to little information),   AcousticBrainz validation: 60000   \n                                                                                                                        2 \n                                                                                                                     744  \n                                                                                                                       15 \n                                                                                                                    744   \n                                                                                                                        2 \n                                                                                                                    900   \n                                                                                                                        1 \n                                                                                                                    956   \n                                                                                                                        4 \n                                                                              ISMIR2012: 2886, NJU_V1: 777, Hindi: 1037   \n                                                                                                                        9 \n                                                                   total: 564; unambiguous: 416, circular validation: 39  \n                                                                                                                        6 \n\n# Deal with four studies involving multiple datasets: \nC_studies$stimulus_n[C_studies$stimulus_n==\" 429; 350 popular songs + 79 songs from the Beatles (Mirex 2009 collection)  \"] &lt;- 429 # resolved from the paper\nC_studies$stimulus_n[C_studies$stimulus_n==\" 5192; 12 per user in user validation (not included here due to little information),   AcousticBrainz validation: 60000  \"] &lt;- 5192 # resolved\nC_studies$stimulus_n[C_studies$stimulus_n==\" ISMIR2012: 2886, NJU_V1: 777, Hindi: 1037  \"] &lt;- 2886+777+1037 # decided to take this from validation\nC_studies$stimulus_n[C_studies$stimulus_n==\" total: 564; unambiguous: 416, circular validation: 39 \"] &lt;- 564 # \n#table(C_studies$stimulus_n)\nC_studies$stimulus_n &lt;- as.numeric(C_studies$stimulus_n)"
  },
  {
    "objectID": "analysis/preprocessing.html#diagnostics-1",
    "href": "analysis/preprocessing.html#diagnostics-1",
    "title": "Preprocessing",
    "section": "Diagnostics",
    "text": "Diagnostics\n\nlibrary(ggplot2)\n\ng1&lt;-ggplot(C_studies,aes(x=values,fill=citekey))+\n  geom_histogram()+\n  facet_wrap(.~model_class_id)+\n  theme_dark()+\n  scale_x_continuous(breaks = seq(0,1,by=.1))\n\ng1"
  },
  {
    "objectID": "analysis/preprocessing.html#select-a-summary-measure-for-valence-and-arousal-separately-1",
    "href": "analysis/preprocessing.html#select-a-summary-measure-for-valence-and-arousal-separately-1",
    "title": "Preprocessing",
    "section": "Select a summary measure for valence and arousal separately",
    "text": "Select a summary measure for valence and arousal separately\n\nlibrary(tidyverse)\nC_studies$citekey &lt;- factor(C_studies$citekey)\n\nC_summary &lt;- summarise(group_by(C_studies,citekey),valuesMean=mean(values,na.rm=TRUE),valuesMedian=median(values,na.rm=TRUE),valuesMax=max(values,na.rm=TRUE),stimulus_n=first(stimulus_n),studyREF=first(studyREF),model_class_id=first(model_class_id), stimulus_genre_mixed=first(stimulus_genre_mixed),journal_type = first(journal_type))"
  },
  {
    "objectID": "analysis/preprocessing.html#visualise-summary",
    "href": "analysis/preprocessing.html#visualise-summary",
    "title": "Preprocessing",
    "section": "Visualise Summary",
    "text": "Visualise Summary\n\ng2 &lt;- ggplot(C_summary,aes(x=stimulus_n,y=valuesMax,label=citekey,color=stimulus_genre_mixed))+\n  geom_point()+\n  geom_label_repel(size=1.5)+\n#  coord_flip()+\n  theme_bw()\ng2\n\n\n\ng3 &lt;- ggplot(C_summary,aes(x=stimulus_n,y=valuesMax,label=citekey,color=model_class_id))+\n  geom_point()+\n  geom_label_repel(size=1.2)+\n#  coord_flip()+\n  theme_bw()\ng3\n\n\n\n## could be more informative when done with the full data\nC_studies$citekey&lt;-factor(C_studies$citekey)\n\nlibrary(ggrepel)\n\ng4 &lt;- ggplot(C_studies,aes(x=stimulus_n,y=values,label=citekey,color=model_class_id,fill=model_class_id))+\n  geom_point(size=4)+\n  geom_label_repel(size=1.2, max.overlaps=50,show.legend = T,color='white')+\n#  scale_x_continuous(breaks = seq(0,1,by=.25),limits = c(0,1))+\n#  scale_y_continuous(breaks = seq(0,1,by=.25),limits = c(0,1))+\n  theme_bw()\ng4\n\nWarning: Removed 19 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\nWarning: Removed 19 rows containing missing values or values outside the scale range\n(`geom_label_repel()`)."
  },
  {
    "objectID": "analysis/preprocessing.html#simple-model-complexity-metric-based-on-feature_n",
    "href": "analysis/preprocessing.html#simple-model-complexity-metric-based-on-feature_n",
    "title": "Preprocessing",
    "section": "Simple model complexity metric based on feature_n",
    "text": "Simple model complexity metric based on feature_n\n\ntable(C_studies$feature_n)\n\n\n 'eight different non‐text‐dependent features are employed; they are rhythm, timbre,intensity, chromagram, MFCC, OSC, SSDs, and DWCH'  \n                                                                                                                                     9 \n                                                                                                                                 119   \n                                                                                                                                    21 \n                                                                                                                                 122   \n                                                                                                                                     4 \n                                                                                                                    126, retained 97   \n                                                                                                                                     6 \n                                                                                           1702; best model uses 100 after reduction   \n                                                                                                                                     1 \n                                                                                                                                  231  \n                                                                                                                                     4 \n                                                                                                                                    3  \n                                                                                                                                     2 \n                                                                                                                                 397   \n                                                                                                                                     2 \n                                                                            548 dimensions. Post-reduction: 139 (PCA), 276 (ReliefF)   \n                                                                                                                                     2 \n                                                                              548; after reduction, 139 for PCA and 276 for ReliefF    \n                                                                                                                                    15 \n                                                                                       8; 3 after shrinkage-method feature selection   \n                                                                                                                                    16 \n                                                                                                                               8904    \n                                                                                                                                     8 \n                                                                                                                    between 9 and 10   \n                                                                                                                                     2 \n                                                                  summarize feature categories, but aren't explicit about which ones   \n                                                                                                                                    16 \n\nC_studies$feature_n[str_detect(C_studies$feature_n,'eight different ')]&lt;-600 # arbitrary!\nC_studies$feature_n[str_detect(C_studies$feature_n,'126, retained 97')]&lt;-126 \nC_studies$feature_n[str_detect(C_studies$feature_n,'1702; best model uses 100 after reduction')]&lt;-1702 #  arbitrary!\nC_studies$feature_n[str_detect(C_studies$feature_n,'548; after reduction, ')] &lt;- 548 \nC_studies$feature_n[str_detect(C_studies$feature_n,'548 dimensions')] &lt;- 548 \nC_studies$feature_n[str_detect(C_studies$feature_n,'548. Post-reduction')] &lt;- 548 \nC_studies$feature_n[str_detect(C_studies$feature_n,'8; 3 after')]&lt;-8 \nC_studies$feature_n[str_detect(C_studies$feature_n,'between 9 and 10')]&lt;-10 \nC_studies$feature_n[str_detect(C_studies$feature_n,'summarize feature')]&lt;-600 # arbitrary\ntable(C_studies$feature_n)\n\n\n   119      122       231        3     397    8904          10      126 \n      21        4        4        2        2        8        2        6 \n    1702      548      600        8 \n       1       17       25       16 \n\nC_studies$feature_n &lt;- as.numeric(C_studies$feature_n)\n\nggplot(C_studies,aes(x=feature_n))+geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n#print(quantile(C_studies$feature_n,c(0.333,0.666),na.rm = TRUE))\n#quantile(R_studies$feature_n,c(0.25,0.50,0.75),na.rm = T)\n\n# Assign\nC_studies$feature_n_complexity &lt;- cut(C_studies$feature_n,\n                                      breaks = c(0,30,300,\n                                                 10000),\n                                      labels = c(\"Feature n &lt; 30\",\"Feature n &gt; 30 & &lt; 300\",\"Feature n &gt; 300\"))\ntable(C_studies$feature_n_complexity)\n\n\n        Feature n &lt; 30 Feature n &gt; 30 & &lt; 300        Feature n &gt; 300 \n                    20                     35                     53"
  },
  {
    "objectID": "analysis/preprocessing.html#explore-feature_n_complexity-and-model-success-1",
    "href": "analysis/preprocessing.html#explore-feature_n_complexity-and-model-success-1",
    "title": "Preprocessing",
    "section": "Explore feature_n_complexity and model success",
    "text": "Explore feature_n_complexity and model success\nNeeds to be done from the unsummarised data (C_studies).\n\ntmp &lt;- drop_na(C_studies)\nlibrary(ggdist)\n\ntmp$dimension&lt;-str_to_title(tmp$dimension)\ntmp$model_class_id&lt;-factor(tmp$model_class_id,\n                           levels = c(\"Neural Nets\",\"Flexible Discriminants\", \"Kernel Smoothing, Additive and KNN\", \"Random Forests\",\"Linear Methods\"),\n                           labels = c(\"Neural\\nNets\",\"Flexible\\nDiscriminants\", \"KS\\n & KNN\", \"Random\\nForests\", \"Linear\\nMethods\"))\n\ng &lt;- ggplot(tmp,aes(x=model_class_id,y=values,color=citekey,label=citekey,shape=stimulus_genre_mixed))+\n  stat_halfeye(aes(fill=citekey),point_interval=\"mean_qi\", trim=FALSE, expand=FALSE, show.legend = FALSE,adjust = 1.25, density=\"bounded\", point_size=3,scale = 1,alpha=0.5) + \n  geom_point(alpha=0.5,show.legend = F,position = position_jitter(width = .3))+\n  #geom_label_repel(size=2,max.overlaps = 50)+\n  facet_wrap(.~feature_n_complexity)+\n  ylab(\"Correlation Coefficient\")+\n  xlab(\"Model Technique\")+\n  scale_y_continuous(limits = c(0,1),expand = c(0.01,0.01))+\n  geom_text_repel(aes(x = model_class_id, y = values, label = studyREF),\n             stat = \"summary\", fun = mean,show.legend = F)+\n  theme_bw()\nprint(g)\n\nWarning: Removed 116 rows containing missing values or values outside the scale range\n(`geom_slabinterval()`).\n\n\nWarning: Removed 87 rows containing missing values or values outside the scale range\n(`geom_slabinterval()`).\n\n\nWarning: Removed 34 rows containing missing values or values outside the scale range\n(`geom_slabinterval()`).\n\n\n\n\n#ggsave(filename = 'FeatureN_regression.pdf',g,height = 7,width = 11)"
  },
  {
    "objectID": "analysis/preprocessing.html#create-descriptive-table-for-the-manuscript-1",
    "href": "analysis/preprocessing.html#create-descriptive-table-for-the-manuscript-1",
    "title": "Preprocessing",
    "section": "Create descriptive table for the manuscript",
    "text": "Create descriptive table for the manuscript\n\nTC &lt;- NULL\nTC$study_n &lt;- length(unique(C_studies$citekey))\nTC$model_n &lt;- nrow(C_studies)\nt&lt;-table(C_studies$model_class_id)\nt2 &lt;- paste0(names(t),': ', as.numeric(t))\nTC$model_types_n &lt;- str_c(t2,collapse = \"\\n\")\nTC$feature_Desc &lt;- paste0('Min=',min(C_studies$feature_n,na.rm = TRUE),', Md=',median(C_studies$feature_n,na.rm = TRUE),', Max=', max(C_studies$feature_n,na.rm = TRUE))\nTC$stimulus_Desc &lt;- paste0('Min=',min(C_studies$stimulus_n,na.rm = TRUE),', Md=',median(C_studies$stimulus_n,na.rm = TRUE),', Max=', max(C_studies$stimulus_n,na.rm = TRUE))\nprint(TC)\n\n$study_n\n[1] 14\n\n$model_n\n[1] 108\n\n$model_types_n\n[1] \"Flexible Discriminants: 37\\nKernel Smoothing, Additive and KNN: 8\\nLinear Methods: 24\\nNeural Nets: 27\\nRandom Forests: 12\"\n\n$feature_Desc\n[1] \"Min=3, Md=231, Max=8904\"\n\n$stimulus_Desc\n[1] \"Min=124, Md=387, Max=5192\""
  },
  {
    "objectID": "analysis/preprocessing.html#export-as-csv-1",
    "href": "analysis/preprocessing.html#export-as-csv-1",
    "title": "Preprocessing",
    "section": "Export as csv",
    "text": "Export as csv\n\nwrite.csv(x = C_studies,file = 'C_studies.csv')\nwrite.csv(x = C_summary,file = 'C_summary.csv')"
  },
  {
    "objectID": "etc/Secondary Databases.html",
    "href": "etc/Secondary Databases.html",
    "title": "Secondary Databases",
    "section": "",
    "text": "Secondary Databases\n\n\n\nIndex\nDatabase\nStim. Type\nStim. Dur.\nStim. N\nFeature N.\nPpt. N\nPpt. Expertise\nPpt. Origin\nPpt. Sampling\nPpt. Task\nFeature Source\nFeature Categories\nCitation\n\n\n\n\n1\nEMOPIA\nPiano Solo (pop music)\n30 to 40\n387\n24 (average of 20 MFCC + note length, velocity, beat note density, key)\n4 total, 1 per song (annotators, not ppts)\nnot specified\nnot specified\npresumably researchers\nclassify\nMIDI Toolbox\nRhythm, Harmony, Timbre\nHung et al. (2021)\n\n\n2\nAMG1608\npop\n30\n1608\n72\n643 MTurk, 22 Taiwan subjects\nno restrictions\nMTurk\ncrowdsource\nrate\nMIRToolbox, YAAFE\nTimbre, tonal, spectral, temporal\nChen et al. (2015)\n\n\n3\nNTUMIR\nFamous pop songs\n25\n60\n46\n99 (40 annotations per clip)\nno restrictions\ncampus\nconvenience\nrate\nMIRToolbox, Sound Description Toolbox, MA Toolbox\nMelody/harmony, spectral, temporal, rhythmic, lyrics\nYang et al. (2011)*\n\n\n4\nDEAM\npop\n58 full-length and 1744 45-second excerpts\n1802\n261\nTotal n not specified. Minimum annotations per piece: 2013-14: 10; 2015: 5 MTurk workers\nno restrictions\n2013-14: MTurk; 2015: MTurk and Lab workers\ncrowdsourcing, convenience\nrate\nOpenSMILE\nPitch, Timbre, Voice, Dynamic. Many MFCC features\nAljanaki et al. (2017)\n\n\n5\nMediaEval2013/emoMusic/1000 songs\nwestern pop of various genres\n45\n744\n6670\nmin. 10 per clip (100 qualified workers in final HIT)\nNonexperts (Mturk) + experts\nMTurk\nCrowdsourcing, presumed convenience for experts\nrate\nOpenSMILE\nPitch, Timbre, Voice, Dynamic. Many MFCC features\nSoleymani et al. (2013)\n\n\n6\nSoundtracks\nobscure film soundtracks\n5\n110\nnone?\n116 university students\nnonmusicians\ncampus\nconvenience\nrate, classify\nNA\nNA\nEerola & Vuoskoski (2011)\n\n\n7\nPSIC3839\nChinese popular\nfull? 180 s excerpts extracted for analyses\n3839\nns. About 10 feature categories. Unclear dimensionaltiy\n87\nno restrictions\ncampus\nconvenience\nrate\nLibrosa\nPitch, Timbre, Harmony, Rhythm\nLiang et al. (2022)\n\n\n8\nCH818\nChinese pop\n30\n818\n15\n3\nexperts\nChina\nconvenience\nrate\nMIRToolbox, PsySound, ChromaToolbox,Tempogram Toolbox\nDynamic, Pitch, Rhythm, Timbre, Harmony\nHu & Yang (2017)\n\n\n9\nZhang, Huang, Yang, & Xu (2015)\nChinese pop\n30\n171\n84 (dimensionality)\n10\nNonexperts\nnot specified\nnot specified\nclassify\nMAToolbox, MIRToolbox, Coversongs\nDynamics, Timbre, Rhythm\nZhang et al. 2015\n\n\n10\nPMEmo\nchoruses of top pop songs\nvariable\n794\n65 (260 dims)\n457\n366 Chinese university students (44 music majors); 47 English speakers\ncampus\nconvenience\nrate\nComParE 2013 baseline feature set\nDynamic, Timbre, Pitch (tabulated as energy-related, spectral, voicing related)\nZhang et al. (2018)\n\n\n11\nNJU-V1\nMusic clips (limited detail)\nvariable\n777\nLyric (BoW; 50 dims before filtering), MFCC, spectral contrast, chromagram\nNA (lastfm tags)\nNA\nLastFM\ncrowdsource (webscraping)\nNA\nNA\nLyric, Timbre, Harmony\nXue et al. (2015)\n\n\n12\nISMIR-2012\npopular\n30 or 60\n2904\n54 (means + sds)\nNA (lastfm tags)\nNA\nLastFM\ncrowdsource (webscraping)\nNA\nMIRToolbox\nDynamics, Rhythm, Timbre (they call this Spectral), Harmony\nSong et al. 2012**\n\n\n\n* Dataset not available online\n** Only lyrics & timestamps included in public dataset\n\n\nReferences\n\nAljanaki, A., Yang, Y. H., & Soleymani, M. (2017). Developing a benchmark for emotional analysis of music. PloS one, 12(3), e0173392.\n\n\nChen, Y. A., Yang, Y. H., Wang, J. C., & Chen, H. (2015, April). The AMG1608 dataset for music emotion recognition. In 2015 IEEE international conference on acoustics, speech and signal processing (ICASSP) (pp. 693-697). IEEE.\n\n\nEerola, T. & Vuoskoski, J. K. (2011). A comparison of the discrete and dimensional models of emotion in music. Psychology of Music, 39(1), 18-49. https://doi.org/10.1177/0305735610362821\n\n\nHu, X., & Yang, Y. H. (2017). The mood of Chinese Pop music: Representation and recognition. Journal of the Association for Information Science and Technology, 68(8), 1899-1910.\n\n\nHung, H. T., Ching, J., Doh, S., Kim, N., Nam, J., & Yang, Y. H. (2021). EMOPIA: A multi-modal pop piano dataset for emotion recognition and emotion-based music generation. arXiv preprint arXiv:2108.01374.\n\n\nSoleymani, M., Caro, M. N., Schmidt, E. M., Sha, C. Y., & Yang, Y. H. (2013, October). 1000 songs for emotional analysis of music. In Proceedings of the 2nd ACM international workshop on Crowdsourcing for multimedia (pp. 1-6).\n\n\nXu, L., Yun, Z., Sun, Z., Wen, X., Qin, X., & Qian, X. (2022). PSIC3839: Predicting the Overall Emotion and Depth of Entire Songs. In Design Studies and Intelligence Engineering (pp. 1-9). IOS Press.\n\n\nXue, H., Xue, L., & Su, F. (2015). Multimodal music mood classification by fusion of audio and lyrics. In MultiMedia Modeling: 21st International Conference, MMM 2015, Sydney, NSW, Australia, January 5-7, 2015, Proceedings, Part II 21 (pp. 26-37). Springer International Publishing.\n\n\nZhang, J. L., Huang, X. L., Yang, L. F., Xu, Y., & Sun, S. T. (2017). Feature selection and feature learning in arousal dimension of music emotion by using shrinkage methods. Multimedia systems, 23, 251-264.\n\n\nZhang, K., Zhang, H., Li, S., Yang, C., & Sun, L. (2018, June). The PMEmo dataset for music emotion recognition. In Proceedings of the 2018 acm on international conference on multimedia retrieval (pp. 135-142).\n\n\nSong, Y., Dixon, S., & Pearce, M. T. (2012, October). Evaluation of musical features for emotion classification. In ISMIR (pp. 523-528).\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "preregistration/preregistration.html",
    "href": "preregistration/preregistration.html",
    "title": "metaMER",
    "section": "",
    "text": "This preregistration is made with preregr package from https://preregr.opens.science/ that implements the BMJ published guidance for meta-analysis protocols (Shamseer et al., 2015).\nMeta-analysis Pre-registration: Music Emotion Recognition\n\nSection: Metadata\n\n\n\nTitle\n\n\ntitle\n\n\n\nMusic emotion recognition: Meta-analysis of regression and classification success of emotion ratings from audio\n\n\n\n\n\nContributors\n\n\nauthors\n\n\n\nEerola, T., Anderson, C. J.\n\n\n\n\n\nSubjects\n\n\ntarget_discipline\n\n\n\nmusic cognition, music information retrieval, music psychology\n\n\n\n\n\nTasks and roles\n\n\ntasks_and_roles\n\n\n\nequal contribution\n\n\n\n\nSection: Review methods\n\n\n\nType of review\n\n\ntype_of_review\n\n\n\nMeta-analysis\n\n\n\n\n\nReview stages\n\n\nreview_stages\n\n\n\nSearch, Screening, Extraction, Synthesis\n\n\n\n\n\nCurrent review stage\n\n\ncurrent_stage\n\n\n\nScreening\n\n\n\n\n\nStart date\n\n\nstart_date\n\n\n\n2024-05-15 2024-05-15\n\n\n\n\n\nEnd date\n\n\nend_date\n\n\n\n2024-06-30\n\n\n\n\n\nBackground\n\n\nbackground\n\n\n\nThe aim is to establish the current state of the model success in predicting emotions expressed by music from audio. We will focus on the last 10 years of research and especially the research that has predicted valence and arousal ratings from music audio. No such analysis exists and there are interesting challenges in predicting emotional content of music that relates to specificity of the music and the type of emotions and features used that would benefit from a systematic analysis.\n\n\n\n\n\nPrimary research question(s)\n\n\nprimary_research_question\n\n\n\nTo what degree can arousal and valence ratings of emotions expressed by music be predicted from audio? How are the prediction rates related to genres of music, the type of models used, the type of features, modelling design and cross-validation utilised, and the model complexity and parsimony?\n\n\n\n\n\nSecondary research question(s)\n\n\nsecondary_research_question\n\n\n\nWhat is the prediction rate related to classification of quadrants in the affective circumplex?\n\n\n\n\n\nExpectations / hypotheses\n\n\nexpectations_hypotheses\n\n\n\nPrediction of arousal ratings is generally high and robust, and in terms of the model outcome metrics (correlation), achieves at least r = 0.77 (R square of 0.60). Prediction of valence ratings from audio is more challenging and more context dependent and will achieve generally a lower prediction rate, r = 0.63 (R square 0.40)\n\n\n\n\n\nDependent variable(s) / outcome(s) / main variables\n\n\ndvs_outcomes_main_vars\n\n\n\nRegression model performance will be converted to Pearson correlation coefficients and classification model performance will be converted to Matthews correlation coefficient (MCC) when possible.\n\n\n\n\n\nIndependent variable(s) / intervention(s) / treatment(s)\n\n\nivs_intervention_treatment\n\n\n\nMusic genre, prediction type (linear or classification), feature type (based on prior work by Panda et al., 2020), model complexity (high, medium, low), model validation (exists or not)\n\n\n\n\n\nAdditional variable(s) / covariate(s)\n\n\nadditional_variables\n\n\n\nUnspecified\n\n\n\n\n\nSoftware\n\n\nsoftware\n\n\n\nR and Github repository\n\n\n\n\n\nFunding\n\n\nfunding\n\n\n\nMitacs Globalink Research Award (Mitacs & British High Commission - Ottawa, Canada)\n\n\n\n\n\nConflicts of interest\n\n\ncois\n\n\n\nThere are no identified conflicts of interests.\n\n\n\n\n\nOverlapping authorships\n\n\noverlapping_authorships\n\n\n\nNot applicable\n\n\n\n\nSection: Search strategy\n\n\n\nDatabases\n\n\ndatabases\n\n\n\nWeb of Science, Scopus, and Open Alex\n\n\n\n\n\nInterfaces\n\n\ninterfaces\n\n\n\nWeb of Science, Scopus, and Open Alex\n\n\n\n\n\nGrey literature\n\n\ngrey_literature\n\n\n\nNot included\n\n\n\n\n\nInclusion and exclusion criteria\n\n\ninclusions_exclusion_criteria\n\n\n\nSample, Phenomenon of Interest, Design, Evaluation, Research type\n\n\n\n\n\nQuery strings\n\n\nquery_strings\n\n\n\nScopus: TITLE-ABS-KEY ( valence OR arousal OR classi OR categor OR algorithm AND music  AND emotion AND recognition ) AND PUBYEAR &gt; 2013 AND PUBYEAR &lt; 2025 AND  ( LIMIT-TO ( DOCTYPE , “ar” ) )  Web of science:  (DT=(Article) AND PY=(2014-2025)) AND ALL=(music emotion recognition valence arousal)  Open Alex:  https://openalex.org/works?page=1&filter=default.search%3Amusic%20emotion%20recognition%20valence%20arousal, type%3Atypes%2Farticle,publication_year%3A2014-2024, keywords.id%3Akeywords%2Femotion-recognition, keywords.id%3Akeywords%2Faffective-computing, language%3Alanguages%2Fen, open_access.any_repository_has_fulltext%3Atrue \n\n\n\n\n\nSearch validation procedure\n\n\nsearch_validation_procedure\n\n\n\nManual checking, separate keywords searches\n\n\n\n\n\nOther search strategies\n\n\nother_search_strategies\n\n\n\nNot applied\n\n\n\n\n\nProcedures to contact authors\n\n\nprocedure_for_contacting_authors\n\n\n\nUnspecified\n\n\n\n\n\nResults of contacting authors\n\n\nresults_of_contacting_authors\n\n\n\nNot carried out\n\n\n\n\n\nSearch expiration and repetition\n\n\nsearch_expiration_and_repetition\n\n\n\nSearches were done during the active search period in late May early June 2024 and no repetition is planned.\n\n\n\n\n\nSearch strategy justification\n\n\nsearch_strategy_justification\n\n\n\nThe three major databases should be able yield a robust picture of the topic\n\n\n\n\n\nMiscellaneous search strategy details\n\n\nmisc_search_strategy_details\n\n\n\nNo alternative searches were articulated or envisaged.\n\n\n\n\nSection: Screening\n\n\n\nScreening stages\n\n\nscreening_stages\n\n\n\nWe completed screening using custom fields inserted to the bibtex file and managed with citation managers (jabref and bibdesk). To filter relevant studies, we followed a three-stage screening procedure.  In stage 1, we screened the 553 studies’ titles for relevance, removing irrelevant studies and recording exclusion criteria (see Used exclusion criteria). CA assigned 63 studies to the High Priority based on titles’ relevance, assigned 338 studies to Low Priority based on irrelevant titles, and 152 studies to Medium Priority for additional screening. In stage 2, CA assessed the 152 Medium Priority studies for relevance by screening abstracts. 95 studies’ status changed to Low Priority, whereas 30 studies’ status changed to High Priority. 27 studies remained in the Medium priority category. TE and CA evaluated the remaining 27 studies’, moving 15 to the High Priority Category and 12 to the Medium Priority Category. For studies moved to Low Priority, brief BiBTex comments summarized the rationale for exclusion. In stage 3, TE and CA independently screened Priority 1 studies for relevance, including an include, exclude, or unsure decision in a user-comment BiBTeX field.\n\n\n\n\n\nScreened fields / masking\n\n\nscreened_fields_masking\n\n\n\nWe left authors, titles, publication years, and journal names unmasked.\n\n\n\n\n\nUsed exclusion criteria\n\n\nused_exclusion_criteria\n\n\n\nWe excluded studies according to the following exclusion criteria: soundscapes/vocalisations, non-music audio, video clips, physiological markers, dance, video/movie, physiological/EEG/ECG/MEG/GSR/brain imaging/heart rate/neuroscience/brain studies, sensor data, multimodal, autism, ageing, review/systematic review/overview/survey, face emotion recognition, mental health, music therapy, schizophrenia, memory/emotion factors as IVs, recommender systems, or systems that identify the location of emotional excerpts. We included results from some studies meeting exclusion criteria (e.g., multimodal studies involving physiological measurements) if they reported separately on acoustic-only models.\n\n\n\n\n\nScreener instructions\n\n\nscreener_instructions\n\n\n\nAs described above.\n\n\n\n\n\nScreening reliability\n\n\nscreening_reliability\n\n\n\nIn the pass 1 and 2, we included a quality control check after the pass to discuss the identified categories. In the third pass, we double-coded decisions, resolving discrepancies through discussion.\n\n\n\n\n\nScreening reconciliation procedure\n\n\nscreening_reconciliation_procedure\n\n\n\nWe reconcile discrepancies through discussion, resolving “unsure” votes first, followed by discrepancies in include/exclude decisions between authors Results of this updating procedure are available in the Pass 3 comparison document.\n\n\n\n\n\nSampling and sample size\n\n\nsampling_and_sample_size\n\n\n\nWe identified and retained 553 articles from Scopus, Web of Science, and Open Alex based on the search strategy outlined above. See table at the end that details the cumulative exclusions.\n\n\n\n\n\nScreening procedure justification\n\n\nscreening_procedure_justification\n\n\n\nTo offer a broad summary of music emotion recognition tasks, we attempted to include all studies involving prediction with acoustic features. We performed screening unblinded and determined inclusion/exclusion criteria based on studies’ relevance to the task explored.\n\n\n\n\n\nData management and sharing\n\n\nscreening_data_management_and_sharing\n\n\n\nSources will be shared as (a) BibTeX library(ies) including reviewer notes.\n\n\n\n\n\nMiscellaneous screening details\n\n\nmisc_screening_details\n\n\n\nUnspecified\n\n\n\n\nSection: Extraction\n\n\n\nEntities to extract\n\n\nentities_to_extract\n\n\n\nThese are listed and defined in extraction details.\n\n\n\n\n\nExtraction stages\n\n\nextraction_stages\n\n\n\nThe data extraction will be completed in stages. In the first stage, CA will complete a pass of the collection using our initial entities to extract document. The challenges are discussed and the entities are revised.\n\n\n\n\n\nExtractor instructions\n\n\nextractor_instructions\n\n\n\nSee extraction details.\n\n\n\n\n\nExtractor blinding\n\n\nextractor_blinding\n\n\n\nBlinding was not used.\n\n\n\n\n\nExtraction reliability\n\n\nextraction_reliability\n\n\n\nCA will perform extractions; TE will verify extractions for quality assurance.\n\n\n\n\n\nExtraction reconciliation procedure\n\n\nextraction_reconciliation_procedure\n\n\n\nDiscussion and joint decision for studies where extraction proves to be challenging and issues of interpretation arise.\n\n\n\n\n\nExtraction procedure justification\n\n\nextraction_procedure_justification\n\n\n\nThese are documented in the extraction details.\n\n\n\n\n\nData management and sharing\n\n\nextraction_data_management_and_sharing\n\n\n\nWe retain the information of the studies in shared bibtex files, extraction data will be stored in ascii data files (.bibtex), and the parser for reading the data from .bibtex files to R for the analysis will be available (as quarto/markdown/R files), and all these are managed, structured, shared and documented in Github repository according to FAIR principles.\n\n\n\n\n\nMiscellaneous extraction details\n\n\nmisc_extraction_details\n\n\n\nNA\n\n\n\n\nSection: Synthesis and Quality Assessment\n\n\n\nPlanned data transformations\n\n\nplanned_data_transformations\n\n\n\nFor regression studies, we convert all metrics to Pearson correlation coefficients. For classification studies, we convert the outcomes of classification to Matthews Correlation Coefficient (MCC) from the precision, accuracy, specificity, F1 scores. Alternatively, we use Cohen’s kappa for multiple classes.\n\n\n\n\n\nMissing data\n\n\nmissing_data\n\n\n\nIf no main outcome variables are available, we exclude the study.\n\n\n\n\n\nData validation\n\n\ndata_validation\n\n\n\nNone planned beyond the staged approached already documented in extraction process.\n\n\n\n\n\nQuality assessment\n\n\nquality_assessment\n\n\n\nNot all the bias assessment tools for clinical studies are relevant for our purposes, we adapt the overall approached advocated in [Higgins et al. (2011)] (https://doi.org/10.1136/bmj.d5928).\n\n\n\n\n\nSynthesis plan\n\n\nsynthesis_plan\n\n\n\nWe analyse regression and classification studies separately, and depending on the quantity of the studies forming suitable sub-groupings based on techniques, materials or music collections/genres, we may further synthesise the results across groupings that are formed along these subsets.\n\n\n\n\n\nCriteria for conclusions / inference criteria\n\n\ncriteria_for_conclusions\n\n\n\nNA\n\n\n\n\n\nSynthesist masking\n\n\nsynthesis_masking\n\n\n\nNA\n\n\n\n\n\nSynthesis reliability\n\n\nsynthesis_reliability\n\n\n\nNA\n\n\n\n\n\nSynthesis reconciliation procedure\n\n\nsynthesis_reconciliation_procedure\n\n\n\nNA\n\n\n\n\n\nPublication bias analyses\n\n\npublication_bias\n\n\n\nWe utilise Egger’s test to assess the publication bias and potentially correct the effect size bias by selecting 10% most precise effect sizes as recommended by Van Aert, Wicherts, & Van Assen (2019).\n\n\n\n\n\nSensitivity analyses / robustness checks\n\n\nsensitivity_analysis\n\n\n\nWithin regression and classificiation tasks, we will carry out sensitivity analysis using sub-groups of studied based on type of models, and the type of journal the studies were published in.\n\n\n\n\n\nSynthesis procedure justification\n\n\nsynthesis_procedure_justification\n\n\n\nWe share our justification of the synthesis and the subsetting carried out in the manuscript but we have not formulated these in advance except for synthesizing classiciation and regression approaches separately and creating subsets within these approaches according to techniques and datasets utilised.\n\n\n\n\n\nSynthesis data management and sharing\n\n\nsynthesis_data_management_and_sharing\n\n\n\nWe share the data, procedures, definitions, the analysis scripts with the outcomes as R code in Quarto notes at Github.\n\n\n\n\n\nMiscellaneous synthesis details\n\n\nmisc_synthesis_details\n\n\n\nUnspecified"
  },
  {
    "objectID": "preregistration/preregistration.html#preregr-prereg-spec-Ya8oq9lMLd",
    "href": "preregistration/preregistration.html#preregr-prereg-spec-Ya8oq9lMLd",
    "title": "metaMER",
    "section": "Meta-analysis Pre-registration: Music Emotion Recognition",
    "text": "Meta-analysis Pre-registration: Music Emotion Recognition\n\nSection: Metadata\n\n\n\nTitle\n\n\ntitle\n\n\n\nMusic emotion recognition: Meta-analysis of regression and classification success of emotion ratings from audio\n\n\n\n\n\nContributors\n\n\nauthors\n\n\n\nEerola, T., Anderson, C. J.\n\n\n\n\n\nSubjects\n\n\ntarget_discipline\n\n\n\nmusic cognition, music information retrieval, music psychology\n\n\n\n\n\nTasks and roles\n\n\ntasks_and_roles\n\n\n\nequal contribution\n\n\n\n\nSection: Review methods\n\n\n\nType of review\n\n\ntype_of_review\n\n\n\nMeta-analysis\n\n\n\n\n\nReview stages\n\n\nreview_stages\n\n\n\nSearch, Screening, Extraction, Synthesis\n\n\n\n\n\nCurrent review stage\n\n\ncurrent_stage\n\n\n\nScreening\n\n\n\n\n\nStart date\n\n\nstart_date\n\n\n\n2024-05-15 2024-05-15\n\n\n\n\n\nEnd date\n\n\nend_date\n\n\n\n2024-06-30\n\n\n\n\n\nBackground\n\n\nbackground\n\n\n\nThe aim is to establish the current state of the model success in predicting emotions expressed by music from audio. We will focus on the last 10 years of research and especially the research that has predicted valence and arousal ratings from music audio. No such analysis exists and there are interesting challenges in predicting emotional content of music that relates to specificity of the music and the type of emotions and features used that would benefit from a systematic analysis.\n\n\n\n\n\nPrimary research question(s)\n\n\nprimary_research_question\n\n\n\nTo what degree can arousal and valence ratings of emotions expressed by music be predicted from audio? How are the prediction rates related to genres of music, the type of models used, the type of features, modelling design and cross-validation utilised, and the model complexity and parsimony?\n\n\n\n\n\nSecondary research question(s)\n\n\nsecondary_research_question\n\n\n\nWhat is the prediction rate related to classification of quadrants in the affective circumplex?\n\n\n\n\n\nExpectations / hypotheses\n\n\nexpectations_hypotheses\n\n\n\nPrediction of arousal ratings is generally high and robust, and in terms of the model outcome metrics (correlation), achieves at least r = 0.77 (R square of 0.60). Prediction of valence ratings from audio is more challenging and more context dependent and will achieve generally a lower prediction rate, r = 0.63 (R square 0.40)\n\n\n\n\n\nDependent variable(s) / outcome(s) / main variables\n\n\ndvs_outcomes_main_vars\n\n\n\nRegression model performance will be converted to Pearson correlation coefficients and classification model performance will be converted to Matthews correlation coefficient (MCC) when possible.\n\n\n\n\n\nIndependent variable(s) / intervention(s) / treatment(s)\n\n\nivs_intervention_treatment\n\n\n\nMusic genre, prediction type (linear or classification), feature type (based on prior work by Panda et al., 2020), model complexity (high, medium, low), model validation (exists or not)\n\n\n\n\n\nAdditional variable(s) / covariate(s)\n\n\nadditional_variables\n\n\n\nUnspecified\n\n\n\n\n\nSoftware\n\n\nsoftware\n\n\n\nR and Github repository\n\n\n\n\n\nFunding\n\n\nfunding\n\n\n\nMitacs Globalink Research Award (Mitacs & British High Commission - Ottawa, Canada)\n\n\n\n\n\nConflicts of interest\n\n\ncois\n\n\n\nThere are no identified conflicts of interests.\n\n\n\n\n\nOverlapping authorships\n\n\noverlapping_authorships\n\n\n\nNot applicable\n\n\n\n\nSection: Search strategy\n\n\n\nDatabases\n\n\ndatabases\n\n\n\nWeb of Science, Scopus, and Open Alex\n\n\n\n\n\nInterfaces\n\n\ninterfaces\n\n\n\nWeb of Science, Scopus, and Open Alex\n\n\n\n\n\nGrey literature\n\n\ngrey_literature\n\n\n\nNot included\n\n\n\n\n\nInclusion and exclusion criteria\n\n\ninclusions_exclusion_criteria\n\n\n\nSample, Phenomenon of Interest, Design, Evaluation, Research type\n\n\n\n\n\nQuery strings\n\n\nquery_strings\n\n\n\nScopus: TITLE-ABS-KEY ( valence OR arousal OR classi OR categor OR algorithm AND music  AND emotion AND recognition ) AND PUBYEAR &gt; 2013 AND PUBYEAR &lt; 2025 AND  ( LIMIT-TO ( DOCTYPE , “ar” ) )  Web of science:  (DT=(Article) AND PY=(2014-2025)) AND ALL=(music emotion recognition valence arousal)  Open Alex:  https://openalex.org/works?page=1&filter=default.search%3Amusic%20emotion%20recognition%20valence%20arousal, type%3Atypes%2Farticle,publication_year%3A2014-2024, keywords.id%3Akeywords%2Femotion-recognition, keywords.id%3Akeywords%2Faffective-computing, language%3Alanguages%2Fen, open_access.any_repository_has_fulltext%3Atrue \n\n\n\n\n\nSearch validation procedure\n\n\nsearch_validation_procedure\n\n\n\nManual checking, separate keywords searches\n\n\n\n\n\nOther search strategies\n\n\nother_search_strategies\n\n\n\nNot applied\n\n\n\n\n\nProcedures to contact authors\n\n\nprocedure_for_contacting_authors\n\n\n\nUnspecified\n\n\n\n\n\nResults of contacting authors\n\n\nresults_of_contacting_authors\n\n\n\nNot carried out\n\n\n\n\n\nSearch expiration and repetition\n\n\nsearch_expiration_and_repetition\n\n\n\nSearches were done during the active search period in late May early June 2024 and no repetition is planned.\n\n\n\n\n\nSearch strategy justification\n\n\nsearch_strategy_justification\n\n\n\nThe three major databases should be able yield a robust picture of the topic\n\n\n\n\n\nMiscellaneous search strategy details\n\n\nmisc_search_strategy_details\n\n\n\nNo alternative searches were articulated or envisaged.\n\n\n\n\nSection: Screening\n\n\n\nScreening stages\n\n\nscreening_stages\n\n\n\nWe completed screening using custom fields inserted to the bibtex file and managed with citation managers (jabref and bibdesk). To filter relevant studies, we followed a three-stage screening procedure.  In stage 1, we screened the 553 studies’ titles for relevance, removing irrelevant studies and recording exclusion criteria (see Used exclusion criteria). CA assigned 63 studies to the High Priority based on titles’ relevance, assigned 338 studies to Low Priority based on irrelevant titles, and 152 studies to Medium Priority for additional screening. In stage 2, CA assessed the 152 Medium Priority studies for relevance by screening abstracts. 95 studies’ status changed to Low Priority, whereas 30 studies’ status changed to High Priority. 27 studies remained in the Medium priority category. TE and CA evaluated the remaining 27 studies’, moving 15 to the High Priority Category and 12 to the Medium Priority Category. For studies moved to Low Priority, brief BiBTex comments summarized the rationale for exclusion. In stage 3, TE and CA independently screened Priority 1 studies for relevance, including an include, exclude, or unsure decision in a user-comment BiBTeX field.\n\n\n\n\n\nScreened fields / masking\n\n\nscreened_fields_masking\n\n\n\nWe left authors, titles, publication years, and journal names unmasked.\n\n\n\n\n\nUsed exclusion criteria\n\n\nused_exclusion_criteria\n\n\n\nWe excluded studies according to the following exclusion criteria: soundscapes/vocalisations, non-music audio, video clips, physiological markers, dance, video/movie, physiological/EEG/ECG/MEG/GSR/brain imaging/heart rate/neuroscience/brain studies, sensor data, multimodal, autism, ageing, review/systematic review/overview/survey, face emotion recognition, mental health, music therapy, schizophrenia, memory/emotion factors as IVs, recommender systems, or systems that identify the location of emotional excerpts. We included results from some studies meeting exclusion criteria (e.g., multimodal studies involving physiological measurements) if they reported separately on acoustic-only models.\n\n\n\n\n\nScreener instructions\n\n\nscreener_instructions\n\n\n\nAs described above.\n\n\n\n\n\nScreening reliability\n\n\nscreening_reliability\n\n\n\nIn the pass 1 and 2, we included a quality control check after the pass to discuss the identified categories. In the third pass, we double-coded decisions, resolving discrepancies through discussion.\n\n\n\n\n\nScreening reconciliation procedure\n\n\nscreening_reconciliation_procedure\n\n\n\nWe reconcile discrepancies through discussion, resolving “unsure” votes first, followed by discrepancies in include/exclude decisions between authors Results of this updating procedure are available in the Pass 3 comparison document.\n\n\n\n\n\nSampling and sample size\n\n\nsampling_and_sample_size\n\n\n\nWe identified and retained 553 articles from Scopus, Web of Science, and Open Alex based on the search strategy outlined above. See table at the end that details the cumulative exclusions.\n\n\n\n\n\nScreening procedure justification\n\n\nscreening_procedure_justification\n\n\n\nTo offer a broad summary of music emotion recognition tasks, we attempted to include all studies involving prediction with acoustic features. We performed screening unblinded and determined inclusion/exclusion criteria based on studies’ relevance to the task explored.\n\n\n\n\n\nData management and sharing\n\n\nscreening_data_management_and_sharing\n\n\n\nSources will be shared as (a) BibTeX library(ies) including reviewer notes.\n\n\n\n\n\nMiscellaneous screening details\n\n\nmisc_screening_details\n\n\n\nUnspecified\n\n\n\n\nSection: Extraction\n\n\n\nEntities to extract\n\n\nentities_to_extract\n\n\n\nThese are listed and defined in extraction details.\n\n\n\n\n\nExtraction stages\n\n\nextraction_stages\n\n\n\nThe data extraction will be completed in stages. In the first stage, CA will complete a pass of the collection using our initial entities to extract document. The challenges are discussed and the entities are revised.\n\n\n\n\n\nExtractor instructions\n\n\nextractor_instructions\n\n\n\nSee extraction details.\n\n\n\n\n\nExtractor blinding\n\n\nextractor_blinding\n\n\n\nBlinding was not used.\n\n\n\n\n\nExtraction reliability\n\n\nextraction_reliability\n\n\n\nCA will perform extractions; TE will verify extractions for quality assurance.\n\n\n\n\n\nExtraction reconciliation procedure\n\n\nextraction_reconciliation_procedure\n\n\n\nDiscussion and joint decision for studies where extraction proves to be challenging and issues of interpretation arise.\n\n\n\n\n\nExtraction procedure justification\n\n\nextraction_procedure_justification\n\n\n\nThese are documented in the extraction details.\n\n\n\n\n\nData management and sharing\n\n\nextraction_data_management_and_sharing\n\n\n\nWe retain the information of the studies in shared bibtex files, extraction data will be stored in ascii data files (.bibtex), and the parser for reading the data from .bibtex files to R for the analysis will be available (as quarto/markdown/R files), and all these are managed, structured, shared and documented in Github repository according to FAIR principles.\n\n\n\n\n\nMiscellaneous extraction details\n\n\nmisc_extraction_details\n\n\n\nNA\n\n\n\n\nSection: Synthesis and Quality Assessment\n\n\n\nPlanned data transformations\n\n\nplanned_data_transformations\n\n\n\nFor regression studies, we convert all metrics to Pearson correlation coefficients. For classification studies, we convert the outcomes of classification to Matthews Correlation Coefficient (MCC) from the precision, accuracy, specificity, F1 scores. Alternatively, we use Cohen’s kappa for multiple classes.\n\n\n\n\n\nMissing data\n\n\nmissing_data\n\n\n\nIf no main outcome variables are available, we exclude the study.\n\n\n\n\n\nData validation\n\n\ndata_validation\n\n\n\nNone planned beyond the staged approached already documented in extraction process.\n\n\n\n\n\nQuality assessment\n\n\nquality_assessment\n\n\n\nNot all the bias assessment tools for clinical studies are relevant for our purposes, we adapt the overall approached advocated in [Higgins et al. (2011)] (https://doi.org/10.1136/bmj.d5928).\n\n\n\n\n\nSynthesis plan\n\n\nsynthesis_plan\n\n\n\nWe analyse regression and classification studies separately, and depending on the quantity of the studies forming suitable sub-groupings based on techniques, materials or music collections/genres, we may further synthesise the results across groupings that are formed along these subsets.\n\n\n\n\n\nCriteria for conclusions / inference criteria\n\n\ncriteria_for_conclusions\n\n\n\nNA\n\n\n\n\n\nSynthesist masking\n\n\nsynthesis_masking\n\n\n\nNA\n\n\n\n\n\nSynthesis reliability\n\n\nsynthesis_reliability\n\n\n\nNA\n\n\n\n\n\nSynthesis reconciliation procedure\n\n\nsynthesis_reconciliation_procedure\n\n\n\nNA\n\n\n\n\n\nPublication bias analyses\n\n\npublication_bias\n\n\n\nWe utilise Egger’s test to assess the publication bias and potentially correct the effect size bias by selecting 10% most precise effect sizes as recommended by Van Aert, Wicherts, & Van Assen (2019).\n\n\n\n\n\nSensitivity analyses / robustness checks\n\n\nsensitivity_analysis\n\n\n\nWithin regression and classificiation tasks, we will carry out sensitivity analysis using sub-groups of studied based on type of models, and the type of journal the studies were published in.\n\n\n\n\n\nSynthesis procedure justification\n\n\nsynthesis_procedure_justification\n\n\n\nWe share our justification of the synthesis and the subsetting carried out in the manuscript but we have not formulated these in advance except for synthesizing classiciation and regression approaches separately and creating subsets within these approaches according to techniques and datasets utilised.\n\n\n\n\n\nSynthesis data management and sharing\n\n\nsynthesis_data_management_and_sharing\n\n\n\nWe share the data, procedures, definitions, the analysis scripts with the outcomes as R code in Quarto notes at Github.\n\n\n\n\n\nMiscellaneous synthesis details\n\n\nmisc_synthesis_details\n\n\n\nUnspecified"
  },
  {
    "objectID": "preregistration/preregistration.html#references",
    "href": "preregistration/preregistration.html#references",
    "title": "metaMER",
    "section": "References",
    "text": "References\n\nHiggins, J. P. T., Altman, D. G., Gøtzsche, P. C., Jüni, P., Moher, D., Oxman, A. D., Savović, J., Schulz, K. F., Weeks, L., & Sterne, J. A. C. (2011). The Cochrane Collaboration tool for assessing risk of bias in randomised trials. BMJ, 343. https://www.bmj.com/content/343/bmj.d5928\nPanda, R., Malheiro, R., & Paiva, R. P. (2020). Audio features for music emotion recognition: a survey. IEEE Transactions on Affective Computing, 14(1), 68-88. https://doi.org/10.1109/TAFFC.2020.3032373\nShamseer, L., Moher, D., Clarke, M., Ghersi, D., Liberati, A., Petticrew, M., Shekelle, P., & Stewart, L. A. (2015). Preferred reporting items for systematic review and meta-analysis protocols (PRISMA-P) 2015: elaboration and explanation. BMJ, 349. https://www.bmj.com/content/349/bmj.g7647"
  },
  {
    "objectID": "studies/extraction_details.html",
    "href": "studies/extraction_details.html",
    "title": "Extraction Details",
    "section": "",
    "text": "To capture relevant information from studies, we expanded BiBTeX fields for each study with additional fields. For reproducibility, these instructions provide information on the process followed for each field."
  },
  {
    "objectID": "studies/extraction_details.html#identifier",
    "href": "studies/extraction_details.html#identifier",
    "title": "Extraction Details",
    "section": "IDENTIFIER",
    "text": "IDENTIFIER\nUnique identifier of article. Contains last name of lead author, year of publication and first two letters of article title. Hyphenated last names collapsed."
  },
  {
    "objectID": "studies/extraction_details.html#author",
    "href": "studies/extraction_details.html#author",
    "title": "Extraction Details",
    "section": "AUTHOR",
    "text": "AUTHOR\nNames of all authors. Last name precedes first name and separated by comma. For multiple authors “and” precedes each listed subsequent author. E.g., Sorussa, Kanawat and Choksuriwong, Anant and Karnjanadecha, Montri"
  },
  {
    "objectID": "studies/extraction_details.html#journal",
    "href": "studies/extraction_details.html#journal",
    "title": "Extraction Details",
    "section": "JOURNAL",
    "text": "JOURNAL\nTitle of journal containing article."
  },
  {
    "objectID": "studies/extraction_details.html#note",
    "href": "studies/extraction_details.html#note",
    "title": "Extraction Details",
    "section": "NOTE",
    "text": "NOTE\nIncludes number of citing articles and open access details. E.g., Cited by: 4; All Open Access, Gold Open Access, Green Open Access"
  },
  {
    "objectID": "studies/extraction_details.html#title",
    "href": "studies/extraction_details.html#title",
    "title": "Extraction Details",
    "section": "TITLE",
    "text": "TITLE\nTitle of article."
  },
  {
    "objectID": "studies/extraction_details.html#volume",
    "href": "studies/extraction_details.html#volume",
    "title": "Extraction Details",
    "section": "VOLUME",
    "text": "VOLUME\nVolume number of publication."
  },
  {
    "objectID": "studies/extraction_details.html#year",
    "href": "studies/extraction_details.html#year",
    "title": "Extraction Details",
    "section": "YEAR",
    "text": "YEAR\nPublication year."
  },
  {
    "objectID": "studies/extraction_details.html#doi",
    "href": "studies/extraction_details.html#doi",
    "title": "Extraction Details",
    "section": "DOI",
    "text": "DOI\nDigital object identifier of article."
  },
  {
    "objectID": "studies/extraction_details.html#abstract",
    "href": "studies/extraction_details.html#abstract",
    "title": "Extraction Details",
    "section": "ABSTRACT",
    "text": "ABSTRACT\nComplete text of article abstract."
  },
  {
    "objectID": "studies/extraction_details.html#source",
    "href": "studies/extraction_details.html#source",
    "title": "Extraction Details",
    "section": "SOURCE",
    "text": "SOURCE\nDatabase article was sourced from. Scopus, Web of Science (WoS) or OpenAlex."
  },
  {
    "objectID": "studies/extraction_details.html#author_keywords",
    "href": "studies/extraction_details.html#author_keywords",
    "title": "Extraction Details",
    "section": "AUTHOR_KEYWORDS",
    "text": "AUTHOR_KEYWORDS\nCorresponding keywords for article indicated by author."
  },
  {
    "objectID": "studies/extraction_details.html#notes_authorinitials",
    "href": "studies/extraction_details.html#notes_authorinitials",
    "title": "Extraction Details",
    "section": "NOTES_AUTHORINITIALS",
    "text": "NOTES_AUTHORINITIALS\nDecision and comments by respective author"
  },
  {
    "objectID": "studies/extraction_details.html#stimulus_type",
    "href": "studies/extraction_details.html#stimulus_type",
    "title": "Extraction Details",
    "section": "STIMULUS_TYPE",
    "text": "STIMULUS_TYPE\nMetadata pertaining to stimuli employed in paradigm. Can be listed as genres of music stimuli employed, or if stimuli come from a standard database, name of standard."
  },
  {
    "objectID": "studies/extraction_details.html#stimulus_duration",
    "href": "studies/extraction_details.html#stimulus_duration",
    "title": "Extraction Details",
    "section": "STIMULUS_DURATION",
    "text": "STIMULUS_DURATION\nDuration of stimuli, if applicable. Unit of measurement (seconds, measures) specified in STIMULUS_DURATION_UNIT"
  },
  {
    "objectID": "studies/extraction_details.html#stimulus_duration_unit",
    "href": "studies/extraction_details.html#stimulus_duration_unit",
    "title": "Extraction Details",
    "section": "STIMULUS_DURATION_UNIT",
    "text": "STIMULUS_DURATION_UNIT\nUnit of measurement pertaining to STIMULUS_DURATION. E.g., seconds, measures, etc."
  },
  {
    "objectID": "studies/extraction_details.html#stimulus_n",
    "href": "studies/extraction_details.html#stimulus_n",
    "title": "Extraction Details",
    "section": "STIMULUS_N",
    "text": "STIMULUS_N\nNumber of stimuli employed in experiment. If multiple experimental conditions reported, separate \\(n\\) by conditions where possible."
  },
  {
    "objectID": "studies/extraction_details.html#feature_n",
    "href": "studies/extraction_details.html#feature_n",
    "title": "Extraction Details",
    "section": "FEATURE_N",
    "text": "FEATURE_N\nNumber of features included in data modeling (if available)."
  },
  {
    "objectID": "studies/extraction_details.html#participant_n",
    "href": "studies/extraction_details.html#participant_n",
    "title": "Extraction Details",
    "section": "PARTICIPANT_N",
    "text": "PARTICIPANT_N\nTotal number of participants in experiment."
  },
  {
    "objectID": "studies/extraction_details.html#participant_expertise",
    "href": "studies/extraction_details.html#participant_expertise",
    "title": "Extraction Details",
    "section": "PARTICIPANT_EXPERTISE",
    "text": "PARTICIPANT_EXPERTISE\nExpertise of annotators. E.g., experts, non-experts, not specified."
  },
  {
    "objectID": "studies/extraction_details.html#participant_origin",
    "href": "studies/extraction_details.html#participant_origin",
    "title": "Extraction Details",
    "section": "PARTICIPANT_ORIGIN",
    "text": "PARTICIPANT_ORIGIN\nOrigin country of participants, or online platform participants were recruited from (e.g., MTurk)"
  },
  {
    "objectID": "studies/extraction_details.html#participant_sampling",
    "href": "studies/extraction_details.html#participant_sampling",
    "title": "Extraction Details",
    "section": "PARTICIPANT_SAMPLING",
    "text": "PARTICIPANT_SAMPLING\nHow participants were recruited (e.g., convenience, random sampling, crowdsourcing)"
  },
  {
    "objectID": "studies/extraction_details.html#participant_task",
    "href": "studies/extraction_details.html#participant_task",
    "title": "Extraction Details",
    "section": "PARTICIPANT_TASK",
    "text": "PARTICIPANT_TASK\nNature of rating/classification task undertaken by participants. E.g., rate, annotate."
  },
  {
    "objectID": "studies/extraction_details.html#feature_categories",
    "href": "studies/extraction_details.html#feature_categories",
    "title": "Extraction Details",
    "section": "FEATURE_CATEGORIES",
    "text": "FEATURE_CATEGORIES\nNames of categories analyzed features pertain to, based on names in Panda (2021). Includes names of all pertinent categories: Melody, Rhythm, Timbre, Pitch, Tonality, Expressivity, Texture, Form, Vocal, High-Level"
  },
  {
    "objectID": "studies/extraction_details.html#feature_source",
    "href": "studies/extraction_details.html#feature_source",
    "title": "Extraction Details",
    "section": "FEATURE_SOURCE",
    "text": "FEATURE_SOURCE\nName(s) of feature analysis toolbox(es)."
  },
  {
    "objectID": "studies/extraction_details.html#feature_reduction_method",
    "href": "studies/extraction_details.html#feature_reduction_method",
    "title": "Extraction Details",
    "section": "FEATURE_REDUCTION_METHOD",
    "text": "FEATURE_REDUCTION_METHOD\nName(s) of feature reduction or feature selection methods employed."
  },
  {
    "objectID": "studies/extraction_details.html#model_category",
    "href": "studies/extraction_details.html#model_category",
    "title": "Extraction Details",
    "section": "MODEL_CATEGORY",
    "text": "MODEL_CATEGORY\nName of model type (regression, classification, or both)."
  },
  {
    "objectID": "studies/extraction_details.html#model_detail",
    "href": "studies/extraction_details.html#model_detail",
    "title": "Extraction Details",
    "section": "MODEL_DETAIL",
    "text": "MODEL_DETAIL\nAdditional information pertaining to predictive model, such as the name of algorithm used and other pertinent parameters. E.g., Random Forest, Commonality Analysis, Multiple Regression, Neural Networks, LDSM."
  },
  {
    "objectID": "studies/extraction_details.html#model_measure",
    "href": "studies/extraction_details.html#model_measure",
    "title": "Extraction Details",
    "section": "MODEL_MEASURE",
    "text": "MODEL_MEASURE\nMetric used in model evaluation. E.g., \\(R^2\\), \\(MSE\\), \\(CCC\\), Classification accuracy, etc."
  },
  {
    "objectID": "studies/extraction_details.html#model_complexity_parameters",
    "href": "studies/extraction_details.html#model_complexity_parameters",
    "title": "Extraction Details",
    "section": "MODEL_COMPLEXITY_PARAMETERS",
    "text": "MODEL_COMPLEXITY_PARAMETERS\nAdditional information pertaining to predictive model. E.g., training epochs: 100; n layers: 1, 2; LSTM units: 124,248."
  },
  {
    "objectID": "studies/extraction_details.html#model_rate_emotion_names",
    "href": "studies/extraction_details.html#model_rate_emotion_names",
    "title": "Extraction Details",
    "section": "MODEL_RATE_EMOTION_NAMES",
    "text": "MODEL_RATE_EMOTION_NAMES\nNames of predicted emotions. E.g., valence, arousal, happy, sad, angry, fearful, etc."
  },
  {
    "objectID": "studies/extraction_details.html#model_rate_emotion_values",
    "href": "studies/extraction_details.html#model_rate_emotion_values",
    "title": "Extraction Details",
    "section": "MODEL_RATE_EMOTION_VALUES",
    "text": "MODEL_RATE_EMOTION_VALUES\nPertinent prediction of model summaries. Report as R named arrays, including summary statistics in variables. When reporting results of multiple models, concatenate multiple entries with bind_field. When reporting results for different toolboxes or feature subsets, assign each to a new BiBTeX field with relevant identifier following final underscore. See additional details below."
  },
  {
    "objectID": "studies/extraction_details.html#model_validation",
    "href": "studies/extraction_details.html#model_validation",
    "title": "Extraction Details",
    "section": "MODEL_VALIDATION",
    "text": "MODEL_VALIDATION\nValidation method used (if applicable). E.g., 10-fold cross validation, leave one out cross validation."
  },
  {
    "objectID": "studies/extraction_details.html#classification",
    "href": "studies/extraction_details.html#classification",
    "title": "Extraction Details",
    "section": "Classification",
    "text": "Classification\nConfusion matrices can be encoded using the unflatten function, which assigns relevant meta-parameters to the model_parameters attribute of the output matrix. The function automatically builds a \\(n\\) by \\(n\\) matrix and takes individual values as arguments. Values can be specified for the first row, and are recycled in subsequent rows.\nunflatten(A = .5, B = .2, C = .3,\n          .3, .5, .2,\n          .1, .1, .8)\nSummary parameters can be extracted from the resulting matrix by calling the summarize_matrix function. This function calls on caret to extract several summary statistics at once. Including bind_field in the call ensures consistent nomenclature with other study encodings.\nbind_field(\n  'library.model.features.data.exp' = summarize_matrix(\n    unflatten(Q1=185.85,Q2=14.4,Q3=8.6,Q4=18.15,\n              23.95,190.55,7,3.5,\n              14.2,8.4,157.25,45.15,\n              24.35,1.65,45.85,153.15)\n  )\n)\nMultiple matrices in a study can be summarized by putting them in a list and using the lapply function to extract relevant statistics:\nbind_field(\n  lapply(\n    list(\n      'library.model.features.data.exp1' = unflatten(\n        Angry=.984,Happy=.007,Relax=.007,Sad=0,\n        0,.987,0,.007,\n        .008,.007,.987,0,\n        .008,0,.007,.993\n        ),\n      'library.model.features.data.exp2' = unflatten(\n        Angry=.976,Happy=.013,Relax=.014,Sad=0,\n        .008,.967,0,.02,\n        .008,.013,.98,.007,\n        .008,.007,.007,.974\n       )\n      ),\n    summarize_matrix\n  )\n)\nWhen confusion matrices are not available, encode available parameters (accuracy, precision, recall, \\(F\\) scores, etc.) using the standard nomenclature to distinguish relevant outcomes for each class:\nbind_field(\nlibrary.model.features.data.experiment = c(class_measure.summaryStat = 0, ...),\n...\n)"
  },
  {
    "objectID": "studies/library_formatter.html#load-libraries",
    "href": "studies/library_formatter.html#load-libraries",
    "title": "Library Formatter",
    "section": "Load libraries",
    "text": "Load libraries\n\n# load dplyr\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union"
  },
  {
    "objectID": "studies/library_formatter.html#read-data",
    "href": "studies/library_formatter.html#read-data",
    "title": "Library Formatter",
    "section": "Read data",
    "text": "Read data\n\n# read in bibtex library as data frame\nbib_df_ca &lt;- bib2df::bib2df(paste0(here::here(),\n                                   \"/studies/bib/Passes/\", \n                                   \"metaMER_library_third_pass_ca.bib\")\n)\n\nSome BibTeX entries may have been dropped.\n            The result could be malformed.\n            Review the .bib file and make sure every single entry starts\n            with a '@'.\n\n\nColumn `YEAR` contains character strings.\n              No coercion to numeric applied.\n\nbib_df_te &lt;- bib2df::bib2df(paste0(here::here(),\n                                   \"/studies/bib/Passes/\", \n                                   \"metaMER_library_third_pass_te.bib\")\n)\n\nSome BibTeX entries may have been dropped.\n            The result could be malformed.\n            Review the .bib file and make sure every single entry starts\n            with a '@'.\nColumn `YEAR` contains character strings.\n              No coercion to numeric applied.\n\nbib_df_ca &lt;- dplyr::filter(bib_df_ca,PRIORITY=='prio1')\nbib_df_te &lt;- dplyr::filter(bib_df_te,PRIORITY=='prio1')\nsum(bib_df_ca$BIBTEXKEY %in% bib_df_te$BIBTEXKEY)==nrow(bib_df_ca)\n\n[1] TRUE"
  },
  {
    "objectID": "studies/library_formatter.html#identify-sources",
    "href": "studies/library_formatter.html#identify-sources",
    "title": "Library Formatter",
    "section": "Identify sources",
    "text": "Identify sources\n\n# filter open_alex entries and declare source (c1 unique to database)\nbib_df_ca %&gt;% \n  filter(!is.na(C1)) %&gt;%\n  mutate(SOURCE = 'open_alex') -&gt; oa_entries\n\n# filter wos entries and declare source (unique_id unique to database)\nbib_df_ca %&gt;% \n  filter(!is.na(UNIQUE.ID)) %&gt;%\n  mutate(SOURCE = 'web_of_science') -&gt; wos_entries\n\n# filter scopus entries\nbib_df_ca %&gt;% \n  filter(SOURCE == 'Scopus') -&gt; scopus_entries\n\nscopus_entries$JOURNAL &lt;- scopus_entries$JOURNALTITLE\nscopus_entries$JOURNALTITLE &lt;- NA\n\n# bind sources\nbib_df_ca &lt;- rbind(oa_entries, wos_entries)\nbib_df_ca &lt;- rbind(bib_df_ca, scopus_entries)"
  },
  {
    "objectID": "studies/library_formatter.html#clean-up-entries",
    "href": "studies/library_formatter.html#clean-up-entries",
    "title": "Library Formatter",
    "section": "Clean up entries",
    "text": "Clean up entries\n\n# remove columns only belonging to one database\nbib_df_ca$UNIQUE.ID &lt;- NULL\nbib_df_ca$C1 &lt;- NULL\n# remove unnecessary column\nbib_df_ca$HASABSTRACT &lt;- NULL\n# relevel priority column with intuitive names\n# bib_df_ca$PRIORITY &lt;- as.factor(bib_df_ca$PRIORITY)\n#levels(bib_df_ca$PRIORITY) &lt;- c('high_priority', 'low_priority')\n# bib_df_ca$PRIORITY &lt;- plyr::revalue(bib_df_ca$PRIORITY, \n#                                     c(prio1 = 'high_priority',\n#                                       prio3 = 'low_prioirty'))\n# make casing consistent\nbib_df_ca$SOURCE &lt;- tolower(bib_df_ca$SOURCE)\n# consistent names for private notes\nnames(bib_df_ca)[names(bib_df_ca) == 'COMMENT.CAMJA'] &lt;- 'NOTES.CA'\n# after subsetting out high-priority studies, no longer need priority column\nbib_df_ca$PRIORITY &lt;- NULL\nbib_df_ca$RANKING &lt;- NULL\nbib_df_ca$MODIFICATIONDATE &lt;- NULL"
  },
  {
    "objectID": "studies/library_formatter.html#add-comments-from-second-reviewer",
    "href": "studies/library_formatter.html#add-comments-from-second-reviewer",
    "title": "Library Formatter",
    "section": "Add comments from second reviewer",
    "text": "Add comments from second reviewer\n\n# select bibkey (for merge) and notes from second reviewer\nbib_df_te &lt;- bib_df_te %&gt;% select(BIBTEXKEY, NOTES.TE)\n\nbib_df_merged &lt;- merge(bib_df_ca, \n                       bib_df_te, \n                       by = c('BIBTEXKEY'))"
  },
  {
    "objectID": "studies/library_formatter.html#drop-empty-columns",
    "href": "studies/library_formatter.html#drop-empty-columns",
    "title": "Library Formatter",
    "section": "Drop empty columns",
    "text": "Drop empty columns\n\n# identify columns entirely empty\nempty_cols &lt;- sapply(bib_df_merged, function(x) {\n  all(is.na(x))\n  }\n) \n# remove them\nbib_df_merged &lt;- bib_df_merged[ , !empty_cols]"
  },
  {
    "objectID": "studies/library_formatter.html#rewrite-bibtex-library",
    "href": "studies/library_formatter.html#rewrite-bibtex-library",
    "title": "Library Formatter",
    "section": "Rewrite BiBTeX library",
    "text": "Rewrite BiBTeX library\n\ndim(bib_df_merged)\n\n[1] 96 37\n\nbib2df::df2bib(bib_df_merged, file = 'metaMER_library_third_pass_clean.bib')"
  },
  {
    "objectID": "studies/library_formatter.html#next",
    "href": "studies/library_formatter.html#next",
    "title": "Library Formatter",
    "section": "Next",
    "text": "Next\nCompare pass 3 annotations and resolve conflicts (pass 3 comparison.qmd)"
  },
  {
    "objectID": "studies/library_parser.html",
    "href": "studies/library_parser.html",
    "title": "Library Parser",
    "section": "",
    "text": "Status: in progress.\nTODO:\n- Separate scripts and functions into separate .qmd files/directories.\n- Update model_rate_emotion_values nomenclature process for classification papers.\n- Replace rbind with custom bind function throughout"
  },
  {
    "objectID": "studies/library_parser.html#preparing-data",
    "href": "studies/library_parser.html#preparing-data",
    "title": "Library Parser",
    "section": "Preparing data",
    "text": "Preparing data\nThe follow code extracts information from the .bib library to format it as a data.frame for further processing. The code makes use of the stringr package and uses regular expressions to extract relevant parameters. First we read in the .bib file and use some string manipulations to retrieve the citation keys.\n\nlibrary(stringr)\nlibrary(knitr, include.only = 'kable')\n\n\nbib_file &lt;- read.delim('bib/extractions.bib',\n           sep = '@', header = F)\n\n# get citekeys from bibtex file:\ncitekeys &lt;- unique(bib_file$V2)\n# improve formatting\ncitekeys &lt;- str_remove(citekeys, '\\\\{')\ncitekeys &lt;- str_remove(citekeys, ',')\ncitekeys &lt;- str_remove(citekeys, '%%.*$')\ncitekeys &lt;- str_remove(citekeys, 'Article')\ncitekeys[citekeys ==''] &lt;- NA\ncitekeys &lt;- na.omit(citekeys)\n\nR reads the .bib file as a two column data.frame, with the citation key appearing in the second column and the remaining metadata appearing in the first column. When the citation key appears in the second column, the corresponding row in the first column is blank. Because of this quirk, we can index metadata matching each citation key by keeping track of blank rows in the first column. We’ll append each to a new entry of a list. The name of each list entry is the citation key; the corresponding value is the remaining unprocessed metadata.\n\n# find where new entries begin:\nnew_entries = which(bib_file$V2 != '')\n\n# loop across unique indices for each entry\nmeta_list = list()\n# loop across unique indices for each entry\nmeta_list = list()\nfor(this_entry in 1:(length(new_entries)-1))\n{\n  # get unique citekey\n  this_cite_key &lt;- citekeys[this_entry]\n  # capture lines following citekey\n  corresponding_lines &lt;- bib_file[new_entries[this_entry]:new_entries[this_entry+1]-1,]$V1\n  # store matching lines as data frame\n  corresponding_lines &lt;- data.frame(corresponding_lines)\n  # assign lines distinct name\n  names(corresponding_lines) &lt;- this_cite_key\n  # add to a list for further processing\n  meta_list &lt;- append(meta_list, corresponding_lines)\n}"
  },
  {
    "objectID": "studies/library_parser.html#extracting-relevant-.bib-fields",
    "href": "studies/library_parser.html#extracting-relevant-.bib-fields",
    "title": "Library Parser",
    "section": "Extracting Relevant .bib Fields",
    "text": "Extracting Relevant .bib Fields\nNot every bibtex field is equally useful for analysis. To facilitate data manipulation, we can save the names of the target fields separately in a .txt file, and use a regular expression to create a new column each time R finds one of the target fields in a string containing the bibtex metadata.\n\n# read in target bibtex fields\nsearch_fields &lt;- field_names &lt;- readLines('bibtex_fields.txt')\n\n# match casing in bibtex file\nfield_names &lt;- toupper(field_names)\n# add a pattern allowing us to find text between two adjacent bibtex fields\nrep_pattern &lt;- paste0(field_names[1:length(field_names)-1], '\\\\s*(.*?)\\\\s')\n# apply this same pattern to all but the last of the field names                  \nfield_names[1:length(field_names)-1] &lt;- rep_pattern\n# collapse all the new field names into a single string for string manipulation with stringr\nfield_names[length(field_names)] &lt;- paste0(field_names[length(field_names)], '.*')\nfield_names &lt;- paste0(field_names, collapse = '')"
  },
  {
    "objectID": "studies/library_parser.html#prepare-dataframe",
    "href": "studies/library_parser.html#prepare-dataframe",
    "title": "Library Parser",
    "section": "Prepare dataframe",
    "text": "Prepare dataframe\nNow we can convert our list into a data frame with the target bibtex fields. For the last field MODEL_VALIDATION, we will apply a different regex pattern which matches all characters following the field name (?&lt;=MODEL_VALIDATION).* .\n\n# create new column containing information between two adjacent target fields for all entries in list\nmeta_df &lt;- lapply(meta_list, function(x) str_match(paste0(x, collapse = ' '), field_names))\nmeta_df &lt;- lapply(meta_list, function(x) str_match(paste0(x, collapse = ' '), field_names))\n\n# collapse list entries into rows\nmeta_df &lt;- do.call('rbind', meta_df)\n# format as a data.frame\nmeta_df &lt;- data.frame(meta_df)\n# match text after final column name\nmeta_df[,ncol(meta_df)+1] &lt;- sapply(meta_df[,1], function(x) str_match(paste0(x, collapse = ' '), '(?&lt;=FINAL_NOTES).*'))\n# replace first column with citationkeys\nmeta_df[,1] &lt;- names(meta_list)\nnames(meta_df) &lt;- c('citekey', search_fields)\nnames(meta_df) &lt;- trimws(names(meta_df))"
  },
  {
    "objectID": "studies/library_parser.html#formatting",
    "href": "studies/library_parser.html#formatting",
    "title": "Library Parser",
    "section": "Formatting",
    "text": "Formatting\nFinally, we’ll perform some formatting to remove unwanted characters left over following the conversion (in progress)\n\n## remove bibtext field formatting\n# remove curly braces\nmeta_df &lt;- apply(meta_df, 2, function(x) str_remove_all(x, '\\\\{')) \nmeta_df &lt;- apply(meta_df, 2, function(x) str_remove_all(x, '\\\\},'))\n# remove first '=' (from bibtex field )\nmeta_df &lt;- apply(meta_df, 2, function(x) str_remove(x, '='))\n# remove double-commas\n#meta_df &lt;- apply(meta_df, 2, function(x) str_remove_all(x, ',,'))\n# remove comments\nmeta_df &lt;- apply(meta_df, 2, function(x) str_remove_all(x, '%%.*'))\n#meta_df &lt;- apply(meta_df, 2, function(x) str_remove_all(x, ' , '))\n# remove extra characters in final column\nmeta_df[, ncol(meta_df)] = str_remove_all(meta_df[, ncol(meta_df)], '\\\\}')\nmeta_df &lt;- as.data.frame(meta_df)\n\nExample: Evaluate model_rate_emotion_values as R code\n\nsource(paste0(here::here(), \"/R/format-study-results.R\"))\neval(parse(text = meta_df$model_rate_emotion_values[22]))\n\n                                                          arousal_r2\nvarious.svr.mixed.classical.1                                 0.7249\nvarious.sparse bayesian regression.mixed.classical.1          0.7381\nvarious.variational bayesian regression.mixed.classical.1     0.7108\n                                                          arousal_variance explained\nvarious.svr.mixed.classical.1                                                 0.7556\nvarious.sparse bayesian regression.mixed.classical.1                          0.7395\nvarious.variational bayesian regression.mixed.classical.1                     0.7415\n                                                          valence_r2\nvarious.svr.mixed.classical.1                                 0.6119\nvarious.sparse bayesian regression.mixed.classical.1          0.6296\nvarious.variational bayesian regression.mixed.classical.1     0.6328\n                                                          valence_variance explained\nvarious.svr.mixed.classical.1                                                 0.6142\nvarious.sparse bayesian regression.mixed.classical.1                          0.6376\nvarious.variational bayesian regression.mixed.classical.1                     0.6340\n                                                          resonance_r2\nvarious.svr.mixed.classical.1                                   0.5374\nvarious.sparse bayesian regression.mixed.classical.1            0.5456\nvarious.variational bayesian regression.mixed.classical.1       0.5554\n                                                          resonance_variance explained\nvarious.svr.mixed.classical.1                                                   0.5496\nvarious.sparse bayesian regression.mixed.classical.1                            0.5558\nvarious.variational bayesian regression.mixed.classical.1                       0.5630"
  },
  {
    "objectID": "studies/library_parser.html#track-excluded-studies-during-extraction",
    "href": "studies/library_parser.html#track-excluded-studies-during-extraction",
    "title": "Library Parser",
    "section": "Track Excluded Studies (During Extraction)",
    "text": "Track Excluded Studies (During Extraction)\n\nmeta_df[which(str_detect(meta_df$final_notes, '!EXCL!')),] |&gt; dplyr::tibble()\n\n# A tibble: 9 × 28\n  citekey        paradigm notes_ca notes_te emotions emotion_locus stimulus_type\n  &lt;chr&gt;          &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;         &lt;chr&gt;        \n1 \"feng2024ex\"   \" class… \" inclu… \" inclu… \"    \"   \"    \"        \"    \"       \n2 \"nag2022on\"    \" class… \" inclu… \" inclu… \" happy… \"    \"        \"    \"       \n3 \"cao2023th\"    \" regre… \" inclu… \" inclu… \" valen… \" perceived … \" million so…\n4 \"malheiro2018… \" regre… \" inclu… \" inclu… \"    \"   \"    \"        \"    \"       \n5 \"medina2020em\" \" class… \" inclu… \" inclu… \" valen… \" perceived … \" MediaEval …\n6 \"panwar2019ar\" \" regre… \" inclu… \" inclu… \"    \"   \"    \"        \"    \"       \n7 \"vempala2024p… \" regre… \" inclu… \" inclu… \" valen… \" perceived … \" classical …\n8 \"xia2022st\"    \" regre… \" inclu… \" inclu… \"   \"    \"    \"        \"   \"        \n9 \"zhang2024ap\"  \" regre… \" inclu… \" inclu… \"    \"   \"    \"        \"    \"       \n# ℹ 21 more variables: stimulus_genre &lt;chr&gt;, stimulus_duration &lt;chr&gt;,\n#   stimulus_duration_unit &lt;chr&gt;, stimulus_n &lt;chr&gt;, feature_n &lt;chr&gt;,\n#   participant_n &lt;chr&gt;, participant_expertise &lt;chr&gt;, participant_origin &lt;chr&gt;,\n#   participant_sampling &lt;chr&gt;, participant_task &lt;chr&gt;,\n#   feature_categories &lt;chr&gt;, feature_source &lt;chr&gt;,\n#   feature_reduction_method &lt;chr&gt;, model_category &lt;chr&gt;, model_detail &lt;chr&gt;,\n#   model_measure &lt;chr&gt;, model_complexity_parameters &lt;chr&gt;, …\n\n\n\nmeta_df[-which(str_detect(meta_df$final_notes, '!EXCL!')),] -&gt; included_studies\n\nincluded_studies |&gt; dplyr::tibble()\n\n# A tibble: 37 × 28\n   citekey       paradigm notes_ca notes_te emotions emotion_locus stimulus_type\n   &lt;chr&gt;         &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;         &lt;chr&gt;        \n 1 agarwal2021an \" class… \" inclu… \" inclu… \" discr… \" perceived … \" Hindi musi…\n 2 alvarez2023ri \" class… \" inclu… \" inclu… \" discr… \" perceived … \" Spotify \"  \n 3 bai2017mu     \" class… \" inclu… \" inclu… \" valen… \" perceived … \" MediaEval …\n 4 bhuvanakumar… \" class… \" inclu… \" inclu… \" quadr… \" not specif… \" EMOPIA; po…\n 5 dufour2021us  \" class… \" inclu… \" inclu… \"  c1 (… \" perceived … \" pop, disco…\n 6 hizlisoy2021… \" class… \" inclu… \" inclu… \" valen… \" perceived … \" Turkish tr…\n 7 nguyen2017an  \" class… \" inclu… \" inclu… \" 288 e… \" perceived … \" pop  \"     \n 8 panda2020no   \" class… \" inclu… \" inclu… \" valen… \" perceived … \" AllMusic  \"\n 9 sorussa2020em \" class… \" inclu… \" inclu… \" valen… \" perceived … \" DEAM  \"    \n10 yang2021an    \" class… \" inclu… \" inclu… \" happy… \" perceived … \" MediaEval …\n# ℹ 27 more rows\n# ℹ 21 more variables: stimulus_genre &lt;chr&gt;, stimulus_duration &lt;chr&gt;,\n#   stimulus_duration_unit &lt;chr&gt;, stimulus_n &lt;chr&gt;, feature_n &lt;chr&gt;,\n#   participant_n &lt;chr&gt;, participant_expertise &lt;chr&gt;, participant_origin &lt;chr&gt;,\n#   participant_sampling &lt;chr&gt;, participant_task &lt;chr&gt;,\n#   feature_categories &lt;chr&gt;, feature_source &lt;chr&gt;,\n#   feature_reduction_method &lt;chr&gt;, model_category &lt;chr&gt;, model_detail &lt;chr&gt;, …"
  },
  {
    "objectID": "studies/library_parser.html#data-frame-expansion",
    "href": "studies/library_parser.html#data-frame-expansion",
    "title": "Library Parser",
    "section": "Data Frame Expansion",
    "text": "Data Frame Expansion\nNext we want to copy the number of rows for each of the bibtex cells requiring special nesting"
  },
  {
    "objectID": "studies/library_parser.html#sanity-check",
    "href": "studies/library_parser.html#sanity-check",
    "title": "Library Parser",
    "section": "Sanity check",
    "text": "Sanity check"
  },
  {
    "objectID": "studies/library_parser.html#print-output-of-all-studies",
    "href": "studies/library_parser.html#print-output-of-all-studies",
    "title": "Library Parser",
    "section": "Print output of all studies:",
    "text": "Print output of all studies:\n\n# low-level function to extract relevant values from named array\nmodel_result_2_df &lt;- function(x) {\n  # evaluate the expression\n  x &lt;- rlang::eval_tidy(rlang::parse_expr(x))\n  # get name of fitted models from column names\n  model_names &lt;- colnames(x)\n  # print(model_names)\n  # split across model name for summary statistic (e.g., mean, sd, etc.)\n  model_statistic &lt;- str_split(model_names, '\\\\.')\n  model_statistic &lt;- unlist(lapply(model_statistic, function(x) x[2]))\n  # get values\n  model_values &lt;- as.numeric(x)\n  # names(model_values) &lt;- 'score'\n  print(model_values)\n  # get additional attributes (feature.data.exp)\n  model_attributes &lt;- rownames(x)\n  data.frame(model_attributes)\n  # get additional model details\n  model_attributes &lt;- data.frame(do.call('rbind', str_split(model_attributes, '\\\\.')))\n  names(model_attributes) &lt;- c('library_id', 'model_id', 'feature_id', 'data_id', 'experiment_id')\n  print(names(model_attributes))\n  # split across '_' to \n  model_measures &lt;- data.frame(do.call('rbind', stringr::str_split(colnames(x), '_')))\n  print(model_measures)\n  names(model_measures) &lt;- c('dimension', 'measure')\n  model_measures_split &lt;- stringr::str_split(model_measures[,'measure'], '\\\\.')\n  model_measures[,'measure'] &lt;- unlist(lapply(model_measures_split, \n                                              function(x) x[1]))\n  return(data.frame(\n             model_attributes, \n             model_measures, \n             values = model_values,\n             statistic = model_statistic))\n}\n\n# high level function to apply model_result_2_df to multiple studies\nget_study_summaries &lt;- function(df) {\n  do.call(rbind,\n          lapply(df$model_rate_emotion_values, \n                 FUN = function(x) {\n                   study_id &lt;- unique(df$citekey[which(df$model_rate_emotion_values == x)])\n                   model_results &lt;- model_result_2_df(x)\n                   return(cbind(study_id, model_results))\n                   }\n                 )\n          )\n}"
  },
  {
    "objectID": "studies/pass3_comparison.html#load-libraries",
    "href": "studies/pass3_comparison.html#load-libraries",
    "title": "Pass 3 Comparison",
    "section": "Load libraries",
    "text": "Load libraries\n\n# load libraries\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(stringr)\nlibrary(knitr)"
  },
  {
    "objectID": "studies/pass3_comparison.html#read-data",
    "href": "studies/pass3_comparison.html#read-data",
    "title": "Pass 3 Comparison",
    "section": "Read data",
    "text": "Read data\n\n# read in bibtex library as data frame\nbib_df_merged &lt;- bib2df::bib2df('metaMER_library_third_pass_clean.bib')\n\nSome BibTeX entries may have been dropped.\n            The result could be malformed.\n            Review the .bib file and make sure every single entry starts\n            with a '@'."
  },
  {
    "objectID": "studies/pass3_comparison.html#compare",
    "href": "studies/pass3_comparison.html#compare",
    "title": "Pass 3 Comparison",
    "section": "Compare",
    "text": "Compare\n\n# check dimensions are accurate\ndim(bib_df_merged)\n\n[1] 96 47\n\n# distinguish notes with author initials\nnames(bib_df_merged)[names(bib_df_merged) == 'NOTES'] &lt;- 'NOTES.CA'\nnames(bib_df_merged)[names(bib_df_merged) == 'NOTES.1'] &lt;- 'NOTES.TE'\n\n# extract decisions less comments\ncapture_group &lt;- 'include|exclude|unsure'\n\n\n# create new index to track entries\nbib_df_merged$NOTES_INDEX.CA&lt;-NA\n\n# create new column tracking decisions\nbib_df_merged$NOTES_INDEX.CA &lt;- str_extract(tolower(bib_df_merged$NOTES.CA),\n                                         capture_group)\nbib_df_merged$NOTES_INDEX.TE &lt;- str_extract(tolower(bib_df_merged$NOTES.TE),\n                                     capture_group)\n\n# check entries are consistent\nsum(is.na(bib_df_merged$NOTES_INDEX.CA))\n\n[1] 0\n\nsum(is.na(bib_df_merged$NOTES_INDEX.TE))\n\n[1] 0"
  },
  {
    "objectID": "studies/pass3_comparison.html#report-annotation-reliabilityagreement",
    "href": "studies/pass3_comparison.html#report-annotation-reliabilityagreement",
    "title": "Pass 3 Comparison",
    "section": "Report annotation reliability/agreement",
    "text": "Report annotation reliability/agreement\n\n# compare raters' decisions with confusion matrix\nt&lt;-table(bib_df_merged$NOTES_INDEX.CA,\n         bib_df_merged$NOTES_INDEX.TE)\n\n# get agreement\nt2&lt;-round(t/sum(t),2)\nag_before &lt;- sum(diag(t2))\n\n# make table\nknitr::kable(t,  \n             caption = paste('Votes before discussion. \\n\n             Rows: CA votes; cols: TE votes, Agreement = ', ag_before)\n             )\n\nTable: Votes before discussion.\n         Rows: CA votes; cols: TE votes, Agreement =  0.73\n\n\n\n\nexclude\ninclude\nunsure\n\n\n\n\nexclude\n24\n8\n2\n\n\ninclude\n4\n45\n1\n\n\nunsure\n10\n1\n1"
  },
  {
    "objectID": "studies/pass3_comparison.html#ca-unsure",
    "href": "studies/pass3_comparison.html#ca-unsure",
    "title": "Pass 3 Comparison",
    "section": "CA: unsure",
    "text": "CA: unsure\n\n# resolve unsure ones\nIND &lt;- which(bib_df_merged$NOTES_INDEX.CA=='unsure')\nresolved_index &lt;- bib_df_merged$BIBTEXKEY[IND] # 12\n# CA updates ratings:\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'deng2024an'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'hao2022re'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'he2022al'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'huang2023th'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'priscillajoy2023mu'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'shen2024re'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'wang2021mu'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'wang2021re'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'wang2022mua'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'zhang2016rea'] &lt;- 'exclude'\n\n# both CA and TE update ratings:\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'na2022mu'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.TE[bib_df_merged$BIBTEXKEY == 'na2022mu'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'tian2023mu'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.TE[bib_df_merged$BIBTEXKEY == 'tian2023mu'] &lt;- 'exclude'\n\n# resolved &lt;-c('deng2024an' = 'exclude',\n#              'hao2022re' = 'exclude',\n#              'he2022al' = 'exclude',\n#              'huang2023th' = 'exclude',\n#              'na2022mu' = 'exclude',\n#              'priscillajoy2023mu' = 'exclude',\n#              'shen2024re' = 'exclude',\n#              'tian2023mu' = 'exclude',\n#              'wang2021mu' = 'exclude',\n#              'wang2021re' = 'exclude',\n#              'wang2022mua' = 'exclude',\n#              'zhang2016rea' = 'exclude')"
  },
  {
    "objectID": "studies/pass3_comparison.html#te-unsure-in-progress",
    "href": "studies/pass3_comparison.html#te-unsure-in-progress",
    "title": "Pass 3 Comparison",
    "section": "TE: unsure (in progress)",
    "text": "TE: unsure (in progress)\n\n# update TE decision\nbib_df_merged$NOTES_INDEX.TE[bib_df_merged$BIBTEXKEY == 'tang2023ap'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.TE[bib_df_merged$BIBTEXKEY == 'xing2015em'] &lt;- 'exclude'\n\n# update TE and CA decisions\nbib_df_merged$NOTES_INDEX.TE[bib_df_merged$BIBTEXKEY == 'wang2022mu'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'wang2022mu'] &lt;- 'exclude'"
  },
  {
    "objectID": "studies/pass3_comparison.html#summary",
    "href": "studies/pass3_comparison.html#summary",
    "title": "Pass 3 Comparison",
    "section": "Summary",
    "text": "Summary\n\n\n\n\n\n\n\n\n\nStudy\nCA\nTE\n\n\n\n\n\ntang2023ap\nuses image features\nNo relevant features, lack of stimulus detail\nExclude\n\n\nxing2015em\nincludes classification task\nNo N of musical excerpts, missing information regarding data processing\nExclude\n\n\nwang2022mu\nonly reports DET and equal error rate\nAlthough they report correlation coefficients, emotions are not valence or arousal. Do report MSE of classification task\nExclude"
  },
  {
    "objectID": "studies/pass3_comparison.html#tabulate-results-after-resolving-unsures",
    "href": "studies/pass3_comparison.html#tabulate-results-after-resolving-unsures",
    "title": "Pass 3 Comparison",
    "section": "Tabulate results after resolving unsures",
    "text": "Tabulate results after resolving unsures\n\n# compare raters' decisions with confusion matrix\nt&lt;-table(bib_df_merged$NOTES_INDEX.CA,\n         bib_df_merged$NOTES_INDEX.TE)\n\n# get agreement\nt2&lt;-round(t/sum(t),2)\nag_before &lt;- sum(diag(t2))\n\n# make table\nknitr::kable(t,  \n             caption = paste('Votes after resolving unsure discrepancies. \\n\n             Rows: CA votes; cols: TE votes, Agreement = ', ag_before)\n             )\n\nTable: Votes after resolving unsure discrepancies.\n         Rows: CA votes; cols: TE votes, Agreement =  0.88\n\n\n\n\nexclude\ninclude\n\n\n\n\nexclude\n39\n8\n\n\ninclude\n4\n45"
  },
  {
    "objectID": "studies/pass3_comparison.html#ca-exclude-te-include",
    "href": "studies/pass3_comparison.html#ca-exclude-te-include",
    "title": "Pass 3 Comparison",
    "section": "CA: exclude, TE: include",
    "text": "CA: exclude, TE: include\n\n# Resolving conflicting exclude/include annotations, part 1\nIND &lt;- which(bib_df_merged$NOTES_INDEX.CA=='exclude' & \n  bib_df_merged$NOTES_INDEX.TE=='include')\n# check discrepant entries\nresolved_exclude_index &lt;- bib_df_merged$BIBTEXKEY[IND]\nresolved_exclude_index # 8\n\n[1] \"aljanaki2017de\"          \"li2024im\"               \n[3] \"pandeya2024gl\"           \"saizclar2022pr\"         \n[5] \"sanmillancastillo2022an\" \"wang2015mo\"             \n[7] \"wang2016af\"              \"yang2023ex\"             \n\n# update TE votes to exclude\nbib_df_merged$NOTES_INDEX.TE[bib_df_merged$BIBTEXKEY == 'aljanaki2017de'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.TE[bib_df_merged$BIBTEXKEY == 'li2024im'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.TE[bib_df_merged$BIBTEXKEY == 'pandeya2024gl'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.TE[bib_df_merged$BIBTEXKEY == 'sanmillancastillo2022an'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.TE[bib_df_merged$BIBTEXKEY == 'wang2015mo'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.TE[bib_df_merged$BIBTEXKEY == 'wang2016af'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.TE[bib_df_merged$BIBTEXKEY == 'yang2023ex'] &lt;- 'exclude'\n# update CA votes to include\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'saizclar2022pr'] &lt;- 'include'\n\n\n# resolved_exclude &lt;-c('aljanaki2017de' = 'exclude',\n#                      'li2024im' = 'exclude',\n#                      'pandeya2024gl' = 'exclude',\n#                      'saizclar2022pr' = 'include',\n#                      'sanmillancastillo2022an' = 'exclude',\n#                      'wang2015mo' = 'exclude',\n#                      'wang2016af' = 'exclude',\n#                      'yang2023ex' = 'exclude')"
  },
  {
    "objectID": "studies/pass3_comparison.html#summary-1",
    "href": "studies/pass3_comparison.html#summary-1",
    "title": "Pass 3 Comparison",
    "section": "Summary",
    "text": "Summary\n\nCA: exclude, TE: include\n\n\n\n\n\n\n\n\n\nStudy\nCA\nTE\nResolution/Decision\n\n\n\n\naljanaki2017de\nMultiple teams’ performance reported\nPossible to report teams as substudies\nExclude: Benchmark, does not contain original study details from reporting team\n\n\nli2024im\nNo relevant task\nReports classification accuracy and DEAM results\nExclude: No audio features reported\n\n\npandeya2024gl\nInsufficient detail for meta-analysis\nIncludes timbre and global audio features, confusion matrix included\nExclude: Reporting on music videos; quality issues in data set\n\n\nsaizclar2022pr\nNo modeling task\nModeling is based on onsets\nInclude: although no cross-validation, still performed task\n\n\nsanmillancastillo2022an\nNo music\nTask present\nExclude: No music\n\n\nwang2015mo\nNo relevant task\nNot sure of outcome measures\nExclude: No translation of distances into VA accuracy\n\n\nwang2016af\nChapter\nIncludes relevant task\nExclude: Meets exclusion criteria (not an article)\n\n\nyang2023ex\nNo relevant task\nFinal metrics missing\nExclude: Collected VA emotion ratings, but don’t use audio features to predict VA (not reported)"
  },
  {
    "objectID": "studies/pass3_comparison.html#te-exclude-ca-include",
    "href": "studies/pass3_comparison.html#te-exclude-ca-include",
    "title": "Pass 3 Comparison",
    "section": "TE: exclude, CA: include",
    "text": "TE: exclude, CA: include\n\n# Resolving conflicting exclude/include annotations, part 2\nIND &lt;- which(bib_df_merged$NOTES_INDEX.TE=='exclude' & \n               bib_df_merged$NOTES_INDEX.CA=='include')\n\n# check discrepant entries\nresolved_exclude2_index &lt;- bib_df_merged$BIBTEXKEY[IND]\nresolved_exclude2_index # 4\n\n[1] \"cunningham2021su\" \"eyben2015em\"      \"tian2023mua\"      \"tiple2022mu\"     \n\n# update CA votes\n\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'cunningham2021su'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'eyben2015em'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'tian2023mua'] &lt;- 'exclude'\nbib_df_merged$NOTES_INDEX.CA[bib_df_merged$BIBTEXKEY == 'tiple2022mu'] &lt;- 'exclude'\n\n# resolved_exclude2 &lt;-c('cunningham2021su' = 'exclude',\n#                       'eyben2015em' = 'exclude',\n#                       'tian2023mua' = 'exclude',\n#                       'tiple2022mu' = 'exclude')"
  },
  {
    "objectID": "studies/pass3_comparison.html#summary-2",
    "href": "studies/pass3_comparison.html#summary-2",
    "title": "Pass 3 Comparison",
    "section": "Summary",
    "text": "Summary\n\n\n\n\n\n\n\n\n\nStudy\nTE\nCA\nResolution/Decision\n\n\n\n\ncunningham2021su\nReports on IADS (not music)\nRelevant task\nExclude: No music\n\n\neyben2015em\nFocused on laboratory singing\nRelevant task\nExclude: Laboratory singing of a scale\n\n\ntiple2022mu\nData set just includes annotation of tonic pitch\nRelevant task, but only reports overall accuracy\nExclude: Data set not sufficiently detailed for MER task"
  },
  {
    "objectID": "studies/pass3_comparison.html#update-table-after-resolving-disagreements",
    "href": "studies/pass3_comparison.html#update-table-after-resolving-disagreements",
    "title": "Pass 3 Comparison",
    "section": "Update table after resolving disagreements",
    "text": "Update table after resolving disagreements\n\n# compare raters' decisions with confusion matrix\nt&lt;-table(bib_df_merged$NOTES_INDEX.CA,\n         bib_df_merged$NOTES_INDEX.TE)\n\n# get agreement\nt2&lt;-round(t/sum(t),2)\nag_before &lt;- sum(diag(t2))\n\n# make table\nknitr::kable(t,  \n             caption = paste('Votes after resolving include vs. exclude discrepancies. \\n\n             Rows: CA votes; cols: TE votes, Agreement = ', ag_before)\n             )\n\nTable: Votes after resolving include vs. exclude discrepancies.\n         Rows: CA votes; cols: TE votes, Agreement =  1\n\n\n\n\nexclude\ninclude\n\n\n\n\nexclude\n50\n0\n\n\ninclude\n0\n46"
  },
  {
    "objectID": "studies/pass3_comparison.html#track-task-types",
    "href": "studies/pass3_comparison.html#track-task-types",
    "title": "Pass 3 Comparison",
    "section": "Track task types",
    "text": "Track task types\n\n# add column tracking task type\nbib_df_merged$PARADIGM &lt;- 'regression'\nbib_df_merged[str_detect(bib_df_merged$NOTES.CA, 'classification'),]$PARADIGM &lt;- 'classification'\n\n# sort by task\nbib_df_merged &lt;- bib_df_merged[order(bib_df_merged$PARADIGM),]\n\n# put rater notes side-by-side\nNOTES.CA &lt;- bib_df_merged$NOTES.CA\nNOTES.TE &lt;- bib_df_merged$NOTES.TE\nbib_df_merged$NOTES.CA &lt;- NULL\nbib_df_merged$NOTES.TE &lt;- NULL\nbib_df_merged$NOTES_CA&lt;-NOTES.CA\nbib_df_merged$NOTES_TE&lt;-NOTES.TE"
  },
  {
    "objectID": "studies/pass3_comparison.html#add-fields-for-annotation",
    "href": "studies/pass3_comparison.html#add-fields-for-annotation",
    "title": "Pass 3 Comparison",
    "section": "Add fields for annotation",
    "text": "Add fields for annotation\n\n# add new fields for annotating bibtex library\nbib_df_merged %&gt;% mutate(emotions = ' ',\n                         emotion_locus = ' ',\n                         stimulus_type = ' ',\n                         stimulus_duration = ' ',\n                         stimulus_duration_unit = ' ',\n                         stimulus_N = ' ',\n                         feature_N = ' ',\n                         participant_N = ' ',\n                         participant_expertise = ' ',\n                         participant_origin = ' ',\n                         participant_sampling = ' ',\n                         participant_task = ' ',\n                         feature_N = ' ',\n                         feature_categories = ' ',\n                         feature_source = ' ',\n                         feature_reduction_method = ' ',\n                         model_category = ' ',\n                         model_detail = ' ',\n                         model_measure = ' ',\n                         model_complexity_parameters = ' ',\n                         model_rate_emotion_names = ' ',\n                         model_rate_emotion_values = ' ',\n                         model_validation = ' ',\n                         final_decision = NOTES_INDEX.CA) -&gt; bib_df_merged"
  },
  {
    "objectID": "studies/pass3_comparison.html#export-bibtex-for-the-annotation",
    "href": "studies/pass3_comparison.html#export-bibtex-for-the-annotation",
    "title": "Pass 3 Comparison",
    "section": "Export bibtex for the annotation",
    "text": "Export bibtex for the annotation\n\nbib_df_merged$NOTES_INDEX.CA &lt;- NULL\nbib_df_merged$NOTES_INDEX.TE &lt;- NULL"
  },
  {
    "objectID": "studies/pass3_comparison.html#get-included-studies",
    "href": "studies/pass3_comparison.html#get-included-studies",
    "title": "Pass 3 Comparison",
    "section": "Get included studies",
    "text": "Get included studies\n\nbib_df_merged &lt;- subset(bib_df_merged, final_decision == 'include')\nbib_df_merged$final_decision &lt;- NULL"
  },
  {
    "objectID": "studies/pass3_comparison.html#write-resulting-bibtex-library",
    "href": "studies/pass3_comparison.html#write-resulting-bibtex-library",
    "title": "Pass 3 Comparison",
    "section": "Write resulting bibtex library",
    "text": "Write resulting bibtex library\n\nbib2df::df2bib(bib_df_merged, file = 'metaMER_library_template.bib')\n\nNotes:\nFor Feature classification, use this one:\nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9229494\nInsert the template the annotation fields from googledoc to the bibtex file."
  },
  {
    "objectID": "studies/search_syntax.html",
    "href": "studies/search_syntax.html",
    "title": "Search Syntax",
    "section": "",
    "text": "We first performed search through three databases using the following syntax for each.\n\n\n\n\n\n\n\n\n\nDatabase\nDate\nResults\nSearch syntax\n\n\n\n\nScopus\n12 May 2024\n227\nTITLE-ABS-KEY ( valence OR arousal OR classi OR categor OR algorithm AND music AND emotion AND recognition ) AND PUBYEAR &gt; 2013 AND PUBYEAR &lt; 2025 AND ( LIMIT-TO ( DOCTYPE , \"ar\" ) )\n\n\nWeb of Science\n12 May 2024\n142\n(DT=(Article) AND PY=(2014-2025)) AND ALL=(music emotion recognition valence arousal)\n\n\nOpen Alex\n12 May 2024\n278\nhttps://openalex.org/works?page=1&filter=default.search%3Amusic%20emotion%20recognition%20valence%20arousal,type%3Atypes%2Farticle, publication_year%3A2014-2024, keywords.id%3Akeywords%2Femotion-recognition, keywords.id%3Akeywords%2Faffective-computing, language%3Alanguages%2Fen,open_access.any_repository_has_fulltext%3Atrue"
  },
  {
    "objectID": "studies/search_syntax.html#second-pass-assessment-of-relevant-content",
    "href": "studies/search_syntax.html#second-pass-assessment-of-relevant-content",
    "title": "Search Syntax",
    "section": "Second pass: Assessment of relevant content",
    "text": "Second pass: Assessment of relevant content\nOut of the studies identified in the first pass, a closer look at the priority 2 studies using the criteria established [link to prereg] was carried out."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "README",
    "section": "",
    "text": "How well we can predict emotions in music? What is the evidence in the published literature for explaining what emotions the listeners can perceive in music when the source consists of audio examples. To what degree the results are dependent on the actual models, emotions, musical/acoustic features, or musical materials or participants?\nTo obtain answers to these questions, we have set out to record and analyse the current state of the art from the literature using a meta-analysis paradigm. We focus on Music Emotion Recognition and hence the acronym metaMER.\nThe public-facing version of the repository is available at https://tuomaseerola.github.io/metaMER/\n\n\nWe define the aims and methods in preregistration plan, which has beeb preregistered at https://osf.io/6y3dr/.\n\n\nSearch databases and criteria are documented in studies/search_syntax.qmd.\n\n\n\nData extraction is described in extraction details. See also pass3 comparison.\nThe data will be parsed to a tabular format using a custom library_parser.qmd.\n\n\n\nData analysis is covered in analysis/analysis.qmd document.\n\n\n\nThe study report is available manuscript/manuscript.qmd document."
  },
  {
    "objectID": "index.html#plan",
    "href": "index.html#plan",
    "title": "README",
    "section": "",
    "text": "We define the aims and methods in preregistration plan, which has beeb preregistered at https://osf.io/6y3dr/.\n\n\nSearch databases and criteria are documented in studies/search_syntax.qmd.\n\n\n\nData extraction is described in extraction details. See also pass3 comparison.\nThe data will be parsed to a tabular format using a custom library_parser.qmd.\n\n\n\nData analysis is covered in analysis/analysis.qmd document.\n\n\n\nThe study report is available manuscript/manuscript.qmd document."
  },
  {
    "objectID": "analysis/analysis.html",
    "href": "analysis/analysis.html",
    "title": "Analysis",
    "section": "",
    "text": "This assumes that the data has been parsed (parse-model-output.R, format-study-results.R) and preprocessed (processing.qmd).\n\n\n\n\nFor creating Table 2\n\nlibrary(dmetar)\nlibrary(tidyverse)\nlibrary(meta)\nlibrary(DescTools)\nlibrary(ggrepel)\n\n\n\n\nR_studies &lt;- read.csv(\"R_studies.csv\")\n#R_summary &lt;- read.csv(\"R_summary.csv\")\n\n# select regression studies with r2\n#tmp &lt;- dplyr::filter(R_summary,dimension==\"valence\")\ntmp &lt;- dplyr::filter(R_studies,dimension==\"valence\")\n#dim(tmp)\n\n#if all studies, remove two with NA values\ntmp &lt;- tmp[!is.na(tmp$values),]\n#dim(tmp)\n\n# Take all models\nm.cor &lt;- metacor(cor = values,     # values \n                 n = stimulus_n,\n                 studlab = unique_id,\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\n\nprint(m.cor)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 120\nNumber of observations: o = 73685\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.5674 [0.5297; 0.6028] 23.67 &lt; 0.0001\nPrediction interval         [0.0703; 0.8387]               \n\nQuantifying heterogeneity:\n tau^2 = 0.0831 [0.0654; 0.1127]; tau = 0.2882 [0.2557; 0.3357]\n I^2 = 97.5% [97.2%; 97.7%]; H = 6.29 [6.02; 6.58]\n\nTest of heterogeneity:\n       Q d.f. p-value\n 4711.95  119       0\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 119)\n- Prediction interval based on t-distribution (df = 118)\n- Fisher's z transformation of correlations\n\nprint(FisherZInv(m.cor$TE.random))\n\n[1] 0.5673564\n\nprint(FisherZInv(m.cor$upper.random))\n\n[1] 0.6027511\n\nprint(FisherZInv(m.cor$lower.random))\n\n[1] 0.5297333\n\n#m.cor_backtransformed &lt;- m.cor\n#m.cor_backtransformed$TE &lt;- FisherZInv(m.cor_backtransformed$TE)\n#print(funnel(m.cor_backtransformed, common = FALSE, studlab=TRUE,backtransf=TRUE))\n\n\n\n\n\n#R_studies &lt;- read.csv(\"R_studies.csv\")\nR_summary &lt;- read.csv(\"R_summary.csv\")\n\n# select regression studies with r2\ntmp &lt;- dplyr::filter(R_summary,dimension==\"valence\")\n#tmp &lt;- dplyr::filter(R_studies,dimension==\"valence\")\n#dim(tmp)\n\n#if all studies, remove two\n#tmp &lt;- tmp[!is.na(tmp$values),]\n#dim(tmp)\n\n## Disambiguate the studies\ntmp$studyREF[tmp$studyREF==\"Wang et al 2022\"] &lt;- c(\"Wang et al. 2022a\",\"Wang et al. 2022b\")\n\n# Max values\nm.cor &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = studyREF,#citekey, # unique_id\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\n\nprint(m.cor)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 24\nNumber of observations: o = 15660\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.6585 [0.5574; 0.7404] 10.14 &lt; 0.0001\nPrediction interval         [0.0042; 0.9180]               \n\nQuantifying heterogeneity:\n tau^2 = 0.1376 [0.0804; 0.2802]; tau = 0.3709 [0.2836; 0.5293]\n I^2 = 98.2% [97.9%; 98.5%]; H = 7.50 [6.86; 8.20]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1294.03   23 &lt; 0.0001\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 23)\n- Prediction interval based on t-distribution (df = 22)\n- Fisher's z transformation of correlations\n\nprint(FisherZInv(m.cor$TE.random))\n\n[1] 0.6585298\n\nprint(FisherZInv(m.cor$upper.random))\n\n[1] 0.740407\n\nprint(FisherZInv(m.cor$lower.random))\n\n[1] 0.5573953\n\n#m.cor_backtransformed &lt;- m.cor\n#m.cor_backtransformed$TE &lt;- FisherZInv(m.cor_backtransformed$TE)\n#print(funnel(m.cor_backtransformed, common = FALSE, studlab=TRUE,backtransf=TRUE))\n\n\n\n\n\n\nm.cor1 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  model_class_id,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\nprint(m.cor1)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 24\nNumber of observations: o = 15660\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.6585 [0.5574; 0.7404] 10.14 &lt; 0.0001\nPrediction interval         [0.0042; 0.9180]               \n\nQuantifying heterogeneity:\n tau^2 = 0.1376 [0.0804; 0.2802]; tau = 0.3709 [0.2836; 0.5293]\n I^2 = 98.2% [97.9%; 98.5%]; H = 7.50 [6.86; 8.20]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1294.03   23 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                                                      k    COR\nmodel_class_id = Kernel Smoothing, Additive and KNN   2 0.4662\nmodel_class_id = Random Forests                       4 0.7024\nmodel_class_id = Linear Methods                       8 0.7840\nmodel_class_id = Neural Nets                          4 0.3404\nmodel_class_id = Flexible Discriminants               6 0.6555\n                                                               95%-CI  tau^2\nmodel_class_id = Kernel Smoothing, Additive and KNN [-0.6342; 0.9424] 0.0185\nmodel_class_id = Random Forests                     [ 0.3914; 0.8694] 0.0803\nmodel_class_id = Linear Methods                     [ 0.6249; 0.8806] 0.1370\nmodel_class_id = Neural Nets                        [-0.0970; 0.6676] 0.0761\nmodel_class_id = Flexible Discriminants             [ 0.4838; 0.7786] 0.0574\n                                                       tau      Q   I^2\nmodel_class_id = Kernel Smoothing, Additive and KNN 0.1361  20.56 95.1%\nmodel_class_id = Random Forests                     0.2833 198.79 98.5%\nmodel_class_id = Linear Methods                     0.3701 195.78 96.4%\nmodel_class_id = Neural Nets                        0.2759 102.54 97.1%\nmodel_class_id = Flexible Discriminants             0.2396 161.22 96.9%\n\nTest for subgroup differences (random effects model):\n                   Q d.f. p-value\nBetween groups 18.75    4  0.0009\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 23)\n- Prediction interval based on t-distribution (df = 22)\n- Fisher's z transformation of correlations\n\nS&lt;-summarise(group_by(tmp,model_class_id),n=n(),obs=sum(stimulus_n))\nprint(S)\n\n# A tibble: 5 × 3\n  model_class_id                         n   obs\n  &lt;chr&gt;                              &lt;int&gt; &lt;int&gt;\n1 Flexible Discriminants                 6  4993\n2 Kernel Smoothing, Additive and KNN     2  2582\n3 Linear Methods                         8  1762\n4 Neural Nets                            4  2249\n5 Random Forests                         4  4074\n\n\n\n\n\n\nm.cor2 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  journal_type,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\n\n\n\n\n\ntmp&lt;-tmp[!is.na(tmp$feature_n_categories),] # remove missing values\ndim(tmp)\n\n[1] 23 13\n\nm.cor3 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  feature_n_categories,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\nprint(m.cor3)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 23\nNumber of observations: o = 14916\n\n                        COR            95%-CI    t  p-value\nRandom effects model 0.6597 [ 0.5535; 0.7448] 9.73 &lt; 0.0001\nPrediction interval         [-0.0159; 0.9218]              \n\nQuantifying heterogeneity:\n tau^2 = 0.1444 [0.0834; 0.2986]; tau = 0.3800 [0.2889; 0.5464]\n I^2 = 98.3% [98.0%; 98.6%]; H = 7.65 [6.99; 8.38]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1288.44   22 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                                                k    COR           95%-CI\nfeature_n_categories = Feature n &gt; 260          7 0.6845 [0.5660; 0.7752]\nfeature_n_categories = Feature n &lt; 18           5 0.8111 [0.5342; 0.9308]\nfeature_n_categories = Feature n &gt; 18 & &lt; 260  11 0.5477 [0.3434; 0.7025]\n                                               tau^2    tau      Q   I^2\nfeature_n_categories = Feature n &gt; 260        0.0435 0.2085 211.87 97.2%\nfeature_n_categories = Feature n &lt; 18         0.1815 0.4260 362.55 98.9%\nfeature_n_categories = Feature n &gt; 18 & &lt; 260 0.1331 0.3648 416.81 97.6%\n\nTest for subgroup differences (random effects model):\n                  Q d.f. p-value\nBetween groups 5.73    2  0.0570\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 22)\n- Prediction interval based on t-distribution (df = 21)\n- Fisher's z transformation of correlations\n\nS&lt;-summarise(group_by(tmp,feature_n_categories),n=n(),obs=sum(stimulus_n))\nprint(S)\n\n# A tibble: 3 × 3\n  feature_n_categories       n   obs\n  &lt;chr&gt;                  &lt;int&gt; &lt;int&gt;\n1 Feature n &lt; 18             5  3036\n2 Feature n &gt; 18 & &lt; 260    11  7318\n3 Feature n &gt; 260            7  4562\n\n\n\n\n\nforest(m.cor,\n       sortvar = TE,\n       prediction = FALSE, \n             print.tau2 = FALSE,\n             leftlabs = c(\"Author\", \"g\", \"SE\"),studlab = studyREF)\n\n\n\n#funnel(m.cor, common = FALSE, studlab=TRUE,backtransf=TRUE)\n\n\n\n\n\nO &lt;- find.outliers(m.cor)\n# 6 datasets identified as outliers, without them the r drops to 0.5781\ninfan &lt;- InfluenceAnalysis(m.cor)\n\n[===========================================================================] DONE \n\nprint(eggers.test(m.cor))\n\nEggers' test of the intercept \n============================= \n\n intercept        95% CI     t         p\n     4.997 -0.78 - 10.78 1.695 0.1042273\n\nEggers' test does not indicate the presence of funnel plot asymmetry. \n\n\n\n\n\n\n\n\nTo show the quality differences between core and eliminated studies.\n\ntmpdata &lt;- data.frame(SE = FisherZInv(m.cor$seTE), Zr = FisherZInv(m.cor$TE),studies=m.cor$studlab)\n#tmpdata &lt;- data.frame(SE = m.cor$seTE, Zr = m.cor$TE, studies=m.cor$studlab)\n\nestimate = m.cor$TE.common\nse = m.cor$seTE.common\nse.seq=seq(0, max(m.cor$cor), 0.001)\nll95 = estimate-(1.96*se.seq)\nul95 = estimate+(1.96*se.seq)\nll99 = estimate-(3.29*se.seq)\nul99 = estimate+(3.29*se.seq)\nmeanll95 = estimate-(1.96*se)\nmeanul95 = estimate+(1.96*se)\ndfCI = data.frame(ll95, ul95, ll99, ul99, se.seq, estimate, meanll95, meanul95)\n\nfp = ggplot(NULL) +\n  geom_point(aes(x = SE, y = Zr), color='grey50',data=tmpdata) +\n  geom_text_repel(aes(x = SE, y = Zr, label=studies), data=tmpdata,size=2.5,max.overlaps = 40)+\n  xlab('Standard Error') + ylab('Correlation')+\n  geom_line(aes(x = se.seq, y = ll95), linetype = 'dotted', data = dfCI) +\n  geom_line(aes(x = se.seq, y = ul95), linetype = 'dotted', data = dfCI) +\n  geom_hline(yintercept = estimate, linetype='solid', color='grey50',linewidth=0.2) +\n  scale_x_reverse(breaks=seq(0,0.2,0.05),limits=c(0.15,0),expand=c(0.00,0.00))+\n  scale_y_continuous(breaks=seq(0.0,1.00,0.20),limits=c(0.0,1.00),expand=c(0.00,0.00))+\n  coord_flip()+\n  theme_bw()\nprint(fp)\n\nWarning: Removed 3 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\nWarning: Removed 3 rows containing missing values or values outside the scale range\n(`geom_text_repel()`).\n\n\nWarning: Removed 771 rows containing missing values or values outside the scale range\n(`geom_line()`).\nRemoved 771 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\nadd journal_type and stimulus_genre_mixed as a grouping option\n\nm.cor_subgroups &lt;- update(m.cor, \n       subgroup = model_class_id, \n#       subgroup = journal_type, \n#       subgroup = stimulus_genre_mixed, \n       tau.common = FALSE,\n       prediction = TRUE)\n\nprint(m.cor_subgroups)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 24\nNumber of observations: o = 15660\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.6585 [0.5574; 0.7404] 10.14 &lt; 0.0001\nPrediction interval         [0.0042; 0.9180]               \n\nQuantifying heterogeneity:\n tau^2 = 0.1376 [0.0804; 0.2802]; tau = 0.3709 [0.2836; 0.5293]\n I^2 = 98.2% [97.9%; 98.5%]; H = 7.50 [6.86; 8.20]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1294.03   23 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                                                      k    COR\nmodel_class_id = Kernel Smoothing, Additive and KNN   2 0.4662\nmodel_class_id = Random Forests                       4 0.7024\nmodel_class_id = Linear Methods                       8 0.7840\nmodel_class_id = Neural Nets                          4 0.3404\nmodel_class_id = Flexible Discriminants               6 0.6555\n                                                               95%-CI  tau^2\nmodel_class_id = Kernel Smoothing, Additive and KNN [-0.6342; 0.9424] 0.0185\nmodel_class_id = Random Forests                     [ 0.3914; 0.8694] 0.0803\nmodel_class_id = Linear Methods                     [ 0.6249; 0.8806] 0.1370\nmodel_class_id = Neural Nets                        [-0.0970; 0.6676] 0.0761\nmodel_class_id = Flexible Discriminants             [ 0.4838; 0.7786] 0.0574\n                                                       tau      Q   I^2\nmodel_class_id = Kernel Smoothing, Additive and KNN 0.1361  20.56 95.1%\nmodel_class_id = Random Forests                     0.2833 198.79 98.5%\nmodel_class_id = Linear Methods                     0.3701 195.78 96.4%\nmodel_class_id = Neural Nets                        0.2759 102.54 97.1%\nmodel_class_id = Flexible Discriminants             0.2396 161.22 96.9%\n\nTest for subgroup differences (random effects model):\n                   Q d.f. p-value\nBetween groups 18.75    4  0.0009\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 23)\n- Prediction interval based on t-distribution (df = 22)\n- Fisher's z transformation of correlations\n\n#forest(m.cor_subgroups,subgroup=TRUE)\n\n\nIdea: visualise the distributions of the model successes within studies (done in preprocessing)\n\n\n\n\n\n\n# select regression studies with r2\ntmp &lt;- dplyr::filter(R_summary,dimension==\"arousal\")\n#tmp &lt;- dplyr::filter(R_studies,dimension==\"arousal\")\ndim(tmp)\n\n[1] 24 13\n\n#tmp &lt;- tmp[!is.na(tmp$values),]\ndim(tmp)\n\n[1] 24 13\n\n#tmp&lt;-drop_na(tmp)\n\nm.cor &lt;- metacor(cor = valuesMax, \n                 n = stimulus_n,\n                 studlab = citekey,\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 backtransf = TRUE,\n                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Arousal: Summary\")\n\nprint(m.cor)\n\nReview:     MER: Regression: Arousal: Summary\n\nNumber of studies: k = 24\nNumber of observations: o = 15660\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.8070 [0.7453; 0.8550] 14.83 &lt; 0.0001\nPrediction interval         [0.3466; 0.9541]               \n\nQuantifying heterogeneity:\n tau^2 = 0.1276 [0.0746; 0.2631]; tau = 0.3571 [0.2731; 0.5130]\n I^2 = 97.7% [97.2%; 98.1%]; H = 6.60 [5.99; 7.27]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1001.16   23 &lt; 0.0001\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 23)\n- Prediction interval based on t-distribution (df = 22)\n- Fisher's z transformation of correlations\n\n\n\n\n\n\nO &lt;- find.outliers(m.cor)\n\n\n\n\nforest(m.cor,\n       sortvar = TE,\n       prediction = FALSE, \n             print.tau2 = FALSE,\n             leftlabs = c(\"Author\", \"g\", \"SE\"))\n\n\n\nplot(eggers.test(m.cor))\n\n\n\n\n\n\n\n\nmeta &lt;- metagen(valuesMax, sqrt(valuesMax), \n                data = tmp, \n                studlab = tmp$citekey, \n                comb.fixed = FALSE, \n                method.tau = \"PM\")\nfind.outliers(meta)\ninfan &lt;- InfluenceAnalysis(meta)\nprint(eggers.test(meta))\n\n\n\n\n\nupdate(m.cor, \n       subgroup = model_class_id, \n       tau.common = FALSE)\n\nReview:     MER: Regression: Arousal: Summary\n\nNumber of studies: k = 24\nNumber of observations: o = 15660\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.8070 [0.7453; 0.8550] 14.83 &lt; 0.0001\nPrediction interval         [0.3466; 0.9541]               \n\nQuantifying heterogeneity:\n tau^2 = 0.1276 [0.0746; 0.2631]; tau = 0.3571 [0.2731; 0.5130]\n I^2 = 97.7% [97.2%; 98.1%]; H = 6.60 [5.99; 7.27]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1001.16   23 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                                                      k    COR           95%-CI\nmodel_class_id = Kernel Smoothing, Additive and KNN   2 0.8068 [0.5493; 0.9244]\nmodel_class_id = Random Forests                       4 0.8024 [0.7672; 0.8327]\nmodel_class_id = Linear Methods                       8 0.8812 [0.8079; 0.9277]\nmodel_class_id = Neural Nets                          4 0.5339 [0.3281; 0.6912]\nmodel_class_id = Flexible Discriminants               6 0.8077 [0.6437; 0.9008]\n                                                     tau^2    tau      Q   I^2\nmodel_class_id = Kernel Smoothing, Additive and KNN 0.0022 0.0470   3.33 70.0%\nmodel_class_id = Random Forests                     0.0012 0.0348   6.34 52.7%\nmodel_class_id = Linear Methods                     0.0846 0.2908 104.87 93.3%\nmodel_class_id = Neural Nets                        0.0190 0.1379  21.17 85.8%\nmodel_class_id = Flexible Discriminants             0.1125 0.3354 246.31 98.0%\n\nTest for subgroup differences (random effects model):\n                   Q d.f.  p-value\nBetween groups 45.86    4 &lt; 0.0001\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 23)\n- Prediction interval based on t-distribution (df = 22)\n- Fisher's z transformation of correlations\n\nm.cor_subgroups &lt;- update(m.cor, \n       subgroup = model_class_id, \n       tau.common = FALSE)\n\nforest(m.cor_subgroups,subgroup=TRUE)\n\n\n\n\n\nIdea: visualise the distributions of the model successes within studies (done in preprocessing)\n\n\ng1 &lt;- ggplot(tmp,aes(y=valuesMax,fill=model_class_id))+\n   geom_histogram(show.legend = T)+\n  facet_wrap(.~studyREF)+\n   coord_flip()+\n   theme_bw()\ng1\n\n# S &lt;- summarise(group_by(tmp,citekey),maxvalue=max(values))\n# g&lt;-ggplot(S,aes(y=maxvalue))+\n#   geom_histogram(bins = 14)+\n#   #facet_wrap(.~studyREF)+\n#   coord_flip()+\n#   theme_bw()\n# g\n\n\n\n\n\n\n\nC_studies &lt;- read.csv(\"C_studies.csv\")\nC_studies &lt;- C_studies[!is.na(C_studies$values),]\n\nC_summary &lt;- read.csv(\"C_summary.csv\")\n\nm.cor &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = studyREF, # unique_id\n                 data = C_summary,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 backtransf = TRUE,\n                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Classification: Summary\")\n\n#print(m.cor)\n\n#m.cor_backtransformed &lt;- m.cor\n#m.cor_backtransformed$TE &lt;- FisherZInv(m.cor_backtransformed$TE)\nprint(funnel(m.cor, common = FALSE, studlab=TRUE,backtransf=TRUE))\n\n\n\n\n$xlim\n[1] 0.598722 2.439471\n\n$ylim\n[1] 0.09090909 0.00000000\n\n\n\n\n\nlibrary(ggrepel)\ntmpdata &lt;- data.frame(SE = FisherZInv(m.cor$seTE), Zr = FisherZInv(m.cor$TE),studies=m.cor$studlab)\n\ntmpdata$citekey&lt;-str_replace_all(tmpdata$studies,'-.*$','')\ntmpdata$citekey&lt;-factor(tmpdata$citekey)\n\ng &lt;- ggplot(tmpdata,aes(y = SE, x = Zr,label=studies,color=citekey,fill=citekey)) +\n  geom_point(show.legend = FALSE) +\n  geom_label_repel(size=1.5,max.overlaps = 39,color=\"black\",show.legend = FALSE)+\n  ylab('Standard Error') + \n  xlab('r')+\n  scale_y_reverse()+\n#  scale_x_continuous(breaks=seq(0.0,1.0,0.25),limits=c(0,1.0))+\n#  coord_flip()+\n  theme_bw()\nprint(g)\n\n\n\n\n\n\n\n\nforest(m.cor,\n       sortvar = TE,\n       prediction = FALSE, \n             print.tau2 = FALSE,\n             leftlabs = c(\"Author\", \"g\", \"SE\"),studlab = citekey)\n\n\n\nfunnel(m.cor, common = FALSE, studlab=TRUE,backtransf=TRUE)\n\n\n\n\n\n\n\n\nO &lt;- find.outliers(m.cor)\n# 6 datasets identified as outliers, without them the r drops to 0.5781\n#infan &lt;- InfluenceAnalysis(m.cor)\n#print(eggers.test(m.cor))\n\n\n\n\n\n\n\nTo show the quality differences between core and eliminated studies (in progress).\n\ntmpdata &lt;- data.frame(SE = m.cor$seTE, Zr = m.cor$TE, studies=m.cor$studlab)\n\ntmpdata$studyREF &lt;- substr(tmpdata$studies,1,nchar(tmpdata$studies)-2)\ntmpdata$studyREF &lt;- str_replace_all(tmpdata$studyREF,'([0-9]+)',' et al \\\\1')\ntmpdata$studyREF &lt;- str_to_sentence(tmpdata$studyREF)\ntmpdata$studyREF\n\n [1] \"Agarwal et al  et al 20\"      \"Alvarez et al  et al 20\"     \n [3] \"Bai et al  et al 20\"          \"Bai et al  et al 20\"         \n [5] \"Bhuvanakumar et al  et al 20\" \"Dufour et al  et al 20\"      \n [7] \"Hizlisoy et al  et al 20\"     \"Hu et al  et al 20\"          \n [9] \"Nguyen et al  et al 20\"       \"Panda et al  et al 20\"       \n[11] \"Sorussa et al  et al 20\"      \"Yeh et al  et al 20\"         \n[13] \"Zhang et al  et al 20\"        \"Zhang et al  et al 20\"       \n\nestimate = m.cor$TE.common\nse = m.cor$seTE.common\nse.seq=seq(0, max(m.cor$cor), 0.001)\nll95 = estimate-(1.96*se.seq)\nul95 = estimate+(1.96*se.seq)\nll99 = estimate-(3.29*se.seq)\nul99 = estimate+(3.29*se.seq)\nmeanll95 = estimate-(1.96*se)\nmeanul95 = estimate+(1.96*se)\ndfCI = data.frame(ll95, ul95, ll99, ul99, se.seq, estimate, meanll95, meanul95)\n\nfp = ggplot(NULL) +\n  geom_point(aes(x = SE, y = Zr), color='grey50',data=tmpdata) +\n  geom_text_repel(aes(x = SE, y = Zr, label=studyREF), data=tmpdata,size=2.5,max.overlaps = 40)+\n  xlab('Standard Error') + ylab('Fisher\\'s z transformed correlation')+\n  geom_line(aes(x = se.seq, y = ll95), linetype = 'dotted', data = dfCI) +\n  geom_line(aes(x = se.seq, y = ul95), linetype = 'dotted', data = dfCI) +\n  geom_segment(aes(x = min(se.seq), y = meanll95, xend = max(se.seq), yend = meanll95), linetype='dotted', data=dfCI) +\n  geom_segment(aes(x = min(se.seq), y = meanul95, xend = max(se.seq), yend = meanul95), linetype='dotted', data=dfCI) +\n#  scale_x_reverse()+\n  scale_x_reverse(breaks=seq(0,0.2,0.05),limits=c(0.15,0),expand=c(0.00,0.00))+\n  scale_y_continuous(breaks=seq(0.3,1.25,0.20),limits=c(0.3,1.23))+\n  coord_flip()+\n  theme_bw()\nprint(fp)\n\nWarning: Removed 6 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\nWarning: Removed 6 rows containing missing values or values outside the scale range\n(`geom_text_repel()`).\n\n\nWarning: Removed 984 rows containing missing values or values outside the scale range\n(`geom_line()`).\nRemoved 984 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\nWarning: Removed 984 rows containing missing values or values outside the scale range\n(`geom_segment()`).\nRemoved 984 rows containing missing values or values outside the scale range\n(`geom_segment()`).\n\n\n\n\n\n\n\n\nadd journal_type and stimulus_genre_mixed as a grouping option\n\nm.cor_subgroups &lt;- update(m.cor, \n       subgroup = model_class_id, \n#       subgroup = journal_type, \n#       subgroup = stimulus_genre_mixed, \n       tau.common = FALSE,\n       prediction = TRUE)\n\nprint(m.cor_subgroups)\n#forest(m.cor_subgroups,subgroup=TRUE)\n\n\nIdea: visualise the distributions of the model successes within studies (done in preprocessing)"
  },
  {
    "objectID": "analysis/analysis.html#regression-studies",
    "href": "analysis/analysis.html#regression-studies",
    "title": "Analysis",
    "section": "",
    "text": "For creating Table 2\n\nlibrary(dmetar)\nlibrary(tidyverse)\nlibrary(meta)\nlibrary(DescTools)\nlibrary(ggrepel)\n\n\n\n\nR_studies &lt;- read.csv(\"R_studies.csv\")\n#R_summary &lt;- read.csv(\"R_summary.csv\")\n\n# select regression studies with r2\n#tmp &lt;- dplyr::filter(R_summary,dimension==\"valence\")\ntmp &lt;- dplyr::filter(R_studies,dimension==\"valence\")\n#dim(tmp)\n\n#if all studies, remove two with NA values\ntmp &lt;- tmp[!is.na(tmp$values),]\n#dim(tmp)\n\n# Take all models\nm.cor &lt;- metacor(cor = values,     # values \n                 n = stimulus_n,\n                 studlab = unique_id,\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\n\nprint(m.cor)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 120\nNumber of observations: o = 73685\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.5674 [0.5297; 0.6028] 23.67 &lt; 0.0001\nPrediction interval         [0.0703; 0.8387]               \n\nQuantifying heterogeneity:\n tau^2 = 0.0831 [0.0654; 0.1127]; tau = 0.2882 [0.2557; 0.3357]\n I^2 = 97.5% [97.2%; 97.7%]; H = 6.29 [6.02; 6.58]\n\nTest of heterogeneity:\n       Q d.f. p-value\n 4711.95  119       0\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 119)\n- Prediction interval based on t-distribution (df = 118)\n- Fisher's z transformation of correlations\n\nprint(FisherZInv(m.cor$TE.random))\n\n[1] 0.5673564\n\nprint(FisherZInv(m.cor$upper.random))\n\n[1] 0.6027511\n\nprint(FisherZInv(m.cor$lower.random))\n\n[1] 0.5297333\n\n#m.cor_backtransformed &lt;- m.cor\n#m.cor_backtransformed$TE &lt;- FisherZInv(m.cor_backtransformed$TE)\n#print(funnel(m.cor_backtransformed, common = FALSE, studlab=TRUE,backtransf=TRUE))\n\n\n\n\n\n#R_studies &lt;- read.csv(\"R_studies.csv\")\nR_summary &lt;- read.csv(\"R_summary.csv\")\n\n# select regression studies with r2\ntmp &lt;- dplyr::filter(R_summary,dimension==\"valence\")\n#tmp &lt;- dplyr::filter(R_studies,dimension==\"valence\")\n#dim(tmp)\n\n#if all studies, remove two\n#tmp &lt;- tmp[!is.na(tmp$values),]\n#dim(tmp)\n\n## Disambiguate the studies\ntmp$studyREF[tmp$studyREF==\"Wang et al 2022\"] &lt;- c(\"Wang et al. 2022a\",\"Wang et al. 2022b\")\n\n# Max values\nm.cor &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = studyREF,#citekey, # unique_id\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\n\nprint(m.cor)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 24\nNumber of observations: o = 15660\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.6585 [0.5574; 0.7404] 10.14 &lt; 0.0001\nPrediction interval         [0.0042; 0.9180]               \n\nQuantifying heterogeneity:\n tau^2 = 0.1376 [0.0804; 0.2802]; tau = 0.3709 [0.2836; 0.5293]\n I^2 = 98.2% [97.9%; 98.5%]; H = 7.50 [6.86; 8.20]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1294.03   23 &lt; 0.0001\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 23)\n- Prediction interval based on t-distribution (df = 22)\n- Fisher's z transformation of correlations\n\nprint(FisherZInv(m.cor$TE.random))\n\n[1] 0.6585298\n\nprint(FisherZInv(m.cor$upper.random))\n\n[1] 0.740407\n\nprint(FisherZInv(m.cor$lower.random))\n\n[1] 0.5573953\n\n#m.cor_backtransformed &lt;- m.cor\n#m.cor_backtransformed$TE &lt;- FisherZInv(m.cor_backtransformed$TE)\n#print(funnel(m.cor_backtransformed, common = FALSE, studlab=TRUE,backtransf=TRUE))\n\n\n\n\n\n\nm.cor1 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  model_class_id,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\nprint(m.cor1)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 24\nNumber of observations: o = 15660\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.6585 [0.5574; 0.7404] 10.14 &lt; 0.0001\nPrediction interval         [0.0042; 0.9180]               \n\nQuantifying heterogeneity:\n tau^2 = 0.1376 [0.0804; 0.2802]; tau = 0.3709 [0.2836; 0.5293]\n I^2 = 98.2% [97.9%; 98.5%]; H = 7.50 [6.86; 8.20]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1294.03   23 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                                                      k    COR\nmodel_class_id = Kernel Smoothing, Additive and KNN   2 0.4662\nmodel_class_id = Random Forests                       4 0.7024\nmodel_class_id = Linear Methods                       8 0.7840\nmodel_class_id = Neural Nets                          4 0.3404\nmodel_class_id = Flexible Discriminants               6 0.6555\n                                                               95%-CI  tau^2\nmodel_class_id = Kernel Smoothing, Additive and KNN [-0.6342; 0.9424] 0.0185\nmodel_class_id = Random Forests                     [ 0.3914; 0.8694] 0.0803\nmodel_class_id = Linear Methods                     [ 0.6249; 0.8806] 0.1370\nmodel_class_id = Neural Nets                        [-0.0970; 0.6676] 0.0761\nmodel_class_id = Flexible Discriminants             [ 0.4838; 0.7786] 0.0574\n                                                       tau      Q   I^2\nmodel_class_id = Kernel Smoothing, Additive and KNN 0.1361  20.56 95.1%\nmodel_class_id = Random Forests                     0.2833 198.79 98.5%\nmodel_class_id = Linear Methods                     0.3701 195.78 96.4%\nmodel_class_id = Neural Nets                        0.2759 102.54 97.1%\nmodel_class_id = Flexible Discriminants             0.2396 161.22 96.9%\n\nTest for subgroup differences (random effects model):\n                   Q d.f. p-value\nBetween groups 18.75    4  0.0009\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 23)\n- Prediction interval based on t-distribution (df = 22)\n- Fisher's z transformation of correlations\n\nS&lt;-summarise(group_by(tmp,model_class_id),n=n(),obs=sum(stimulus_n))\nprint(S)\n\n# A tibble: 5 × 3\n  model_class_id                         n   obs\n  &lt;chr&gt;                              &lt;int&gt; &lt;int&gt;\n1 Flexible Discriminants                 6  4993\n2 Kernel Smoothing, Additive and KNN     2  2582\n3 Linear Methods                         8  1762\n4 Neural Nets                            4  2249\n5 Random Forests                         4  4074\n\n\n\n\n\n\nm.cor2 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  journal_type,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\n\n\n\n\n\ntmp&lt;-tmp[!is.na(tmp$feature_n_categories),] # remove missing values\ndim(tmp)\n\n[1] 23 13\n\nm.cor3 &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = citekey, # unique_id\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 subgroup =  feature_n_categories,\n#                 backtransf = TRUE,\n#                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Valence: Summary\")\nprint(m.cor3)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 23\nNumber of observations: o = 14916\n\n                        COR            95%-CI    t  p-value\nRandom effects model 0.6597 [ 0.5535; 0.7448] 9.73 &lt; 0.0001\nPrediction interval         [-0.0159; 0.9218]              \n\nQuantifying heterogeneity:\n tau^2 = 0.1444 [0.0834; 0.2986]; tau = 0.3800 [0.2889; 0.5464]\n I^2 = 98.3% [98.0%; 98.6%]; H = 7.65 [6.99; 8.38]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1288.44   22 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                                                k    COR           95%-CI\nfeature_n_categories = Feature n &gt; 260          7 0.6845 [0.5660; 0.7752]\nfeature_n_categories = Feature n &lt; 18           5 0.8111 [0.5342; 0.9308]\nfeature_n_categories = Feature n &gt; 18 & &lt; 260  11 0.5477 [0.3434; 0.7025]\n                                               tau^2    tau      Q   I^2\nfeature_n_categories = Feature n &gt; 260        0.0435 0.2085 211.87 97.2%\nfeature_n_categories = Feature n &lt; 18         0.1815 0.4260 362.55 98.9%\nfeature_n_categories = Feature n &gt; 18 & &lt; 260 0.1331 0.3648 416.81 97.6%\n\nTest for subgroup differences (random effects model):\n                  Q d.f. p-value\nBetween groups 5.73    2  0.0570\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 22)\n- Prediction interval based on t-distribution (df = 21)\n- Fisher's z transformation of correlations\n\nS&lt;-summarise(group_by(tmp,feature_n_categories),n=n(),obs=sum(stimulus_n))\nprint(S)\n\n# A tibble: 3 × 3\n  feature_n_categories       n   obs\n  &lt;chr&gt;                  &lt;int&gt; &lt;int&gt;\n1 Feature n &lt; 18             5  3036\n2 Feature n &gt; 18 & &lt; 260    11  7318\n3 Feature n &gt; 260            7  4562\n\n\n\n\n\nforest(m.cor,\n       sortvar = TE,\n       prediction = FALSE, \n             print.tau2 = FALSE,\n             leftlabs = c(\"Author\", \"g\", \"SE\"),studlab = studyREF)\n\n\n\n#funnel(m.cor, common = FALSE, studlab=TRUE,backtransf=TRUE)\n\n\n\n\n\nO &lt;- find.outliers(m.cor)\n# 6 datasets identified as outliers, without them the r drops to 0.5781\ninfan &lt;- InfluenceAnalysis(m.cor)\n\n[===========================================================================] DONE \n\nprint(eggers.test(m.cor))\n\nEggers' test of the intercept \n============================= \n\n intercept        95% CI     t         p\n     4.997 -0.78 - 10.78 1.695 0.1042273\n\nEggers' test does not indicate the presence of funnel plot asymmetry. \n\n\n\n\n\n\n\n\nTo show the quality differences between core and eliminated studies.\n\ntmpdata &lt;- data.frame(SE = FisherZInv(m.cor$seTE), Zr = FisherZInv(m.cor$TE),studies=m.cor$studlab)\n#tmpdata &lt;- data.frame(SE = m.cor$seTE, Zr = m.cor$TE, studies=m.cor$studlab)\n\nestimate = m.cor$TE.common\nse = m.cor$seTE.common\nse.seq=seq(0, max(m.cor$cor), 0.001)\nll95 = estimate-(1.96*se.seq)\nul95 = estimate+(1.96*se.seq)\nll99 = estimate-(3.29*se.seq)\nul99 = estimate+(3.29*se.seq)\nmeanll95 = estimate-(1.96*se)\nmeanul95 = estimate+(1.96*se)\ndfCI = data.frame(ll95, ul95, ll99, ul99, se.seq, estimate, meanll95, meanul95)\n\nfp = ggplot(NULL) +\n  geom_point(aes(x = SE, y = Zr), color='grey50',data=tmpdata) +\n  geom_text_repel(aes(x = SE, y = Zr, label=studies), data=tmpdata,size=2.5,max.overlaps = 40)+\n  xlab('Standard Error') + ylab('Correlation')+\n  geom_line(aes(x = se.seq, y = ll95), linetype = 'dotted', data = dfCI) +\n  geom_line(aes(x = se.seq, y = ul95), linetype = 'dotted', data = dfCI) +\n  geom_hline(yintercept = estimate, linetype='solid', color='grey50',linewidth=0.2) +\n  scale_x_reverse(breaks=seq(0,0.2,0.05),limits=c(0.15,0),expand=c(0.00,0.00))+\n  scale_y_continuous(breaks=seq(0.0,1.00,0.20),limits=c(0.0,1.00),expand=c(0.00,0.00))+\n  coord_flip()+\n  theme_bw()\nprint(fp)\n\nWarning: Removed 3 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\nWarning: Removed 3 rows containing missing values or values outside the scale range\n(`geom_text_repel()`).\n\n\nWarning: Removed 771 rows containing missing values or values outside the scale range\n(`geom_line()`).\nRemoved 771 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\nadd journal_type and stimulus_genre_mixed as a grouping option\n\nm.cor_subgroups &lt;- update(m.cor, \n       subgroup = model_class_id, \n#       subgroup = journal_type, \n#       subgroup = stimulus_genre_mixed, \n       tau.common = FALSE,\n       prediction = TRUE)\n\nprint(m.cor_subgroups)\n\nReview:     MER: Regression: Valence: Summary\n\nNumber of studies: k = 24\nNumber of observations: o = 15660\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.6585 [0.5574; 0.7404] 10.14 &lt; 0.0001\nPrediction interval         [0.0042; 0.9180]               \n\nQuantifying heterogeneity:\n tau^2 = 0.1376 [0.0804; 0.2802]; tau = 0.3709 [0.2836; 0.5293]\n I^2 = 98.2% [97.9%; 98.5%]; H = 7.50 [6.86; 8.20]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1294.03   23 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                                                      k    COR\nmodel_class_id = Kernel Smoothing, Additive and KNN   2 0.4662\nmodel_class_id = Random Forests                       4 0.7024\nmodel_class_id = Linear Methods                       8 0.7840\nmodel_class_id = Neural Nets                          4 0.3404\nmodel_class_id = Flexible Discriminants               6 0.6555\n                                                               95%-CI  tau^2\nmodel_class_id = Kernel Smoothing, Additive and KNN [-0.6342; 0.9424] 0.0185\nmodel_class_id = Random Forests                     [ 0.3914; 0.8694] 0.0803\nmodel_class_id = Linear Methods                     [ 0.6249; 0.8806] 0.1370\nmodel_class_id = Neural Nets                        [-0.0970; 0.6676] 0.0761\nmodel_class_id = Flexible Discriminants             [ 0.4838; 0.7786] 0.0574\n                                                       tau      Q   I^2\nmodel_class_id = Kernel Smoothing, Additive and KNN 0.1361  20.56 95.1%\nmodel_class_id = Random Forests                     0.2833 198.79 98.5%\nmodel_class_id = Linear Methods                     0.3701 195.78 96.4%\nmodel_class_id = Neural Nets                        0.2759 102.54 97.1%\nmodel_class_id = Flexible Discriminants             0.2396 161.22 96.9%\n\nTest for subgroup differences (random effects model):\n                   Q d.f. p-value\nBetween groups 18.75    4  0.0009\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 23)\n- Prediction interval based on t-distribution (df = 22)\n- Fisher's z transformation of correlations\n\n#forest(m.cor_subgroups,subgroup=TRUE)\n\n\nIdea: visualise the distributions of the model successes within studies (done in preprocessing)\n\n\n\n\n\n\n# select regression studies with r2\ntmp &lt;- dplyr::filter(R_summary,dimension==\"arousal\")\n#tmp &lt;- dplyr::filter(R_studies,dimension==\"arousal\")\ndim(tmp)\n\n[1] 24 13\n\n#tmp &lt;- tmp[!is.na(tmp$values),]\ndim(tmp)\n\n[1] 24 13\n\n#tmp&lt;-drop_na(tmp)\n\nm.cor &lt;- metacor(cor = valuesMax, \n                 n = stimulus_n,\n                 studlab = citekey,\n                 data = tmp,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 backtransf = TRUE,\n                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Regression: Arousal: Summary\")\n\nprint(m.cor)\n\nReview:     MER: Regression: Arousal: Summary\n\nNumber of studies: k = 24\nNumber of observations: o = 15660\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.8070 [0.7453; 0.8550] 14.83 &lt; 0.0001\nPrediction interval         [0.3466; 0.9541]               \n\nQuantifying heterogeneity:\n tau^2 = 0.1276 [0.0746; 0.2631]; tau = 0.3571 [0.2731; 0.5130]\n I^2 = 97.7% [97.2%; 98.1%]; H = 6.60 [5.99; 7.27]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1001.16   23 &lt; 0.0001\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 23)\n- Prediction interval based on t-distribution (df = 22)\n- Fisher's z transformation of correlations\n\n\n\n\n\n\nO &lt;- find.outliers(m.cor)\n\n\n\n\nforest(m.cor,\n       sortvar = TE,\n       prediction = FALSE, \n             print.tau2 = FALSE,\n             leftlabs = c(\"Author\", \"g\", \"SE\"))\n\n\n\nplot(eggers.test(m.cor))\n\n\n\n\n\n\n\n\nmeta &lt;- metagen(valuesMax, sqrt(valuesMax), \n                data = tmp, \n                studlab = tmp$citekey, \n                comb.fixed = FALSE, \n                method.tau = \"PM\")\nfind.outliers(meta)\ninfan &lt;- InfluenceAnalysis(meta)\nprint(eggers.test(meta))\n\n\n\n\n\nupdate(m.cor, \n       subgroup = model_class_id, \n       tau.common = FALSE)\n\nReview:     MER: Regression: Arousal: Summary\n\nNumber of studies: k = 24\nNumber of observations: o = 15660\n\n                        COR           95%-CI     t  p-value\nRandom effects model 0.8070 [0.7453; 0.8550] 14.83 &lt; 0.0001\nPrediction interval         [0.3466; 0.9541]               \n\nQuantifying heterogeneity:\n tau^2 = 0.1276 [0.0746; 0.2631]; tau = 0.3571 [0.2731; 0.5130]\n I^2 = 97.7% [97.2%; 98.1%]; H = 6.60 [5.99; 7.27]\n\nTest of heterogeneity:\n       Q d.f.  p-value\n 1001.16   23 &lt; 0.0001\n\nResults for subgroups (random effects model):\n                                                      k    COR           95%-CI\nmodel_class_id = Kernel Smoothing, Additive and KNN   2 0.8068 [0.5493; 0.9244]\nmodel_class_id = Random Forests                       4 0.8024 [0.7672; 0.8327]\nmodel_class_id = Linear Methods                       8 0.8812 [0.8079; 0.9277]\nmodel_class_id = Neural Nets                          4 0.5339 [0.3281; 0.6912]\nmodel_class_id = Flexible Discriminants               6 0.8077 [0.6437; 0.9008]\n                                                     tau^2    tau      Q   I^2\nmodel_class_id = Kernel Smoothing, Additive and KNN 0.0022 0.0470   3.33 70.0%\nmodel_class_id = Random Forests                     0.0012 0.0348   6.34 52.7%\nmodel_class_id = Linear Methods                     0.0846 0.2908 104.87 93.3%\nmodel_class_id = Neural Nets                        0.0190 0.1379  21.17 85.8%\nmodel_class_id = Flexible Discriminants             0.1125 0.3354 246.31 98.0%\n\nTest for subgroup differences (random effects model):\n                   Q d.f.  p-value\nBetween groups 45.86    4 &lt; 0.0001\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 23)\n- Prediction interval based on t-distribution (df = 22)\n- Fisher's z transformation of correlations\n\nm.cor_subgroups &lt;- update(m.cor, \n       subgroup = model_class_id, \n       tau.common = FALSE)\n\nforest(m.cor_subgroups,subgroup=TRUE)\n\n\n\n\n\nIdea: visualise the distributions of the model successes within studies (done in preprocessing)\n\n\ng1 &lt;- ggplot(tmp,aes(y=valuesMax,fill=model_class_id))+\n   geom_histogram(show.legend = T)+\n  facet_wrap(.~studyREF)+\n   coord_flip()+\n   theme_bw()\ng1\n\n# S &lt;- summarise(group_by(tmp,citekey),maxvalue=max(values))\n# g&lt;-ggplot(S,aes(y=maxvalue))+\n#   geom_histogram(bins = 14)+\n#   #facet_wrap(.~studyREF)+\n#   coord_flip()+\n#   theme_bw()\n# g"
  },
  {
    "objectID": "analysis/analysis.html#classification-studies",
    "href": "analysis/analysis.html#classification-studies",
    "title": "Analysis",
    "section": "",
    "text": "C_studies &lt;- read.csv(\"C_studies.csv\")\nC_studies &lt;- C_studies[!is.na(C_studies$values),]\n\nC_summary &lt;- read.csv(\"C_summary.csv\")\n\nm.cor &lt;- metacor(cor = valuesMax,     # values \n                 n = stimulus_n,\n                 studlab = studyREF, # unique_id\n                 data = C_summary,\n                 fixed = FALSE,\n                 random = TRUE,\n                 prediction = TRUE,\n                 backtransf = TRUE,\n                 sm = \"ZCOR\",\n                 method.tau = \"REML\",# could be PM (Paule-Mandel) as well\n                 method.random.ci = \"HK\", \n                 title = \"MER: Classification: Summary\")\n\n#print(m.cor)\n\n#m.cor_backtransformed &lt;- m.cor\n#m.cor_backtransformed$TE &lt;- FisherZInv(m.cor_backtransformed$TE)\nprint(funnel(m.cor, common = FALSE, studlab=TRUE,backtransf=TRUE))\n\n\n\n\n$xlim\n[1] 0.598722 2.439471\n\n$ylim\n[1] 0.09090909 0.00000000\n\n\n\n\n\nlibrary(ggrepel)\ntmpdata &lt;- data.frame(SE = FisherZInv(m.cor$seTE), Zr = FisherZInv(m.cor$TE),studies=m.cor$studlab)\n\ntmpdata$citekey&lt;-str_replace_all(tmpdata$studies,'-.*$','')\ntmpdata$citekey&lt;-factor(tmpdata$citekey)\n\ng &lt;- ggplot(tmpdata,aes(y = SE, x = Zr,label=studies,color=citekey,fill=citekey)) +\n  geom_point(show.legend = FALSE) +\n  geom_label_repel(size=1.5,max.overlaps = 39,color=\"black\",show.legend = FALSE)+\n  ylab('Standard Error') + \n  xlab('r')+\n  scale_y_reverse()+\n#  scale_x_continuous(breaks=seq(0.0,1.0,0.25),limits=c(0,1.0))+\n#  coord_flip()+\n  theme_bw()\nprint(g)\n\n\n\n\n\n\n\n\nforest(m.cor,\n       sortvar = TE,\n       prediction = FALSE, \n             print.tau2 = FALSE,\n             leftlabs = c(\"Author\", \"g\", \"SE\"),studlab = citekey)\n\n\n\nfunnel(m.cor, common = FALSE, studlab=TRUE,backtransf=TRUE)\n\n\n\n\n\n\n\n\nO &lt;- find.outliers(m.cor)\n# 6 datasets identified as outliers, without them the r drops to 0.5781\n#infan &lt;- InfluenceAnalysis(m.cor)\n#print(eggers.test(m.cor))\n\n\n\n\n\n\n\nTo show the quality differences between core and eliminated studies (in progress).\n\ntmpdata &lt;- data.frame(SE = m.cor$seTE, Zr = m.cor$TE, studies=m.cor$studlab)\n\ntmpdata$studyREF &lt;- substr(tmpdata$studies,1,nchar(tmpdata$studies)-2)\ntmpdata$studyREF &lt;- str_replace_all(tmpdata$studyREF,'([0-9]+)',' et al \\\\1')\ntmpdata$studyREF &lt;- str_to_sentence(tmpdata$studyREF)\ntmpdata$studyREF\n\n [1] \"Agarwal et al  et al 20\"      \"Alvarez et al  et al 20\"     \n [3] \"Bai et al  et al 20\"          \"Bai et al  et al 20\"         \n [5] \"Bhuvanakumar et al  et al 20\" \"Dufour et al  et al 20\"      \n [7] \"Hizlisoy et al  et al 20\"     \"Hu et al  et al 20\"          \n [9] \"Nguyen et al  et al 20\"       \"Panda et al  et al 20\"       \n[11] \"Sorussa et al  et al 20\"      \"Yeh et al  et al 20\"         \n[13] \"Zhang et al  et al 20\"        \"Zhang et al  et al 20\"       \n\nestimate = m.cor$TE.common\nse = m.cor$seTE.common\nse.seq=seq(0, max(m.cor$cor), 0.001)\nll95 = estimate-(1.96*se.seq)\nul95 = estimate+(1.96*se.seq)\nll99 = estimate-(3.29*se.seq)\nul99 = estimate+(3.29*se.seq)\nmeanll95 = estimate-(1.96*se)\nmeanul95 = estimate+(1.96*se)\ndfCI = data.frame(ll95, ul95, ll99, ul99, se.seq, estimate, meanll95, meanul95)\n\nfp = ggplot(NULL) +\n  geom_point(aes(x = SE, y = Zr), color='grey50',data=tmpdata) +\n  geom_text_repel(aes(x = SE, y = Zr, label=studyREF), data=tmpdata,size=2.5,max.overlaps = 40)+\n  xlab('Standard Error') + ylab('Fisher\\'s z transformed correlation')+\n  geom_line(aes(x = se.seq, y = ll95), linetype = 'dotted', data = dfCI) +\n  geom_line(aes(x = se.seq, y = ul95), linetype = 'dotted', data = dfCI) +\n  geom_segment(aes(x = min(se.seq), y = meanll95, xend = max(se.seq), yend = meanll95), linetype='dotted', data=dfCI) +\n  geom_segment(aes(x = min(se.seq), y = meanul95, xend = max(se.seq), yend = meanul95), linetype='dotted', data=dfCI) +\n#  scale_x_reverse()+\n  scale_x_reverse(breaks=seq(0,0.2,0.05),limits=c(0.15,0),expand=c(0.00,0.00))+\n  scale_y_continuous(breaks=seq(0.3,1.25,0.20),limits=c(0.3,1.23))+\n  coord_flip()+\n  theme_bw()\nprint(fp)\n\nWarning: Removed 6 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\nWarning: Removed 6 rows containing missing values or values outside the scale range\n(`geom_text_repel()`).\n\n\nWarning: Removed 984 rows containing missing values or values outside the scale range\n(`geom_line()`).\nRemoved 984 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\nWarning: Removed 984 rows containing missing values or values outside the scale range\n(`geom_segment()`).\nRemoved 984 rows containing missing values or values outside the scale range\n(`geom_segment()`).\n\n\n\n\n\n\n\n\nadd journal_type and stimulus_genre_mixed as a grouping option\n\nm.cor_subgroups &lt;- update(m.cor, \n       subgroup = model_class_id, \n#       subgroup = journal_type, \n#       subgroup = stimulus_genre_mixed, \n       tau.common = FALSE,\n       prediction = TRUE)\n\nprint(m.cor_subgroups)\n#forest(m.cor_subgroups,subgroup=TRUE)\n\n\nIdea: visualise the distributions of the model successes within studies (done in preprocessing)"
  }
]